{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.데이터 전처리 및 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dldkr\\AppData\\Local\\Temp\\ipykernel_27268\\2941201424.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.calibration import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../csv/train.csv')\n",
    "test = pd.read_csv('../csv/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>24.443011</td>\n",
       "      <td>1.699998</td>\n",
       "      <td>81.669950</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.983297</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.763573</td>\n",
       "      <td>no</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.976473</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.711460</td>\n",
       "      <td>50.165754</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.880534</td>\n",
       "      <td>1.411685</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.910378</td>\n",
       "      <td>no</td>\n",
       "      <td>0.866045</td>\n",
       "      <td>1.673584</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Insufficient_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>20.952737</td>\n",
       "      <td>1.710730</td>\n",
       "      <td>131.274851</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.674061</td>\n",
       "      <td>no</td>\n",
       "      <td>1.467863</td>\n",
       "      <td>0.780199</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>31.641081</td>\n",
       "      <td>1.914186</td>\n",
       "      <td>93.798055</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.679664</td>\n",
       "      <td>1.971472</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.979848</td>\n",
       "      <td>no</td>\n",
       "      <td>1.967973</td>\n",
       "      <td>0.931721</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34593</th>\n",
       "      <td>34593</td>\n",
       "      <td>Male</td>\n",
       "      <td>23.327836</td>\n",
       "      <td>1.721384</td>\n",
       "      <td>78.030383</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.813234</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>0.807076</td>\n",
       "      <td>0.778632</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34594</th>\n",
       "      <td>34594</td>\n",
       "      <td>Female</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.590000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34595</th>\n",
       "      <td>34595</td>\n",
       "      <td>Female</td>\n",
       "      <td>22.935612</td>\n",
       "      <td>1.585547</td>\n",
       "      <td>44.376637</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.273740</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>1.949840</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34596</th>\n",
       "      <td>34596</td>\n",
       "      <td>Male</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.620000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34597</th>\n",
       "      <td>34597</td>\n",
       "      <td>Male</td>\n",
       "      <td>26.490926</td>\n",
       "      <td>1.812259</td>\n",
       "      <td>120.980508</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.744994</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.205977</td>\n",
       "      <td>no</td>\n",
       "      <td>1.304291</td>\n",
       "      <td>0.630866</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34598 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  Gender        Age    Height      Weight  \\\n",
       "0          0    Male  24.443011  1.699998   81.669950   \n",
       "1          1  Female  18.000000  1.560000   57.000000   \n",
       "2          2  Female  18.000000  1.711460   50.165754   \n",
       "3          3  Female  20.952737  1.710730  131.274851   \n",
       "4          4    Male  31.641081  1.914186   93.798055   \n",
       "...      ...     ...        ...       ...         ...   \n",
       "34593  34593    Male  23.327836  1.721384   78.030383   \n",
       "34594  34594  Female  29.000000  1.590000   62.000000   \n",
       "34595  34595  Female  22.935612  1.585547   44.376637   \n",
       "34596  34596    Male  21.000000  1.620000   53.000000   \n",
       "34597  34597    Male  26.490926  1.812259  120.980508   \n",
       "\n",
       "      family_history_with_overweight FAVC      FCVC       NCP        CAEC  \\\n",
       "0                                yes  yes  2.000000  2.983297   Sometimes   \n",
       "1                                yes  yes  2.000000  3.000000  Frequently   \n",
       "2                                yes  yes  1.880534  1.411685   Sometimes   \n",
       "3                                yes  yes  3.000000  3.000000   Sometimes   \n",
       "4                                yes  yes  2.679664  1.971472   Sometimes   \n",
       "...                              ...  ...       ...       ...         ...   \n",
       "34593                            yes   no  2.813234  3.000000   Sometimes   \n",
       "34594                             no  yes  3.000000  3.000000   Sometimes   \n",
       "34595                             no  yes  3.000000  2.273740  Frequently   \n",
       "34596                            yes  yes  2.000000  3.000000   Sometimes   \n",
       "34597                            yes  yes  2.744994  3.000000   Sometimes   \n",
       "\n",
       "      SMOKE      CH2O SCC       FAF       TUE       CALC  \\\n",
       "0        no  2.763573  no  0.000000  0.976473  Sometimes   \n",
       "1        no  2.000000  no  1.000000  1.000000         no   \n",
       "2        no  1.910378  no  0.866045  1.673584         no   \n",
       "3        no  1.674061  no  1.467863  0.780199  Sometimes   \n",
       "4        no  1.979848  no  1.967973  0.931721  Sometimes   \n",
       "...     ...       ...  ..       ...       ...        ...   \n",
       "34593    no  1.000000  no  0.807076  0.778632  Sometimes   \n",
       "34594    no  2.000000  no  0.000000  0.000000  Sometimes   \n",
       "34595    no  2.000000  no  1.949840  1.000000  Sometimes   \n",
       "34596    no  2.000000  no  3.000000  2.000000         no   \n",
       "34597    no  2.205977  no  1.304291  0.630866  Sometimes   \n",
       "\n",
       "                      MTRANS           NObeyesdad  \n",
       "0      Public_Transportation  Overweight_Level_II  \n",
       "1                 Automobile        Normal_Weight  \n",
       "2      Public_Transportation  Insufficient_Weight  \n",
       "3      Public_Transportation     Obesity_Type_III  \n",
       "4      Public_Transportation  Overweight_Level_II  \n",
       "...                      ...                  ...  \n",
       "34593  Public_Transportation                  NaN  \n",
       "34594  Public_Transportation                  NaN  \n",
       "34595  Public_Transportation                  NaN  \n",
       "34596  Public_Transportation                  NaN  \n",
       "34597  Public_Transportation                  NaN  \n",
       "\n",
       "[34598 rows x 18 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전처리 전, 하나의 데이터프레임으로 합치기\n",
    "all_df = pd.concat([train,test],sort=False).reset_index(drop=True)\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>24.443011</td>\n",
       "      <td>1.699998</td>\n",
       "      <td>81.669950</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.983297</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.763573</td>\n",
       "      <td>no</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.976473</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>Automobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.711460</td>\n",
       "      <td>50.165754</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.880534</td>\n",
       "      <td>1.411685</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.910378</td>\n",
       "      <td>no</td>\n",
       "      <td>0.866045</td>\n",
       "      <td>1.673584</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>20.952737</td>\n",
       "      <td>1.710730</td>\n",
       "      <td>131.274851</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.674061</td>\n",
       "      <td>no</td>\n",
       "      <td>1.467863</td>\n",
       "      <td>0.780199</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>31.641081</td>\n",
       "      <td>1.914186</td>\n",
       "      <td>93.798055</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.679664</td>\n",
       "      <td>1.971472</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.979848</td>\n",
       "      <td>no</td>\n",
       "      <td>1.967973</td>\n",
       "      <td>0.931721</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34593</th>\n",
       "      <td>Male</td>\n",
       "      <td>23.327836</td>\n",
       "      <td>1.721384</td>\n",
       "      <td>78.030383</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.813234</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>0.807076</td>\n",
       "      <td>0.778632</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34594</th>\n",
       "      <td>Female</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.590000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34595</th>\n",
       "      <td>Female</td>\n",
       "      <td>22.935612</td>\n",
       "      <td>1.585547</td>\n",
       "      <td>44.376637</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.273740</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>1.949840</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34596</th>\n",
       "      <td>Male</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.620000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34597</th>\n",
       "      <td>Male</td>\n",
       "      <td>26.490926</td>\n",
       "      <td>1.812259</td>\n",
       "      <td>120.980508</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.744994</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.205977</td>\n",
       "      <td>no</td>\n",
       "      <td>1.304291</td>\n",
       "      <td>0.630866</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34598 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Gender        Age    Height      Weight family_history_with_overweight  \\\n",
       "0        Male  24.443011  1.699998   81.669950                            yes   \n",
       "1      Female  18.000000  1.560000   57.000000                            yes   \n",
       "2      Female  18.000000  1.711460   50.165754                            yes   \n",
       "3      Female  20.952737  1.710730  131.274851                            yes   \n",
       "4        Male  31.641081  1.914186   93.798055                            yes   \n",
       "...       ...        ...       ...         ...                            ...   \n",
       "34593    Male  23.327836  1.721384   78.030383                            yes   \n",
       "34594  Female  29.000000  1.590000   62.000000                             no   \n",
       "34595  Female  22.935612  1.585547   44.376637                             no   \n",
       "34596    Male  21.000000  1.620000   53.000000                            yes   \n",
       "34597    Male  26.490926  1.812259  120.980508                            yes   \n",
       "\n",
       "      FAVC      FCVC       NCP        CAEC SMOKE      CH2O SCC       FAF  \\\n",
       "0      yes  2.000000  2.983297   Sometimes    no  2.763573  no  0.000000   \n",
       "1      yes  2.000000  3.000000  Frequently    no  2.000000  no  1.000000   \n",
       "2      yes  1.880534  1.411685   Sometimes    no  1.910378  no  0.866045   \n",
       "3      yes  3.000000  3.000000   Sometimes    no  1.674061  no  1.467863   \n",
       "4      yes  2.679664  1.971472   Sometimes    no  1.979848  no  1.967973   \n",
       "...    ...       ...       ...         ...   ...       ...  ..       ...   \n",
       "34593   no  2.813234  3.000000   Sometimes    no  1.000000  no  0.807076   \n",
       "34594  yes  3.000000  3.000000   Sometimes    no  2.000000  no  0.000000   \n",
       "34595  yes  3.000000  2.273740  Frequently    no  2.000000  no  1.949840   \n",
       "34596  yes  2.000000  3.000000   Sometimes    no  2.000000  no  3.000000   \n",
       "34597  yes  2.744994  3.000000   Sometimes    no  2.205977  no  1.304291   \n",
       "\n",
       "            TUE       CALC                 MTRANS  \n",
       "0      0.976473  Sometimes  Public_Transportation  \n",
       "1      1.000000         no             Automobile  \n",
       "2      1.673584         no  Public_Transportation  \n",
       "3      0.780199  Sometimes  Public_Transportation  \n",
       "4      0.931721  Sometimes  Public_Transportation  \n",
       "...         ...        ...                    ...  \n",
       "34593  0.778632  Sometimes  Public_Transportation  \n",
       "34594  0.000000  Sometimes  Public_Transportation  \n",
       "34595  1.000000  Sometimes  Public_Transportation  \n",
       "34596  2.000000         no  Public_Transportation  \n",
       "34597  0.630866  Sometimes  Public_Transportation  \n",
       "\n",
       "[34598 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# id와 목적변수 제거\n",
    "all_df = all_df.drop(columns=['id','NObeyesdad'],axis=1)\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34598 entries, 0 to 34597\n",
      "Data columns (total 16 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Gender                          34598 non-null  object \n",
      " 1   Age                             34598 non-null  float64\n",
      " 2   Height                          34598 non-null  float64\n",
      " 3   Weight                          34598 non-null  float64\n",
      " 4   family_history_with_overweight  34598 non-null  object \n",
      " 5   FAVC                            34598 non-null  object \n",
      " 6   FCVC                            34598 non-null  float64\n",
      " 7   NCP                             34598 non-null  float64\n",
      " 8   CAEC                            34598 non-null  object \n",
      " 9   SMOKE                           34598 non-null  object \n",
      " 10  CH2O                            34598 non-null  float64\n",
      " 11  SCC                             34598 non-null  object \n",
      " 12  FAF                             34598 non-null  float64\n",
      " 13  TUE                             34598 non-null  float64\n",
      " 14  CALC                            34598 non-null  object \n",
      " 15  MTRANS                          34598 non-null  object \n",
      "dtypes: float64(8), object(8)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "all_df.info()\n",
    "# null값 없음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>34598.0</td>\n",
       "      <td>23.886181</td>\n",
       "      <td>5.733207</td>\n",
       "      <td>14.00</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>22.851747</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>61.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Height</th>\n",
       "      <td>34598.0</td>\n",
       "      <td>1.699721</td>\n",
       "      <td>0.087895</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.631856</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>1.761773</td>\n",
       "      <td>1.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weight</th>\n",
       "      <td>34598.0</td>\n",
       "      <td>87.686451</td>\n",
       "      <td>26.273493</td>\n",
       "      <td>39.00</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>111.539494</td>\n",
       "      <td>165.057269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FCVC</th>\n",
       "      <td>34598.0</td>\n",
       "      <td>2.444704</td>\n",
       "      <td>0.532568</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.392179</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCP</th>\n",
       "      <td>34598.0</td>\n",
       "      <td>2.757043</td>\n",
       "      <td>0.707610</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CH2O</th>\n",
       "      <td>34598.0</td>\n",
       "      <td>2.030469</td>\n",
       "      <td>0.609566</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.784710</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.550570</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAF</th>\n",
       "      <td>34598.0</td>\n",
       "      <td>0.978861</td>\n",
       "      <td>0.839122</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.006892</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.583832</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TUE</th>\n",
       "      <td>34598.0</td>\n",
       "      <td>0.614467</td>\n",
       "      <td>0.604475</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555591</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count       mean        std    min        25%        50%  \\\n",
       "Age     34598.0  23.886181   5.733207  14.00  20.000000  22.851747   \n",
       "Height  34598.0   1.699721   0.087895   1.45   1.631856   1.700000   \n",
       "Weight  34598.0  87.686451  26.273493  39.00  66.000000  84.000000   \n",
       "FCVC    34598.0   2.444704   0.532568   1.00   2.000000   2.392179   \n",
       "NCP     34598.0   2.757043   0.707610   1.00   3.000000   3.000000   \n",
       "CH2O    34598.0   2.030469   0.609566   1.00   1.784710   2.000000   \n",
       "FAF     34598.0   0.978861   0.839122   0.00   0.006892   1.000000   \n",
       "TUE     34598.0   0.614467   0.604475   0.00   0.000000   0.555591   \n",
       "\n",
       "               75%         max  \n",
       "Age      26.000000   61.000000  \n",
       "Height    1.761773    1.980000  \n",
       "Weight  111.539494  165.057269  \n",
       "FCVC      3.000000    3.000000  \n",
       "NCP       3.000000    4.000000  \n",
       "CH2O      2.550570    3.000000  \n",
       "FAF       1.583832    3.000000  \n",
       "TUE       1.000000    2.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 수치형 변수 요약\n",
    "all_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>34598</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>17387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <td>34598</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>28398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAVC</th>\n",
       "      <td>34598</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>31565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAEC</th>\n",
       "      <td>34598</td>\n",
       "      <td>4</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>29218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOKE</th>\n",
       "      <td>34598</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>34173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCC</th>\n",
       "      <td>34598</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>33447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CALC</th>\n",
       "      <td>34598</td>\n",
       "      <td>4</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>25045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MTRANS</th>\n",
       "      <td>34598</td>\n",
       "      <td>5</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>27798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                count unique                    top   freq\n",
       "Gender                          34598      2                 Female  17387\n",
       "family_history_with_overweight  34598      2                    yes  28398\n",
       "FAVC                            34598      2                    yes  31565\n",
       "CAEC                            34598      4              Sometimes  29218\n",
       "SMOKE                           34598      2                     no  34173\n",
       "SCC                             34598      2                     no  33447\n",
       "CALC                            34598      4              Sometimes  25045\n",
       "MTRANS                          34598      5  Public_Transportation  27798"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 범주형 변수 요약\n",
    "all_df.describe(include='object').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 수치형 변수_시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dldkr\\AppData\\Local\\Temp\\ipykernel_27268\\167327582.py:24: UserWarning: Glyph 48712 (\\N{HANGUL SYLLABLE BIN}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\dldkr\\AppData\\Local\\Temp\\ipykernel_27268\\167327582.py:24: UserWarning: Glyph 46020 (\\N{HANGUL SYLLABLE DO}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\dldkr\\AppData\\Local\\Temp\\ipykernel_27268\\167327582.py:24: UserWarning: Glyph 51032 (\\N{HANGUL SYLLABLE YI}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\dldkr\\AppData\\Local\\Temp\\ipykernel_27268\\167327582.py:24: UserWarning: Glyph 48516 (\\N{HANGUL SYLLABLE BUN}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\dldkr\\AppData\\Local\\Temp\\ipykernel_27268\\167327582.py:24: UserWarning: Glyph 54252 (\\N{HANGUL SYLLABLE PO}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "c:\\Users\\dldkr\\anaconda3\\envs\\envFirstMini\\lib\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 48712 (\\N{HANGUL SYLLABLE BIN}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\dldkr\\anaconda3\\envs\\envFirstMini\\lib\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 46020 (\\N{HANGUL SYLLABLE DO}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\dldkr\\anaconda3\\envs\\envFirstMini\\lib\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 51032 (\\N{HANGUL SYLLABLE YI}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\dldkr\\anaconda3\\envs\\envFirstMini\\lib\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 48516 (\\N{HANGUL SYLLABLE BUN}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\dldkr\\anaconda3\\envs\\envFirstMini\\lib\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 54252 (\\N{HANGUL SYLLABLE PO}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 분포 시각화\n",
    "\n",
    "# 수치형 변수 열 선택\n",
    "numeric_columns = all_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# 다중 플롯 설정\n",
    "num_plots = len(numeric_columns) # 수치형의 len 값 : 8\n",
    "num_cols = 3  # col = 3\n",
    "num_rows = -(-num_plots // num_cols)  # -(-8 // 3) -> row = 3\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 5*num_rows))\n",
    "\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "# 각 수치형 변수에 대해 시각화 수행\n",
    "for i, column in enumerate(numeric_columns):\n",
    "    row = i // num_cols # //  두 수를 나누고 정수만 반환 ex) 0 // 3 = 0 , 1 // 3 = 0 , 2 // 3 = 0\n",
    "    col = i % num_cols # % 나머지 반환 ex) 0 % 3 = 0 , 1 % 3 = 1 , 2 % 3 = 2 , 3 % 3 = 1\n",
    "    \n",
    "    sns.histplot(all_df[column], kde=True, ax=axes[row, col])  \n",
    "    axes[row, col].set_title(f'{column}의 분포')\n",
    "    axes[row, col].set_xlabel(column)\n",
    "    axes[row, col].set_ylabel('빈도')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 상관성 시각화\n",
    "\n",
    "import seaborn as sns\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "corr_numerical = all_df[numeric_columns].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(corr_numerical, annot=True, cmap=\"OrRd\", fmt='.3f', cbar=True, vmin=-1, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "범주형 변수_시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dldkr\\AppData\\Local\\Temp\\ipykernel_27268\\1047191307.py:24: UserWarning: Glyph 48712 (\\N{HANGUL SYLLABLE BIN}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\dldkr\\AppData\\Local\\Temp\\ipykernel_27268\\1047191307.py:24: UserWarning: Glyph 46020 (\\N{HANGUL SYLLABLE DO}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "c:\\Users\\dldkr\\anaconda3\\envs\\envFirstMini\\lib\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 48712 (\\N{HANGUL SYLLABLE BIN}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\dldkr\\anaconda3\\envs\\envFirstMini\\lib\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 46020 (\\N{HANGUL SYLLABLE DO}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "categorical_columns = all_df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# 다중 플롯 설정\n",
    "num_plots = len(categorical_columns)\n",
    "num_cols = 3  \n",
    "num_rows = -(-num_plots // num_cols)\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 5*num_rows))\n",
    "\n",
    "# 스타일 설정 변경\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "for i, column in enumerate(categorical_columns):\n",
    "    row = i // num_cols\n",
    "    col = i % num_cols\n",
    "    \n",
    "    sns.countplot(data=all_df, x=column, hue=column, ax=axes[row, col], palette='Set3')  # hue 매개변수를 통해 각 범주에 다른 색상 적용\n",
    "    axes[row, col].set_title(f'{column}')\n",
    "    axes[row, col].set_xlabel(column)\n",
    "    axes[row, col].set_ylabel('빈도')\n",
    "    axes[row, col].tick_params(axis='x', rotation=45) \n",
    "\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n- 원-핫 인코딩: (명목척도 인 것)\\ngender(2), family_history_with_overweight(2), favc(2), smoke(2), scc(2), mtrans(5)\\n\\n- 라벨 인코딩: (서열척도 인 것)\\ncaec(4), calc(3)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "- 원-핫 인코딩: (명목척도 인 것)\n",
    "gender(2), family_history_with_overweight(2), favc(2), smoke(2), scc(2), mtrans(5)\n",
    "\n",
    "- 라벨 인코딩: (서열척도 인 것)\n",
    "caec(4), calc(3)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>family_history_with_overweight_yes</th>\n",
       "      <th>FAVC_yes</th>\n",
       "      <th>SMOKE_yes</th>\n",
       "      <th>SCC_yes</th>\n",
       "      <th>MTRANS_Bike</th>\n",
       "      <th>MTRANS_Motorbike</th>\n",
       "      <th>MTRANS_Public_Transportation</th>\n",
       "      <th>MTRANS_Walking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.443011</td>\n",
       "      <td>1.699998</td>\n",
       "      <td>81.669950</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.983297</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>2.763573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.976473</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.711460</td>\n",
       "      <td>50.165754</td>\n",
       "      <td>1.880534</td>\n",
       "      <td>1.411685</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1.910378</td>\n",
       "      <td>0.866045</td>\n",
       "      <td>1.673584</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.952737</td>\n",
       "      <td>1.710730</td>\n",
       "      <td>131.274851</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1.674061</td>\n",
       "      <td>1.467863</td>\n",
       "      <td>0.780199</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.641081</td>\n",
       "      <td>1.914186</td>\n",
       "      <td>93.798055</td>\n",
       "      <td>2.679664</td>\n",
       "      <td>1.971472</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1.979848</td>\n",
       "      <td>1.967973</td>\n",
       "      <td>0.931721</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34593</th>\n",
       "      <td>23.327836</td>\n",
       "      <td>1.721384</td>\n",
       "      <td>78.030383</td>\n",
       "      <td>2.813234</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.807076</td>\n",
       "      <td>0.778632</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34594</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.590000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34595</th>\n",
       "      <td>22.935612</td>\n",
       "      <td>1.585547</td>\n",
       "      <td>44.376637</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.273740</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.949840</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34596</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.620000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34597</th>\n",
       "      <td>26.490926</td>\n",
       "      <td>1.812259</td>\n",
       "      <td>120.980508</td>\n",
       "      <td>2.744994</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>2.205977</td>\n",
       "      <td>1.304291</td>\n",
       "      <td>0.630866</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34598 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Age    Height      Weight      FCVC       NCP        CAEC  \\\n",
       "0      24.443011  1.699998   81.669950  2.000000  2.983297   Sometimes   \n",
       "1      18.000000  1.560000   57.000000  2.000000  3.000000  Frequently   \n",
       "2      18.000000  1.711460   50.165754  1.880534  1.411685   Sometimes   \n",
       "3      20.952737  1.710730  131.274851  3.000000  3.000000   Sometimes   \n",
       "4      31.641081  1.914186   93.798055  2.679664  1.971472   Sometimes   \n",
       "...          ...       ...         ...       ...       ...         ...   \n",
       "34593  23.327836  1.721384   78.030383  2.813234  3.000000   Sometimes   \n",
       "34594  29.000000  1.590000   62.000000  3.000000  3.000000   Sometimes   \n",
       "34595  22.935612  1.585547   44.376637  3.000000  2.273740  Frequently   \n",
       "34596  21.000000  1.620000   53.000000  2.000000  3.000000   Sometimes   \n",
       "34597  26.490926  1.812259  120.980508  2.744994  3.000000   Sometimes   \n",
       "\n",
       "           CH2O       FAF       TUE       CALC  Gender_Male  \\\n",
       "0      2.763573  0.000000  0.976473  Sometimes         True   \n",
       "1      2.000000  1.000000  1.000000         no        False   \n",
       "2      1.910378  0.866045  1.673584         no        False   \n",
       "3      1.674061  1.467863  0.780199  Sometimes        False   \n",
       "4      1.979848  1.967973  0.931721  Sometimes         True   \n",
       "...         ...       ...       ...        ...          ...   \n",
       "34593  1.000000  0.807076  0.778632  Sometimes         True   \n",
       "34594  2.000000  0.000000  0.000000  Sometimes        False   \n",
       "34595  2.000000  1.949840  1.000000  Sometimes        False   \n",
       "34596  2.000000  3.000000  2.000000         no         True   \n",
       "34597  2.205977  1.304291  0.630866  Sometimes         True   \n",
       "\n",
       "       family_history_with_overweight_yes  FAVC_yes  SMOKE_yes  SCC_yes  \\\n",
       "0                                    True      True      False    False   \n",
       "1                                    True      True      False    False   \n",
       "2                                    True      True      False    False   \n",
       "3                                    True      True      False    False   \n",
       "4                                    True      True      False    False   \n",
       "...                                   ...       ...        ...      ...   \n",
       "34593                                True     False      False    False   \n",
       "34594                               False      True      False    False   \n",
       "34595                               False      True      False    False   \n",
       "34596                                True      True      False    False   \n",
       "34597                                True      True      False    False   \n",
       "\n",
       "       MTRANS_Bike  MTRANS_Motorbike  MTRANS_Public_Transportation  \\\n",
       "0            False             False                          True   \n",
       "1            False             False                         False   \n",
       "2            False             False                          True   \n",
       "3            False             False                          True   \n",
       "4            False             False                          True   \n",
       "...            ...               ...                           ...   \n",
       "34593        False             False                          True   \n",
       "34594        False             False                          True   \n",
       "34595        False             False                          True   \n",
       "34596        False             False                          True   \n",
       "34597        False             False                          True   \n",
       "\n",
       "       MTRANS_Walking  \n",
       "0               False  \n",
       "1               False  \n",
       "2               False  \n",
       "3               False  \n",
       "4               False  \n",
       "...               ...  \n",
       "34593           False  \n",
       "34594           False  \n",
       "34595           False  \n",
       "34596           False  \n",
       "34597           False  \n",
       "\n",
       "[34598 rows x 19 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원-핫 인코딩\n",
    "all_df = pd.get_dummies(all_df, columns=['Gender', 'family_history_with_overweight', 'FAVC', 'SMOKE',\n",
    "       'SCC', 'MTRANS'], drop_first=True)\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAEC\n",
      "CALC\n"
     ]
    }
   ],
   "source": [
    "# 라벨 인코딩\n",
    "le_cat = ['CAEC', 'CALC']\n",
    "\n",
    "for cat in le_cat:\n",
    "    le = LabelEncoder()\n",
    "    print(cat)\n",
    "    if all_df[cat].dtypes == 'object':\n",
    "        le = le.fit(all_df[cat])\n",
    "        all_df[cat] = le.transform(all_df[cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>family_history_with_overweight_yes</th>\n",
       "      <th>FAVC_yes</th>\n",
       "      <th>SMOKE_yes</th>\n",
       "      <th>SCC_yes</th>\n",
       "      <th>MTRANS_Bike</th>\n",
       "      <th>MTRANS_Motorbike</th>\n",
       "      <th>MTRANS_Public_Transportation</th>\n",
       "      <th>MTRANS_Walking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.443011</td>\n",
       "      <td>1.699998</td>\n",
       "      <td>81.669950</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.983297</td>\n",
       "      <td>2</td>\n",
       "      <td>2.763573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.976473</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.711460</td>\n",
       "      <td>50.165754</td>\n",
       "      <td>1.880534</td>\n",
       "      <td>1.411685</td>\n",
       "      <td>2</td>\n",
       "      <td>1.910378</td>\n",
       "      <td>0.866045</td>\n",
       "      <td>1.673584</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.952737</td>\n",
       "      <td>1.710730</td>\n",
       "      <td>131.274851</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.674061</td>\n",
       "      <td>1.467863</td>\n",
       "      <td>0.780199</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.641081</td>\n",
       "      <td>1.914186</td>\n",
       "      <td>93.798055</td>\n",
       "      <td>2.679664</td>\n",
       "      <td>1.971472</td>\n",
       "      <td>2</td>\n",
       "      <td>1.979848</td>\n",
       "      <td>1.967973</td>\n",
       "      <td>0.931721</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34593</th>\n",
       "      <td>23.327836</td>\n",
       "      <td>1.721384</td>\n",
       "      <td>78.030383</td>\n",
       "      <td>2.813234</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.807076</td>\n",
       "      <td>0.778632</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34594</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.590000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34595</th>\n",
       "      <td>22.935612</td>\n",
       "      <td>1.585547</td>\n",
       "      <td>44.376637</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.273740</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.949840</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34596</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.620000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34597</th>\n",
       "      <td>26.490926</td>\n",
       "      <td>1.812259</td>\n",
       "      <td>120.980508</td>\n",
       "      <td>2.744994</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2.205977</td>\n",
       "      <td>1.304291</td>\n",
       "      <td>0.630866</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34598 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Age    Height      Weight      FCVC       NCP  CAEC      CH2O  \\\n",
       "0      24.443011  1.699998   81.669950  2.000000  2.983297     2  2.763573   \n",
       "1      18.000000  1.560000   57.000000  2.000000  3.000000     1  2.000000   \n",
       "2      18.000000  1.711460   50.165754  1.880534  1.411685     2  1.910378   \n",
       "3      20.952737  1.710730  131.274851  3.000000  3.000000     2  1.674061   \n",
       "4      31.641081  1.914186   93.798055  2.679664  1.971472     2  1.979848   \n",
       "...          ...       ...         ...       ...       ...   ...       ...   \n",
       "34593  23.327836  1.721384   78.030383  2.813234  3.000000     2  1.000000   \n",
       "34594  29.000000  1.590000   62.000000  3.000000  3.000000     2  2.000000   \n",
       "34595  22.935612  1.585547   44.376637  3.000000  2.273740     1  2.000000   \n",
       "34596  21.000000  1.620000   53.000000  2.000000  3.000000     2  2.000000   \n",
       "34597  26.490926  1.812259  120.980508  2.744994  3.000000     2  2.205977   \n",
       "\n",
       "            FAF       TUE  CALC  Gender_Male  \\\n",
       "0      0.000000  0.976473     2         True   \n",
       "1      1.000000  1.000000     3        False   \n",
       "2      0.866045  1.673584     3        False   \n",
       "3      1.467863  0.780199     2        False   \n",
       "4      1.967973  0.931721     2         True   \n",
       "...         ...       ...   ...          ...   \n",
       "34593  0.807076  0.778632     2         True   \n",
       "34594  0.000000  0.000000     2        False   \n",
       "34595  1.949840  1.000000     2        False   \n",
       "34596  3.000000  2.000000     3         True   \n",
       "34597  1.304291  0.630866     2         True   \n",
       "\n",
       "       family_history_with_overweight_yes  FAVC_yes  SMOKE_yes  SCC_yes  \\\n",
       "0                                    True      True      False    False   \n",
       "1                                    True      True      False    False   \n",
       "2                                    True      True      False    False   \n",
       "3                                    True      True      False    False   \n",
       "4                                    True      True      False    False   \n",
       "...                                   ...       ...        ...      ...   \n",
       "34593                                True     False      False    False   \n",
       "34594                               False      True      False    False   \n",
       "34595                               False      True      False    False   \n",
       "34596                                True      True      False    False   \n",
       "34597                                True      True      False    False   \n",
       "\n",
       "       MTRANS_Bike  MTRANS_Motorbike  MTRANS_Public_Transportation  \\\n",
       "0            False             False                          True   \n",
       "1            False             False                         False   \n",
       "2            False             False                          True   \n",
       "3            False             False                          True   \n",
       "4            False             False                          True   \n",
       "...            ...               ...                           ...   \n",
       "34593        False             False                          True   \n",
       "34594        False             False                          True   \n",
       "34595        False             False                          True   \n",
       "34596        False             False                          True   \n",
       "34597        False             False                          True   \n",
       "\n",
       "       MTRANS_Walking  \n",
       "0               False  \n",
       "1               False  \n",
       "2               False  \n",
       "3               False  \n",
       "4               False  \n",
       "...               ...  \n",
       "34593           False  \n",
       "34594           False  \n",
       "34595           False  \n",
       "34596           False  \n",
       "34597           False  \n",
       "\n",
       "[34598 rows x 19 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>34598.0</td>\n",
       "      <td>23.886181</td>\n",
       "      <td>5.733207</td>\n",
       "      <td>14.00</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>22.851747</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>61.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Height</th>\n",
       "      <td>34598.0</td>\n",
       "      <td>1.699721</td>\n",
       "      <td>0.087895</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.631856</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>1.761773</td>\n",
       "      <td>1.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weight</th>\n",
       "      <td>34598.0</td>\n",
       "      <td>87.686451</td>\n",
       "      <td>26.273493</td>\n",
       "      <td>39.00</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>111.539494</td>\n",
       "      <td>165.057269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FCVC</th>\n",
       "      <td>34598.0</td>\n",
       "      <td>2.444704</td>\n",
       "      <td>0.532568</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.392179</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCP</th>\n",
       "      <td>34598.0</td>\n",
       "      <td>2.757043</td>\n",
       "      <td>0.707610</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAEC</th>\n",
       "      <td>34598.0</td>\n",
       "      <td>1.846552</td>\n",
       "      <td>0.452257</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CH2O</th>\n",
       "      <td>34598.0</td>\n",
       "      <td>2.030469</td>\n",
       "      <td>0.609566</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.784710</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.550570</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAF</th>\n",
       "      <td>34598.0</td>\n",
       "      <td>0.978861</td>\n",
       "      <td>0.839122</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.006892</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.583832</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TUE</th>\n",
       "      <td>34598.0</td>\n",
       "      <td>0.614467</td>\n",
       "      <td>0.604475</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555591</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CALC</th>\n",
       "      <td>34598.0</td>\n",
       "      <td>2.225360</td>\n",
       "      <td>0.474876</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count       mean        std    min        25%        50%  \\\n",
       "Age     34598.0  23.886181   5.733207  14.00  20.000000  22.851747   \n",
       "Height  34598.0   1.699721   0.087895   1.45   1.631856   1.700000   \n",
       "Weight  34598.0  87.686451  26.273493  39.00  66.000000  84.000000   \n",
       "FCVC    34598.0   2.444704   0.532568   1.00   2.000000   2.392179   \n",
       "NCP     34598.0   2.757043   0.707610   1.00   3.000000   3.000000   \n",
       "CAEC    34598.0   1.846552   0.452257   0.00   2.000000   2.000000   \n",
       "CH2O    34598.0   2.030469   0.609566   1.00   1.784710   2.000000   \n",
       "FAF     34598.0   0.978861   0.839122   0.00   0.006892   1.000000   \n",
       "TUE     34598.0   0.614467   0.604475   0.00   0.000000   0.555591   \n",
       "CALC    34598.0   2.225360   0.474876   0.00   2.000000   2.000000   \n",
       "\n",
       "               75%         max  \n",
       "Age      26.000000   61.000000  \n",
       "Height    1.761773    1.980000  \n",
       "Weight  111.539494  165.057269  \n",
       "FCVC      3.000000    3.000000  \n",
       "NCP       3.000000    4.000000  \n",
       "CAEC      2.000000    3.000000  \n",
       "CH2O      2.550570    3.000000  \n",
       "FAF       1.583832    3.000000  \n",
       "TUE       1.000000    2.000000  \n",
       "CALC      3.000000    3.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 표준화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34598 entries, 0 to 34597\n",
      "Data columns (total 19 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   Age                                 34598 non-null  float64\n",
      " 1   Height                              34598 non-null  float64\n",
      " 2   Weight                              34598 non-null  float64\n",
      " 3   FCVC                                34598 non-null  float64\n",
      " 4   NCP                                 34598 non-null  float64\n",
      " 5   CAEC                                34598 non-null  int32  \n",
      " 6   CH2O                                34598 non-null  float64\n",
      " 7   FAF                                 34598 non-null  float64\n",
      " 8   TUE                                 34598 non-null  float64\n",
      " 9   CALC                                34598 non-null  int32  \n",
      " 10  Gender_Male                         34598 non-null  bool   \n",
      " 11  family_history_with_overweight_yes  34598 non-null  bool   \n",
      " 12  FAVC_yes                            34598 non-null  bool   \n",
      " 13  SMOKE_yes                           34598 non-null  bool   \n",
      " 14  SCC_yes                             34598 non-null  bool   \n",
      " 15  MTRANS_Bike                         34598 non-null  bool   \n",
      " 16  MTRANS_Motorbike                    34598 non-null  bool   \n",
      " 17  MTRANS_Public_Transportation        34598 non-null  bool   \n",
      " 18  MTRANS_Walking                      34598 non-null  bool   \n",
      "dtypes: bool(9), float64(8), int32(2)\n",
      "memory usage: 2.7 MB\n"
     ]
    }
   ],
   "source": [
    "all_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터프레임에서 수치형 변수 추출\n",
    "numerical_columns = all_df.select_dtypes(include=['float64']).columns\n",
    "numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>family_history_with_overweight_yes</th>\n",
       "      <th>FAVC_yes</th>\n",
       "      <th>SMOKE_yes</th>\n",
       "      <th>SCC_yes</th>\n",
       "      <th>MTRANS_Bike</th>\n",
       "      <th>MTRANS_Motorbike</th>\n",
       "      <th>MTRANS_Public_Transportation</th>\n",
       "      <th>MTRANS_Walking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.097125</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>-0.228998</td>\n",
       "      <td>-0.835030</td>\n",
       "      <td>0.319748</td>\n",
       "      <td>2</td>\n",
       "      <td>1.202683</td>\n",
       "      <td>-1.166547</td>\n",
       "      <td>0.598886</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.026697</td>\n",
       "      <td>-1.589647</td>\n",
       "      <td>-1.167979</td>\n",
       "      <td>-0.835030</td>\n",
       "      <td>0.343353</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.049985</td>\n",
       "      <td>0.025192</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.026697</td>\n",
       "      <td>0.133563</td>\n",
       "      <td>-1.428102</td>\n",
       "      <td>-1.059354</td>\n",
       "      <td>-1.901298</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.197013</td>\n",
       "      <td>-0.134447</td>\n",
       "      <td>1.752153</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.511666</td>\n",
       "      <td>0.125258</td>\n",
       "      <td>1.659050</td>\n",
       "      <td>1.042690</td>\n",
       "      <td>0.343353</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.584699</td>\n",
       "      <td>0.582763</td>\n",
       "      <td>0.274179</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.352648</td>\n",
       "      <td>2.440044</td>\n",
       "      <td>0.232618</td>\n",
       "      <td>0.441189</td>\n",
       "      <td>-1.110191</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.083045</td>\n",
       "      <td>1.178764</td>\n",
       "      <td>0.524850</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34593</th>\n",
       "      <td>-0.097389</td>\n",
       "      <td>0.246472</td>\n",
       "      <td>-0.367527</td>\n",
       "      <td>0.691996</td>\n",
       "      <td>0.343353</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.690520</td>\n",
       "      <td>-0.204723</td>\n",
       "      <td>0.271587</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34594</th>\n",
       "      <td>0.891978</td>\n",
       "      <td>-1.248327</td>\n",
       "      <td>-0.977671</td>\n",
       "      <td>1.042690</td>\n",
       "      <td>0.343353</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.049985</td>\n",
       "      <td>-1.166547</td>\n",
       "      <td>-1.016544</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34595</th>\n",
       "      <td>-0.165803</td>\n",
       "      <td>-1.298990</td>\n",
       "      <td>-1.648446</td>\n",
       "      <td>1.042690</td>\n",
       "      <td>-0.683018</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.049985</td>\n",
       "      <td>1.157154</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34596</th>\n",
       "      <td>-0.503422</td>\n",
       "      <td>-0.907007</td>\n",
       "      <td>-1.320226</td>\n",
       "      <td>-0.835030</td>\n",
       "      <td>0.343353</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.049985</td>\n",
       "      <td>2.408672</td>\n",
       "      <td>2.292160</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34597</th>\n",
       "      <td>0.454333</td>\n",
       "      <td>1.280387</td>\n",
       "      <td>1.267229</td>\n",
       "      <td>0.563860</td>\n",
       "      <td>0.343353</td>\n",
       "      <td>2</td>\n",
       "      <td>0.287928</td>\n",
       "      <td>0.387828</td>\n",
       "      <td>0.027130</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34598 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Age    Height    Weight      FCVC       NCP  CAEC      CH2O  \\\n",
       "0      0.097125  0.003156 -0.228998 -0.835030  0.319748     2  1.202683   \n",
       "1     -1.026697 -1.589647 -1.167979 -0.835030  0.343353     1 -0.049985   \n",
       "2     -1.026697  0.133563 -1.428102 -1.059354 -1.901298     2 -0.197013   \n",
       "3     -0.511666  0.125258  1.659050  1.042690  0.343353     2 -0.584699   \n",
       "4      1.352648  2.440044  0.232618  0.441189 -1.110191     2 -0.083045   \n",
       "...         ...       ...       ...       ...       ...   ...       ...   \n",
       "34593 -0.097389  0.246472 -0.367527  0.691996  0.343353     2 -1.690520   \n",
       "34594  0.891978 -1.248327 -0.977671  1.042690  0.343353     2 -0.049985   \n",
       "34595 -0.165803 -1.298990 -1.648446  1.042690 -0.683018     1 -0.049985   \n",
       "34596 -0.503422 -0.907007 -1.320226 -0.835030  0.343353     2 -0.049985   \n",
       "34597  0.454333  1.280387  1.267229  0.563860  0.343353     2  0.287928   \n",
       "\n",
       "            FAF       TUE  CALC  Gender_Male  \\\n",
       "0     -1.166547  0.598886     2         True   \n",
       "1      0.025192  0.637808     3        False   \n",
       "2     -0.134447  1.752153     3        False   \n",
       "3      0.582763  0.274179     2        False   \n",
       "4      1.178764  0.524850     2         True   \n",
       "...         ...       ...   ...          ...   \n",
       "34593 -0.204723  0.271587     2         True   \n",
       "34594 -1.166547 -1.016544     2        False   \n",
       "34595  1.157154  0.637808     2        False   \n",
       "34596  2.408672  2.292160     3         True   \n",
       "34597  0.387828  0.027130     2         True   \n",
       "\n",
       "       family_history_with_overweight_yes  FAVC_yes  SMOKE_yes  SCC_yes  \\\n",
       "0                                    True      True      False    False   \n",
       "1                                    True      True      False    False   \n",
       "2                                    True      True      False    False   \n",
       "3                                    True      True      False    False   \n",
       "4                                    True      True      False    False   \n",
       "...                                   ...       ...        ...      ...   \n",
       "34593                                True     False      False    False   \n",
       "34594                               False      True      False    False   \n",
       "34595                               False      True      False    False   \n",
       "34596                                True      True      False    False   \n",
       "34597                                True      True      False    False   \n",
       "\n",
       "       MTRANS_Bike  MTRANS_Motorbike  MTRANS_Public_Transportation  \\\n",
       "0            False             False                          True   \n",
       "1            False             False                         False   \n",
       "2            False             False                          True   \n",
       "3            False             False                          True   \n",
       "4            False             False                          True   \n",
       "...            ...               ...                           ...   \n",
       "34593        False             False                          True   \n",
       "34594        False             False                          True   \n",
       "34595        False             False                          True   \n",
       "34596        False             False                          True   \n",
       "34597        False             False                          True   \n",
       "\n",
       "       MTRANS_Walking  \n",
       "0               False  \n",
       "1               False  \n",
       "2               False  \n",
       "3               False  \n",
       "4               False  \n",
       "...               ...  \n",
       "34593           False  \n",
       "34594           False  \n",
       "34595           False  \n",
       "34596           False  \n",
       "34597           False  \n",
       "\n",
       "[34598 rows x 19 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# StandardScaler 객체 생성\n",
    "scaler = StandardScaler()\n",
    "all_df[numerical_columns]= scaler.fit_transform(all_df[numerical_columns])\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>34598.0</td>\n",
       "      <td>8.379139e-17</td>\n",
       "      <td>1.000014</td>\n",
       "      <td>-1.724397</td>\n",
       "      <td>-0.677847</td>\n",
       "      <td>-0.180431</td>\n",
       "      <td>0.368703</td>\n",
       "      <td>6.473577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Height</th>\n",
       "      <td>34598.0</td>\n",
       "      <td>-5.770926e-17</td>\n",
       "      <td>1.000014</td>\n",
       "      <td>-2.841154</td>\n",
       "      <td>-0.772118</td>\n",
       "      <td>0.003179</td>\n",
       "      <td>0.705991</td>\n",
       "      <td>3.188832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weight</th>\n",
       "      <td>34598.0</td>\n",
       "      <td>-2.330961e-17</td>\n",
       "      <td>1.000014</td>\n",
       "      <td>-1.853090</td>\n",
       "      <td>-0.825424</td>\n",
       "      <td>-0.140313</td>\n",
       "      <td>0.907888</td>\n",
       "      <td>2.944867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FCVC</th>\n",
       "      <td>34598.0</td>\n",
       "      <td>-2.873141e-16</td>\n",
       "      <td>1.000014</td>\n",
       "      <td>-2.712750</td>\n",
       "      <td>-0.835030</td>\n",
       "      <td>-0.098628</td>\n",
       "      <td>1.042690</td>\n",
       "      <td>1.042690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCP</th>\n",
       "      <td>34598.0</td>\n",
       "      <td>6.074875e-16</td>\n",
       "      <td>1.000014</td>\n",
       "      <td>-2.483103</td>\n",
       "      <td>0.343353</td>\n",
       "      <td>0.343353</td>\n",
       "      <td>0.343353</td>\n",
       "      <td>1.756581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAEC</th>\n",
       "      <td>34598.0</td>\n",
       "      <td>1.846552e+00</td>\n",
       "      <td>0.452257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CH2O</th>\n",
       "      <td>34598.0</td>\n",
       "      <td>-7.136644e-16</td>\n",
       "      <td>1.000014</td>\n",
       "      <td>-1.690520</td>\n",
       "      <td>-0.403176</td>\n",
       "      <td>-0.049985</td>\n",
       "      <td>0.853244</td>\n",
       "      <td>1.590550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAF</th>\n",
       "      <td>34598.0</td>\n",
       "      <td>-1.887360e-16</td>\n",
       "      <td>1.000014</td>\n",
       "      <td>-1.166547</td>\n",
       "      <td>-1.158333</td>\n",
       "      <td>0.025192</td>\n",
       "      <td>0.720968</td>\n",
       "      <td>2.408672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TUE</th>\n",
       "      <td>34598.0</td>\n",
       "      <td>-1.015560e-16</td>\n",
       "      <td>1.000014</td>\n",
       "      <td>-1.016544</td>\n",
       "      <td>-1.016544</td>\n",
       "      <td>-0.097401</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>2.292160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CALC</th>\n",
       "      <td>34598.0</td>\n",
       "      <td>2.225360e+00</td>\n",
       "      <td>0.474876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count          mean       std       min       25%       50%  \\\n",
       "Age     34598.0  8.379139e-17  1.000014 -1.724397 -0.677847 -0.180431   \n",
       "Height  34598.0 -5.770926e-17  1.000014 -2.841154 -0.772118  0.003179   \n",
       "Weight  34598.0 -2.330961e-17  1.000014 -1.853090 -0.825424 -0.140313   \n",
       "FCVC    34598.0 -2.873141e-16  1.000014 -2.712750 -0.835030 -0.098628   \n",
       "NCP     34598.0  6.074875e-16  1.000014 -2.483103  0.343353  0.343353   \n",
       "CAEC    34598.0  1.846552e+00  0.452257  0.000000  2.000000  2.000000   \n",
       "CH2O    34598.0 -7.136644e-16  1.000014 -1.690520 -0.403176 -0.049985   \n",
       "FAF     34598.0 -1.887360e-16  1.000014 -1.166547 -1.158333  0.025192   \n",
       "TUE     34598.0 -1.015560e-16  1.000014 -1.016544 -1.016544 -0.097401   \n",
       "CALC    34598.0  2.225360e+00  0.474876  0.000000  2.000000  2.000000   \n",
       "\n",
       "             75%       max  \n",
       "Age     0.368703  6.473577  \n",
       "Height  0.705991  3.188832  \n",
       "Weight  0.907888  2.944867  \n",
       "FCVC    1.042690  1.042690  \n",
       "NCP     0.343353  1.756581  \n",
       "CAEC    2.000000  3.000000  \n",
       "CH2O    0.853244  1.590550  \n",
       "FAF     0.720968  2.408672  \n",
       "TUE     0.637808  2.292160  \n",
       "CALC    3.000000  3.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>family_history_with_overweight_yes</th>\n",
       "      <th>FAVC_yes</th>\n",
       "      <th>SMOKE_yes</th>\n",
       "      <th>SCC_yes</th>\n",
       "      <th>MTRANS_Bike</th>\n",
       "      <th>MTRANS_Motorbike</th>\n",
       "      <th>MTRANS_Public_Transportation</th>\n",
       "      <th>MTRANS_Walking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.097125</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>-0.228998</td>\n",
       "      <td>-0.835030</td>\n",
       "      <td>0.319748</td>\n",
       "      <td>2</td>\n",
       "      <td>1.202683</td>\n",
       "      <td>-1.166547</td>\n",
       "      <td>0.598886</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.026697</td>\n",
       "      <td>-1.589647</td>\n",
       "      <td>-1.167979</td>\n",
       "      <td>-0.835030</td>\n",
       "      <td>0.343353</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.049985</td>\n",
       "      <td>0.025192</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.026697</td>\n",
       "      <td>0.133563</td>\n",
       "      <td>-1.428102</td>\n",
       "      <td>-1.059354</td>\n",
       "      <td>-1.901298</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.197013</td>\n",
       "      <td>-0.134447</td>\n",
       "      <td>1.752153</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.511666</td>\n",
       "      <td>0.125258</td>\n",
       "      <td>1.659050</td>\n",
       "      <td>1.042690</td>\n",
       "      <td>0.343353</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.584699</td>\n",
       "      <td>0.582763</td>\n",
       "      <td>0.274179</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.352648</td>\n",
       "      <td>2.440044</td>\n",
       "      <td>0.232618</td>\n",
       "      <td>0.441189</td>\n",
       "      <td>-1.110191</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.083045</td>\n",
       "      <td>1.178764</td>\n",
       "      <td>0.524850</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20753</th>\n",
       "      <td>0.218189</td>\n",
       "      <td>0.761205</td>\n",
       "      <td>1.008660</td>\n",
       "      <td>0.891692</td>\n",
       "      <td>0.343353</td>\n",
       "      <td>2</td>\n",
       "      <td>0.199063</td>\n",
       "      <td>0.419085</td>\n",
       "      <td>-0.691167</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20754</th>\n",
       "      <td>-1.026697</td>\n",
       "      <td>0.116953</td>\n",
       "      <td>-1.434411</td>\n",
       "      <td>1.042690</td>\n",
       "      <td>1.756581</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.690520</td>\n",
       "      <td>1.216932</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20755</th>\n",
       "      <td>-0.660226</td>\n",
       "      <td>1.363419</td>\n",
       "      <td>0.681078</td>\n",
       "      <td>-0.069264</td>\n",
       "      <td>0.343353</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.049985</td>\n",
       "      <td>0.213535</td>\n",
       "      <td>0.966096</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20756</th>\n",
       "      <td>1.738454</td>\n",
       "      <td>0.003179</td>\n",
       "      <td>-0.158578</td>\n",
       "      <td>0.425367</td>\n",
       "      <td>-1.110191</td>\n",
       "      <td>2</td>\n",
       "      <td>0.187627</td>\n",
       "      <td>-1.166547</td>\n",
       "      <td>0.594520</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20757</th>\n",
       "      <td>0.487377</td>\n",
       "      <td>1.329173</td>\n",
       "      <td>1.158920</td>\n",
       "      <td>1.042690</td>\n",
       "      <td>0.343353</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.044140</td>\n",
       "      <td>-0.350817</td>\n",
       "      <td>0.164370</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20758 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Age    Height    Weight      FCVC       NCP  CAEC      CH2O  \\\n",
       "0      0.097125  0.003156 -0.228998 -0.835030  0.319748     2  1.202683   \n",
       "1     -1.026697 -1.589647 -1.167979 -0.835030  0.343353     1 -0.049985   \n",
       "2     -1.026697  0.133563 -1.428102 -1.059354 -1.901298     2 -0.197013   \n",
       "3     -0.511666  0.125258  1.659050  1.042690  0.343353     2 -0.584699   \n",
       "4      1.352648  2.440044  0.232618  0.441189 -1.110191     2 -0.083045   \n",
       "...         ...       ...       ...       ...       ...   ...       ...   \n",
       "20753  0.218189  0.761205  1.008660  0.891692  0.343353     2  0.199063   \n",
       "20754 -1.026697  0.116953 -1.434411  1.042690  1.756581     1 -1.690520   \n",
       "20755 -0.660226  1.363419  0.681078 -0.069264  0.343353     2 -0.049985   \n",
       "20756  1.738454  0.003179 -0.158578  0.425367 -1.110191     2  0.187627   \n",
       "20757  0.487377  1.329173  1.158920  1.042690  0.343353     2 -0.044140   \n",
       "\n",
       "            FAF       TUE  CALC  Gender_Male  \\\n",
       "0     -1.166547  0.598886     2         True   \n",
       "1      0.025192  0.637808     3        False   \n",
       "2     -0.134447  1.752153     3        False   \n",
       "3      0.582763  0.274179     2        False   \n",
       "4      1.178764  0.524850     2         True   \n",
       "...         ...       ...   ...          ...   \n",
       "20753  0.419085 -0.691167     2         True   \n",
       "20754  1.216932  0.637808     2         True   \n",
       "20755  0.213535  0.966096     3         True   \n",
       "20756 -1.166547  0.594520     3         True   \n",
       "20757 -0.350817  0.164370     2         True   \n",
       "\n",
       "       family_history_with_overweight_yes  FAVC_yes  SMOKE_yes  SCC_yes  \\\n",
       "0                                    True      True      False    False   \n",
       "1                                    True      True      False    False   \n",
       "2                                    True      True      False    False   \n",
       "3                                    True      True      False    False   \n",
       "4                                    True      True      False    False   \n",
       "...                                   ...       ...        ...      ...   \n",
       "20753                                True      True      False    False   \n",
       "20754                               False      True      False    False   \n",
       "20755                                True      True      False    False   \n",
       "20756                                True      True      False    False   \n",
       "20757                                True      True      False    False   \n",
       "\n",
       "       MTRANS_Bike  MTRANS_Motorbike  MTRANS_Public_Transportation  \\\n",
       "0            False             False                          True   \n",
       "1            False             False                         False   \n",
       "2            False             False                          True   \n",
       "3            False             False                          True   \n",
       "4            False             False                          True   \n",
       "...            ...               ...                           ...   \n",
       "20753        False             False                          True   \n",
       "20754        False             False                          True   \n",
       "20755        False             False                          True   \n",
       "20756        False             False                         False   \n",
       "20757        False             False                          True   \n",
       "\n",
       "       MTRANS_Walking  \n",
       "0               False  \n",
       "1               False  \n",
       "2               False  \n",
       "3               False  \n",
       "4               False  \n",
       "...               ...  \n",
       "20753           False  \n",
       "20754           False  \n",
       "20755           False  \n",
       "20756           False  \n",
       "20757           False  \n",
       "\n",
       "[20758 rows x 19 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df[:20758] # train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다시 학습데이터와 테스트 데이터로 되돌리기\n",
    "\n",
    "X_features = all_df[:20758]\n",
    "y_label = train['NObeyesdad']\n",
    "\n",
    "X_pred = all_df[20758:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 1, 0, ..., 3, 6, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 목적변수 라벨인코딩\n",
    "le = LabelEncoder()\n",
    "le = le.fit(y_label)\n",
    "\n",
    "y_label = le.transform(y_label)\n",
    "y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터 중 80%는 학습용 데이터, 20%는 테스트용 데이터 추출\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_label, test_size=0.2, random_state=42)\n",
    "\n",
    "# 위에서 만든 X_train, y_train을 다시 쪼개서 90%는 학습과 10%는 검증용 데이터로 분리\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.LightGBM 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install lightgbm==3.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's multi_logloss: 1.70649\tvalid_1's multi_logloss: 1.70575\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\ttraining's multi_logloss: 1.53557\tvalid_1's multi_logloss: 1.53891\n",
      "[3]\ttraining's multi_logloss: 1.39736\tvalid_1's multi_logloss: 1.40401\n",
      "[4]\ttraining's multi_logloss: 1.28164\tvalid_1's multi_logloss: 1.29133\n",
      "[5]\ttraining's multi_logloss: 1.18247\tvalid_1's multi_logloss: 1.19447\n",
      "[6]\ttraining's multi_logloss: 1.09637\tvalid_1's multi_logloss: 1.11084\n",
      "[7]\ttraining's multi_logloss: 1.02054\tvalid_1's multi_logloss: 1.03714\n",
      "[8]\ttraining's multi_logloss: 0.953505\tvalid_1's multi_logloss: 0.971533\n",
      "[9]\ttraining's multi_logloss: 0.893424\tvalid_1's multi_logloss: 0.91306\n",
      "[10]\ttraining's multi_logloss: 0.83973\tvalid_1's multi_logloss: 0.860759\n",
      "[11]\ttraining's multi_logloss: 0.791362\tvalid_1's multi_logloss: 0.813555\n",
      "[12]\ttraining's multi_logloss: 0.74772\tvalid_1's multi_logloss: 0.771268\n",
      "[13]\ttraining's multi_logloss: 0.708009\tvalid_1's multi_logloss: 0.732681\n",
      "[14]\ttraining's multi_logloss: 0.671855\tvalid_1's multi_logloss: 0.69764\n",
      "[15]\ttraining's multi_logloss: 0.639043\tvalid_1's multi_logloss: 0.6654\n",
      "[16]\ttraining's multi_logloss: 0.608776\tvalid_1's multi_logloss: 0.636415\n",
      "[17]\ttraining's multi_logloss: 0.580895\tvalid_1's multi_logloss: 0.609544\n",
      "[18]\ttraining's multi_logloss: 0.555467\tvalid_1's multi_logloss: 0.585024\n",
      "[19]\ttraining's multi_logloss: 0.532018\tvalid_1's multi_logloss: 0.56299\n",
      "[20]\ttraining's multi_logloss: 0.510428\tvalid_1's multi_logloss: 0.542399\n",
      "[21]\ttraining's multi_logloss: 0.490504\tvalid_1's multi_logloss: 0.523601\n",
      "[22]\ttraining's multi_logloss: 0.472043\tvalid_1's multi_logloss: 0.505987\n",
      "[23]\ttraining's multi_logloss: 0.45456\tvalid_1's multi_logloss: 0.489539\n",
      "[24]\ttraining's multi_logloss: 0.438499\tvalid_1's multi_logloss: 0.474586\n",
      "[25]\ttraining's multi_logloss: 0.423855\tvalid_1's multi_logloss: 0.460534\n",
      "[26]\ttraining's multi_logloss: 0.410209\tvalid_1's multi_logloss: 0.447807\n",
      "[27]\ttraining's multi_logloss: 0.39742\tvalid_1's multi_logloss: 0.43555\n",
      "[28]\ttraining's multi_logloss: 0.38571\tvalid_1's multi_logloss: 0.424817\n",
      "[29]\ttraining's multi_logloss: 0.374498\tvalid_1's multi_logloss: 0.414591\n",
      "[30]\ttraining's multi_logloss: 0.364132\tvalid_1's multi_logloss: 0.405047\n",
      "[31]\ttraining's multi_logloss: 0.354336\tvalid_1's multi_logloss: 0.396254\n",
      "[32]\ttraining's multi_logloss: 0.345266\tvalid_1's multi_logloss: 0.388467\n",
      "[33]\ttraining's multi_logloss: 0.336383\tvalid_1's multi_logloss: 0.380991\n",
      "[34]\ttraining's multi_logloss: 0.327794\tvalid_1's multi_logloss: 0.373178\n",
      "[35]\ttraining's multi_logloss: 0.320233\tvalid_1's multi_logloss: 0.36677\n",
      "[36]\ttraining's multi_logloss: 0.312785\tvalid_1's multi_logloss: 0.360821\n",
      "[37]\ttraining's multi_logloss: 0.30558\tvalid_1's multi_logloss: 0.354412\n",
      "[38]\ttraining's multi_logloss: 0.298965\tvalid_1's multi_logloss: 0.349174\n",
      "[39]\ttraining's multi_logloss: 0.292647\tvalid_1's multi_logloss: 0.344431\n",
      "[40]\ttraining's multi_logloss: 0.286802\tvalid_1's multi_logloss: 0.339725\n",
      "[41]\ttraining's multi_logloss: 0.28121\tvalid_1's multi_logloss: 0.335009\n",
      "[42]\ttraining's multi_logloss: 0.275852\tvalid_1's multi_logloss: 0.331049\n",
      "[43]\ttraining's multi_logloss: 0.270681\tvalid_1's multi_logloss: 0.327313\n",
      "[44]\ttraining's multi_logloss: 0.265663\tvalid_1's multi_logloss: 0.323602\n",
      "[45]\ttraining's multi_logloss: 0.260882\tvalid_1's multi_logloss: 0.320292\n",
      "[46]\ttraining's multi_logloss: 0.25621\tvalid_1's multi_logloss: 0.317135\n",
      "[47]\ttraining's multi_logloss: 0.251924\tvalid_1's multi_logloss: 0.314389\n",
      "[48]\ttraining's multi_logloss: 0.247796\tvalid_1's multi_logloss: 0.311368\n",
      "[49]\ttraining's multi_logloss: 0.243786\tvalid_1's multi_logloss: 0.308867\n",
      "[50]\ttraining's multi_logloss: 0.240007\tvalid_1's multi_logloss: 0.306251\n",
      "[51]\ttraining's multi_logloss: 0.2365\tvalid_1's multi_logloss: 0.303978\n",
      "[52]\ttraining's multi_logloss: 0.233134\tvalid_1's multi_logloss: 0.302225\n",
      "[53]\ttraining's multi_logloss: 0.229779\tvalid_1's multi_logloss: 0.300596\n",
      "[54]\ttraining's multi_logloss: 0.226471\tvalid_1's multi_logloss: 0.298672\n",
      "[55]\ttraining's multi_logloss: 0.223253\tvalid_1's multi_logloss: 0.29651\n",
      "[56]\ttraining's multi_logloss: 0.220284\tvalid_1's multi_logloss: 0.294922\n",
      "[57]\ttraining's multi_logloss: 0.217557\tvalid_1's multi_logloss: 0.293238\n",
      "[58]\ttraining's multi_logloss: 0.214765\tvalid_1's multi_logloss: 0.291563\n",
      "[59]\ttraining's multi_logloss: 0.212032\tvalid_1's multi_logloss: 0.290125\n",
      "[60]\ttraining's multi_logloss: 0.209421\tvalid_1's multi_logloss: 0.28902\n",
      "[61]\ttraining's multi_logloss: 0.206815\tvalid_1's multi_logloss: 0.287416\n",
      "[62]\ttraining's multi_logloss: 0.204389\tvalid_1's multi_logloss: 0.28625\n",
      "[63]\ttraining's multi_logloss: 0.201962\tvalid_1's multi_logloss: 0.285165\n",
      "[64]\ttraining's multi_logloss: 0.199533\tvalid_1's multi_logloss: 0.283957\n",
      "[65]\ttraining's multi_logloss: 0.197355\tvalid_1's multi_logloss: 0.282347\n",
      "[66]\ttraining's multi_logloss: 0.195173\tvalid_1's multi_logloss: 0.281569\n",
      "[67]\ttraining's multi_logloss: 0.193052\tvalid_1's multi_logloss: 0.280501\n",
      "[68]\ttraining's multi_logloss: 0.190863\tvalid_1's multi_logloss: 0.279806\n",
      "[69]\ttraining's multi_logloss: 0.188731\tvalid_1's multi_logloss: 0.278913\n",
      "[70]\ttraining's multi_logloss: 0.186685\tvalid_1's multi_logloss: 0.277961\n",
      "[71]\ttraining's multi_logloss: 0.184612\tvalid_1's multi_logloss: 0.277385\n",
      "[72]\ttraining's multi_logloss: 0.182767\tvalid_1's multi_logloss: 0.276511\n",
      "[73]\ttraining's multi_logloss: 0.180805\tvalid_1's multi_logloss: 0.27581\n",
      "[74]\ttraining's multi_logloss: 0.179001\tvalid_1's multi_logloss: 0.274996\n",
      "[75]\ttraining's multi_logloss: 0.177113\tvalid_1's multi_logloss: 0.274493\n",
      "[76]\ttraining's multi_logloss: 0.175294\tvalid_1's multi_logloss: 0.273915\n",
      "[77]\ttraining's multi_logloss: 0.173662\tvalid_1's multi_logloss: 0.273238\n",
      "[78]\ttraining's multi_logloss: 0.172145\tvalid_1's multi_logloss: 0.272938\n",
      "[79]\ttraining's multi_logloss: 0.17052\tvalid_1's multi_logloss: 0.272556\n",
      "[80]\ttraining's multi_logloss: 0.169005\tvalid_1's multi_logloss: 0.272326\n",
      "[81]\ttraining's multi_logloss: 0.16741\tvalid_1's multi_logloss: 0.271644\n",
      "[82]\ttraining's multi_logloss: 0.165893\tvalid_1's multi_logloss: 0.271378\n",
      "[83]\ttraining's multi_logloss: 0.164473\tvalid_1's multi_logloss: 0.270968\n",
      "[84]\ttraining's multi_logloss: 0.16302\tvalid_1's multi_logloss: 0.27059\n",
      "[85]\ttraining's multi_logloss: 0.161602\tvalid_1's multi_logloss: 0.270111\n",
      "[86]\ttraining's multi_logloss: 0.160029\tvalid_1's multi_logloss: 0.269899\n",
      "[87]\ttraining's multi_logloss: 0.158612\tvalid_1's multi_logloss: 0.269585\n",
      "[88]\ttraining's multi_logloss: 0.157234\tvalid_1's multi_logloss: 0.269125\n",
      "[89]\ttraining's multi_logloss: 0.15583\tvalid_1's multi_logloss: 0.268973\n",
      "[90]\ttraining's multi_logloss: 0.154509\tvalid_1's multi_logloss: 0.269224\n",
      "[91]\ttraining's multi_logloss: 0.153242\tvalid_1's multi_logloss: 0.268953\n",
      "[92]\ttraining's multi_logloss: 0.151883\tvalid_1's multi_logloss: 0.268589\n",
      "[93]\ttraining's multi_logloss: 0.150624\tvalid_1's multi_logloss: 0.268393\n",
      "[94]\ttraining's multi_logloss: 0.149428\tvalid_1's multi_logloss: 0.268304\n",
      "[95]\ttraining's multi_logloss: 0.148209\tvalid_1's multi_logloss: 0.267946\n",
      "[96]\ttraining's multi_logloss: 0.147055\tvalid_1's multi_logloss: 0.267708\n",
      "[97]\ttraining's multi_logloss: 0.145983\tvalid_1's multi_logloss: 0.267438\n",
      "[98]\ttraining's multi_logloss: 0.144792\tvalid_1's multi_logloss: 0.267272\n",
      "[99]\ttraining's multi_logloss: 0.143646\tvalid_1's multi_logloss: 0.267199\n",
      "[100]\ttraining's multi_logloss: 0.142566\tvalid_1's multi_logloss: 0.267103\n",
      "[101]\ttraining's multi_logloss: 0.141401\tvalid_1's multi_logloss: 0.266766\n",
      "[102]\ttraining's multi_logloss: 0.140286\tvalid_1's multi_logloss: 0.266711\n",
      "[103]\ttraining's multi_logloss: 0.13927\tvalid_1's multi_logloss: 0.266578\n",
      "[104]\ttraining's multi_logloss: 0.138298\tvalid_1's multi_logloss: 0.266394\n",
      "[105]\ttraining's multi_logloss: 0.137301\tvalid_1's multi_logloss: 0.266648\n",
      "[106]\ttraining's multi_logloss: 0.136274\tvalid_1's multi_logloss: 0.266528\n",
      "[107]\ttraining's multi_logloss: 0.135278\tvalid_1's multi_logloss: 0.266419\n",
      "[108]\ttraining's multi_logloss: 0.134265\tvalid_1's multi_logloss: 0.266333\n",
      "[109]\ttraining's multi_logloss: 0.133305\tvalid_1's multi_logloss: 0.266113\n",
      "[110]\ttraining's multi_logloss: 0.132368\tvalid_1's multi_logloss: 0.266063\n",
      "[111]\ttraining's multi_logloss: 0.131437\tvalid_1's multi_logloss: 0.265977\n",
      "[112]\ttraining's multi_logloss: 0.130557\tvalid_1's multi_logloss: 0.26604\n",
      "[113]\ttraining's multi_logloss: 0.129693\tvalid_1's multi_logloss: 0.266102\n",
      "[114]\ttraining's multi_logloss: 0.128817\tvalid_1's multi_logloss: 0.26594\n",
      "[115]\ttraining's multi_logloss: 0.127944\tvalid_1's multi_logloss: 0.266063\n",
      "[116]\ttraining's multi_logloss: 0.127065\tvalid_1's multi_logloss: 0.265896\n",
      "[117]\ttraining's multi_logloss: 0.126167\tvalid_1's multi_logloss: 0.266228\n",
      "[118]\ttraining's multi_logloss: 0.125316\tvalid_1's multi_logloss: 0.265934\n",
      "[119]\ttraining's multi_logloss: 0.12446\tvalid_1's multi_logloss: 0.265925\n",
      "[120]\ttraining's multi_logloss: 0.12364\tvalid_1's multi_logloss: 0.265923\n",
      "[121]\ttraining's multi_logloss: 0.122881\tvalid_1's multi_logloss: 0.265904\n",
      "[122]\ttraining's multi_logloss: 0.122152\tvalid_1's multi_logloss: 0.265985\n",
      "[123]\ttraining's multi_logloss: 0.121397\tvalid_1's multi_logloss: 0.266073\n",
      "[124]\ttraining's multi_logloss: 0.120589\tvalid_1's multi_logloss: 0.266136\n",
      "[125]\ttraining's multi_logloss: 0.119757\tvalid_1's multi_logloss: 0.26591\n",
      "[126]\ttraining's multi_logloss: 0.119023\tvalid_1's multi_logloss: 0.266018\n",
      "[127]\ttraining's multi_logloss: 0.11829\tvalid_1's multi_logloss: 0.265881\n",
      "[128]\ttraining's multi_logloss: 0.117565\tvalid_1's multi_logloss: 0.265865\n",
      "[129]\ttraining's multi_logloss: 0.116823\tvalid_1's multi_logloss: 0.265635\n",
      "[130]\ttraining's multi_logloss: 0.116028\tvalid_1's multi_logloss: 0.265677\n",
      "[131]\ttraining's multi_logloss: 0.11531\tvalid_1's multi_logloss: 0.265727\n",
      "[132]\ttraining's multi_logloss: 0.114538\tvalid_1's multi_logloss: 0.265708\n",
      "[133]\ttraining's multi_logloss: 0.113832\tvalid_1's multi_logloss: 0.265731\n",
      "[134]\ttraining's multi_logloss: 0.113076\tvalid_1's multi_logloss: 0.265907\n",
      "[135]\ttraining's multi_logloss: 0.112322\tvalid_1's multi_logloss: 0.265863\n",
      "[136]\ttraining's multi_logloss: 0.111719\tvalid_1's multi_logloss: 0.265893\n",
      "[137]\ttraining's multi_logloss: 0.111012\tvalid_1's multi_logloss: 0.266064\n",
      "[138]\ttraining's multi_logloss: 0.11033\tvalid_1's multi_logloss: 0.266185\n",
      "[139]\ttraining's multi_logloss: 0.109716\tvalid_1's multi_logloss: 0.266112\n",
      "[140]\ttraining's multi_logloss: 0.108982\tvalid_1's multi_logloss: 0.26597\n",
      "[141]\ttraining's multi_logloss: 0.10833\tvalid_1's multi_logloss: 0.265805\n",
      "[142]\ttraining's multi_logloss: 0.107704\tvalid_1's multi_logloss: 0.265823\n",
      "[143]\ttraining's multi_logloss: 0.107123\tvalid_1's multi_logloss: 0.26591\n",
      "[144]\ttraining's multi_logloss: 0.106535\tvalid_1's multi_logloss: 0.266008\n",
      "[145]\ttraining's multi_logloss: 0.105954\tvalid_1's multi_logloss: 0.265898\n",
      "[146]\ttraining's multi_logloss: 0.105283\tvalid_1's multi_logloss: 0.265846\n",
      "[147]\ttraining's multi_logloss: 0.104619\tvalid_1's multi_logloss: 0.265764\n",
      "[148]\ttraining's multi_logloss: 0.103909\tvalid_1's multi_logloss: 0.265679\n",
      "[149]\ttraining's multi_logloss: 0.10341\tvalid_1's multi_logloss: 0.265859\n",
      "[150]\ttraining's multi_logloss: 0.102842\tvalid_1's multi_logloss: 0.265864\n",
      "[151]\ttraining's multi_logloss: 0.102251\tvalid_1's multi_logloss: 0.266104\n",
      "[152]\ttraining's multi_logloss: 0.101627\tvalid_1's multi_logloss: 0.266311\n",
      "[153]\ttraining's multi_logloss: 0.100984\tvalid_1's multi_logloss: 0.266347\n",
      "[154]\ttraining's multi_logloss: 0.100448\tvalid_1's multi_logloss: 0.266298\n",
      "[155]\ttraining's multi_logloss: 0.099858\tvalid_1's multi_logloss: 0.266441\n",
      "[156]\ttraining's multi_logloss: 0.0992839\tvalid_1's multi_logloss: 0.266276\n",
      "[157]\ttraining's multi_logloss: 0.0986833\tvalid_1's multi_logloss: 0.266315\n",
      "[158]\ttraining's multi_logloss: 0.0981437\tvalid_1's multi_logloss: 0.266419\n",
      "[159]\ttraining's multi_logloss: 0.0975807\tvalid_1's multi_logloss: 0.266205\n",
      "[160]\ttraining's multi_logloss: 0.0969933\tvalid_1's multi_logloss: 0.2663\n",
      "[161]\ttraining's multi_logloss: 0.0963095\tvalid_1's multi_logloss: 0.266266\n",
      "[162]\ttraining's multi_logloss: 0.0956629\tvalid_1's multi_logloss: 0.266281\n",
      "[163]\ttraining's multi_logloss: 0.0951558\tvalid_1's multi_logloss: 0.266465\n",
      "[164]\ttraining's multi_logloss: 0.094646\tvalid_1's multi_logloss: 0.266319\n",
      "[165]\ttraining's multi_logloss: 0.094188\tvalid_1's multi_logloss: 0.266356\n",
      "[166]\ttraining's multi_logloss: 0.0936184\tvalid_1's multi_logloss: 0.26641\n",
      "[167]\ttraining's multi_logloss: 0.0930201\tvalid_1's multi_logloss: 0.266406\n",
      "[168]\ttraining's multi_logloss: 0.0925175\tvalid_1's multi_logloss: 0.266539\n",
      "[169]\ttraining's multi_logloss: 0.0920141\tvalid_1's multi_logloss: 0.266676\n",
      "[170]\ttraining's multi_logloss: 0.0915093\tvalid_1's multi_logloss: 0.266838\n",
      "[171]\ttraining's multi_logloss: 0.0910178\tvalid_1's multi_logloss: 0.266982\n",
      "[172]\ttraining's multi_logloss: 0.0905395\tvalid_1's multi_logloss: 0.266934\n",
      "[173]\ttraining's multi_logloss: 0.0900568\tvalid_1's multi_logloss: 0.266677\n",
      "[174]\ttraining's multi_logloss: 0.0895653\tvalid_1's multi_logloss: 0.266542\n",
      "[175]\ttraining's multi_logloss: 0.0891057\tvalid_1's multi_logloss: 0.266699\n",
      "[176]\ttraining's multi_logloss: 0.08865\tvalid_1's multi_logloss: 0.266675\n",
      "[177]\ttraining's multi_logloss: 0.0881036\tvalid_1's multi_logloss: 0.266898\n",
      "[178]\ttraining's multi_logloss: 0.0875847\tvalid_1's multi_logloss: 0.267085\n",
      "[179]\ttraining's multi_logloss: 0.0870888\tvalid_1's multi_logloss: 0.267091\n",
      "Early stopping, best iteration is:\n",
      "[129]\ttraining's multi_logloss: 0.116823\tvalid_1's multi_logloss: 0.265635\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.05, n_estimators=400)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LGBMClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(learning_rate=0.05, n_estimators=400)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.05, n_estimators=400)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_wrapper = LGBMClassifier(n_estimators=400, learning_rate=0.05)\n",
    "\n",
    "evals = [(X_tr,y_tr), (X_val,y_val)]\n",
    "lgbm_wrapper.fit(X_tr, y_tr, early_stopping_rounds=50, eval_metric='multi_logloss', eval_set=evals, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 훈련 세트 및 검증 세트에 대한 손실 값을 얻습니다.\n",
    "train_loss = lgbm_wrapper.evals_result_['training']['multi_logloss']\n",
    "val_loss = lgbm_wrapper.evals_result_['valid_1']['multi_logloss']\n",
    "\n",
    "# 손실 값 그래프를 그립니다.\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_loss, label='Training Multi-Logloss')\n",
    "plt.plot(val_loss, label='Validation Multi-Logloss')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Multi-Logloss')\n",
    "plt.title('Training and Validation Multi-Logloss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4152"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = lgbm_wrapper.predict(X_test)\n",
    "pred_proba = lgbm_wrapper.predict_proba(X_test) # 각 클래스별로 속할 확률\n",
    "\n",
    "len(pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9060693641618497\n",
      "[[488  32   0   0   0   2   2]\n",
      " [ 23 559   0   0   1  38   5]\n",
      " [  2   0 475  11   1  15  39]\n",
      " [  0   0  12 640   3   0   2]\n",
      " [  0   0   0   1 802   1   0]\n",
      " [  1  35  11   0   1 382  54]\n",
      " [  0  10  39   3   0  46 416]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       524\n",
      "           1       0.88      0.89      0.89       626\n",
      "           2       0.88      0.87      0.88       543\n",
      "           3       0.98      0.97      0.98       657\n",
      "           4       0.99      1.00      1.00       804\n",
      "           5       0.79      0.79      0.79       484\n",
      "           6       0.80      0.81      0.81       514\n",
      "\n",
      "    accuracy                           0.91      4152\n",
      "   macro avg       0.90      0.90      0.90      4152\n",
      "weighted avg       0.91      0.91      0.91      4152\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_predictions = lgbm_wrapper.predict(X_test)\n",
    "print(accuracy_score(y_test, test_predictions))\n",
    "print(confusion_matrix(y_test, test_predictions))\n",
    "print(classification_report(y_test, test_predictions))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.set_style(\"whitegrid\", {\"axes.edgecolor\": \".6\", \"grid.color\": \".6\"})\n",
    "\n",
    "cmap = sns.color_palette(\"crest\", as_cmap=True)\n",
    "heatmap = sns.heatmap(confusion_matrix(y_test, test_predictions), annot=True, fmt='d', cmap=cmap, annot_kws={'size': 14}, cbar=False)\n",
    "heatmap.set_title('Confusion Matrix', fontdict={'fontsize': 16})\n",
    "heatmap.set_xlabel('Predicted', fontdict={'fontsize': 14})\n",
    "heatmap.set_ylabel('True', fontdict={'fontsize': 14})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Feature importance'}, xlabel='Feature importance', ylabel='Features'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot_importance()를 이용하여 feature 중요도 시각화\n",
    "from lightgbm import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,12))\n",
    "plot_importance(lgbm_wrapper, ax= ax)\n",
    "\n",
    "## 몸무게, 키, 나이 순으로 비만도에 피처중요도를 가졌다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, Trials\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_search_space = {'num_leaves':hp.quniform('num_leaves', 32,64, 1),\n",
    "                     'max_depth': hp.quniform('max_depth', 100, 160, 1),\n",
    "                     'min_child_samples': hp.quniform('min_child_samples',60, 100, 1),\n",
    "                     'subsample': hp.uniform('subsample', 0.7, 1),\n",
    "                     'learning_rate': hp.uniform('learning_rate', 0.01, 0.2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_func(search_space):\n",
    "    lgbm_clf = LGBMClassifier(n_estimators=400,\n",
    "                            num_leaves=int(search_space['num_leaves']),\n",
    "                            max_depth=int(search_space['max_depth']),\n",
    "                            min_child_samples=int(search_space['min_child_samples']),\n",
    "                            subsample = search_space['subsample'],\n",
    "                            learning_rate = search_space['learning_rate'])\n",
    "    # 3개 k-fold 방식으로 평가된 accuracy 지표를 담는 list\n",
    "    acc_score_list = []\n",
    "    \n",
    "    # 3개 k-fold 방식 적용\n",
    "    kf = KFold(n_splits=3)\n",
    "    # X_train을 다시 학습과 검증용 데이터로 분리\n",
    "    for tr_index, val_index in kf.split(X_train):\n",
    "        # index로 분리\n",
    "        X_tr , y_tr = X_train.iloc[tr_index], y_train[tr_index]\n",
    "        X_val, y_val = X_train.iloc[val_index], y_train[val_index]\n",
    "        \n",
    "        # early stopping은 30회로 설정하고 추출된 학습과 검증데이터로 lgbm 학습수행\n",
    "        lgbm_clf.fit(X_tr, y_tr, early_stopping_rounds=30, eval_metric='multi_logloss',\n",
    "                     eval_set = [(X_tr, y_tr), (X_val, y_val)])\n",
    "        \n",
    "        #\n",
    "        score = accuracy_score(y_val, lgbm_clf.predict(X_val))\n",
    "        acc_score_list.append(score)\n",
    "    \n",
    "    # 3개 k-fold로 계산된 accuracy 값의 평균값을 반환하되, \n",
    "    # HyperOpt는 목적함수의 최솟값을 위한 입력값을 찾으므로 -1을 곱한뒤 반환\n",
    "    \n",
    "    return -1*np.mean(acc_score_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's multi_logloss: 1.30898\tvalid_1's multi_logloss: 1.32163\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\ttraining's multi_logloss: 1.01931\tvalid_1's multi_logloss: 1.03995\n",
      "[3]\ttraining's multi_logloss: 0.83339\tvalid_1's multi_logloss: 0.859959\n",
      "[4]\ttraining's multi_logloss: 0.701367\tvalid_1's multi_logloss: 0.732793\n",
      "[5]\ttraining's multi_logloss: 0.603146\tvalid_1's multi_logloss: 0.638929\n",
      "[6]\ttraining's multi_logloss: 0.527092\tvalid_1's multi_logloss: 0.56692\n",
      "[7]\ttraining's multi_logloss: 0.467918\tvalid_1's multi_logloss: 0.511954\n",
      "[8]\ttraining's multi_logloss: 0.421265\tvalid_1's multi_logloss: 0.469254\n",
      "[9]\ttraining's multi_logloss: 0.382788\tvalid_1's multi_logloss: 0.434673\n",
      "[10]\ttraining's multi_logloss: 0.351695\tvalid_1's multi_logloss: 0.407947\n",
      "[11]\ttraining's multi_logloss: 0.326228\tvalid_1's multi_logloss: 0.38604\n",
      "[12]\ttraining's multi_logloss: 0.304099\tvalid_1's multi_logloss: 0.368683\n",
      "[13]\ttraining's multi_logloss: 0.285871\tvalid_1's multi_logloss: 0.354037\n",
      "[14]\ttraining's multi_logloss: 0.269289\tvalid_1's multi_logloss: 0.342282\n",
      "[15]\ttraining's multi_logloss: 0.255667\tvalid_1's multi_logloss: 0.333141\n",
      "[16]\ttraining's multi_logloss: 0.243054\tvalid_1's multi_logloss: 0.325802\n",
      "[17]\ttraining's multi_logloss: 0.231091\tvalid_1's multi_logloss: 0.318933\n",
      "[18]\ttraining's multi_logloss: 0.220414\tvalid_1's multi_logloss: 0.313343\n",
      "[19]\ttraining's multi_logloss: 0.211281\tvalid_1's multi_logloss: 0.308733\n",
      "[20]\ttraining's multi_logloss: 0.202822\tvalid_1's multi_logloss: 0.305603\n",
      "[21]\ttraining's multi_logloss: 0.195027\tvalid_1's multi_logloss: 0.302415\n",
      "[22]\ttraining's multi_logloss: 0.187196\tvalid_1's multi_logloss: 0.300556\n",
      "[23]\ttraining's multi_logloss: 0.179692\tvalid_1's multi_logloss: 0.298752\n",
      "[24]\ttraining's multi_logloss: 0.172694\tvalid_1's multi_logloss: 0.29657\n",
      "[25]\ttraining's multi_logloss: 0.165594\tvalid_1's multi_logloss: 0.295393\n",
      "[26]\ttraining's multi_logloss: 0.159337\tvalid_1's multi_logloss: 0.294548\n",
      "[27]\ttraining's multi_logloss: 0.153482\tvalid_1's multi_logloss: 0.293821\n",
      "[28]\ttraining's multi_logloss: 0.147799\tvalid_1's multi_logloss: 0.293432\n",
      "[29]\ttraining's multi_logloss: 0.142485\tvalid_1's multi_logloss: 0.292721\n",
      "[30]\ttraining's multi_logloss: 0.137347\tvalid_1's multi_logloss: 0.292525\n",
      "[31]\ttraining's multi_logloss: 0.132483\tvalid_1's multi_logloss: 0.292325\n",
      "[32]\ttraining's multi_logloss: 0.127548\tvalid_1's multi_logloss: 0.291934\n",
      "[33]\ttraining's multi_logloss: 0.122994\tvalid_1's multi_logloss: 0.291755\n",
      "[34]\ttraining's multi_logloss: 0.118225\tvalid_1's multi_logloss: 0.292466\n",
      "[35]\ttraining's multi_logloss: 0.114103\tvalid_1's multi_logloss: 0.292765\n",
      "[36]\ttraining's multi_logloss: 0.110206\tvalid_1's multi_logloss: 0.29288\n",
      "[37]\ttraining's multi_logloss: 0.106584\tvalid_1's multi_logloss: 0.293387\n",
      "[38]\ttraining's multi_logloss: 0.103316\tvalid_1's multi_logloss: 0.293844\n",
      "[39]\ttraining's multi_logloss: 0.10019\tvalid_1's multi_logloss: 0.29513\n",
      "[40]\ttraining's multi_logloss: 0.0970994\tvalid_1's multi_logloss: 0.296414\n",
      "[41]\ttraining's multi_logloss: 0.0938791\tvalid_1's multi_logloss: 0.297902\n",
      "[42]\ttraining's multi_logloss: 0.0911602\tvalid_1's multi_logloss: 0.298316\n",
      "[43]\ttraining's multi_logloss: 0.0884586\tvalid_1's multi_logloss: 0.298847\n",
      "[44]\ttraining's multi_logloss: 0.0857652\tvalid_1's multi_logloss: 0.299583\n",
      "[45]\ttraining's multi_logloss: 0.0833048\tvalid_1's multi_logloss: 0.300276\n",
      "[46]\ttraining's multi_logloss: 0.0807613\tvalid_1's multi_logloss: 0.301248\n",
      "[47]\ttraining's multi_logloss: 0.0782802\tvalid_1's multi_logloss: 0.302196\n",
      "[48]\ttraining's multi_logloss: 0.0761198\tvalid_1's multi_logloss: 0.303183\n",
      "[49]\ttraining's multi_logloss: 0.073264\tvalid_1's multi_logloss: 0.303783\n",
      "[50]\ttraining's multi_logloss: 0.070812\tvalid_1's multi_logloss: 0.305524\n",
      "[51]\ttraining's multi_logloss: 0.0685873\tvalid_1's multi_logloss: 0.305863\n",
      "[52]\ttraining's multi_logloss: 0.066825\tvalid_1's multi_logloss: 0.307341\n",
      "[53]\ttraining's multi_logloss: 0.0646263\tvalid_1's multi_logloss: 0.308303\n",
      "[54]\ttraining's multi_logloss: 0.0627533\tvalid_1's multi_logloss: 0.309398\n",
      "[55]\ttraining's multi_logloss: 0.0609964\tvalid_1's multi_logloss: 0.31038\n",
      "[56]\ttraining's multi_logloss: 0.0592679\tvalid_1's multi_logloss: 0.3114\n",
      "[57]\ttraining's multi_logloss: 0.0575959\tvalid_1's multi_logloss: 0.312418\n",
      "[58]\ttraining's multi_logloss: 0.0561326\tvalid_1's multi_logloss: 0.313296\n",
      "[59]\ttraining's multi_logloss: 0.0546054\tvalid_1's multi_logloss: 0.314452\n",
      "[60]\ttraining's multi_logloss: 0.0529254\tvalid_1's multi_logloss: 0.315299\n",
      "[61]\ttraining's multi_logloss: 0.0511666\tvalid_1's multi_logloss: 0.316273\n",
      "[62]\ttraining's multi_logloss: 0.0497274\tvalid_1's multi_logloss: 0.317471\n",
      "[63]\ttraining's multi_logloss: 0.0484354\tvalid_1's multi_logloss: 0.318245\n",
      "Early stopping, best iteration is:                    \n",
      "[33]\ttraining's multi_logloss: 0.122994\tvalid_1's multi_logloss: 0.291755\n",
      "[1]\ttraining's multi_logloss: 1.30771\tvalid_1's multi_logloss: 1.31473\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\ttraining's multi_logloss: 1.02362\tvalid_1's multi_logloss: 1.03546\n",
      "[3]\ttraining's multi_logloss: 0.840652\tvalid_1's multi_logloss: 0.856536\n",
      "[4]\ttraining's multi_logloss: 0.708518\tvalid_1's multi_logloss: 0.729534\n",
      "[5]\ttraining's multi_logloss: 0.609334\tvalid_1's multi_logloss: 0.635761\n",
      "[6]\ttraining's multi_logloss: 0.533618\tvalid_1's multi_logloss: 0.563626\n",
      "[7]\ttraining's multi_logloss: 0.474179\tvalid_1's multi_logloss: 0.507992\n",
      "[8]\ttraining's multi_logloss: 0.426742\tvalid_1's multi_logloss: 0.46441\n",
      "[9]\ttraining's multi_logloss: 0.387185\tvalid_1's multi_logloss: 0.429387\n",
      "[10]\ttraining's multi_logloss: 0.356084\tvalid_1's multi_logloss: 0.402678\n",
      "[11]\ttraining's multi_logloss: 0.330569\tvalid_1's multi_logloss: 0.381007\n",
      "[12]\ttraining's multi_logloss: 0.308241\tvalid_1's multi_logloss: 0.362925\n",
      "[13]\ttraining's multi_logloss: 0.288151\tvalid_1's multi_logloss: 0.346914\n",
      "[14]\ttraining's multi_logloss: 0.272254\tvalid_1's multi_logloss: 0.335706\n",
      "[15]\ttraining's multi_logloss: 0.257348\tvalid_1's multi_logloss: 0.324984\n",
      "[16]\ttraining's multi_logloss: 0.244342\tvalid_1's multi_logloss: 0.317572\n",
      "[17]\ttraining's multi_logloss: 0.232071\tvalid_1's multi_logloss: 0.31131\n",
      "[18]\ttraining's multi_logloss: 0.221435\tvalid_1's multi_logloss: 0.306272\n",
      "[19]\ttraining's multi_logloss: 0.21213\tvalid_1's multi_logloss: 0.302085\n",
      "[20]\ttraining's multi_logloss: 0.20321\tvalid_1's multi_logloss: 0.298444\n",
      "[21]\ttraining's multi_logloss: 0.195197\tvalid_1's multi_logloss: 0.296493\n",
      "[22]\ttraining's multi_logloss: 0.18746\tvalid_1's multi_logloss: 0.294452\n",
      "[23]\ttraining's multi_logloss: 0.180315\tvalid_1's multi_logloss: 0.292597\n",
      "[24]\ttraining's multi_logloss: 0.173551\tvalid_1's multi_logloss: 0.290838\n",
      "[25]\ttraining's multi_logloss: 0.166983\tvalid_1's multi_logloss: 0.289631\n",
      "[26]\ttraining's multi_logloss: 0.160599\tvalid_1's multi_logloss: 0.288187\n",
      "[27]\ttraining's multi_logloss: 0.154611\tvalid_1's multi_logloss: 0.287296\n",
      "[28]\ttraining's multi_logloss: 0.148748\tvalid_1's multi_logloss: 0.286227\n",
      "[29]\ttraining's multi_logloss: 0.143348\tvalid_1's multi_logloss: 0.285573\n",
      "[30]\ttraining's multi_logloss: 0.138312\tvalid_1's multi_logloss: 0.285031\n",
      "[31]\ttraining's multi_logloss: 0.133491\tvalid_1's multi_logloss: 0.285238\n",
      "[32]\ttraining's multi_logloss: 0.128723\tvalid_1's multi_logloss: 0.284845\n",
      "[33]\ttraining's multi_logloss: 0.124166\tvalid_1's multi_logloss: 0.284745\n",
      "[34]\ttraining's multi_logloss: 0.119688\tvalid_1's multi_logloss: 0.284308\n",
      "[35]\ttraining's multi_logloss: 0.115583\tvalid_1's multi_logloss: 0.285086\n",
      "[36]\ttraining's multi_logloss: 0.111201\tvalid_1's multi_logloss: 0.285335\n",
      "[37]\ttraining's multi_logloss: 0.107458\tvalid_1's multi_logloss: 0.285584\n",
      "[38]\ttraining's multi_logloss: 0.103705\tvalid_1's multi_logloss: 0.286085\n",
      "[39]\ttraining's multi_logloss: 0.100031\tvalid_1's multi_logloss: 0.286177\n",
      "[40]\ttraining's multi_logloss: 0.0965788\tvalid_1's multi_logloss: 0.286713\n",
      "[41]\ttraining's multi_logloss: 0.0937062\tvalid_1's multi_logloss: 0.287247\n",
      "[42]\ttraining's multi_logloss: 0.0904039\tvalid_1's multi_logloss: 0.288763\n",
      "[43]\ttraining's multi_logloss: 0.087602\tvalid_1's multi_logloss: 0.289897\n",
      "[44]\ttraining's multi_logloss: 0.0846477\tvalid_1's multi_logloss: 0.290495\n",
      "[45]\ttraining's multi_logloss: 0.0820657\tvalid_1's multi_logloss: 0.291225\n",
      "[46]\ttraining's multi_logloss: 0.079087\tvalid_1's multi_logloss: 0.291781\n",
      "[47]\ttraining's multi_logloss: 0.0766679\tvalid_1's multi_logloss: 0.29182\n",
      "[48]\ttraining's multi_logloss: 0.0738574\tvalid_1's multi_logloss: 0.292226\n",
      "[49]\ttraining's multi_logloss: 0.0717929\tvalid_1's multi_logloss: 0.292561\n",
      "[50]\ttraining's multi_logloss: 0.0696134\tvalid_1's multi_logloss: 0.293823\n",
      "[51]\ttraining's multi_logloss: 0.0674971\tvalid_1's multi_logloss: 0.294842\n",
      "[52]\ttraining's multi_logloss: 0.0649753\tvalid_1's multi_logloss: 0.295669\n",
      "[53]\ttraining's multi_logloss: 0.0630297\tvalid_1's multi_logloss: 0.296905\n",
      "[54]\ttraining's multi_logloss: 0.0608688\tvalid_1's multi_logloss: 0.298049\n",
      "[55]\ttraining's multi_logloss: 0.0589581\tvalid_1's multi_logloss: 0.299355\n",
      "[56]\ttraining's multi_logloss: 0.0571722\tvalid_1's multi_logloss: 0.300115\n",
      "[57]\ttraining's multi_logloss: 0.0552307\tvalid_1's multi_logloss: 0.301258\n",
      "[58]\ttraining's multi_logloss: 0.0535063\tvalid_1's multi_logloss: 0.302862\n",
      "[59]\ttraining's multi_logloss: 0.0519045\tvalid_1's multi_logloss: 0.304742\n",
      "[60]\ttraining's multi_logloss: 0.0502286\tvalid_1's multi_logloss: 0.305919\n",
      "[61]\ttraining's multi_logloss: 0.0488567\tvalid_1's multi_logloss: 0.307019\n",
      "[62]\ttraining's multi_logloss: 0.0473005\tvalid_1's multi_logloss: 0.308753\n",
      "[63]\ttraining's multi_logloss: 0.0459927\tvalid_1's multi_logloss: 0.310535\n",
      "[64]\ttraining's multi_logloss: 0.0446955\tvalid_1's multi_logloss: 0.311602\n",
      "Early stopping, best iteration is:                    \n",
      "[34]\ttraining's multi_logloss: 0.119688\tvalid_1's multi_logloss: 0.284308\n",
      "[1]\ttraining's multi_logloss: 1.31081\tvalid_1's multi_logloss: 1.31607\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\ttraining's multi_logloss: 1.02766\tvalid_1's multi_logloss: 1.03566\n",
      "[3]\ttraining's multi_logloss: 0.843448\tvalid_1's multi_logloss: 0.854444\n",
      "[4]\ttraining's multi_logloss: 0.710398\tvalid_1's multi_logloss: 0.724112\n",
      "[5]\ttraining's multi_logloss: 0.61287\tvalid_1's multi_logloss: 0.630217\n",
      "[6]\ttraining's multi_logloss: 0.537224\tvalid_1's multi_logloss: 0.557516\n",
      "[7]\ttraining's multi_logloss: 0.477467\tvalid_1's multi_logloss: 0.501076\n",
      "[8]\ttraining's multi_logloss: 0.430982\tvalid_1's multi_logloss: 0.457832\n",
      "[9]\ttraining's multi_logloss: 0.393116\tvalid_1's multi_logloss: 0.423717\n",
      "[10]\ttraining's multi_logloss: 0.361418\tvalid_1's multi_logloss: 0.395145\n",
      "[11]\ttraining's multi_logloss: 0.335399\tvalid_1's multi_logloss: 0.372886\n",
      "[12]\ttraining's multi_logloss: 0.312851\tvalid_1's multi_logloss: 0.3546\n",
      "[13]\ttraining's multi_logloss: 0.293495\tvalid_1's multi_logloss: 0.339194\n",
      "[14]\ttraining's multi_logloss: 0.277722\tvalid_1's multi_logloss: 0.327212\n",
      "[15]\ttraining's multi_logloss: 0.263292\tvalid_1's multi_logloss: 0.317376\n",
      "[16]\ttraining's multi_logloss: 0.250317\tvalid_1's multi_logloss: 0.309669\n",
      "[17]\ttraining's multi_logloss: 0.238245\tvalid_1's multi_logloss: 0.302974\n",
      "[18]\ttraining's multi_logloss: 0.22788\tvalid_1's multi_logloss: 0.297504\n",
      "[19]\ttraining's multi_logloss: 0.218535\tvalid_1's multi_logloss: 0.293134\n",
      "[20]\ttraining's multi_logloss: 0.209499\tvalid_1's multi_logloss: 0.289292\n",
      "[21]\ttraining's multi_logloss: 0.201581\tvalid_1's multi_logloss: 0.286238\n",
      "[22]\ttraining's multi_logloss: 0.193651\tvalid_1's multi_logloss: 0.284096\n",
      "[23]\ttraining's multi_logloss: 0.186146\tvalid_1's multi_logloss: 0.281915\n",
      "[24]\ttraining's multi_logloss: 0.17906\tvalid_1's multi_logloss: 0.279753\n",
      "[25]\ttraining's multi_logloss: 0.1726\tvalid_1's multi_logloss: 0.278962\n",
      "[26]\ttraining's multi_logloss: 0.166039\tvalid_1's multi_logloss: 0.277396\n",
      "[27]\ttraining's multi_logloss: 0.160129\tvalid_1's multi_logloss: 0.276719\n",
      "[28]\ttraining's multi_logloss: 0.154098\tvalid_1's multi_logloss: 0.275754\n",
      "[29]\ttraining's multi_logloss: 0.148676\tvalid_1's multi_logloss: 0.275607\n",
      "[30]\ttraining's multi_logloss: 0.143234\tvalid_1's multi_logloss: 0.275022\n",
      "[31]\ttraining's multi_logloss: 0.137932\tvalid_1's multi_logloss: 0.274564\n",
      "[32]\ttraining's multi_logloss: 0.132785\tvalid_1's multi_logloss: 0.274056\n",
      "[33]\ttraining's multi_logloss: 0.128102\tvalid_1's multi_logloss: 0.273524\n",
      "[34]\ttraining's multi_logloss: 0.123908\tvalid_1's multi_logloss: 0.273461\n",
      "[35]\ttraining's multi_logloss: 0.11956\tvalid_1's multi_logloss: 0.272983\n",
      "[36]\ttraining's multi_logloss: 0.115859\tvalid_1's multi_logloss: 0.273457\n",
      "[37]\ttraining's multi_logloss: 0.111893\tvalid_1's multi_logloss: 0.273123\n",
      "[38]\ttraining's multi_logloss: 0.108156\tvalid_1's multi_logloss: 0.273769\n",
      "[39]\ttraining's multi_logloss: 0.104516\tvalid_1's multi_logloss: 0.274294\n",
      "[40]\ttraining's multi_logloss: 0.101219\tvalid_1's multi_logloss: 0.27486\n",
      "[41]\ttraining's multi_logloss: 0.0978122\tvalid_1's multi_logloss: 0.275236\n",
      "[42]\ttraining's multi_logloss: 0.094455\tvalid_1's multi_logloss: 0.275036\n",
      "[43]\ttraining's multi_logloss: 0.0914875\tvalid_1's multi_logloss: 0.275562\n",
      "[44]\ttraining's multi_logloss: 0.0887642\tvalid_1's multi_logloss: 0.276016\n",
      "[45]\ttraining's multi_logloss: 0.0856629\tvalid_1's multi_logloss: 0.276775\n",
      "[46]\ttraining's multi_logloss: 0.0828185\tvalid_1's multi_logloss: 0.277172\n",
      "[47]\ttraining's multi_logloss: 0.0800158\tvalid_1's multi_logloss: 0.278374\n",
      "[48]\ttraining's multi_logloss: 0.0774701\tvalid_1's multi_logloss: 0.279164\n",
      "[49]\ttraining's multi_logloss: 0.0751051\tvalid_1's multi_logloss: 0.28013\n",
      "[50]\ttraining's multi_logloss: 0.0726469\tvalid_1's multi_logloss: 0.280805\n",
      "[51]\ttraining's multi_logloss: 0.0703853\tvalid_1's multi_logloss: 0.281147\n",
      "[52]\ttraining's multi_logloss: 0.068257\tvalid_1's multi_logloss: 0.281995\n",
      "[53]\ttraining's multi_logloss: 0.0660991\tvalid_1's multi_logloss: 0.282625\n",
      "[54]\ttraining's multi_logloss: 0.0642845\tvalid_1's multi_logloss: 0.283131\n",
      "[55]\ttraining's multi_logloss: 0.0624678\tvalid_1's multi_logloss: 0.283853\n",
      "[56]\ttraining's multi_logloss: 0.0606308\tvalid_1's multi_logloss: 0.284874\n",
      "[57]\ttraining's multi_logloss: 0.0588304\tvalid_1's multi_logloss: 0.285074\n",
      "[58]\ttraining's multi_logloss: 0.0570972\tvalid_1's multi_logloss: 0.285695\n",
      "[59]\ttraining's multi_logloss: 0.0551791\tvalid_1's multi_logloss: 0.286236\n",
      "[60]\ttraining's multi_logloss: 0.0536368\tvalid_1's multi_logloss: 0.287537\n",
      "[61]\ttraining's multi_logloss: 0.0518671\tvalid_1's multi_logloss: 0.287854\n",
      "[62]\ttraining's multi_logloss: 0.0503005\tvalid_1's multi_logloss: 0.288426\n",
      "[63]\ttraining's multi_logloss: 0.0489528\tvalid_1's multi_logloss: 0.289751\n",
      "[64]\ttraining's multi_logloss: 0.0476027\tvalid_1's multi_logloss: 0.290736\n",
      "[65]\ttraining's multi_logloss: 0.0464027\tvalid_1's multi_logloss: 0.292207\n",
      "Early stopping, best iteration is:                    \n",
      "[35]\ttraining's multi_logloss: 0.11956\tvalid_1's multi_logloss: 0.272983\n",
      "[1]\ttraining's multi_logloss: 1.44877\tvalid_1's multi_logloss: 1.45706           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.18152\tvalid_1's multi_logloss: 1.19768           \n",
      "[3]\ttraining's multi_logloss: 0.995049\tvalid_1's multi_logloss: 1.01713          \n",
      "[4]\ttraining's multi_logloss: 0.856475\tvalid_1's multi_logloss: 0.88286          \n",
      "[5]\ttraining's multi_logloss: 0.749516\tvalid_1's multi_logloss: 0.779782         \n",
      "[6]\ttraining's multi_logloss: 0.664459\tvalid_1's multi_logloss: 0.698313         \n",
      "[7]\ttraining's multi_logloss: 0.595437\tvalid_1's multi_logloss: 0.631566         \n",
      "[8]\ttraining's multi_logloss: 0.538427\tvalid_1's multi_logloss: 0.577909         \n",
      "[9]\ttraining's multi_logloss: 0.491265\tvalid_1's multi_logloss: 0.533314         \n",
      "[10]\ttraining's multi_logloss: 0.451352\tvalid_1's multi_logloss: 0.496717        \n",
      "[11]\ttraining's multi_logloss: 0.417211\tvalid_1's multi_logloss: 0.465669        \n",
      "[12]\ttraining's multi_logloss: 0.387636\tvalid_1's multi_logloss: 0.439505        \n",
      "[13]\ttraining's multi_logloss: 0.362968\tvalid_1's multi_logloss: 0.417259        \n",
      "[14]\ttraining's multi_logloss: 0.341263\tvalid_1's multi_logloss: 0.398672        \n",
      "[15]\ttraining's multi_logloss: 0.323084\tvalid_1's multi_logloss: 0.383383        \n",
      "[16]\ttraining's multi_logloss: 0.306813\tvalid_1's multi_logloss: 0.370558        \n",
      "[17]\ttraining's multi_logloss: 0.292174\tvalid_1's multi_logloss: 0.359422        \n",
      "[18]\ttraining's multi_logloss: 0.27934\tvalid_1's multi_logloss: 0.34994          \n",
      "[19]\ttraining's multi_logloss: 0.267265\tvalid_1's multi_logloss: 0.341288        \n",
      "[20]\ttraining's multi_logloss: 0.25679\tvalid_1's multi_logloss: 0.333973         \n",
      "[21]\ttraining's multi_logloss: 0.247096\tvalid_1's multi_logloss: 0.328066        \n",
      "[22]\ttraining's multi_logloss: 0.237776\tvalid_1's multi_logloss: 0.322849        \n",
      "[23]\ttraining's multi_logloss: 0.229311\tvalid_1's multi_logloss: 0.318219        \n",
      "[24]\ttraining's multi_logloss: 0.221585\tvalid_1's multi_logloss: 0.314755        \n",
      "[25]\ttraining's multi_logloss: 0.214288\tvalid_1's multi_logloss: 0.310813        \n",
      "[26]\ttraining's multi_logloss: 0.207727\tvalid_1's multi_logloss: 0.308175        \n",
      "[27]\ttraining's multi_logloss: 0.201083\tvalid_1's multi_logloss: 0.304833        \n",
      "[28]\ttraining's multi_logloss: 0.195076\tvalid_1's multi_logloss: 0.302487        \n",
      "[29]\ttraining's multi_logloss: 0.189077\tvalid_1's multi_logloss: 0.300271        \n",
      "[30]\ttraining's multi_logloss: 0.183247\tvalid_1's multi_logloss: 0.298605        \n",
      "[31]\ttraining's multi_logloss: 0.178158\tvalid_1's multi_logloss: 0.297596        \n",
      "[32]\ttraining's multi_logloss: 0.173142\tvalid_1's multi_logloss: 0.296724        \n",
      "[33]\ttraining's multi_logloss: 0.168215\tvalid_1's multi_logloss: 0.295617        \n",
      "[34]\ttraining's multi_logloss: 0.163475\tvalid_1's multi_logloss: 0.29482         \n",
      "[35]\ttraining's multi_logloss: 0.158543\tvalid_1's multi_logloss: 0.29431         \n",
      "[36]\ttraining's multi_logloss: 0.154201\tvalid_1's multi_logloss: 0.293635        \n",
      "[37]\ttraining's multi_logloss: 0.150029\tvalid_1's multi_logloss: 0.293678        \n",
      "[38]\ttraining's multi_logloss: 0.146092\tvalid_1's multi_logloss: 0.293254        \n",
      "[39]\ttraining's multi_logloss: 0.142039\tvalid_1's multi_logloss: 0.292738        \n",
      "[40]\ttraining's multi_logloss: 0.138313\tvalid_1's multi_logloss: 0.293077        \n",
      "[41]\ttraining's multi_logloss: 0.134679\tvalid_1's multi_logloss: 0.293279        \n",
      "[42]\ttraining's multi_logloss: 0.131227\tvalid_1's multi_logloss: 0.292956        \n",
      "[43]\ttraining's multi_logloss: 0.127701\tvalid_1's multi_logloss: 0.292993        \n",
      "[44]\ttraining's multi_logloss: 0.123976\tvalid_1's multi_logloss: 0.292718        \n",
      "[45]\ttraining's multi_logloss: 0.120417\tvalid_1's multi_logloss: 0.292869        \n",
      "[46]\ttraining's multi_logloss: 0.117392\tvalid_1's multi_logloss: 0.29281         \n",
      "[47]\ttraining's multi_logloss: 0.114214\tvalid_1's multi_logloss: 0.293053        \n",
      "[48]\ttraining's multi_logloss: 0.111262\tvalid_1's multi_logloss: 0.292939        \n",
      "[49]\ttraining's multi_logloss: 0.108336\tvalid_1's multi_logloss: 0.293319        \n",
      "[50]\ttraining's multi_logloss: 0.10576\tvalid_1's multi_logloss: 0.293573         \n",
      "[51]\ttraining's multi_logloss: 0.103245\tvalid_1's multi_logloss: 0.293945        \n",
      "[52]\ttraining's multi_logloss: 0.100347\tvalid_1's multi_logloss: 0.294081        \n",
      "[53]\ttraining's multi_logloss: 0.0978512\tvalid_1's multi_logloss: 0.294264       \n",
      "[54]\ttraining's multi_logloss: 0.0955026\tvalid_1's multi_logloss: 0.294995       \n",
      "[55]\ttraining's multi_logloss: 0.093107\tvalid_1's multi_logloss: 0.295128        \n",
      "[56]\ttraining's multi_logloss: 0.0908256\tvalid_1's multi_logloss: 0.29542        \n",
      "[57]\ttraining's multi_logloss: 0.0883053\tvalid_1's multi_logloss: 0.295493       \n",
      "[58]\ttraining's multi_logloss: 0.0862351\tvalid_1's multi_logloss: 0.296036       \n",
      "[59]\ttraining's multi_logloss: 0.0841318\tvalid_1's multi_logloss: 0.296824       \n",
      "[60]\ttraining's multi_logloss: 0.0823788\tvalid_1's multi_logloss: 0.296996       \n",
      "[61]\ttraining's multi_logloss: 0.080576\tvalid_1's multi_logloss: 0.297843        \n",
      "[62]\ttraining's multi_logloss: 0.0786802\tvalid_1's multi_logloss: 0.29881        \n",
      "[63]\ttraining's multi_logloss: 0.0770623\tvalid_1's multi_logloss: 0.299209       \n",
      "[64]\ttraining's multi_logloss: 0.0751744\tvalid_1's multi_logloss: 0.2997         \n",
      "[65]\ttraining's multi_logloss: 0.0732553\tvalid_1's multi_logloss: 0.300441       \n",
      "[66]\ttraining's multi_logloss: 0.0717923\tvalid_1's multi_logloss: 0.300977       \n",
      "[67]\ttraining's multi_logloss: 0.0703107\tvalid_1's multi_logloss: 0.301477       \n",
      "[68]\ttraining's multi_logloss: 0.0688491\tvalid_1's multi_logloss: 0.302513       \n",
      "[69]\ttraining's multi_logloss: 0.067055\tvalid_1's multi_logloss: 0.303454        \n",
      "[70]\ttraining's multi_logloss: 0.0656182\tvalid_1's multi_logloss: 0.304234       \n",
      "[71]\ttraining's multi_logloss: 0.0642272\tvalid_1's multi_logloss: 0.305124       \n",
      "[72]\ttraining's multi_logloss: 0.0626352\tvalid_1's multi_logloss: 0.305821       \n",
      "[73]\ttraining's multi_logloss: 0.0614934\tvalid_1's multi_logloss: 0.306604       \n",
      "[74]\ttraining's multi_logloss: 0.0600096\tvalid_1's multi_logloss: 0.306823       \n",
      "Early stopping, best iteration is:                                               \n",
      "[44]\ttraining's multi_logloss: 0.123976\tvalid_1's multi_logloss: 0.292718\n",
      "[1]\ttraining's multi_logloss: 1.44714\tvalid_1's multi_logloss: 1.45248           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.18028\tvalid_1's multi_logloss: 1.18969           \n",
      "[3]\ttraining's multi_logloss: 0.998559\tvalid_1's multi_logloss: 1.00971          \n",
      "[4]\ttraining's multi_logloss: 0.863277\tvalid_1's multi_logloss: 0.877239         \n",
      "[5]\ttraining's multi_logloss: 0.756863\tvalid_1's multi_logloss: 0.77347          \n",
      "[6]\ttraining's multi_logloss: 0.672272\tvalid_1's multi_logloss: 0.692985         \n",
      "[7]\ttraining's multi_logloss: 0.603305\tvalid_1's multi_logloss: 0.62735          \n",
      "[8]\ttraining's multi_logloss: 0.545776\tvalid_1's multi_logloss: 0.572627         \n",
      "[9]\ttraining's multi_logloss: 0.497952\tvalid_1's multi_logloss: 0.527788         \n",
      "[10]\ttraining's multi_logloss: 0.457745\tvalid_1's multi_logloss: 0.49056         \n",
      "[11]\ttraining's multi_logloss: 0.423186\tvalid_1's multi_logloss: 0.459242        \n",
      "[12]\ttraining's multi_logloss: 0.394114\tvalid_1's multi_logloss: 0.434014        \n",
      "[13]\ttraining's multi_logloss: 0.369634\tvalid_1's multi_logloss: 0.412737        \n",
      "[14]\ttraining's multi_logloss: 0.347869\tvalid_1's multi_logloss: 0.393842        \n",
      "[15]\ttraining's multi_logloss: 0.329015\tvalid_1's multi_logloss: 0.378047        \n",
      "[16]\ttraining's multi_logloss: 0.312492\tvalid_1's multi_logloss: 0.365554        \n",
      "[17]\ttraining's multi_logloss: 0.297158\tvalid_1's multi_logloss: 0.35297         \n",
      "[18]\ttraining's multi_logloss: 0.28388\tvalid_1's multi_logloss: 0.342759         \n",
      "[19]\ttraining's multi_logloss: 0.271238\tvalid_1's multi_logloss: 0.334069        \n",
      "[20]\ttraining's multi_logloss: 0.260338\tvalid_1's multi_logloss: 0.326738        \n",
      "[21]\ttraining's multi_logloss: 0.2502\tvalid_1's multi_logloss: 0.320246          \n",
      "[22]\ttraining's multi_logloss: 0.240639\tvalid_1's multi_logloss: 0.314909        \n",
      "[23]\ttraining's multi_logloss: 0.231948\tvalid_1's multi_logloss: 0.310519        \n",
      "[24]\ttraining's multi_logloss: 0.223574\tvalid_1's multi_logloss: 0.306679        \n",
      "[25]\ttraining's multi_logloss: 0.216131\tvalid_1's multi_logloss: 0.304129        \n",
      "[26]\ttraining's multi_logloss: 0.208948\tvalid_1's multi_logloss: 0.300991        \n",
      "[27]\ttraining's multi_logloss: 0.202243\tvalid_1's multi_logloss: 0.298429        \n",
      "[28]\ttraining's multi_logloss: 0.196186\tvalid_1's multi_logloss: 0.296371        \n",
      "[29]\ttraining's multi_logloss: 0.190299\tvalid_1's multi_logloss: 0.294283        \n",
      "[30]\ttraining's multi_logloss: 0.18429\tvalid_1's multi_logloss: 0.292633         \n",
      "[31]\ttraining's multi_logloss: 0.178974\tvalid_1's multi_logloss: 0.291728        \n",
      "[32]\ttraining's multi_logloss: 0.173453\tvalid_1's multi_logloss: 0.290453        \n",
      "[33]\ttraining's multi_logloss: 0.168108\tvalid_1's multi_logloss: 0.289171        \n",
      "[34]\ttraining's multi_logloss: 0.163091\tvalid_1's multi_logloss: 0.288465        \n",
      "[35]\ttraining's multi_logloss: 0.158549\tvalid_1's multi_logloss: 0.28764         \n",
      "[36]\ttraining's multi_logloss: 0.154135\tvalid_1's multi_logloss: 0.286879        \n",
      "[37]\ttraining's multi_logloss: 0.149641\tvalid_1's multi_logloss: 0.286331        \n",
      "[38]\ttraining's multi_logloss: 0.145512\tvalid_1's multi_logloss: 0.285553        \n",
      "[39]\ttraining's multi_logloss: 0.141564\tvalid_1's multi_logloss: 0.285012        \n",
      "[40]\ttraining's multi_logloss: 0.137464\tvalid_1's multi_logloss: 0.284284        \n",
      "[41]\ttraining's multi_logloss: 0.133789\tvalid_1's multi_logloss: 0.284398        \n",
      "[42]\ttraining's multi_logloss: 0.130034\tvalid_1's multi_logloss: 0.284541        \n",
      "[43]\ttraining's multi_logloss: 0.12655\tvalid_1's multi_logloss: 0.284939         \n",
      "[44]\ttraining's multi_logloss: 0.123181\tvalid_1's multi_logloss: 0.284842        \n",
      "[45]\ttraining's multi_logloss: 0.119956\tvalid_1's multi_logloss: 0.285292        \n",
      "[46]\ttraining's multi_logloss: 0.116892\tvalid_1's multi_logloss: 0.285224        \n",
      "[47]\ttraining's multi_logloss: 0.113541\tvalid_1's multi_logloss: 0.285332        \n",
      "[48]\ttraining's multi_logloss: 0.110371\tvalid_1's multi_logloss: 0.28581         \n",
      "[49]\ttraining's multi_logloss: 0.107298\tvalid_1's multi_logloss: 0.286056        \n",
      "[50]\ttraining's multi_logloss: 0.104587\tvalid_1's multi_logloss: 0.285938        \n",
      "[51]\ttraining's multi_logloss: 0.101812\tvalid_1's multi_logloss: 0.286507        \n",
      "[52]\ttraining's multi_logloss: 0.099101\tvalid_1's multi_logloss: 0.286348        \n",
      "[53]\ttraining's multi_logloss: 0.0965262\tvalid_1's multi_logloss: 0.286672       \n",
      "[54]\ttraining's multi_logloss: 0.0941681\tvalid_1's multi_logloss: 0.287187       \n",
      "[55]\ttraining's multi_logloss: 0.0918358\tvalid_1's multi_logloss: 0.287153       \n",
      "[56]\ttraining's multi_logloss: 0.0896859\tvalid_1's multi_logloss: 0.288014       \n",
      "[57]\ttraining's multi_logloss: 0.0874899\tvalid_1's multi_logloss: 0.288817       \n",
      "[58]\ttraining's multi_logloss: 0.0853176\tvalid_1's multi_logloss: 0.289352       \n",
      "[59]\ttraining's multi_logloss: 0.0833013\tvalid_1's multi_logloss: 0.289895       \n",
      "[60]\ttraining's multi_logloss: 0.081328\tvalid_1's multi_logloss: 0.290195        \n",
      "[61]\ttraining's multi_logloss: 0.0791808\tvalid_1's multi_logloss: 0.290635       \n",
      "[62]\ttraining's multi_logloss: 0.0771366\tvalid_1's multi_logloss: 0.291269       \n",
      "[63]\ttraining's multi_logloss: 0.0752077\tvalid_1's multi_logloss: 0.291431       \n",
      "[64]\ttraining's multi_logloss: 0.0735393\tvalid_1's multi_logloss: 0.29231        \n",
      "[65]\ttraining's multi_logloss: 0.071827\tvalid_1's multi_logloss: 0.292953        \n",
      "[66]\ttraining's multi_logloss: 0.070017\tvalid_1's multi_logloss: 0.293532        \n",
      "[67]\ttraining's multi_logloss: 0.0682869\tvalid_1's multi_logloss: 0.294538       \n",
      "[68]\ttraining's multi_logloss: 0.066818\tvalid_1's multi_logloss: 0.295271        \n",
      "[69]\ttraining's multi_logloss: 0.0652448\tvalid_1's multi_logloss: 0.296222       \n",
      "[70]\ttraining's multi_logloss: 0.0636993\tvalid_1's multi_logloss: 0.297377       \n",
      "Early stopping, best iteration is:                                               \n",
      "[40]\ttraining's multi_logloss: 0.137464\tvalid_1's multi_logloss: 0.284284\n",
      "[1]\ttraining's multi_logloss: 1.45061\tvalid_1's multi_logloss: 1.45508           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.18397\tvalid_1's multi_logloss: 1.19094           \n",
      "[3]\ttraining's multi_logloss: 1.00304\tvalid_1's multi_logloss: 1.01269           \n",
      "[4]\ttraining's multi_logloss: 0.866439\tvalid_1's multi_logloss: 0.878205         \n",
      "[5]\ttraining's multi_logloss: 0.758067\tvalid_1's multi_logloss: 0.7719           \n",
      "[6]\ttraining's multi_logloss: 0.672939\tvalid_1's multi_logloss: 0.689299         \n",
      "[7]\ttraining's multi_logloss: 0.604771\tvalid_1's multi_logloss: 0.623421         \n",
      "[8]\ttraining's multi_logloss: 0.546961\tvalid_1's multi_logloss: 0.567837         \n",
      "[9]\ttraining's multi_logloss: 0.49936\tvalid_1's multi_logloss: 0.522668          \n",
      "[10]\ttraining's multi_logloss: 0.459513\tvalid_1's multi_logloss: 0.485049        \n",
      "[11]\ttraining's multi_logloss: 0.426397\tvalid_1's multi_logloss: 0.454247        \n",
      "[12]\ttraining's multi_logloss: 0.397633\tvalid_1's multi_logloss: 0.428046        \n",
      "[13]\ttraining's multi_logloss: 0.372738\tvalid_1's multi_logloss: 0.405803        \n",
      "[14]\ttraining's multi_logloss: 0.350819\tvalid_1's multi_logloss: 0.38616         \n",
      "[15]\ttraining's multi_logloss: 0.332091\tvalid_1's multi_logloss: 0.370658        \n",
      "[16]\ttraining's multi_logloss: 0.315695\tvalid_1's multi_logloss: 0.357306        \n",
      "[17]\ttraining's multi_logloss: 0.301033\tvalid_1's multi_logloss: 0.345676        \n",
      "[18]\ttraining's multi_logloss: 0.287528\tvalid_1's multi_logloss: 0.334888        \n",
      "[19]\ttraining's multi_logloss: 0.275689\tvalid_1's multi_logloss: 0.326616        \n",
      "[20]\ttraining's multi_logloss: 0.264608\tvalid_1's multi_logloss: 0.318917        \n",
      "[21]\ttraining's multi_logloss: 0.254492\tvalid_1's multi_logloss: 0.312778        \n",
      "[22]\ttraining's multi_logloss: 0.245334\tvalid_1's multi_logloss: 0.307246        \n",
      "[23]\ttraining's multi_logloss: 0.237195\tvalid_1's multi_logloss: 0.302609        \n",
      "[24]\ttraining's multi_logloss: 0.229445\tvalid_1's multi_logloss: 0.298202        \n",
      "[25]\ttraining's multi_logloss: 0.222197\tvalid_1's multi_logloss: 0.294538        \n",
      "[26]\ttraining's multi_logloss: 0.215262\tvalid_1's multi_logloss: 0.291458        \n",
      "[27]\ttraining's multi_logloss: 0.208819\tvalid_1's multi_logloss: 0.288968        \n",
      "[28]\ttraining's multi_logloss: 0.202714\tvalid_1's multi_logloss: 0.286528        \n",
      "[29]\ttraining's multi_logloss: 0.19675\tvalid_1's multi_logloss: 0.283745         \n",
      "[30]\ttraining's multi_logloss: 0.191083\tvalid_1's multi_logloss: 0.282006        \n",
      "[31]\ttraining's multi_logloss: 0.185431\tvalid_1's multi_logloss: 0.280741        \n",
      "[32]\ttraining's multi_logloss: 0.18029\tvalid_1's multi_logloss: 0.279106         \n",
      "[33]\ttraining's multi_logloss: 0.175234\tvalid_1's multi_logloss: 0.277721        \n",
      "[34]\ttraining's multi_logloss: 0.170049\tvalid_1's multi_logloss: 0.276343        \n",
      "[35]\ttraining's multi_logloss: 0.165112\tvalid_1's multi_logloss: 0.27531         \n",
      "[36]\ttraining's multi_logloss: 0.160516\tvalid_1's multi_logloss: 0.274816        \n",
      "[37]\ttraining's multi_logloss: 0.155928\tvalid_1's multi_logloss: 0.273829        \n",
      "[38]\ttraining's multi_logloss: 0.151643\tvalid_1's multi_logloss: 0.2728          \n",
      "[39]\ttraining's multi_logloss: 0.147206\tvalid_1's multi_logloss: 0.272329        \n",
      "[40]\ttraining's multi_logloss: 0.143232\tvalid_1's multi_logloss: 0.272029        \n",
      "[41]\ttraining's multi_logloss: 0.139537\tvalid_1's multi_logloss: 0.271329        \n",
      "[42]\ttraining's multi_logloss: 0.135851\tvalid_1's multi_logloss: 0.271298        \n",
      "[43]\ttraining's multi_logloss: 0.132105\tvalid_1's multi_logloss: 0.271113        \n",
      "[44]\ttraining's multi_logloss: 0.128729\tvalid_1's multi_logloss: 0.2715          \n",
      "[45]\ttraining's multi_logloss: 0.125209\tvalid_1's multi_logloss: 0.270884        \n",
      "[46]\ttraining's multi_logloss: 0.122072\tvalid_1's multi_logloss: 0.271245        \n",
      "[47]\ttraining's multi_logloss: 0.11904\tvalid_1's multi_logloss: 0.271331         \n",
      "[48]\ttraining's multi_logloss: 0.116117\tvalid_1's multi_logloss: 0.27143         \n",
      "[49]\ttraining's multi_logloss: 0.113237\tvalid_1's multi_logloss: 0.271473        \n",
      "[50]\ttraining's multi_logloss: 0.110457\tvalid_1's multi_logloss: 0.271799        \n",
      "[51]\ttraining's multi_logloss: 0.107837\tvalid_1's multi_logloss: 0.272133        \n",
      "[52]\ttraining's multi_logloss: 0.105176\tvalid_1's multi_logloss: 0.272071        \n",
      "[53]\ttraining's multi_logloss: 0.102584\tvalid_1's multi_logloss: 0.272146        \n",
      "[54]\ttraining's multi_logloss: 0.100186\tvalid_1's multi_logloss: 0.272551        \n",
      "[55]\ttraining's multi_logloss: 0.0978001\tvalid_1's multi_logloss: 0.273355       \n",
      "[56]\ttraining's multi_logloss: 0.0954835\tvalid_1's multi_logloss: 0.272918       \n",
      "[57]\ttraining's multi_logloss: 0.0933088\tvalid_1's multi_logloss: 0.273211       \n",
      "[58]\ttraining's multi_logloss: 0.09116\tvalid_1's multi_logloss: 0.273895         \n",
      "[59]\ttraining's multi_logloss: 0.0890576\tvalid_1's multi_logloss: 0.274209       \n",
      "[60]\ttraining's multi_logloss: 0.0867695\tvalid_1's multi_logloss: 0.274688       \n",
      "[61]\ttraining's multi_logloss: 0.0848075\tvalid_1's multi_logloss: 0.275142       \n",
      "[62]\ttraining's multi_logloss: 0.0827819\tvalid_1's multi_logloss: 0.275394       \n",
      "[63]\ttraining's multi_logloss: 0.0809926\tvalid_1's multi_logloss: 0.275685       \n",
      "[64]\ttraining's multi_logloss: 0.0793349\tvalid_1's multi_logloss: 0.276151       \n",
      "[65]\ttraining's multi_logloss: 0.0777022\tvalid_1's multi_logloss: 0.276949       \n",
      "[66]\ttraining's multi_logloss: 0.0759533\tvalid_1's multi_logloss: 0.277128       \n",
      "[67]\ttraining's multi_logloss: 0.0741518\tvalid_1's multi_logloss: 0.277949       \n",
      "[68]\ttraining's multi_logloss: 0.0725319\tvalid_1's multi_logloss: 0.278659       \n",
      "[69]\ttraining's multi_logloss: 0.0707735\tvalid_1's multi_logloss: 0.279184       \n",
      "[70]\ttraining's multi_logloss: 0.068955\tvalid_1's multi_logloss: 0.279804        \n",
      "[71]\ttraining's multi_logloss: 0.0672268\tvalid_1's multi_logloss: 0.279953       \n",
      "[72]\ttraining's multi_logloss: 0.0655314\tvalid_1's multi_logloss: 0.280485       \n",
      "[73]\ttraining's multi_logloss: 0.0640476\tvalid_1's multi_logloss: 0.281135       \n",
      "[74]\ttraining's multi_logloss: 0.0625222\tvalid_1's multi_logloss: 0.281758       \n",
      "[75]\ttraining's multi_logloss: 0.0613131\tvalid_1's multi_logloss: 0.282557       \n",
      "Early stopping, best iteration is:                                               \n",
      "[45]\ttraining's multi_logloss: 0.125209\tvalid_1's multi_logloss: 0.270884\n",
      "[1]\ttraining's multi_logloss: 1.44064\tvalid_1's multi_logloss: 1.44992           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.171\tvalid_1's multi_logloss: 1.18829             \n",
      "[3]\ttraining's multi_logloss: 0.984015\tvalid_1's multi_logloss: 1.00729          \n",
      "[4]\ttraining's multi_logloss: 0.845984\tvalid_1's multi_logloss: 0.873796         \n",
      "[5]\ttraining's multi_logloss: 0.737782\tvalid_1's multi_logloss: 0.769908         \n",
      "[6]\ttraining's multi_logloss: 0.653587\tvalid_1's multi_logloss: 0.689253         \n",
      "[7]\ttraining's multi_logloss: 0.584877\tvalid_1's multi_logloss: 0.6235           \n",
      "[8]\ttraining's multi_logloss: 0.528835\tvalid_1's multi_logloss: 0.57021          \n",
      "[9]\ttraining's multi_logloss: 0.481972\tvalid_1's multi_logloss: 0.526551         \n",
      "[10]\ttraining's multi_logloss: 0.442266\tvalid_1's multi_logloss: 0.489431        \n",
      "[11]\ttraining's multi_logloss: 0.409448\tvalid_1's multi_logloss: 0.459075        \n",
      "[12]\ttraining's multi_logloss: 0.381028\tvalid_1's multi_logloss: 0.433619        \n",
      "[13]\ttraining's multi_logloss: 0.356835\tvalid_1's multi_logloss: 0.412222        \n",
      "[14]\ttraining's multi_logloss: 0.335801\tvalid_1's multi_logloss: 0.393859        \n",
      "[15]\ttraining's multi_logloss: 0.318192\tvalid_1's multi_logloss: 0.37968         \n",
      "[16]\ttraining's multi_logloss: 0.302603\tvalid_1's multi_logloss: 0.367218        \n",
      "[17]\ttraining's multi_logloss: 0.288162\tvalid_1's multi_logloss: 0.356535        \n",
      "[18]\ttraining's multi_logloss: 0.276158\tvalid_1's multi_logloss: 0.348168        \n",
      "[19]\ttraining's multi_logloss: 0.264454\tvalid_1's multi_logloss: 0.339387        \n",
      "[20]\ttraining's multi_logloss: 0.254407\tvalid_1's multi_logloss: 0.333161        \n",
      "[21]\ttraining's multi_logloss: 0.245248\tvalid_1's multi_logloss: 0.327195        \n",
      "[22]\ttraining's multi_logloss: 0.236966\tvalid_1's multi_logloss: 0.321751        \n",
      "[23]\ttraining's multi_logloss: 0.229292\tvalid_1's multi_logloss: 0.31768         \n",
      "[24]\ttraining's multi_logloss: 0.222172\tvalid_1's multi_logloss: 0.31348         \n",
      "[25]\ttraining's multi_logloss: 0.215636\tvalid_1's multi_logloss: 0.310293        \n",
      "[26]\ttraining's multi_logloss: 0.209585\tvalid_1's multi_logloss: 0.307886        \n",
      "[27]\ttraining's multi_logloss: 0.20357\tvalid_1's multi_logloss: 0.304728         \n",
      "[28]\ttraining's multi_logloss: 0.197536\tvalid_1's multi_logloss: 0.302317        \n",
      "[29]\ttraining's multi_logloss: 0.19268\tvalid_1's multi_logloss: 0.300829         \n",
      "[30]\ttraining's multi_logloss: 0.187914\tvalid_1's multi_logloss: 0.298975        \n",
      "[31]\ttraining's multi_logloss: 0.183219\tvalid_1's multi_logloss: 0.297365        \n",
      "[32]\ttraining's multi_logloss: 0.178547\tvalid_1's multi_logloss: 0.296841        \n",
      "[33]\ttraining's multi_logloss: 0.173763\tvalid_1's multi_logloss: 0.295714        \n",
      "[34]\ttraining's multi_logloss: 0.169432\tvalid_1's multi_logloss: 0.294977        \n",
      "[35]\ttraining's multi_logloss: 0.165525\tvalid_1's multi_logloss: 0.294336        \n",
      "[36]\ttraining's multi_logloss: 0.161591\tvalid_1's multi_logloss: 0.293542        \n",
      "[37]\ttraining's multi_logloss: 0.158001\tvalid_1's multi_logloss: 0.293159        \n",
      "[38]\ttraining's multi_logloss: 0.154612\tvalid_1's multi_logloss: 0.292742        \n",
      "[39]\ttraining's multi_logloss: 0.151166\tvalid_1's multi_logloss: 0.292381        \n",
      "[40]\ttraining's multi_logloss: 0.14772\tvalid_1's multi_logloss: 0.291863         \n",
      "[41]\ttraining's multi_logloss: 0.144402\tvalid_1's multi_logloss: 0.29162         \n",
      "[42]\ttraining's multi_logloss: 0.141353\tvalid_1's multi_logloss: 0.291383        \n",
      "[43]\ttraining's multi_logloss: 0.13857\tvalid_1's multi_logloss: 0.291041         \n",
      "[44]\ttraining's multi_logloss: 0.135855\tvalid_1's multi_logloss: 0.29111         \n",
      "[45]\ttraining's multi_logloss: 0.133191\tvalid_1's multi_logloss: 0.291138        \n",
      "[46]\ttraining's multi_logloss: 0.130386\tvalid_1's multi_logloss: 0.290714        \n",
      "[47]\ttraining's multi_logloss: 0.127639\tvalid_1's multi_logloss: 0.290843        \n",
      "[48]\ttraining's multi_logloss: 0.125099\tvalid_1's multi_logloss: 0.291127        \n",
      "[49]\ttraining's multi_logloss: 0.122588\tvalid_1's multi_logloss: 0.290749        \n",
      "[50]\ttraining's multi_logloss: 0.120189\tvalid_1's multi_logloss: 0.290849        \n",
      "[51]\ttraining's multi_logloss: 0.117918\tvalid_1's multi_logloss: 0.290805        \n",
      "[52]\ttraining's multi_logloss: 0.115636\tvalid_1's multi_logloss: 0.290732        \n",
      "[53]\ttraining's multi_logloss: 0.113567\tvalid_1's multi_logloss: 0.290775        \n",
      "[54]\ttraining's multi_logloss: 0.111308\tvalid_1's multi_logloss: 0.290687        \n",
      "[55]\ttraining's multi_logloss: 0.109201\tvalid_1's multi_logloss: 0.290724        \n",
      "[56]\ttraining's multi_logloss: 0.107194\tvalid_1's multi_logloss: 0.291244        \n",
      "[57]\ttraining's multi_logloss: 0.105223\tvalid_1's multi_logloss: 0.291405        \n",
      "[58]\ttraining's multi_logloss: 0.103485\tvalid_1's multi_logloss: 0.291578        \n",
      "[59]\ttraining's multi_logloss: 0.101684\tvalid_1's multi_logloss: 0.291914        \n",
      "[60]\ttraining's multi_logloss: 0.0998251\tvalid_1's multi_logloss: 0.292312       \n",
      "[61]\ttraining's multi_logloss: 0.098013\tvalid_1's multi_logloss: 0.291975        \n",
      "[62]\ttraining's multi_logloss: 0.0959712\tvalid_1's multi_logloss: 0.292419       \n",
      "[63]\ttraining's multi_logloss: 0.0944624\tvalid_1's multi_logloss: 0.293128       \n",
      "[64]\ttraining's multi_logloss: 0.0925786\tvalid_1's multi_logloss: 0.294048       \n",
      "[65]\ttraining's multi_logloss: 0.0911022\tvalid_1's multi_logloss: 0.294434       \n",
      "[66]\ttraining's multi_logloss: 0.0894864\tvalid_1's multi_logloss: 0.294928       \n",
      "[67]\ttraining's multi_logloss: 0.0880621\tvalid_1's multi_logloss: 0.295381       \n",
      "[68]\ttraining's multi_logloss: 0.0864326\tvalid_1's multi_logloss: 0.295664       \n",
      "[69]\ttraining's multi_logloss: 0.0849436\tvalid_1's multi_logloss: 0.296353       \n",
      "[70]\ttraining's multi_logloss: 0.0836495\tvalid_1's multi_logloss: 0.296824       \n",
      "[71]\ttraining's multi_logloss: 0.0820611\tvalid_1's multi_logloss: 0.297136       \n",
      "[72]\ttraining's multi_logloss: 0.0807534\tvalid_1's multi_logloss: 0.297846       \n",
      "[73]\ttraining's multi_logloss: 0.0794364\tvalid_1's multi_logloss: 0.298097       \n",
      "[74]\ttraining's multi_logloss: 0.0780226\tvalid_1's multi_logloss: 0.298616       \n",
      "[75]\ttraining's multi_logloss: 0.0767041\tvalid_1's multi_logloss: 0.298685       \n",
      "[76]\ttraining's multi_logloss: 0.0755964\tvalid_1's multi_logloss: 0.299653       \n",
      "[77]\ttraining's multi_logloss: 0.0743875\tvalid_1's multi_logloss: 0.300176       \n",
      "[78]\ttraining's multi_logloss: 0.0732424\tvalid_1's multi_logloss: 0.30072        \n",
      "[79]\ttraining's multi_logloss: 0.0721369\tvalid_1's multi_logloss: 0.301126       \n",
      "[80]\ttraining's multi_logloss: 0.071018\tvalid_1's multi_logloss: 0.301917        \n",
      "[81]\ttraining's multi_logloss: 0.0698884\tvalid_1's multi_logloss: 0.302742       \n",
      "[82]\ttraining's multi_logloss: 0.0688132\tvalid_1's multi_logloss: 0.303227       \n",
      "[83]\ttraining's multi_logloss: 0.0676901\tvalid_1's multi_logloss: 0.303992       \n",
      "[84]\ttraining's multi_logloss: 0.0667173\tvalid_1's multi_logloss: 0.30452        \n",
      "Early stopping, best iteration is:                                               \n",
      "[54]\ttraining's multi_logloss: 0.111308\tvalid_1's multi_logloss: 0.290687\n",
      "[1]\ttraining's multi_logloss: 1.43861\tvalid_1's multi_logloss: 1.44419           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.16989\tvalid_1's multi_logloss: 1.17853           \n",
      "[3]\ttraining's multi_logloss: 0.988077\tvalid_1's multi_logloss: 1.00004          \n",
      "[4]\ttraining's multi_logloss: 0.852855\tvalid_1's multi_logloss: 0.867752         \n",
      "[5]\ttraining's multi_logloss: 0.745947\tvalid_1's multi_logloss: 0.764711         \n",
      "[6]\ttraining's multi_logloss: 0.660361\tvalid_1's multi_logloss: 0.68332          \n",
      "[7]\ttraining's multi_logloss: 0.59146\tvalid_1's multi_logloss: 0.616929          \n",
      "[8]\ttraining's multi_logloss: 0.534854\tvalid_1's multi_logloss: 0.562966         \n",
      "[9]\ttraining's multi_logloss: 0.487445\tvalid_1's multi_logloss: 0.518434         \n",
      "[10]\ttraining's multi_logloss: 0.447849\tvalid_1's multi_logloss: 0.482478        \n",
      "[11]\ttraining's multi_logloss: 0.414217\tvalid_1's multi_logloss: 0.451881        \n",
      "[12]\ttraining's multi_logloss: 0.386119\tvalid_1's multi_logloss: 0.427681        \n",
      "[13]\ttraining's multi_logloss: 0.361521\tvalid_1's multi_logloss: 0.406176        \n",
      "[14]\ttraining's multi_logloss: 0.340651\tvalid_1's multi_logloss: 0.38839         \n",
      "[15]\ttraining's multi_logloss: 0.322364\tvalid_1's multi_logloss: 0.372888        \n",
      "[16]\ttraining's multi_logloss: 0.306385\tvalid_1's multi_logloss: 0.359581        \n",
      "[17]\ttraining's multi_logloss: 0.291624\tvalid_1's multi_logloss: 0.348232        \n",
      "[18]\ttraining's multi_logloss: 0.2786\tvalid_1's multi_logloss: 0.338098          \n",
      "[19]\ttraining's multi_logloss: 0.266897\tvalid_1's multi_logloss: 0.329976        \n",
      "[20]\ttraining's multi_logloss: 0.256742\tvalid_1's multi_logloss: 0.323785        \n",
      "[21]\ttraining's multi_logloss: 0.246756\tvalid_1's multi_logloss: 0.317736        \n",
      "[22]\ttraining's multi_logloss: 0.238248\tvalid_1's multi_logloss: 0.312803        \n",
      "[23]\ttraining's multi_logloss: 0.23004\tvalid_1's multi_logloss: 0.308362         \n",
      "[24]\ttraining's multi_logloss: 0.222619\tvalid_1's multi_logloss: 0.304948        \n",
      "[25]\ttraining's multi_logloss: 0.215628\tvalid_1's multi_logloss: 0.301374        \n",
      "[26]\ttraining's multi_logloss: 0.209162\tvalid_1's multi_logloss: 0.298707        \n",
      "[27]\ttraining's multi_logloss: 0.202854\tvalid_1's multi_logloss: 0.296191        \n",
      "[28]\ttraining's multi_logloss: 0.197185\tvalid_1's multi_logloss: 0.294022        \n",
      "[29]\ttraining's multi_logloss: 0.191717\tvalid_1's multi_logloss: 0.292678        \n",
      "[30]\ttraining's multi_logloss: 0.186487\tvalid_1's multi_logloss: 0.290827        \n",
      "[31]\ttraining's multi_logloss: 0.18164\tvalid_1's multi_logloss: 0.28967          \n",
      "[32]\ttraining's multi_logloss: 0.176711\tvalid_1's multi_logloss: 0.288234        \n",
      "[33]\ttraining's multi_logloss: 0.172017\tvalid_1's multi_logloss: 0.287449        \n",
      "[34]\ttraining's multi_logloss: 0.167664\tvalid_1's multi_logloss: 0.286249        \n",
      "[35]\ttraining's multi_logloss: 0.163374\tvalid_1's multi_logloss: 0.285839        \n",
      "[36]\ttraining's multi_logloss: 0.159235\tvalid_1's multi_logloss: 0.285051        \n",
      "[37]\ttraining's multi_logloss: 0.155253\tvalid_1's multi_logloss: 0.284606        \n",
      "[38]\ttraining's multi_logloss: 0.151629\tvalid_1's multi_logloss: 0.283836        \n",
      "[39]\ttraining's multi_logloss: 0.148259\tvalid_1's multi_logloss: 0.283374        \n",
      "[40]\ttraining's multi_logloss: 0.144776\tvalid_1's multi_logloss: 0.283119        \n",
      "[41]\ttraining's multi_logloss: 0.141487\tvalid_1's multi_logloss: 0.282963        \n",
      "[42]\ttraining's multi_logloss: 0.138574\tvalid_1's multi_logloss: 0.282758        \n",
      "[43]\ttraining's multi_logloss: 0.135473\tvalid_1's multi_logloss: 0.28232         \n",
      "[44]\ttraining's multi_logloss: 0.132758\tvalid_1's multi_logloss: 0.282429        \n",
      "[45]\ttraining's multi_logloss: 0.129886\tvalid_1's multi_logloss: 0.282374        \n",
      "[46]\ttraining's multi_logloss: 0.127241\tvalid_1's multi_logloss: 0.282349        \n",
      "[47]\ttraining's multi_logloss: 0.124718\tvalid_1's multi_logloss: 0.282526        \n",
      "[48]\ttraining's multi_logloss: 0.122061\tvalid_1's multi_logloss: 0.282929        \n",
      "[49]\ttraining's multi_logloss: 0.119614\tvalid_1's multi_logloss: 0.282822        \n",
      "[50]\ttraining's multi_logloss: 0.117014\tvalid_1's multi_logloss: 0.283248        \n",
      "[51]\ttraining's multi_logloss: 0.11468\tvalid_1's multi_logloss: 0.282924         \n",
      "[52]\ttraining's multi_logloss: 0.112466\tvalid_1's multi_logloss: 0.283191        \n",
      "[53]\ttraining's multi_logloss: 0.110263\tvalid_1's multi_logloss: 0.283451        \n",
      "[54]\ttraining's multi_logloss: 0.108282\tvalid_1's multi_logloss: 0.28399         \n",
      "[55]\ttraining's multi_logloss: 0.106239\tvalid_1's multi_logloss: 0.284148        \n",
      "[56]\ttraining's multi_logloss: 0.104272\tvalid_1's multi_logloss: 0.283886        \n",
      "[57]\ttraining's multi_logloss: 0.102408\tvalid_1's multi_logloss: 0.284117        \n",
      "[58]\ttraining's multi_logloss: 0.100531\tvalid_1's multi_logloss: 0.284094        \n",
      "[59]\ttraining's multi_logloss: 0.0986896\tvalid_1's multi_logloss: 0.284522       \n",
      "[60]\ttraining's multi_logloss: 0.0968224\tvalid_1's multi_logloss: 0.285246       \n",
      "[61]\ttraining's multi_logloss: 0.0950866\tvalid_1's multi_logloss: 0.285497       \n",
      "[62]\ttraining's multi_logloss: 0.0935293\tvalid_1's multi_logloss: 0.286079       \n",
      "[63]\ttraining's multi_logloss: 0.09178\tvalid_1's multi_logloss: 0.286541         \n",
      "[64]\ttraining's multi_logloss: 0.0903565\tvalid_1's multi_logloss: 0.28696        \n",
      "[65]\ttraining's multi_logloss: 0.088693\tvalid_1's multi_logloss: 0.2874          \n",
      "[66]\ttraining's multi_logloss: 0.0870157\tvalid_1's multi_logloss: 0.287854       \n",
      "[67]\ttraining's multi_logloss: 0.0855172\tvalid_1's multi_logloss: 0.288444       \n",
      "[68]\ttraining's multi_logloss: 0.0839202\tvalid_1's multi_logloss: 0.289238       \n",
      "[69]\ttraining's multi_logloss: 0.0823181\tvalid_1's multi_logloss: 0.28976        \n",
      "[70]\ttraining's multi_logloss: 0.0807378\tvalid_1's multi_logloss: 0.290068       \n",
      "[71]\ttraining's multi_logloss: 0.0793679\tvalid_1's multi_logloss: 0.290696       \n",
      "[72]\ttraining's multi_logloss: 0.0780026\tvalid_1's multi_logloss: 0.291143       \n",
      "[73]\ttraining's multi_logloss: 0.0766603\tvalid_1's multi_logloss: 0.291451       \n",
      "Early stopping, best iteration is:                                               \n",
      "[43]\ttraining's multi_logloss: 0.135473\tvalid_1's multi_logloss: 0.28232\n",
      "[1]\ttraining's multi_logloss: 1.44278\tvalid_1's multi_logloss: 1.44774           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.17409\tvalid_1's multi_logloss: 1.18088           \n",
      "[3]\ttraining's multi_logloss: 0.990267\tvalid_1's multi_logloss: 0.999682         \n",
      "[4]\ttraining's multi_logloss: 0.853391\tvalid_1's multi_logloss: 0.864827         \n",
      "[5]\ttraining's multi_logloss: 0.74645\tvalid_1's multi_logloss: 0.759747          \n",
      "[6]\ttraining's multi_logloss: 0.662834\tvalid_1's multi_logloss: 0.678387         \n",
      "[7]\ttraining's multi_logloss: 0.594168\tvalid_1's multi_logloss: 0.612234         \n",
      "[8]\ttraining's multi_logloss: 0.536909\tvalid_1's multi_logloss: 0.557348         \n",
      "[9]\ttraining's multi_logloss: 0.490848\tvalid_1's multi_logloss: 0.514023         \n",
      "[10]\ttraining's multi_logloss: 0.452273\tvalid_1's multi_logloss: 0.477872        \n",
      "[11]\ttraining's multi_logloss: 0.41956\tvalid_1's multi_logloss: 0.447683         \n",
      "[12]\ttraining's multi_logloss: 0.390819\tvalid_1's multi_logloss: 0.421256        \n",
      "[13]\ttraining's multi_logloss: 0.366711\tvalid_1's multi_logloss: 0.400247        \n",
      "[14]\ttraining's multi_logloss: 0.345746\tvalid_1's multi_logloss: 0.381252        \n",
      "[15]\ttraining's multi_logloss: 0.328116\tvalid_1's multi_logloss: 0.366234        \n",
      "[16]\ttraining's multi_logloss: 0.311262\tvalid_1's multi_logloss: 0.351948        \n",
      "[17]\ttraining's multi_logloss: 0.296601\tvalid_1's multi_logloss: 0.340383        \n",
      "[18]\ttraining's multi_logloss: 0.284162\tvalid_1's multi_logloss: 0.330116        \n",
      "[19]\ttraining's multi_logloss: 0.272579\tvalid_1's multi_logloss: 0.322242        \n",
      "[20]\ttraining's multi_logloss: 0.262636\tvalid_1's multi_logloss: 0.315582        \n",
      "[21]\ttraining's multi_logloss: 0.253037\tvalid_1's multi_logloss: 0.30942         \n",
      "[22]\ttraining's multi_logloss: 0.244517\tvalid_1's multi_logloss: 0.303985        \n",
      "[23]\ttraining's multi_logloss: 0.236752\tvalid_1's multi_logloss: 0.298548        \n",
      "[24]\ttraining's multi_logloss: 0.229439\tvalid_1's multi_logloss: 0.294333        \n",
      "[25]\ttraining's multi_logloss: 0.223073\tvalid_1's multi_logloss: 0.29128         \n",
      "[26]\ttraining's multi_logloss: 0.216707\tvalid_1's multi_logloss: 0.288256        \n",
      "[27]\ttraining's multi_logloss: 0.210808\tvalid_1's multi_logloss: 0.285455        \n",
      "[28]\ttraining's multi_logloss: 0.205341\tvalid_1's multi_logloss: 0.282925        \n",
      "[29]\ttraining's multi_logloss: 0.199883\tvalid_1's multi_logloss: 0.280934        \n",
      "[30]\ttraining's multi_logloss: 0.194569\tvalid_1's multi_logloss: 0.279329        \n",
      "[31]\ttraining's multi_logloss: 0.189907\tvalid_1's multi_logloss: 0.278097        \n",
      "[32]\ttraining's multi_logloss: 0.185293\tvalid_1's multi_logloss: 0.276957        \n",
      "[33]\ttraining's multi_logloss: 0.180667\tvalid_1's multi_logloss: 0.275821        \n",
      "[34]\ttraining's multi_logloss: 0.176257\tvalid_1's multi_logloss: 0.275216        \n",
      "[35]\ttraining's multi_logloss: 0.172216\tvalid_1's multi_logloss: 0.274247        \n",
      "[36]\ttraining's multi_logloss: 0.168303\tvalid_1's multi_logloss: 0.27381         \n",
      "[37]\ttraining's multi_logloss: 0.164486\tvalid_1's multi_logloss: 0.272775        \n",
      "[38]\ttraining's multi_logloss: 0.160712\tvalid_1's multi_logloss: 0.271869        \n",
      "[39]\ttraining's multi_logloss: 0.15699\tvalid_1's multi_logloss: 0.271272         \n",
      "[40]\ttraining's multi_logloss: 0.153596\tvalid_1's multi_logloss: 0.270852        \n",
      "[41]\ttraining's multi_logloss: 0.150023\tvalid_1's multi_logloss: 0.270287        \n",
      "[42]\ttraining's multi_logloss: 0.146796\tvalid_1's multi_logloss: 0.269984        \n",
      "[43]\ttraining's multi_logloss: 0.143741\tvalid_1's multi_logloss: 0.269482        \n",
      "[44]\ttraining's multi_logloss: 0.140888\tvalid_1's multi_logloss: 0.269527        \n",
      "[45]\ttraining's multi_logloss: 0.138043\tvalid_1's multi_logloss: 0.269294        \n",
      "[46]\ttraining's multi_logloss: 0.135149\tvalid_1's multi_logloss: 0.268238        \n",
      "[47]\ttraining's multi_logloss: 0.13254\tvalid_1's multi_logloss: 0.268185         \n",
      "[48]\ttraining's multi_logloss: 0.129821\tvalid_1's multi_logloss: 0.268327        \n",
      "[49]\ttraining's multi_logloss: 0.127172\tvalid_1's multi_logloss: 0.26811         \n",
      "[50]\ttraining's multi_logloss: 0.124823\tvalid_1's multi_logloss: 0.26818         \n",
      "[51]\ttraining's multi_logloss: 0.122553\tvalid_1's multi_logloss: 0.268259        \n",
      "[52]\ttraining's multi_logloss: 0.120512\tvalid_1's multi_logloss: 0.268043        \n",
      "[53]\ttraining's multi_logloss: 0.118492\tvalid_1's multi_logloss: 0.268302        \n",
      "[54]\ttraining's multi_logloss: 0.116377\tvalid_1's multi_logloss: 0.268855        \n",
      "[55]\ttraining's multi_logloss: 0.114042\tvalid_1's multi_logloss: 0.268703        \n",
      "[56]\ttraining's multi_logloss: 0.111838\tvalid_1's multi_logloss: 0.26893         \n",
      "[57]\ttraining's multi_logloss: 0.109796\tvalid_1's multi_logloss: 0.269066        \n",
      "[58]\ttraining's multi_logloss: 0.107911\tvalid_1's multi_logloss: 0.269387        \n",
      "[59]\ttraining's multi_logloss: 0.106162\tvalid_1's multi_logloss: 0.269675        \n",
      "[60]\ttraining's multi_logloss: 0.10434\tvalid_1's multi_logloss: 0.269604         \n",
      "[61]\ttraining's multi_logloss: 0.102507\tvalid_1's multi_logloss: 0.269855        \n",
      "[62]\ttraining's multi_logloss: 0.100761\tvalid_1's multi_logloss: 0.27019         \n",
      "[63]\ttraining's multi_logloss: 0.099028\tvalid_1's multi_logloss: 0.270054        \n",
      "[64]\ttraining's multi_logloss: 0.0973246\tvalid_1's multi_logloss: 0.270539       \n",
      "[65]\ttraining's multi_logloss: 0.095716\tvalid_1's multi_logloss: 0.270992        \n",
      "[66]\ttraining's multi_logloss: 0.0942281\tvalid_1's multi_logloss: 0.271413       \n",
      "[67]\ttraining's multi_logloss: 0.0927823\tvalid_1's multi_logloss: 0.271754       \n",
      "[68]\ttraining's multi_logloss: 0.0913328\tvalid_1's multi_logloss: 0.271758       \n",
      "[69]\ttraining's multi_logloss: 0.0898653\tvalid_1's multi_logloss: 0.272062       \n",
      "[70]\ttraining's multi_logloss: 0.0883375\tvalid_1's multi_logloss: 0.272156       \n",
      "[71]\ttraining's multi_logloss: 0.0866112\tvalid_1's multi_logloss: 0.272546       \n",
      "[72]\ttraining's multi_logloss: 0.0851696\tvalid_1's multi_logloss: 0.272785       \n",
      "[73]\ttraining's multi_logloss: 0.0837156\tvalid_1's multi_logloss: 0.273195       \n",
      "[74]\ttraining's multi_logloss: 0.0824456\tvalid_1's multi_logloss: 0.273758       \n",
      "[75]\ttraining's multi_logloss: 0.0811727\tvalid_1's multi_logloss: 0.274145       \n",
      "[76]\ttraining's multi_logloss: 0.0797334\tvalid_1's multi_logloss: 0.274531       \n",
      "[77]\ttraining's multi_logloss: 0.0785636\tvalid_1's multi_logloss: 0.274997       \n",
      "[78]\ttraining's multi_logloss: 0.0773301\tvalid_1's multi_logloss: 0.275159       \n",
      "[79]\ttraining's multi_logloss: 0.0760271\tvalid_1's multi_logloss: 0.275656       \n",
      "[80]\ttraining's multi_logloss: 0.0749141\tvalid_1's multi_logloss: 0.276053       \n",
      "[81]\ttraining's multi_logloss: 0.0738506\tvalid_1's multi_logloss: 0.27684        \n",
      "[82]\ttraining's multi_logloss: 0.0726161\tvalid_1's multi_logloss: 0.277789       \n",
      "Early stopping, best iteration is:                                               \n",
      "[52]\ttraining's multi_logloss: 0.120512\tvalid_1's multi_logloss: 0.268043\n",
      "[1]\ttraining's multi_logloss: 1.82582\tvalid_1's multi_logloss: 1.82563           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.73219\tvalid_1's multi_logloss: 1.73423           \n",
      "[3]\ttraining's multi_logloss: 1.64846\tvalid_1's multi_logloss: 1.65244           \n",
      "[4]\ttraining's multi_logloss: 1.57286\tvalid_1's multi_logloss: 1.57895           \n",
      "[5]\ttraining's multi_logloss: 1.50425\tvalid_1's multi_logloss: 1.51224           \n",
      "[6]\ttraining's multi_logloss: 1.44131\tvalid_1's multi_logloss: 1.45102           \n",
      "[7]\ttraining's multi_logloss: 1.38281\tvalid_1's multi_logloss: 1.3943            \n",
      "[8]\ttraining's multi_logloss: 1.32908\tvalid_1's multi_logloss: 1.34195           \n",
      "[9]\ttraining's multi_logloss: 1.27923\tvalid_1's multi_logloss: 1.29342           \n",
      "[10]\ttraining's multi_logloss: 1.23245\tvalid_1's multi_logloss: 1.24801          \n",
      "[11]\ttraining's multi_logloss: 1.18907\tvalid_1's multi_logloss: 1.20592          \n",
      "[12]\ttraining's multi_logloss: 1.14809\tvalid_1's multi_logloss: 1.16612          \n",
      "[13]\ttraining's multi_logloss: 1.10964\tvalid_1's multi_logloss: 1.12895          \n",
      "[14]\ttraining's multi_logloss: 1.07326\tvalid_1's multi_logloss: 1.0938           \n",
      "[15]\ttraining's multi_logloss: 1.03916\tvalid_1's multi_logloss: 1.06081          \n",
      "[16]\ttraining's multi_logloss: 1.00675\tvalid_1's multi_logloss: 1.0295           \n",
      "[17]\ttraining's multi_logloss: 0.976034\tvalid_1's multi_logloss: 0.999813        \n",
      "[18]\ttraining's multi_logloss: 0.946738\tvalid_1's multi_logloss: 0.971524        \n",
      "[19]\ttraining's multi_logloss: 0.919179\tvalid_1's multi_logloss: 0.944907        \n",
      "[20]\ttraining's multi_logloss: 0.892716\tvalid_1's multi_logloss: 0.919312        \n",
      "[21]\ttraining's multi_logloss: 0.867542\tvalid_1's multi_logloss: 0.894953        \n",
      "[22]\ttraining's multi_logloss: 0.843648\tvalid_1's multi_logloss: 0.871797        \n",
      "[23]\ttraining's multi_logloss: 0.820751\tvalid_1's multi_logloss: 0.849715        \n",
      "[24]\ttraining's multi_logloss: 0.798918\tvalid_1's multi_logloss: 0.828664        \n",
      "[25]\ttraining's multi_logloss: 0.778169\tvalid_1's multi_logloss: 0.808645        \n",
      "[26]\ttraining's multi_logloss: 0.758334\tvalid_1's multi_logloss: 0.789445        \n",
      "[27]\ttraining's multi_logloss: 0.739461\tvalid_1's multi_logloss: 0.771252        \n",
      "[28]\ttraining's multi_logloss: 0.721285\tvalid_1's multi_logloss: 0.75379         \n",
      "[29]\ttraining's multi_logloss: 0.703723\tvalid_1's multi_logloss: 0.736935        \n",
      "[30]\ttraining's multi_logloss: 0.686933\tvalid_1's multi_logloss: 0.720817        \n",
      "[31]\ttraining's multi_logloss: 0.67084\tvalid_1's multi_logloss: 0.705497         \n",
      "[32]\ttraining's multi_logloss: 0.655197\tvalid_1's multi_logloss: 0.690622        \n",
      "[33]\ttraining's multi_logloss: 0.640426\tvalid_1's multi_logloss: 0.67656         \n",
      "[34]\ttraining's multi_logloss: 0.626096\tvalid_1's multi_logloss: 0.663002        \n",
      "[35]\ttraining's multi_logloss: 0.61221\tvalid_1's multi_logloss: 0.649954         \n",
      "[36]\ttraining's multi_logloss: 0.598942\tvalid_1's multi_logloss: 0.63735         \n",
      "[37]\ttraining's multi_logloss: 0.586083\tvalid_1's multi_logloss: 0.625179        \n",
      "[38]\ttraining's multi_logloss: 0.573847\tvalid_1's multi_logloss: 0.613622        \n",
      "[39]\ttraining's multi_logloss: 0.562117\tvalid_1's multi_logloss: 0.602476        \n",
      "[40]\ttraining's multi_logloss: 0.550708\tvalid_1's multi_logloss: 0.591711        \n",
      "[41]\ttraining's multi_logloss: 0.539798\tvalid_1's multi_logloss: 0.581379        \n",
      "[42]\ttraining's multi_logloss: 0.529274\tvalid_1's multi_logloss: 0.571504        \n",
      "[43]\ttraining's multi_logloss: 0.519043\tvalid_1's multi_logloss: 0.561948        \n",
      "[44]\ttraining's multi_logloss: 0.509194\tvalid_1's multi_logloss: 0.552866        \n",
      "[45]\ttraining's multi_logloss: 0.499732\tvalid_1's multi_logloss: 0.54409         \n",
      "[46]\ttraining's multi_logloss: 0.490582\tvalid_1's multi_logloss: 0.535578        \n",
      "[47]\ttraining's multi_logloss: 0.481762\tvalid_1's multi_logloss: 0.527411        \n",
      "[48]\ttraining's multi_logloss: 0.473203\tvalid_1's multi_logloss: 0.519488        \n",
      "[49]\ttraining's multi_logloss: 0.464949\tvalid_1's multi_logloss: 0.51188         \n",
      "[50]\ttraining's multi_logloss: 0.457034\tvalid_1's multi_logloss: 0.504627        \n",
      "[51]\ttraining's multi_logloss: 0.449368\tvalid_1's multi_logloss: 0.497704        \n",
      "[52]\ttraining's multi_logloss: 0.441938\tvalid_1's multi_logloss: 0.490847        \n",
      "[53]\ttraining's multi_logloss: 0.434785\tvalid_1's multi_logloss: 0.484303        \n",
      "[54]\ttraining's multi_logloss: 0.427841\tvalid_1's multi_logloss: 0.47804         \n",
      "[55]\ttraining's multi_logloss: 0.421036\tvalid_1's multi_logloss: 0.471761        \n",
      "[56]\ttraining's multi_logloss: 0.414523\tvalid_1's multi_logloss: 0.465811        \n",
      "[57]\ttraining's multi_logloss: 0.408182\tvalid_1's multi_logloss: 0.459961        \n",
      "[58]\ttraining's multi_logloss: 0.402089\tvalid_1's multi_logloss: 0.454449        \n",
      "[59]\ttraining's multi_logloss: 0.396181\tvalid_1's multi_logloss: 0.449082        \n",
      "[60]\ttraining's multi_logloss: 0.390421\tvalid_1's multi_logloss: 0.443934        \n",
      "[61]\ttraining's multi_logloss: 0.384853\tvalid_1's multi_logloss: 0.438911        \n",
      "[62]\ttraining's multi_logloss: 0.37954\tvalid_1's multi_logloss: 0.434093         \n",
      "[63]\ttraining's multi_logloss: 0.374433\tvalid_1's multi_logloss: 0.429637        \n",
      "[64]\ttraining's multi_logloss: 0.369421\tvalid_1's multi_logloss: 0.425203        \n",
      "[65]\ttraining's multi_logloss: 0.364583\tvalid_1's multi_logloss: 0.420993        \n",
      "[66]\ttraining's multi_logloss: 0.359944\tvalid_1's multi_logloss: 0.417006        \n",
      "[67]\ttraining's multi_logloss: 0.355303\tvalid_1's multi_logloss: 0.412892        \n",
      "[68]\ttraining's multi_logloss: 0.350781\tvalid_1's multi_logloss: 0.408946        \n",
      "[69]\ttraining's multi_logloss: 0.346516\tvalid_1's multi_logloss: 0.405421        \n",
      "[70]\ttraining's multi_logloss: 0.342243\tvalid_1's multi_logloss: 0.401898        \n",
      "[71]\ttraining's multi_logloss: 0.338121\tvalid_1's multi_logloss: 0.398466        \n",
      "[72]\ttraining's multi_logloss: 0.334133\tvalid_1's multi_logloss: 0.395144        \n",
      "[73]\ttraining's multi_logloss: 0.330247\tvalid_1's multi_logloss: 0.391901        \n",
      "[74]\ttraining's multi_logloss: 0.326517\tvalid_1's multi_logloss: 0.388834        \n",
      "[75]\ttraining's multi_logloss: 0.322934\tvalid_1's multi_logloss: 0.38588         \n",
      "[76]\ttraining's multi_logloss: 0.319448\tvalid_1's multi_logloss: 0.383001        \n",
      "[77]\ttraining's multi_logloss: 0.316062\tvalid_1's multi_logloss: 0.380185        \n",
      "[78]\ttraining's multi_logloss: 0.312769\tvalid_1's multi_logloss: 0.377577        \n",
      "[79]\ttraining's multi_logloss: 0.309543\tvalid_1's multi_logloss: 0.374865        \n",
      "[80]\ttraining's multi_logloss: 0.306441\tvalid_1's multi_logloss: 0.372363        \n",
      "[81]\ttraining's multi_logloss: 0.303212\tvalid_1's multi_logloss: 0.369629        \n",
      "[82]\ttraining's multi_logloss: 0.300189\tvalid_1's multi_logloss: 0.367298        \n",
      "[83]\ttraining's multi_logloss: 0.29717\tvalid_1's multi_logloss: 0.364933         \n",
      "[84]\ttraining's multi_logloss: 0.294229\tvalid_1's multi_logloss: 0.362676        \n",
      "[85]\ttraining's multi_logloss: 0.291225\tvalid_1's multi_logloss: 0.360418        \n",
      "[86]\ttraining's multi_logloss: 0.288486\tvalid_1's multi_logloss: 0.358303        \n",
      "[87]\ttraining's multi_logloss: 0.285732\tvalid_1's multi_logloss: 0.356145        \n",
      "[88]\ttraining's multi_logloss: 0.283099\tvalid_1's multi_logloss: 0.354201        \n",
      "[89]\ttraining's multi_logloss: 0.280493\tvalid_1's multi_logloss: 0.352306        \n",
      "[90]\ttraining's multi_logloss: 0.277935\tvalid_1's multi_logloss: 0.350308        \n",
      "[91]\ttraining's multi_logloss: 0.275426\tvalid_1's multi_logloss: 0.348517        \n",
      "[92]\ttraining's multi_logloss: 0.27294\tvalid_1's multi_logloss: 0.346693         \n",
      "[93]\ttraining's multi_logloss: 0.270636\tvalid_1's multi_logloss: 0.345006        \n",
      "[94]\ttraining's multi_logloss: 0.268234\tvalid_1's multi_logloss: 0.343245        \n",
      "[95]\ttraining's multi_logloss: 0.265917\tvalid_1's multi_logloss: 0.341618        \n",
      "[96]\ttraining's multi_logloss: 0.263641\tvalid_1's multi_logloss: 0.340015        \n",
      "[97]\ttraining's multi_logloss: 0.261427\tvalid_1's multi_logloss: 0.338474        \n",
      "[98]\ttraining's multi_logloss: 0.259341\tvalid_1's multi_logloss: 0.336994        \n",
      "[99]\ttraining's multi_logloss: 0.257201\tvalid_1's multi_logloss: 0.335514        \n",
      "[100]\ttraining's multi_logloss: 0.255162\tvalid_1's multi_logloss: 0.334195       \n",
      "[101]\ttraining's multi_logloss: 0.253057\tvalid_1's multi_logloss: 0.332831       \n",
      "[102]\ttraining's multi_logloss: 0.251118\tvalid_1's multi_logloss: 0.331585       \n",
      "[103]\ttraining's multi_logloss: 0.249128\tvalid_1's multi_logloss: 0.330302       \n",
      "[104]\ttraining's multi_logloss: 0.24725\tvalid_1's multi_logloss: 0.329092        \n",
      "[105]\ttraining's multi_logloss: 0.245293\tvalid_1's multi_logloss: 0.327903       \n",
      "[106]\ttraining's multi_logloss: 0.243392\tvalid_1's multi_logloss: 0.326685       \n",
      "[107]\ttraining's multi_logloss: 0.241532\tvalid_1's multi_logloss: 0.325542       \n",
      "[108]\ttraining's multi_logloss: 0.239729\tvalid_1's multi_logloss: 0.32453        \n",
      "[109]\ttraining's multi_logloss: 0.23793\tvalid_1's multi_logloss: 0.323376        \n",
      "[110]\ttraining's multi_logloss: 0.236224\tvalid_1's multi_logloss: 0.32253        \n",
      "[111]\ttraining's multi_logloss: 0.234509\tvalid_1's multi_logloss: 0.321379       \n",
      "[112]\ttraining's multi_logloss: 0.232818\tvalid_1's multi_logloss: 0.320379       \n",
      "[113]\ttraining's multi_logloss: 0.231181\tvalid_1's multi_logloss: 0.319507       \n",
      "[114]\ttraining's multi_logloss: 0.229601\tvalid_1's multi_logloss: 0.318646       \n",
      "[115]\ttraining's multi_logloss: 0.22799\tvalid_1's multi_logloss: 0.317888        \n",
      "[116]\ttraining's multi_logloss: 0.226419\tvalid_1's multi_logloss: 0.317075       \n",
      "[117]\ttraining's multi_logloss: 0.224894\tvalid_1's multi_logloss: 0.316366       \n",
      "[118]\ttraining's multi_logloss: 0.223466\tvalid_1's multi_logloss: 0.31568        \n",
      "[119]\ttraining's multi_logloss: 0.221957\tvalid_1's multi_logloss: 0.314858       \n",
      "[120]\ttraining's multi_logloss: 0.220515\tvalid_1's multi_logloss: 0.314111       \n",
      "[121]\ttraining's multi_logloss: 0.219008\tvalid_1's multi_logloss: 0.313386       \n",
      "[122]\ttraining's multi_logloss: 0.217572\tvalid_1's multi_logloss: 0.312727       \n",
      "[123]\ttraining's multi_logloss: 0.216119\tvalid_1's multi_logloss: 0.311931       \n",
      "[124]\ttraining's multi_logloss: 0.214739\tvalid_1's multi_logloss: 0.311303       \n",
      "[125]\ttraining's multi_logloss: 0.213351\tvalid_1's multi_logloss: 0.310545       \n",
      "[126]\ttraining's multi_logloss: 0.211975\tvalid_1's multi_logloss: 0.310028       \n",
      "[127]\ttraining's multi_logloss: 0.210572\tvalid_1's multi_logloss: 0.309276       \n",
      "[128]\ttraining's multi_logloss: 0.209256\tvalid_1's multi_logloss: 0.308729       \n",
      "[129]\ttraining's multi_logloss: 0.207933\tvalid_1's multi_logloss: 0.307918       \n",
      "[130]\ttraining's multi_logloss: 0.20668\tvalid_1's multi_logloss: 0.307318        \n",
      "[131]\ttraining's multi_logloss: 0.205422\tvalid_1's multi_logloss: 0.306904       \n",
      "[132]\ttraining's multi_logloss: 0.204138\tvalid_1's multi_logloss: 0.306302       \n",
      "[133]\ttraining's multi_logloss: 0.202878\tvalid_1's multi_logloss: 0.305831       \n",
      "[134]\ttraining's multi_logloss: 0.201693\tvalid_1's multi_logloss: 0.305254       \n",
      "[135]\ttraining's multi_logloss: 0.200451\tvalid_1's multi_logloss: 0.304687       \n",
      "[136]\ttraining's multi_logloss: 0.199238\tvalid_1's multi_logloss: 0.304164       \n",
      "[137]\ttraining's multi_logloss: 0.198028\tvalid_1's multi_logloss: 0.303716       \n",
      "[138]\ttraining's multi_logloss: 0.196897\tvalid_1's multi_logloss: 0.303344       \n",
      "[139]\ttraining's multi_logloss: 0.195725\tvalid_1's multi_logloss: 0.302897       \n",
      "[140]\ttraining's multi_logloss: 0.194568\tvalid_1's multi_logloss: 0.302464       \n",
      "[141]\ttraining's multi_logloss: 0.193394\tvalid_1's multi_logloss: 0.302022       \n",
      "[142]\ttraining's multi_logloss: 0.192262\tvalid_1's multi_logloss: 0.301582       \n",
      "[143]\ttraining's multi_logloss: 0.191065\tvalid_1's multi_logloss: 0.301198       \n",
      "[144]\ttraining's multi_logloss: 0.189904\tvalid_1's multi_logloss: 0.300895       \n",
      "[145]\ttraining's multi_logloss: 0.188805\tvalid_1's multi_logloss: 0.300477       \n",
      "[146]\ttraining's multi_logloss: 0.187795\tvalid_1's multi_logloss: 0.300116       \n",
      "[147]\ttraining's multi_logloss: 0.186778\tvalid_1's multi_logloss: 0.299784       \n",
      "[148]\ttraining's multi_logloss: 0.185754\tvalid_1's multi_logloss: 0.299553       \n",
      "[149]\ttraining's multi_logloss: 0.184693\tvalid_1's multi_logloss: 0.299334       \n",
      "[150]\ttraining's multi_logloss: 0.183685\tvalid_1's multi_logloss: 0.298818       \n",
      "[151]\ttraining's multi_logloss: 0.182698\tvalid_1's multi_logloss: 0.298495       \n",
      "[152]\ttraining's multi_logloss: 0.181739\tvalid_1's multi_logloss: 0.298181       \n",
      "[153]\ttraining's multi_logloss: 0.18069\tvalid_1's multi_logloss: 0.297944        \n",
      "[154]\ttraining's multi_logloss: 0.179744\tvalid_1's multi_logloss: 0.297696       \n",
      "[155]\ttraining's multi_logloss: 0.178745\tvalid_1's multi_logloss: 0.297494       \n",
      "[156]\ttraining's multi_logloss: 0.177768\tvalid_1's multi_logloss: 0.297189       \n",
      "[157]\ttraining's multi_logloss: 0.176787\tvalid_1's multi_logloss: 0.29696        \n",
      "[158]\ttraining's multi_logloss: 0.175853\tvalid_1's multi_logloss: 0.296738       \n",
      "[159]\ttraining's multi_logloss: 0.174872\tvalid_1's multi_logloss: 0.296618       \n",
      "[160]\ttraining's multi_logloss: 0.173915\tvalid_1's multi_logloss: 0.296379       \n",
      "[161]\ttraining's multi_logloss: 0.172963\tvalid_1's multi_logloss: 0.296175       \n",
      "[162]\ttraining's multi_logloss: 0.172061\tvalid_1's multi_logloss: 0.296047       \n",
      "[163]\ttraining's multi_logloss: 0.171152\tvalid_1's multi_logloss: 0.295846       \n",
      "[164]\ttraining's multi_logloss: 0.170257\tvalid_1's multi_logloss: 0.295579       \n",
      "[165]\ttraining's multi_logloss: 0.169376\tvalid_1's multi_logloss: 0.29542        \n",
      "[166]\ttraining's multi_logloss: 0.168467\tvalid_1's multi_logloss: 0.295264       \n",
      "[167]\ttraining's multi_logloss: 0.167565\tvalid_1's multi_logloss: 0.295037       \n",
      "[168]\ttraining's multi_logloss: 0.166674\tvalid_1's multi_logloss: 0.294838       \n",
      "[169]\ttraining's multi_logloss: 0.165798\tvalid_1's multi_logloss: 0.294575       \n",
      "[170]\ttraining's multi_logloss: 0.164923\tvalid_1's multi_logloss: 0.294486       \n",
      "[171]\ttraining's multi_logloss: 0.164068\tvalid_1's multi_logloss: 0.294234       \n",
      "[172]\ttraining's multi_logloss: 0.163233\tvalid_1's multi_logloss: 0.294123       \n",
      "[173]\ttraining's multi_logloss: 0.162334\tvalid_1's multi_logloss: 0.29387        \n",
      "[174]\ttraining's multi_logloss: 0.161477\tvalid_1's multi_logloss: 0.293593       \n",
      "[175]\ttraining's multi_logloss: 0.160591\tvalid_1's multi_logloss: 0.29337        \n",
      "[176]\ttraining's multi_logloss: 0.159757\tvalid_1's multi_logloss: 0.293273       \n",
      "[177]\ttraining's multi_logloss: 0.158963\tvalid_1's multi_logloss: 0.293092       \n",
      "[178]\ttraining's multi_logloss: 0.158155\tvalid_1's multi_logloss: 0.292906       \n",
      "[179]\ttraining's multi_logloss: 0.15736\tvalid_1's multi_logloss: 0.292769        \n",
      "[180]\ttraining's multi_logloss: 0.156622\tvalid_1's multi_logloss: 0.292702       \n",
      "[181]\ttraining's multi_logloss: 0.155832\tvalid_1's multi_logloss: 0.292618       \n",
      "[182]\ttraining's multi_logloss: 0.155006\tvalid_1's multi_logloss: 0.292557       \n",
      "[183]\ttraining's multi_logloss: 0.154249\tvalid_1's multi_logloss: 0.292454       \n",
      "[184]\ttraining's multi_logloss: 0.15343\tvalid_1's multi_logloss: 0.292259        \n",
      "[185]\ttraining's multi_logloss: 0.152649\tvalid_1's multi_logloss: 0.292197       \n",
      "[186]\ttraining's multi_logloss: 0.151838\tvalid_1's multi_logloss: 0.291986       \n",
      "[187]\ttraining's multi_logloss: 0.151077\tvalid_1's multi_logloss: 0.29187        \n",
      "[188]\ttraining's multi_logloss: 0.150337\tvalid_1's multi_logloss: 0.291693       \n",
      "[189]\ttraining's multi_logloss: 0.149606\tvalid_1's multi_logloss: 0.291555       \n",
      "[190]\ttraining's multi_logloss: 0.148852\tvalid_1's multi_logloss: 0.291497       \n",
      "[191]\ttraining's multi_logloss: 0.148136\tvalid_1's multi_logloss: 0.291389       \n",
      "[192]\ttraining's multi_logloss: 0.147404\tvalid_1's multi_logloss: 0.291282       \n",
      "[193]\ttraining's multi_logloss: 0.146713\tvalid_1's multi_logloss: 0.291155       \n",
      "[194]\ttraining's multi_logloss: 0.146017\tvalid_1's multi_logloss: 0.291149       \n",
      "[195]\ttraining's multi_logloss: 0.145289\tvalid_1's multi_logloss: 0.290993       \n",
      "[196]\ttraining's multi_logloss: 0.144577\tvalid_1's multi_logloss: 0.290822       \n",
      "[197]\ttraining's multi_logloss: 0.143862\tvalid_1's multi_logloss: 0.29074        \n",
      "[198]\ttraining's multi_logloss: 0.143146\tvalid_1's multi_logloss: 0.290687       \n",
      "[199]\ttraining's multi_logloss: 0.142492\tvalid_1's multi_logloss: 0.29062        \n",
      "[200]\ttraining's multi_logloss: 0.141768\tvalid_1's multi_logloss: 0.290625       \n",
      "[201]\ttraining's multi_logloss: 0.141118\tvalid_1's multi_logloss: 0.290615       \n",
      "[202]\ttraining's multi_logloss: 0.140453\tvalid_1's multi_logloss: 0.29056        \n",
      "[203]\ttraining's multi_logloss: 0.139802\tvalid_1's multi_logloss: 0.290586       \n",
      "[204]\ttraining's multi_logloss: 0.139125\tvalid_1's multi_logloss: 0.290463       \n",
      "[205]\ttraining's multi_logloss: 0.13846\tvalid_1's multi_logloss: 0.290426        \n",
      "[206]\ttraining's multi_logloss: 0.137782\tvalid_1's multi_logloss: 0.290397       \n",
      "[207]\ttraining's multi_logloss: 0.13715\tvalid_1's multi_logloss: 0.290379        \n",
      "[208]\ttraining's multi_logloss: 0.136481\tvalid_1's multi_logloss: 0.290397       \n",
      "[209]\ttraining's multi_logloss: 0.135888\tvalid_1's multi_logloss: 0.290403       \n",
      "[210]\ttraining's multi_logloss: 0.135226\tvalid_1's multi_logloss: 0.290425       \n",
      "[211]\ttraining's multi_logloss: 0.134628\tvalid_1's multi_logloss: 0.290346       \n",
      "[212]\ttraining's multi_logloss: 0.134027\tvalid_1's multi_logloss: 0.290391       \n",
      "[213]\ttraining's multi_logloss: 0.133391\tvalid_1's multi_logloss: 0.290311       \n",
      "[214]\ttraining's multi_logloss: 0.13279\tvalid_1's multi_logloss: 0.290298        \n",
      "[215]\ttraining's multi_logloss: 0.1322\tvalid_1's multi_logloss: 0.290311         \n",
      "[216]\ttraining's multi_logloss: 0.131583\tvalid_1's multi_logloss: 0.290291       \n",
      "[217]\ttraining's multi_logloss: 0.130944\tvalid_1's multi_logloss: 0.290319       \n",
      "[218]\ttraining's multi_logloss: 0.130289\tvalid_1's multi_logloss: 0.290322       \n",
      "[219]\ttraining's multi_logloss: 0.129635\tvalid_1's multi_logloss: 0.290271       \n",
      "[220]\ttraining's multi_logloss: 0.129019\tvalid_1's multi_logloss: 0.290246       \n",
      "[221]\ttraining's multi_logloss: 0.128387\tvalid_1's multi_logloss: 0.290198       \n",
      "[222]\ttraining's multi_logloss: 0.127758\tvalid_1's multi_logloss: 0.290214       \n",
      "[223]\ttraining's multi_logloss: 0.127131\tvalid_1's multi_logloss: 0.2902         \n",
      "[224]\ttraining's multi_logloss: 0.126555\tvalid_1's multi_logloss: 0.290114       \n",
      "[225]\ttraining's multi_logloss: 0.125968\tvalid_1's multi_logloss: 0.290145       \n",
      "[226]\ttraining's multi_logloss: 0.12537\tvalid_1's multi_logloss: 0.290112        \n",
      "[227]\ttraining's multi_logloss: 0.124766\tvalid_1's multi_logloss: 0.290053       \n",
      "[228]\ttraining's multi_logloss: 0.124183\tvalid_1's multi_logloss: 0.290026       \n",
      "[229]\ttraining's multi_logloss: 0.12359\tvalid_1's multi_logloss: 0.290031        \n",
      "[230]\ttraining's multi_logloss: 0.123024\tvalid_1's multi_logloss: 0.290054       \n",
      "[231]\ttraining's multi_logloss: 0.122439\tvalid_1's multi_logloss: 0.290061       \n",
      "[232]\ttraining's multi_logloss: 0.121893\tvalid_1's multi_logloss: 0.290007       \n",
      "[233]\ttraining's multi_logloss: 0.121348\tvalid_1's multi_logloss: 0.290043       \n",
      "[234]\ttraining's multi_logloss: 0.120798\tvalid_1's multi_logloss: 0.290097       \n",
      "[235]\ttraining's multi_logloss: 0.120273\tvalid_1's multi_logloss: 0.29008        \n",
      "[236]\ttraining's multi_logloss: 0.119735\tvalid_1's multi_logloss: 0.290144       \n",
      "[237]\ttraining's multi_logloss: 0.119197\tvalid_1's multi_logloss: 0.290148       \n",
      "[238]\ttraining's multi_logloss: 0.118678\tvalid_1's multi_logloss: 0.290129       \n",
      "[239]\ttraining's multi_logloss: 0.118113\tvalid_1's multi_logloss: 0.290153       \n",
      "[240]\ttraining's multi_logloss: 0.117536\tvalid_1's multi_logloss: 0.290157       \n",
      "[241]\ttraining's multi_logloss: 0.117024\tvalid_1's multi_logloss: 0.290149       \n",
      "[242]\ttraining's multi_logloss: 0.116491\tvalid_1's multi_logloss: 0.290228       \n",
      "[243]\ttraining's multi_logloss: 0.115988\tvalid_1's multi_logloss: 0.290226       \n",
      "[244]\ttraining's multi_logloss: 0.115472\tvalid_1's multi_logloss: 0.290206       \n",
      "[245]\ttraining's multi_logloss: 0.114944\tvalid_1's multi_logloss: 0.290301       \n",
      "[246]\ttraining's multi_logloss: 0.114415\tvalid_1's multi_logloss: 0.290372       \n",
      "[247]\ttraining's multi_logloss: 0.113906\tvalid_1's multi_logloss: 0.290345       \n",
      "[248]\ttraining's multi_logloss: 0.113376\tvalid_1's multi_logloss: 0.290394       \n",
      "[249]\ttraining's multi_logloss: 0.112907\tvalid_1's multi_logloss: 0.290443       \n",
      "[250]\ttraining's multi_logloss: 0.112422\tvalid_1's multi_logloss: 0.290437       \n",
      "[251]\ttraining's multi_logloss: 0.11192\tvalid_1's multi_logloss: 0.290386        \n",
      "[252]\ttraining's multi_logloss: 0.111427\tvalid_1's multi_logloss: 0.290385       \n",
      "[253]\ttraining's multi_logloss: 0.110962\tvalid_1's multi_logloss: 0.290376       \n",
      "[254]\ttraining's multi_logloss: 0.110476\tvalid_1's multi_logloss: 0.290426       \n",
      "[255]\ttraining's multi_logloss: 0.109988\tvalid_1's multi_logloss: 0.290412       \n",
      "[256]\ttraining's multi_logloss: 0.109524\tvalid_1's multi_logloss: 0.290445       \n",
      "[257]\ttraining's multi_logloss: 0.109065\tvalid_1's multi_logloss: 0.290474       \n",
      "[258]\ttraining's multi_logloss: 0.10862\tvalid_1's multi_logloss: 0.29052         \n",
      "[259]\ttraining's multi_logloss: 0.108129\tvalid_1's multi_logloss: 0.290407       \n",
      "[260]\ttraining's multi_logloss: 0.107697\tvalid_1's multi_logloss: 0.290453       \n",
      "[261]\ttraining's multi_logloss: 0.107246\tvalid_1's multi_logloss: 0.290426       \n",
      "[262]\ttraining's multi_logloss: 0.106791\tvalid_1's multi_logloss: 0.290465       \n",
      "Early stopping, best iteration is:                                               \n",
      "[232]\ttraining's multi_logloss: 0.121893\tvalid_1's multi_logloss: 0.290007\n",
      "[1]\ttraining's multi_logloss: 1.8244\tvalid_1's multi_logloss: 1.82676            \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.7318\tvalid_1's multi_logloss: 1.73494            \n",
      "[3]\ttraining's multi_logloss: 1.64919\tvalid_1's multi_logloss: 1.65307           \n",
      "[4]\ttraining's multi_logloss: 1.57467\tvalid_1's multi_logloss: 1.57892           \n",
      "[5]\ttraining's multi_logloss: 1.50656\tvalid_1's multi_logloss: 1.51149           \n",
      "[6]\ttraining's multi_logloss: 1.44455\tvalid_1's multi_logloss: 1.44989           \n",
      "[7]\ttraining's multi_logloss: 1.387\tvalid_1's multi_logloss: 1.39305             \n",
      "[8]\ttraining's multi_logloss: 1.33377\tvalid_1's multi_logloss: 1.34043           \n",
      "[9]\ttraining's multi_logloss: 1.28437\tvalid_1's multi_logloss: 1.29183           \n",
      "[10]\ttraining's multi_logloss: 1.23812\tvalid_1's multi_logloss: 1.24642          \n",
      "[11]\ttraining's multi_logloss: 1.19463\tvalid_1's multi_logloss: 1.20354          \n",
      "[12]\ttraining's multi_logloss: 1.15392\tvalid_1's multi_logloss: 1.1636           \n",
      "[13]\ttraining's multi_logloss: 1.11588\tvalid_1's multi_logloss: 1.12615          \n",
      "[14]\ttraining's multi_logloss: 1.08019\tvalid_1's multi_logloss: 1.09108          \n",
      "[15]\ttraining's multi_logloss: 1.04609\tvalid_1's multi_logloss: 1.05764          \n",
      "[16]\ttraining's multi_logloss: 1.01371\tvalid_1's multi_logloss: 1.02598          \n",
      "[17]\ttraining's multi_logloss: 0.983189\tvalid_1's multi_logloss: 0.995953        \n",
      "[18]\ttraining's multi_logloss: 0.954024\tvalid_1's multi_logloss: 0.96746         \n",
      "[19]\ttraining's multi_logloss: 0.926637\tvalid_1's multi_logloss: 0.940714        \n",
      "[20]\ttraining's multi_logloss: 0.900493\tvalid_1's multi_logloss: 0.915192        \n",
      "[21]\ttraining's multi_logloss: 0.875515\tvalid_1's multi_logloss: 0.890895        \n",
      "[22]\ttraining's multi_logloss: 0.851627\tvalid_1's multi_logloss: 0.867465        \n",
      "[23]\ttraining's multi_logloss: 0.828848\tvalid_1's multi_logloss: 0.845384        \n",
      "[24]\ttraining's multi_logloss: 0.806778\tvalid_1's multi_logloss: 0.823937        \n",
      "[25]\ttraining's multi_logloss: 0.785711\tvalid_1's multi_logloss: 0.803527        \n",
      "[26]\ttraining's multi_logloss: 0.765682\tvalid_1's multi_logloss: 0.784211        \n",
      "[27]\ttraining's multi_logloss: 0.746493\tvalid_1's multi_logloss: 0.765685        \n",
      "[28]\ttraining's multi_logloss: 0.727989\tvalid_1's multi_logloss: 0.747859        \n",
      "[29]\ttraining's multi_logloss: 0.710373\tvalid_1's multi_logloss: 0.730951        \n",
      "[30]\ttraining's multi_logloss: 0.693414\tvalid_1's multi_logloss: 0.71472         \n",
      "[31]\ttraining's multi_logloss: 0.677166\tvalid_1's multi_logloss: 0.699161        \n",
      "[32]\ttraining's multi_logloss: 0.661602\tvalid_1's multi_logloss: 0.684352        \n",
      "[33]\ttraining's multi_logloss: 0.646726\tvalid_1's multi_logloss: 0.670098        \n",
      "[34]\ttraining's multi_logloss: 0.63228\tvalid_1's multi_logloss: 0.656265         \n",
      "[35]\ttraining's multi_logloss: 0.618547\tvalid_1's multi_logloss: 0.643079        \n",
      "[36]\ttraining's multi_logloss: 0.605271\tvalid_1's multi_logloss: 0.630345        \n",
      "[37]\ttraining's multi_logloss: 0.59258\tvalid_1's multi_logloss: 0.618302         \n",
      "[38]\ttraining's multi_logloss: 0.580264\tvalid_1's multi_logloss: 0.606614        \n",
      "[39]\ttraining's multi_logloss: 0.568342\tvalid_1's multi_logloss: 0.595291        \n",
      "[40]\ttraining's multi_logloss: 0.55697\tvalid_1's multi_logloss: 0.584651         \n",
      "[41]\ttraining's multi_logloss: 0.545898\tvalid_1's multi_logloss: 0.574125        \n",
      "[42]\ttraining's multi_logloss: 0.535433\tvalid_1's multi_logloss: 0.564273        \n",
      "[43]\ttraining's multi_logloss: 0.525243\tvalid_1's multi_logloss: 0.554625        \n",
      "[44]\ttraining's multi_logloss: 0.515433\tvalid_1's multi_logloss: 0.545358        \n",
      "[45]\ttraining's multi_logloss: 0.505979\tvalid_1's multi_logloss: 0.536303        \n",
      "[46]\ttraining's multi_logloss: 0.496751\tvalid_1's multi_logloss: 0.527827        \n",
      "[47]\ttraining's multi_logloss: 0.487918\tvalid_1's multi_logloss: 0.519615        \n",
      "[48]\ttraining's multi_logloss: 0.479298\tvalid_1's multi_logloss: 0.511705        \n",
      "[49]\ttraining's multi_logloss: 0.471167\tvalid_1's multi_logloss: 0.50412         \n",
      "[50]\ttraining's multi_logloss: 0.46304\tvalid_1's multi_logloss: 0.496789         \n",
      "[51]\ttraining's multi_logloss: 0.455436\tvalid_1's multi_logloss: 0.489831        \n",
      "[52]\ttraining's multi_logloss: 0.448039\tvalid_1's multi_logloss: 0.483109        \n",
      "[53]\ttraining's multi_logloss: 0.44076\tvalid_1's multi_logloss: 0.476443         \n",
      "[54]\ttraining's multi_logloss: 0.433686\tvalid_1's multi_logloss: 0.470274        \n",
      "[55]\ttraining's multi_logloss: 0.427007\tvalid_1's multi_logloss: 0.464231        \n",
      "[56]\ttraining's multi_logloss: 0.420538\tvalid_1's multi_logloss: 0.458581        \n",
      "[57]\ttraining's multi_logloss: 0.414189\tvalid_1's multi_logloss: 0.452922        \n",
      "[58]\ttraining's multi_logloss: 0.408072\tvalid_1's multi_logloss: 0.447493        \n",
      "[59]\ttraining's multi_logloss: 0.402153\tvalid_1's multi_logloss: 0.44225         \n",
      "[60]\ttraining's multi_logloss: 0.396335\tvalid_1's multi_logloss: 0.437126        \n",
      "[61]\ttraining's multi_logloss: 0.390698\tvalid_1's multi_logloss: 0.432286        \n",
      "[62]\ttraining's multi_logloss: 0.38526\tvalid_1's multi_logloss: 0.427583         \n",
      "[63]\ttraining's multi_logloss: 0.380104\tvalid_1's multi_logloss: 0.423078        \n",
      "[64]\ttraining's multi_logloss: 0.375042\tvalid_1's multi_logloss: 0.418656        \n",
      "[65]\ttraining's multi_logloss: 0.370043\tvalid_1's multi_logloss: 0.414193        \n",
      "[66]\ttraining's multi_logloss: 0.36515\tvalid_1's multi_logloss: 0.409935         \n",
      "[67]\ttraining's multi_logloss: 0.360478\tvalid_1's multi_logloss: 0.405827        \n",
      "[68]\ttraining's multi_logloss: 0.35592\tvalid_1's multi_logloss: 0.401959         \n",
      "[69]\ttraining's multi_logloss: 0.351558\tvalid_1's multi_logloss: 0.398283        \n",
      "[70]\ttraining's multi_logloss: 0.347186\tvalid_1's multi_logloss: 0.394521        \n",
      "[71]\ttraining's multi_logloss: 0.343029\tvalid_1's multi_logloss: 0.391059        \n",
      "[72]\ttraining's multi_logloss: 0.339019\tvalid_1's multi_logloss: 0.387758        \n",
      "[73]\ttraining's multi_logloss: 0.335163\tvalid_1's multi_logloss: 0.384522        \n",
      "[74]\ttraining's multi_logloss: 0.331292\tvalid_1's multi_logloss: 0.381256        \n",
      "[75]\ttraining's multi_logloss: 0.327578\tvalid_1's multi_logloss: 0.378121        \n",
      "[76]\ttraining's multi_logloss: 0.323881\tvalid_1's multi_logloss: 0.375039        \n",
      "[77]\ttraining's multi_logloss: 0.320425\tvalid_1's multi_logloss: 0.372105        \n",
      "[78]\ttraining's multi_logloss: 0.317015\tvalid_1's multi_logloss: 0.36938         \n",
      "[79]\ttraining's multi_logloss: 0.3136\tvalid_1's multi_logloss: 0.366702          \n",
      "[80]\ttraining's multi_logloss: 0.310186\tvalid_1's multi_logloss: 0.364009        \n",
      "[81]\ttraining's multi_logloss: 0.306773\tvalid_1's multi_logloss: 0.361283        \n",
      "[82]\ttraining's multi_logloss: 0.303649\tvalid_1's multi_logloss: 0.358804        \n",
      "[83]\ttraining's multi_logloss: 0.3004\tvalid_1's multi_logloss: 0.356231          \n",
      "[84]\ttraining's multi_logloss: 0.297367\tvalid_1's multi_logloss: 0.353918        \n",
      "[85]\ttraining's multi_logloss: 0.294284\tvalid_1's multi_logloss: 0.35151         \n",
      "[86]\ttraining's multi_logloss: 0.291433\tvalid_1's multi_logloss: 0.349321        \n",
      "[87]\ttraining's multi_logloss: 0.28854\tvalid_1's multi_logloss: 0.347095         \n",
      "[88]\ttraining's multi_logloss: 0.285797\tvalid_1's multi_logloss: 0.34504         \n",
      "[89]\ttraining's multi_logloss: 0.283\tvalid_1's multi_logloss: 0.342921           \n",
      "[90]\ttraining's multi_logloss: 0.280271\tvalid_1's multi_logloss: 0.34092         \n",
      "[91]\ttraining's multi_logloss: 0.277708\tvalid_1's multi_logloss: 0.339112        \n",
      "[92]\ttraining's multi_logloss: 0.275221\tvalid_1's multi_logloss: 0.337357        \n",
      "[93]\ttraining's multi_logloss: 0.272653\tvalid_1's multi_logloss: 0.335479        \n",
      "[94]\ttraining's multi_logloss: 0.270253\tvalid_1's multi_logloss: 0.333805        \n",
      "[95]\ttraining's multi_logloss: 0.267864\tvalid_1's multi_logloss: 0.332111        \n",
      "[96]\ttraining's multi_logloss: 0.265556\tvalid_1's multi_logloss: 0.33051         \n",
      "[97]\ttraining's multi_logloss: 0.263232\tvalid_1's multi_logloss: 0.329066        \n",
      "[98]\ttraining's multi_logloss: 0.261004\tvalid_1's multi_logloss: 0.327568        \n",
      "[99]\ttraining's multi_logloss: 0.258771\tvalid_1's multi_logloss: 0.326186        \n",
      "[100]\ttraining's multi_logloss: 0.256618\tvalid_1's multi_logloss: 0.32478        \n",
      "[101]\ttraining's multi_logloss: 0.254542\tvalid_1's multi_logloss: 0.323553       \n",
      "[102]\ttraining's multi_logloss: 0.252461\tvalid_1's multi_logloss: 0.322288       \n",
      "[103]\ttraining's multi_logloss: 0.250485\tvalid_1's multi_logloss: 0.321247       \n",
      "[104]\ttraining's multi_logloss: 0.248505\tvalid_1's multi_logloss: 0.320088       \n",
      "[105]\ttraining's multi_logloss: 0.246552\tvalid_1's multi_logloss: 0.318986       \n",
      "[106]\ttraining's multi_logloss: 0.244634\tvalid_1's multi_logloss: 0.318021       \n",
      "[107]\ttraining's multi_logloss: 0.242697\tvalid_1's multi_logloss: 0.316909       \n",
      "[108]\ttraining's multi_logloss: 0.240782\tvalid_1's multi_logloss: 0.315823       \n",
      "[109]\ttraining's multi_logloss: 0.238921\tvalid_1's multi_logloss: 0.314773       \n",
      "[110]\ttraining's multi_logloss: 0.237026\tvalid_1's multi_logloss: 0.313716       \n",
      "[111]\ttraining's multi_logloss: 0.235262\tvalid_1's multi_logloss: 0.312752       \n",
      "[112]\ttraining's multi_logloss: 0.23342\tvalid_1's multi_logloss: 0.311784        \n",
      "[113]\ttraining's multi_logloss: 0.231765\tvalid_1's multi_logloss: 0.310917       \n",
      "[114]\ttraining's multi_logloss: 0.230006\tvalid_1's multi_logloss: 0.310002       \n",
      "[115]\ttraining's multi_logloss: 0.228336\tvalid_1's multi_logloss: 0.309154       \n",
      "[116]\ttraining's multi_logloss: 0.226688\tvalid_1's multi_logloss: 0.308286       \n",
      "[117]\ttraining's multi_logloss: 0.225102\tvalid_1's multi_logloss: 0.307518       \n",
      "[118]\ttraining's multi_logloss: 0.223515\tvalid_1's multi_logloss: 0.306722       \n",
      "[119]\ttraining's multi_logloss: 0.221988\tvalid_1's multi_logloss: 0.306012       \n",
      "[120]\ttraining's multi_logloss: 0.220444\tvalid_1's multi_logloss: 0.30523        \n",
      "[121]\ttraining's multi_logloss: 0.218991\tvalid_1's multi_logloss: 0.304549       \n",
      "[122]\ttraining's multi_logloss: 0.217501\tvalid_1's multi_logloss: 0.303848       \n",
      "[123]\ttraining's multi_logloss: 0.216032\tvalid_1's multi_logloss: 0.303204       \n",
      "[124]\ttraining's multi_logloss: 0.214618\tvalid_1's multi_logloss: 0.302634       \n",
      "[125]\ttraining's multi_logloss: 0.213217\tvalid_1's multi_logloss: 0.302042       \n",
      "[126]\ttraining's multi_logloss: 0.211841\tvalid_1's multi_logloss: 0.301523       \n",
      "[127]\ttraining's multi_logloss: 0.210471\tvalid_1's multi_logloss: 0.301002       \n",
      "[128]\ttraining's multi_logloss: 0.209104\tvalid_1's multi_logloss: 0.300423       \n",
      "[129]\ttraining's multi_logloss: 0.207766\tvalid_1's multi_logloss: 0.299846       \n",
      "[130]\ttraining's multi_logloss: 0.206469\tvalid_1's multi_logloss: 0.299269       \n",
      "[131]\ttraining's multi_logloss: 0.205123\tvalid_1's multi_logloss: 0.298697       \n",
      "[132]\ttraining's multi_logloss: 0.20387\tvalid_1's multi_logloss: 0.298145        \n",
      "[133]\ttraining's multi_logloss: 0.202642\tvalid_1's multi_logloss: 0.297601       \n",
      "[134]\ttraining's multi_logloss: 0.201358\tvalid_1's multi_logloss: 0.297196       \n",
      "[135]\ttraining's multi_logloss: 0.200107\tvalid_1's multi_logloss: 0.296732       \n",
      "[136]\ttraining's multi_logloss: 0.198851\tvalid_1's multi_logloss: 0.296193       \n",
      "[137]\ttraining's multi_logloss: 0.197664\tvalid_1's multi_logloss: 0.2958         \n",
      "[138]\ttraining's multi_logloss: 0.196532\tvalid_1's multi_logloss: 0.295398       \n",
      "[139]\ttraining's multi_logloss: 0.195285\tvalid_1's multi_logloss: 0.294954       \n",
      "[140]\ttraining's multi_logloss: 0.19406\tvalid_1's multi_logloss: 0.294496        \n",
      "[141]\ttraining's multi_logloss: 0.192899\tvalid_1's multi_logloss: 0.294073       \n",
      "[142]\ttraining's multi_logloss: 0.191767\tvalid_1's multi_logloss: 0.293678       \n",
      "[143]\ttraining's multi_logloss: 0.190642\tvalid_1's multi_logloss: 0.293282       \n",
      "[144]\ttraining's multi_logloss: 0.189551\tvalid_1's multi_logloss: 0.29299        \n",
      "[145]\ttraining's multi_logloss: 0.188423\tvalid_1's multi_logloss: 0.292602       \n",
      "[146]\ttraining's multi_logloss: 0.187341\tvalid_1's multi_logloss: 0.292203       \n",
      "[147]\ttraining's multi_logloss: 0.186202\tvalid_1's multi_logloss: 0.291771       \n",
      "[148]\ttraining's multi_logloss: 0.185151\tvalid_1's multi_logloss: 0.291472       \n",
      "[149]\ttraining's multi_logloss: 0.184077\tvalid_1's multi_logloss: 0.291143       \n",
      "[150]\ttraining's multi_logloss: 0.183004\tvalid_1's multi_logloss: 0.290742       \n",
      "[151]\ttraining's multi_logloss: 0.181942\tvalid_1's multi_logloss: 0.290417       \n",
      "[152]\ttraining's multi_logloss: 0.180947\tvalid_1's multi_logloss: 0.290175       \n",
      "[153]\ttraining's multi_logloss: 0.179932\tvalid_1's multi_logloss: 0.289803       \n",
      "[154]\ttraining's multi_logloss: 0.17893\tvalid_1's multi_logloss: 0.289434        \n",
      "[155]\ttraining's multi_logloss: 0.177917\tvalid_1's multi_logloss: 0.289179       \n",
      "[156]\ttraining's multi_logloss: 0.176941\tvalid_1's multi_logloss: 0.288876       \n",
      "[157]\ttraining's multi_logloss: 0.175863\tvalid_1's multi_logloss: 0.288517       \n",
      "[158]\ttraining's multi_logloss: 0.174847\tvalid_1's multi_logloss: 0.288204       \n",
      "[159]\ttraining's multi_logloss: 0.173797\tvalid_1's multi_logloss: 0.287839       \n",
      "[160]\ttraining's multi_logloss: 0.172818\tvalid_1's multi_logloss: 0.287635       \n",
      "[161]\ttraining's multi_logloss: 0.171827\tvalid_1's multi_logloss: 0.287339       \n",
      "[162]\ttraining's multi_logloss: 0.170858\tvalid_1's multi_logloss: 0.287131       \n",
      "[163]\ttraining's multi_logloss: 0.169835\tvalid_1's multi_logloss: 0.286781       \n",
      "[164]\ttraining's multi_logloss: 0.168818\tvalid_1's multi_logloss: 0.286639       \n",
      "[165]\ttraining's multi_logloss: 0.167815\tvalid_1's multi_logloss: 0.286365       \n",
      "[166]\ttraining's multi_logloss: 0.166867\tvalid_1's multi_logloss: 0.286166       \n",
      "[167]\ttraining's multi_logloss: 0.165865\tvalid_1's multi_logloss: 0.285853       \n",
      "[168]\ttraining's multi_logloss: 0.164929\tvalid_1's multi_logloss: 0.285699       \n",
      "[169]\ttraining's multi_logloss: 0.163966\tvalid_1's multi_logloss: 0.285512       \n",
      "[170]\ttraining's multi_logloss: 0.163039\tvalid_1's multi_logloss: 0.285242       \n",
      "[171]\ttraining's multi_logloss: 0.162103\tvalid_1's multi_logloss: 0.285034       \n",
      "[172]\ttraining's multi_logloss: 0.161241\tvalid_1's multi_logloss: 0.284892       \n",
      "[173]\ttraining's multi_logloss: 0.160374\tvalid_1's multi_logloss: 0.284782       \n",
      "[174]\ttraining's multi_logloss: 0.159477\tvalid_1's multi_logloss: 0.28464        \n",
      "[175]\ttraining's multi_logloss: 0.158611\tvalid_1's multi_logloss: 0.284435       \n",
      "[176]\ttraining's multi_logloss: 0.157734\tvalid_1's multi_logloss: 0.284231       \n",
      "[177]\ttraining's multi_logloss: 0.156877\tvalid_1's multi_logloss: 0.284061       \n",
      "[178]\ttraining's multi_logloss: 0.156059\tvalid_1's multi_logloss: 0.283901       \n",
      "[179]\ttraining's multi_logloss: 0.155266\tvalid_1's multi_logloss: 0.283775       \n",
      "[180]\ttraining's multi_logloss: 0.154451\tvalid_1's multi_logloss: 0.28354        \n",
      "[181]\ttraining's multi_logloss: 0.153639\tvalid_1's multi_logloss: 0.283476       \n",
      "[182]\ttraining's multi_logloss: 0.15286\tvalid_1's multi_logloss: 0.283332        \n",
      "[183]\ttraining's multi_logloss: 0.152072\tvalid_1's multi_logloss: 0.283102       \n",
      "[184]\ttraining's multi_logloss: 0.151307\tvalid_1's multi_logloss: 0.282962       \n",
      "[185]\ttraining's multi_logloss: 0.150511\tvalid_1's multi_logloss: 0.282748       \n",
      "[186]\ttraining's multi_logloss: 0.149725\tvalid_1's multi_logloss: 0.282556       \n",
      "[187]\ttraining's multi_logloss: 0.148982\tvalid_1's multi_logloss: 0.282404       \n",
      "[188]\ttraining's multi_logloss: 0.148228\tvalid_1's multi_logloss: 0.282292       \n",
      "[189]\ttraining's multi_logloss: 0.147493\tvalid_1's multi_logloss: 0.282273       \n",
      "[190]\ttraining's multi_logloss: 0.146719\tvalid_1's multi_logloss: 0.2822         \n",
      "[191]\ttraining's multi_logloss: 0.145986\tvalid_1's multi_logloss: 0.282007       \n",
      "[192]\ttraining's multi_logloss: 0.145277\tvalid_1's multi_logloss: 0.281966       \n",
      "[193]\ttraining's multi_logloss: 0.144542\tvalid_1's multi_logloss: 0.281913       \n",
      "[194]\ttraining's multi_logloss: 0.143838\tvalid_1's multi_logloss: 0.281829       \n",
      "[195]\ttraining's multi_logloss: 0.143139\tvalid_1's multi_logloss: 0.281811       \n",
      "[196]\ttraining's multi_logloss: 0.142417\tvalid_1's multi_logloss: 0.281756       \n",
      "[197]\ttraining's multi_logloss: 0.141666\tvalid_1's multi_logloss: 0.281586       \n",
      "[198]\ttraining's multi_logloss: 0.140986\tvalid_1's multi_logloss: 0.281566       \n",
      "[199]\ttraining's multi_logloss: 0.140258\tvalid_1's multi_logloss: 0.281549       \n",
      "[200]\ttraining's multi_logloss: 0.139512\tvalid_1's multi_logloss: 0.28157        \n",
      "[201]\ttraining's multi_logloss: 0.138837\tvalid_1's multi_logloss: 0.281545       \n",
      "[202]\ttraining's multi_logloss: 0.138171\tvalid_1's multi_logloss: 0.281589       \n",
      "[203]\ttraining's multi_logloss: 0.137494\tvalid_1's multi_logloss: 0.281601       \n",
      "[204]\ttraining's multi_logloss: 0.136819\tvalid_1's multi_logloss: 0.281555       \n",
      "[205]\ttraining's multi_logloss: 0.13614\tvalid_1's multi_logloss: 0.281438        \n",
      "[206]\ttraining's multi_logloss: 0.135513\tvalid_1's multi_logloss: 0.281329       \n",
      "[207]\ttraining's multi_logloss: 0.134803\tvalid_1's multi_logloss: 0.281326       \n",
      "[208]\ttraining's multi_logloss: 0.134142\tvalid_1's multi_logloss: 0.281299       \n",
      "[209]\ttraining's multi_logloss: 0.133494\tvalid_1's multi_logloss: 0.281242       \n",
      "[210]\ttraining's multi_logloss: 0.132877\tvalid_1's multi_logloss: 0.281186       \n",
      "[211]\ttraining's multi_logloss: 0.132256\tvalid_1's multi_logloss: 0.281169       \n",
      "[212]\ttraining's multi_logloss: 0.131595\tvalid_1's multi_logloss: 0.281201       \n",
      "[213]\ttraining's multi_logloss: 0.130973\tvalid_1's multi_logloss: 0.281191       \n",
      "[214]\ttraining's multi_logloss: 0.130351\tvalid_1's multi_logloss: 0.281202       \n",
      "[215]\ttraining's multi_logloss: 0.12976\tvalid_1's multi_logloss: 0.281219        \n",
      "[216]\ttraining's multi_logloss: 0.129154\tvalid_1's multi_logloss: 0.281192       \n",
      "[217]\ttraining's multi_logloss: 0.128566\tvalid_1's multi_logloss: 0.281258       \n",
      "[218]\ttraining's multi_logloss: 0.127937\tvalid_1's multi_logloss: 0.281219       \n",
      "[219]\ttraining's multi_logloss: 0.127361\tvalid_1's multi_logloss: 0.28126        \n",
      "[220]\ttraining's multi_logloss: 0.126741\tvalid_1's multi_logloss: 0.281244       \n",
      "[221]\ttraining's multi_logloss: 0.12616\tvalid_1's multi_logloss: 0.28131         \n",
      "[222]\ttraining's multi_logloss: 0.125618\tvalid_1's multi_logloss: 0.281325       \n",
      "[223]\ttraining's multi_logloss: 0.125017\tvalid_1's multi_logloss: 0.281306       \n",
      "[224]\ttraining's multi_logloss: 0.124425\tvalid_1's multi_logloss: 0.281269       \n",
      "[225]\ttraining's multi_logloss: 0.123862\tvalid_1's multi_logloss: 0.281184       \n",
      "[226]\ttraining's multi_logloss: 0.123283\tvalid_1's multi_logloss: 0.281323       \n",
      "[227]\ttraining's multi_logloss: 0.122728\tvalid_1's multi_logloss: 0.28133        \n",
      "[228]\ttraining's multi_logloss: 0.122184\tvalid_1's multi_logloss: 0.281216       \n",
      "[229]\ttraining's multi_logloss: 0.12162\tvalid_1's multi_logloss: 0.281172        \n",
      "[230]\ttraining's multi_logloss: 0.12107\tvalid_1's multi_logloss: 0.281211        \n",
      "[231]\ttraining's multi_logloss: 0.12052\tvalid_1's multi_logloss: 0.281135        \n",
      "[232]\ttraining's multi_logloss: 0.119959\tvalid_1's multi_logloss: 0.281168       \n",
      "[233]\ttraining's multi_logloss: 0.119439\tvalid_1's multi_logloss: 0.281236       \n",
      "[234]\ttraining's multi_logloss: 0.118886\tvalid_1's multi_logloss: 0.281312       \n",
      "[235]\ttraining's multi_logloss: 0.118353\tvalid_1's multi_logloss: 0.281322       \n",
      "[236]\ttraining's multi_logloss: 0.117828\tvalid_1's multi_logloss: 0.281345       \n",
      "[237]\ttraining's multi_logloss: 0.117359\tvalid_1's multi_logloss: 0.281293       \n",
      "[238]\ttraining's multi_logloss: 0.116882\tvalid_1's multi_logloss: 0.281306       \n",
      "[239]\ttraining's multi_logloss: 0.11631\tvalid_1's multi_logloss: 0.281381        \n",
      "[240]\ttraining's multi_logloss: 0.115801\tvalid_1's multi_logloss: 0.281378       \n",
      "[241]\ttraining's multi_logloss: 0.115246\tvalid_1's multi_logloss: 0.28136        \n",
      "[242]\ttraining's multi_logloss: 0.114767\tvalid_1's multi_logloss: 0.281405       \n",
      "[243]\ttraining's multi_logloss: 0.114223\tvalid_1's multi_logloss: 0.281465       \n",
      "[244]\ttraining's multi_logloss: 0.113693\tvalid_1's multi_logloss: 0.281497       \n",
      "[245]\ttraining's multi_logloss: 0.11313\tvalid_1's multi_logloss: 0.281543        \n",
      "[246]\ttraining's multi_logloss: 0.112586\tvalid_1's multi_logloss: 0.281482       \n",
      "[247]\ttraining's multi_logloss: 0.112082\tvalid_1's multi_logloss: 0.281528       \n",
      "[248]\ttraining's multi_logloss: 0.111593\tvalid_1's multi_logloss: 0.281539       \n",
      "[249]\ttraining's multi_logloss: 0.11111\tvalid_1's multi_logloss: 0.281554        \n",
      "[250]\ttraining's multi_logloss: 0.110589\tvalid_1's multi_logloss: 0.281681       \n",
      "[251]\ttraining's multi_logloss: 0.110097\tvalid_1's multi_logloss: 0.281725       \n",
      "[252]\ttraining's multi_logloss: 0.109623\tvalid_1's multi_logloss: 0.281794       \n",
      "[253]\ttraining's multi_logloss: 0.109145\tvalid_1's multi_logloss: 0.281818       \n",
      "[254]\ttraining's multi_logloss: 0.108629\tvalid_1's multi_logloss: 0.281885       \n",
      "[255]\ttraining's multi_logloss: 0.108179\tvalid_1's multi_logloss: 0.281893       \n",
      "[256]\ttraining's multi_logloss: 0.107681\tvalid_1's multi_logloss: 0.281957       \n",
      "[257]\ttraining's multi_logloss: 0.107207\tvalid_1's multi_logloss: 0.281963       \n",
      "[258]\ttraining's multi_logloss: 0.106762\tvalid_1's multi_logloss: 0.282063       \n",
      "[259]\ttraining's multi_logloss: 0.106268\tvalid_1's multi_logloss: 0.282065       \n",
      "[260]\ttraining's multi_logloss: 0.105813\tvalid_1's multi_logloss: 0.282138       \n",
      "[261]\ttraining's multi_logloss: 0.10539\tvalid_1's multi_logloss: 0.282119        \n",
      "Early stopping, best iteration is:                                               \n",
      "[231]\ttraining's multi_logloss: 0.12052\tvalid_1's multi_logloss: 0.281135\n",
      "[1]\ttraining's multi_logloss: 1.82515\tvalid_1's multi_logloss: 1.82784           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.73272\tvalid_1's multi_logloss: 1.7361            \n",
      "[3]\ttraining's multi_logloss: 1.65019\tvalid_1's multi_logloss: 1.65423           \n",
      "[4]\ttraining's multi_logloss: 1.57544\tvalid_1's multi_logloss: 1.5802            \n",
      "[5]\ttraining's multi_logloss: 1.50741\tvalid_1's multi_logloss: 1.51257           \n",
      "[6]\ttraining's multi_logloss: 1.44504\tvalid_1's multi_logloss: 1.4505            \n",
      "[7]\ttraining's multi_logloss: 1.38729\tvalid_1's multi_logloss: 1.39342           \n",
      "[8]\ttraining's multi_logloss: 1.33398\tvalid_1's multi_logloss: 1.34057           \n",
      "[9]\ttraining's multi_logloss: 1.28422\tvalid_1's multi_logloss: 1.29135           \n",
      "[10]\ttraining's multi_logloss: 1.23827\tvalid_1's multi_logloss: 1.24596          \n",
      "[11]\ttraining's multi_logloss: 1.19515\tvalid_1's multi_logloss: 1.20341          \n",
      "[12]\ttraining's multi_logloss: 1.15472\tvalid_1's multi_logloss: 1.16334          \n",
      "[13]\ttraining's multi_logloss: 1.11654\tvalid_1's multi_logloss: 1.12549          \n",
      "[14]\ttraining's multi_logloss: 1.08043\tvalid_1's multi_logloss: 1.08978          \n",
      "[15]\ttraining's multi_logloss: 1.04618\tvalid_1's multi_logloss: 1.05606          \n",
      "[16]\ttraining's multi_logloss: 1.01413\tvalid_1's multi_logloss: 1.02424          \n",
      "[17]\ttraining's multi_logloss: 0.983563\tvalid_1's multi_logloss: 0.994085        \n",
      "[18]\ttraining's multi_logloss: 0.954516\tvalid_1's multi_logloss: 0.965348        \n",
      "[19]\ttraining's multi_logloss: 0.926983\tvalid_1's multi_logloss: 0.938191        \n",
      "[20]\ttraining's multi_logloss: 0.900699\tvalid_1's multi_logloss: 0.912325        \n",
      "[21]\ttraining's multi_logloss: 0.875505\tvalid_1's multi_logloss: 0.887245        \n",
      "[22]\ttraining's multi_logloss: 0.851531\tvalid_1's multi_logloss: 0.863757        \n",
      "[23]\ttraining's multi_logloss: 0.828597\tvalid_1's multi_logloss: 0.841243        \n",
      "[24]\ttraining's multi_logloss: 0.806701\tvalid_1's multi_logloss: 0.819708        \n",
      "[25]\ttraining's multi_logloss: 0.785681\tvalid_1's multi_logloss: 0.799059        \n",
      "[26]\ttraining's multi_logloss: 0.765735\tvalid_1's multi_logloss: 0.779597        \n",
      "[27]\ttraining's multi_logloss: 0.746679\tvalid_1's multi_logloss: 0.760925        \n",
      "[28]\ttraining's multi_logloss: 0.728449\tvalid_1's multi_logloss: 0.743181        \n",
      "[29]\ttraining's multi_logloss: 0.71097\tvalid_1's multi_logloss: 0.726185         \n",
      "[30]\ttraining's multi_logloss: 0.694135\tvalid_1's multi_logloss: 0.709806        \n",
      "[31]\ttraining's multi_logloss: 0.678124\tvalid_1's multi_logloss: 0.694358        \n",
      "[32]\ttraining's multi_logloss: 0.662782\tvalid_1's multi_logloss: 0.679561        \n",
      "[33]\ttraining's multi_logloss: 0.647803\tvalid_1's multi_logloss: 0.665052        \n",
      "[34]\ttraining's multi_logloss: 0.633567\tvalid_1's multi_logloss: 0.651459        \n",
      "[35]\ttraining's multi_logloss: 0.61994\tvalid_1's multi_logloss: 0.638458         \n",
      "[36]\ttraining's multi_logloss: 0.606592\tvalid_1's multi_logloss: 0.625556        \n",
      "[37]\ttraining's multi_logloss: 0.594117\tvalid_1's multi_logloss: 0.613697        \n",
      "[38]\ttraining's multi_logloss: 0.582001\tvalid_1's multi_logloss: 0.602299        \n",
      "[39]\ttraining's multi_logloss: 0.570143\tvalid_1's multi_logloss: 0.590931        \n",
      "[40]\ttraining's multi_logloss: 0.558951\tvalid_1's multi_logloss: 0.580324        \n",
      "[41]\ttraining's multi_logloss: 0.548105\tvalid_1's multi_logloss: 0.56999         \n",
      "[42]\ttraining's multi_logloss: 0.537655\tvalid_1's multi_logloss: 0.560164        \n",
      "[43]\ttraining's multi_logloss: 0.527607\tvalid_1's multi_logloss: 0.550611        \n",
      "[44]\ttraining's multi_logloss: 0.51792\tvalid_1's multi_logloss: 0.541474         \n",
      "[45]\ttraining's multi_logloss: 0.508557\tvalid_1's multi_logloss: 0.532539        \n",
      "[46]\ttraining's multi_logloss: 0.499524\tvalid_1's multi_logloss: 0.524129        \n",
      "[47]\ttraining's multi_logloss: 0.490776\tvalid_1's multi_logloss: 0.515869        \n",
      "[48]\ttraining's multi_logloss: 0.482498\tvalid_1's multi_logloss: 0.507957        \n",
      "[49]\ttraining's multi_logloss: 0.474496\tvalid_1's multi_logloss: 0.500463        \n",
      "[50]\ttraining's multi_logloss: 0.466727\tvalid_1's multi_logloss: 0.493244        \n",
      "[51]\ttraining's multi_logloss: 0.459256\tvalid_1's multi_logloss: 0.486305        \n",
      "[52]\ttraining's multi_logloss: 0.451923\tvalid_1's multi_logloss: 0.479511        \n",
      "[53]\ttraining's multi_logloss: 0.444934\tvalid_1's multi_logloss: 0.47312         \n",
      "[54]\ttraining's multi_logloss: 0.438069\tvalid_1's multi_logloss: 0.466849        \n",
      "[55]\ttraining's multi_logloss: 0.431399\tvalid_1's multi_logloss: 0.460775        \n",
      "[56]\ttraining's multi_logloss: 0.424993\tvalid_1's multi_logloss: 0.454855        \n",
      "[57]\ttraining's multi_logloss: 0.418754\tvalid_1's multi_logloss: 0.449026        \n",
      "[58]\ttraining's multi_logloss: 0.412717\tvalid_1's multi_logloss: 0.443494        \n",
      "[59]\ttraining's multi_logloss: 0.406768\tvalid_1's multi_logloss: 0.438027        \n",
      "[60]\ttraining's multi_logloss: 0.400837\tvalid_1's multi_logloss: 0.43258         \n",
      "[61]\ttraining's multi_logloss: 0.395175\tvalid_1's multi_logloss: 0.427403        \n",
      "[62]\ttraining's multi_logloss: 0.389756\tvalid_1's multi_logloss: 0.422579        \n",
      "[63]\ttraining's multi_logloss: 0.384518\tvalid_1's multi_logloss: 0.417831        \n",
      "[64]\ttraining's multi_logloss: 0.379401\tvalid_1's multi_logloss: 0.413124        \n",
      "[65]\ttraining's multi_logloss: 0.374329\tvalid_1's multi_logloss: 0.408616        \n",
      "[66]\ttraining's multi_logloss: 0.36955\tvalid_1's multi_logloss: 0.404474         \n",
      "[67]\ttraining's multi_logloss: 0.364803\tvalid_1's multi_logloss: 0.400236        \n",
      "[68]\ttraining's multi_logloss: 0.360321\tvalid_1's multi_logloss: 0.39629         \n",
      "[69]\ttraining's multi_logloss: 0.355912\tvalid_1's multi_logloss: 0.392356        \n",
      "[70]\ttraining's multi_logloss: 0.351586\tvalid_1's multi_logloss: 0.388507        \n",
      "[71]\ttraining's multi_logloss: 0.347475\tvalid_1's multi_logloss: 0.384872        \n",
      "[72]\ttraining's multi_logloss: 0.343471\tvalid_1's multi_logloss: 0.381417        \n",
      "[73]\ttraining's multi_logloss: 0.339497\tvalid_1's multi_logloss: 0.377906        \n",
      "[74]\ttraining's multi_logloss: 0.335645\tvalid_1's multi_logloss: 0.374614        \n",
      "[75]\ttraining's multi_logloss: 0.33193\tvalid_1's multi_logloss: 0.37138          \n",
      "[76]\ttraining's multi_logloss: 0.328209\tvalid_1's multi_logloss: 0.368103        \n",
      "[77]\ttraining's multi_logloss: 0.324632\tvalid_1's multi_logloss: 0.36511         \n",
      "[78]\ttraining's multi_logloss: 0.321167\tvalid_1's multi_logloss: 0.362286        \n",
      "[79]\ttraining's multi_logloss: 0.317803\tvalid_1's multi_logloss: 0.359463        \n",
      "[80]\ttraining's multi_logloss: 0.314495\tvalid_1's multi_logloss: 0.356833        \n",
      "[81]\ttraining's multi_logloss: 0.311193\tvalid_1's multi_logloss: 0.354135        \n",
      "[82]\ttraining's multi_logloss: 0.308034\tvalid_1's multi_logloss: 0.351601        \n",
      "[83]\ttraining's multi_logloss: 0.304973\tvalid_1's multi_logloss: 0.349152        \n",
      "[84]\ttraining's multi_logloss: 0.302013\tvalid_1's multi_logloss: 0.346792        \n",
      "[85]\ttraining's multi_logloss: 0.299162\tvalid_1's multi_logloss: 0.344592        \n",
      "[86]\ttraining's multi_logloss: 0.296362\tvalid_1's multi_logloss: 0.34239         \n",
      "[87]\ttraining's multi_logloss: 0.293544\tvalid_1's multi_logloss: 0.340196        \n",
      "[88]\ttraining's multi_logloss: 0.290769\tvalid_1's multi_logloss: 0.338003        \n",
      "[89]\ttraining's multi_logloss: 0.288078\tvalid_1's multi_logloss: 0.335971        \n",
      "[90]\ttraining's multi_logloss: 0.285416\tvalid_1's multi_logloss: 0.333916        \n",
      "[91]\ttraining's multi_logloss: 0.282859\tvalid_1's multi_logloss: 0.332047        \n",
      "[92]\ttraining's multi_logloss: 0.280352\tvalid_1's multi_logloss: 0.330188        \n",
      "[93]\ttraining's multi_logloss: 0.277912\tvalid_1's multi_logloss: 0.32845         \n",
      "[94]\ttraining's multi_logloss: 0.27549\tvalid_1's multi_logloss: 0.326736         \n",
      "[95]\ttraining's multi_logloss: 0.273113\tvalid_1's multi_logloss: 0.324868        \n",
      "[96]\ttraining's multi_logloss: 0.270816\tvalid_1's multi_logloss: 0.323242        \n",
      "[97]\ttraining's multi_logloss: 0.268629\tvalid_1's multi_logloss: 0.32174         \n",
      "[98]\ttraining's multi_logloss: 0.266384\tvalid_1's multi_logloss: 0.320226        \n",
      "[99]\ttraining's multi_logloss: 0.264314\tvalid_1's multi_logloss: 0.318814        \n",
      "[100]\ttraining's multi_logloss: 0.262209\tvalid_1's multi_logloss: 0.317222       \n",
      "[101]\ttraining's multi_logloss: 0.260158\tvalid_1's multi_logloss: 0.315902       \n",
      "[102]\ttraining's multi_logloss: 0.258134\tvalid_1's multi_logloss: 0.314681       \n",
      "[103]\ttraining's multi_logloss: 0.256146\tvalid_1's multi_logloss: 0.313423       \n",
      "[104]\ttraining's multi_logloss: 0.25417\tvalid_1's multi_logloss: 0.312076        \n",
      "[105]\ttraining's multi_logloss: 0.252279\tvalid_1's multi_logloss: 0.310796       \n",
      "[106]\ttraining's multi_logloss: 0.250466\tvalid_1's multi_logloss: 0.309637       \n",
      "[107]\ttraining's multi_logloss: 0.248594\tvalid_1's multi_logloss: 0.308547       \n",
      "[108]\ttraining's multi_logloss: 0.246831\tvalid_1's multi_logloss: 0.307498       \n",
      "[109]\ttraining's multi_logloss: 0.245084\tvalid_1's multi_logloss: 0.306451       \n",
      "[110]\ttraining's multi_logloss: 0.243267\tvalid_1's multi_logloss: 0.305292       \n",
      "[111]\ttraining's multi_logloss: 0.24151\tvalid_1's multi_logloss: 0.304188        \n",
      "[112]\ttraining's multi_logloss: 0.239773\tvalid_1's multi_logloss: 0.303166       \n",
      "[113]\ttraining's multi_logloss: 0.238095\tvalid_1's multi_logloss: 0.302167       \n",
      "[114]\ttraining's multi_logloss: 0.236435\tvalid_1's multi_logloss: 0.301096       \n",
      "[115]\ttraining's multi_logloss: 0.234891\tvalid_1's multi_logloss: 0.300184       \n",
      "[116]\ttraining's multi_logloss: 0.233304\tvalid_1's multi_logloss: 0.299282       \n",
      "[117]\ttraining's multi_logloss: 0.231756\tvalid_1's multi_logloss: 0.298399       \n",
      "[118]\ttraining's multi_logloss: 0.230254\tvalid_1's multi_logloss: 0.297636       \n",
      "[119]\ttraining's multi_logloss: 0.228794\tvalid_1's multi_logloss: 0.296888       \n",
      "[120]\ttraining's multi_logloss: 0.227272\tvalid_1's multi_logloss: 0.296002       \n",
      "[121]\ttraining's multi_logloss: 0.225818\tvalid_1's multi_logloss: 0.295283       \n",
      "[122]\ttraining's multi_logloss: 0.22437\tvalid_1's multi_logloss: 0.294514        \n",
      "[123]\ttraining's multi_logloss: 0.22293\tvalid_1's multi_logloss: 0.293755        \n",
      "[124]\ttraining's multi_logloss: 0.221488\tvalid_1's multi_logloss: 0.29294        \n",
      "[125]\ttraining's multi_logloss: 0.220142\tvalid_1's multi_logloss: 0.292296       \n",
      "[126]\ttraining's multi_logloss: 0.218798\tvalid_1's multi_logloss: 0.291558       \n",
      "[127]\ttraining's multi_logloss: 0.217426\tvalid_1's multi_logloss: 0.290899       \n",
      "[128]\ttraining's multi_logloss: 0.216116\tvalid_1's multi_logloss: 0.290258       \n",
      "[129]\ttraining's multi_logloss: 0.21477\tvalid_1's multi_logloss: 0.28963         \n",
      "[130]\ttraining's multi_logloss: 0.213388\tvalid_1's multi_logloss: 0.288953       \n",
      "[131]\ttraining's multi_logloss: 0.212101\tvalid_1's multi_logloss: 0.288273       \n",
      "[132]\ttraining's multi_logloss: 0.210837\tvalid_1's multi_logloss: 0.2877         \n",
      "[133]\ttraining's multi_logloss: 0.209634\tvalid_1's multi_logloss: 0.287196       \n",
      "[134]\ttraining's multi_logloss: 0.208385\tvalid_1's multi_logloss: 0.286641       \n",
      "[135]\ttraining's multi_logloss: 0.207144\tvalid_1's multi_logloss: 0.286082       \n",
      "[136]\ttraining's multi_logloss: 0.205865\tvalid_1's multi_logloss: 0.285573       \n",
      "[137]\ttraining's multi_logloss: 0.204639\tvalid_1's multi_logloss: 0.285037       \n",
      "[138]\ttraining's multi_logloss: 0.203429\tvalid_1's multi_logloss: 0.284441       \n",
      "[139]\ttraining's multi_logloss: 0.20222\tvalid_1's multi_logloss: 0.283941        \n",
      "[140]\ttraining's multi_logloss: 0.200993\tvalid_1's multi_logloss: 0.283446       \n",
      "[141]\ttraining's multi_logloss: 0.199821\tvalid_1's multi_logloss: 0.283012       \n",
      "[142]\ttraining's multi_logloss: 0.198669\tvalid_1's multi_logloss: 0.282534       \n",
      "[143]\ttraining's multi_logloss: 0.197483\tvalid_1's multi_logloss: 0.282058       \n",
      "[144]\ttraining's multi_logloss: 0.196319\tvalid_1's multi_logloss: 0.281644       \n",
      "[145]\ttraining's multi_logloss: 0.195177\tvalid_1's multi_logloss: 0.281195       \n",
      "[146]\ttraining's multi_logloss: 0.19406\tvalid_1's multi_logloss: 0.280812        \n",
      "[147]\ttraining's multi_logloss: 0.192952\tvalid_1's multi_logloss: 0.280442       \n",
      "[148]\ttraining's multi_logloss: 0.191821\tvalid_1's multi_logloss: 0.280039       \n",
      "[149]\ttraining's multi_logloss: 0.19073\tvalid_1's multi_logloss: 0.279581        \n",
      "[150]\ttraining's multi_logloss: 0.189636\tvalid_1's multi_logloss: 0.27915        \n",
      "[151]\ttraining's multi_logloss: 0.18853\tvalid_1's multi_logloss: 0.27885         \n",
      "[152]\ttraining's multi_logloss: 0.187511\tvalid_1's multi_logloss: 0.278457       \n",
      "[153]\ttraining's multi_logloss: 0.186541\tvalid_1's multi_logloss: 0.278184       \n",
      "[154]\ttraining's multi_logloss: 0.185488\tvalid_1's multi_logloss: 0.277859       \n",
      "[155]\ttraining's multi_logloss: 0.184477\tvalid_1's multi_logloss: 0.277571       \n",
      "[156]\ttraining's multi_logloss: 0.183478\tvalid_1's multi_logloss: 0.277394       \n",
      "[157]\ttraining's multi_logloss: 0.182513\tvalid_1's multi_logloss: 0.277094       \n",
      "[158]\ttraining's multi_logloss: 0.181509\tvalid_1's multi_logloss: 0.276871       \n",
      "[159]\ttraining's multi_logloss: 0.180523\tvalid_1's multi_logloss: 0.276641       \n",
      "[160]\ttraining's multi_logloss: 0.179519\tvalid_1's multi_logloss: 0.276507       \n",
      "[161]\ttraining's multi_logloss: 0.178534\tvalid_1's multi_logloss: 0.276264       \n",
      "[162]\ttraining's multi_logloss: 0.177539\tvalid_1's multi_logloss: 0.275988       \n",
      "[163]\ttraining's multi_logloss: 0.176587\tvalid_1's multi_logloss: 0.275728       \n",
      "[164]\ttraining's multi_logloss: 0.17568\tvalid_1's multi_logloss: 0.275504        \n",
      "[165]\ttraining's multi_logloss: 0.174761\tvalid_1's multi_logloss: 0.275319       \n",
      "[166]\ttraining's multi_logloss: 0.1739\tvalid_1's multi_logloss: 0.275088         \n",
      "[167]\ttraining's multi_logloss: 0.17303\tvalid_1's multi_logloss: 0.274952        \n",
      "[168]\ttraining's multi_logloss: 0.172128\tvalid_1's multi_logloss: 0.274804       \n",
      "[169]\ttraining's multi_logloss: 0.171306\tvalid_1's multi_logloss: 0.274625       \n",
      "[170]\ttraining's multi_logloss: 0.170376\tvalid_1's multi_logloss: 0.274437       \n",
      "[171]\ttraining's multi_logloss: 0.169475\tvalid_1's multi_logloss: 0.274203       \n",
      "[172]\ttraining's multi_logloss: 0.168656\tvalid_1's multi_logloss: 0.274117       \n",
      "[173]\ttraining's multi_logloss: 0.167799\tvalid_1's multi_logloss: 0.274029       \n",
      "[174]\ttraining's multi_logloss: 0.166911\tvalid_1's multi_logloss: 0.273854       \n",
      "[175]\ttraining's multi_logloss: 0.166089\tvalid_1's multi_logloss: 0.273735       \n",
      "[176]\ttraining's multi_logloss: 0.16522\tvalid_1's multi_logloss: 0.273459        \n",
      "[177]\ttraining's multi_logloss: 0.16441\tvalid_1's multi_logloss: 0.273323        \n",
      "[178]\ttraining's multi_logloss: 0.163599\tvalid_1's multi_logloss: 0.273202       \n",
      "[179]\ttraining's multi_logloss: 0.162746\tvalid_1's multi_logloss: 0.273049       \n",
      "[180]\ttraining's multi_logloss: 0.161924\tvalid_1's multi_logloss: 0.272929       \n",
      "[181]\ttraining's multi_logloss: 0.161149\tvalid_1's multi_logloss: 0.272706       \n",
      "[182]\ttraining's multi_logloss: 0.160358\tvalid_1's multi_logloss: 0.272469       \n",
      "[183]\ttraining's multi_logloss: 0.159552\tvalid_1's multi_logloss: 0.272301       \n",
      "[184]\ttraining's multi_logloss: 0.158732\tvalid_1's multi_logloss: 0.272128       \n",
      "[185]\ttraining's multi_logloss: 0.157902\tvalid_1's multi_logloss: 0.27198        \n",
      "[186]\ttraining's multi_logloss: 0.157158\tvalid_1's multi_logloss: 0.271826       \n",
      "[187]\ttraining's multi_logloss: 0.156337\tvalid_1's multi_logloss: 0.271566       \n",
      "[188]\ttraining's multi_logloss: 0.155502\tvalid_1's multi_logloss: 0.271392       \n",
      "[189]\ttraining's multi_logloss: 0.154762\tvalid_1's multi_logloss: 0.271218       \n",
      "[190]\ttraining's multi_logloss: 0.154017\tvalid_1's multi_logloss: 0.271052       \n",
      "[191]\ttraining's multi_logloss: 0.153265\tvalid_1's multi_logloss: 0.271          \n",
      "[192]\ttraining's multi_logloss: 0.152513\tvalid_1's multi_logloss: 0.270907       \n",
      "[193]\ttraining's multi_logloss: 0.151767\tvalid_1's multi_logloss: 0.270836       \n",
      "[194]\ttraining's multi_logloss: 0.151055\tvalid_1's multi_logloss: 0.270639       \n",
      "[195]\ttraining's multi_logloss: 0.150377\tvalid_1's multi_logloss: 0.270522       \n",
      "[196]\ttraining's multi_logloss: 0.149602\tvalid_1's multi_logloss: 0.27035        \n",
      "[197]\ttraining's multi_logloss: 0.148801\tvalid_1's multi_logloss: 0.270322       \n",
      "[198]\ttraining's multi_logloss: 0.148087\tvalid_1's multi_logloss: 0.270172       \n",
      "[199]\ttraining's multi_logloss: 0.14733\tvalid_1's multi_logloss: 0.270065        \n",
      "[200]\ttraining's multi_logloss: 0.146606\tvalid_1's multi_logloss: 0.270015       \n",
      "[201]\ttraining's multi_logloss: 0.145899\tvalid_1's multi_logloss: 0.269869       \n",
      "[202]\ttraining's multi_logloss: 0.145196\tvalid_1's multi_logloss: 0.26978        \n",
      "[203]\ttraining's multi_logloss: 0.144496\tvalid_1's multi_logloss: 0.269651       \n",
      "[204]\ttraining's multi_logloss: 0.143825\tvalid_1's multi_logloss: 0.269614       \n",
      "[205]\ttraining's multi_logloss: 0.143177\tvalid_1's multi_logloss: 0.269492       \n",
      "[206]\ttraining's multi_logloss: 0.142502\tvalid_1's multi_logloss: 0.269383       \n",
      "[207]\ttraining's multi_logloss: 0.141821\tvalid_1's multi_logloss: 0.269271       \n",
      "[208]\ttraining's multi_logloss: 0.141163\tvalid_1's multi_logloss: 0.269233       \n",
      "[209]\ttraining's multi_logloss: 0.140504\tvalid_1's multi_logloss: 0.269227       \n",
      "[210]\ttraining's multi_logloss: 0.139827\tvalid_1's multi_logloss: 0.269117       \n",
      "[211]\ttraining's multi_logloss: 0.139173\tvalid_1's multi_logloss: 0.269049       \n",
      "[212]\ttraining's multi_logloss: 0.138505\tvalid_1's multi_logloss: 0.269052       \n",
      "[213]\ttraining's multi_logloss: 0.137861\tvalid_1's multi_logloss: 0.269076       \n",
      "[214]\ttraining's multi_logloss: 0.137242\tvalid_1's multi_logloss: 0.269056       \n",
      "[215]\ttraining's multi_logloss: 0.136644\tvalid_1's multi_logloss: 0.269027       \n",
      "[216]\ttraining's multi_logloss: 0.135984\tvalid_1's multi_logloss: 0.268982       \n",
      "[217]\ttraining's multi_logloss: 0.135364\tvalid_1's multi_logloss: 0.268922       \n",
      "[218]\ttraining's multi_logloss: 0.134717\tvalid_1's multi_logloss: 0.268835       \n",
      "[219]\ttraining's multi_logloss: 0.134068\tvalid_1's multi_logloss: 0.268784       \n",
      "[220]\ttraining's multi_logloss: 0.133461\tvalid_1's multi_logloss: 0.268787       \n",
      "[221]\ttraining's multi_logloss: 0.132838\tvalid_1's multi_logloss: 0.268757       \n",
      "[222]\ttraining's multi_logloss: 0.132259\tvalid_1's multi_logloss: 0.26868        \n",
      "[223]\ttraining's multi_logloss: 0.131629\tvalid_1's multi_logloss: 0.268653       \n",
      "[224]\ttraining's multi_logloss: 0.131036\tvalid_1's multi_logloss: 0.268648       \n",
      "[225]\ttraining's multi_logloss: 0.130461\tvalid_1's multi_logloss: 0.268669       \n",
      "[226]\ttraining's multi_logloss: 0.129861\tvalid_1's multi_logloss: 0.268649       \n",
      "[227]\ttraining's multi_logloss: 0.129295\tvalid_1's multi_logloss: 0.268622       \n",
      "[228]\ttraining's multi_logloss: 0.128743\tvalid_1's multi_logloss: 0.268617       \n",
      "[229]\ttraining's multi_logloss: 0.128194\tvalid_1's multi_logloss: 0.268711       \n",
      "[230]\ttraining's multi_logloss: 0.127635\tvalid_1's multi_logloss: 0.268707       \n",
      "[231]\ttraining's multi_logloss: 0.127076\tvalid_1's multi_logloss: 0.268707       \n",
      "[232]\ttraining's multi_logloss: 0.1265\tvalid_1's multi_logloss: 0.268681         \n",
      "[233]\ttraining's multi_logloss: 0.125952\tvalid_1's multi_logloss: 0.268587       \n",
      "[234]\ttraining's multi_logloss: 0.125388\tvalid_1's multi_logloss: 0.268521       \n",
      "[235]\ttraining's multi_logloss: 0.124802\tvalid_1's multi_logloss: 0.268453       \n",
      "[236]\ttraining's multi_logloss: 0.12427\tvalid_1's multi_logloss: 0.268452        \n",
      "[237]\ttraining's multi_logloss: 0.123772\tvalid_1's multi_logloss: 0.268411       \n",
      "[238]\ttraining's multi_logloss: 0.123232\tvalid_1's multi_logloss: 0.268364       \n",
      "[239]\ttraining's multi_logloss: 0.122637\tvalid_1's multi_logloss: 0.268398       \n",
      "[240]\ttraining's multi_logloss: 0.122079\tvalid_1's multi_logloss: 0.268331       \n",
      "[241]\ttraining's multi_logloss: 0.121583\tvalid_1's multi_logloss: 0.268385       \n",
      "[242]\ttraining's multi_logloss: 0.121062\tvalid_1's multi_logloss: 0.26834        \n",
      "[243]\ttraining's multi_logloss: 0.120546\tvalid_1's multi_logloss: 0.26837        \n",
      "[244]\ttraining's multi_logloss: 0.120068\tvalid_1's multi_logloss: 0.268366       \n",
      "[245]\ttraining's multi_logloss: 0.119565\tvalid_1's multi_logloss: 0.268442       \n",
      "[246]\ttraining's multi_logloss: 0.119038\tvalid_1's multi_logloss: 0.268423       \n",
      "[247]\ttraining's multi_logloss: 0.118534\tvalid_1's multi_logloss: 0.268441       \n",
      "[248]\ttraining's multi_logloss: 0.118041\tvalid_1's multi_logloss: 0.268536       \n",
      "[249]\ttraining's multi_logloss: 0.117539\tvalid_1's multi_logloss: 0.268546       \n",
      "[250]\ttraining's multi_logloss: 0.117082\tvalid_1's multi_logloss: 0.26858        \n",
      "[251]\ttraining's multi_logloss: 0.116574\tvalid_1's multi_logloss: 0.268596       \n",
      "[252]\ttraining's multi_logloss: 0.116114\tvalid_1's multi_logloss: 0.268673       \n",
      "[253]\ttraining's multi_logloss: 0.115651\tvalid_1's multi_logloss: 0.26865        \n",
      "[254]\ttraining's multi_logloss: 0.115187\tvalid_1's multi_logloss: 0.268633       \n",
      "[255]\ttraining's multi_logloss: 0.114726\tvalid_1's multi_logloss: 0.268679       \n",
      "[256]\ttraining's multi_logloss: 0.114239\tvalid_1's multi_logloss: 0.268725       \n",
      "[257]\ttraining's multi_logloss: 0.113787\tvalid_1's multi_logloss: 0.268685       \n",
      "[258]\ttraining's multi_logloss: 0.113346\tvalid_1's multi_logloss: 0.268669       \n",
      "[259]\ttraining's multi_logloss: 0.112866\tvalid_1's multi_logloss: 0.268748       \n",
      "[260]\ttraining's multi_logloss: 0.112378\tvalid_1's multi_logloss: 0.268778       \n",
      "[261]\ttraining's multi_logloss: 0.111955\tvalid_1's multi_logloss: 0.268824       \n",
      "[262]\ttraining's multi_logloss: 0.11151\tvalid_1's multi_logloss: 0.268861        \n",
      "[263]\ttraining's multi_logloss: 0.111102\tvalid_1's multi_logloss: 0.268935       \n",
      "[264]\ttraining's multi_logloss: 0.110635\tvalid_1's multi_logloss: 0.268891       \n",
      "[265]\ttraining's multi_logloss: 0.110233\tvalid_1's multi_logloss: 0.26895        \n",
      "[266]\ttraining's multi_logloss: 0.109773\tvalid_1's multi_logloss: 0.268963       \n",
      "[267]\ttraining's multi_logloss: 0.109314\tvalid_1's multi_logloss: 0.268999       \n",
      "[268]\ttraining's multi_logloss: 0.108902\tvalid_1's multi_logloss: 0.268978       \n",
      "[269]\ttraining's multi_logloss: 0.108431\tvalid_1's multi_logloss: 0.269008       \n",
      "[270]\ttraining's multi_logloss: 0.108004\tvalid_1's multi_logloss: 0.269137       \n",
      "Early stopping, best iteration is:                                               \n",
      "[240]\ttraining's multi_logloss: 0.122079\tvalid_1's multi_logloss: 0.268331\n",
      "[1]\ttraining's multi_logloss: 1.61331\tvalid_1's multi_logloss: 1.61869           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.39423\tvalid_1's multi_logloss: 1.40536           \n",
      "[3]\ttraining's multi_logloss: 1.22815\tvalid_1's multi_logloss: 1.24446           \n",
      "[4]\ttraining's multi_logloss: 1.09565\tvalid_1's multi_logloss: 1.1159            \n",
      "[5]\ttraining's multi_logloss: 0.987601\tvalid_1's multi_logloss: 1.01152          \n",
      "[6]\ttraining's multi_logloss: 0.89717\tvalid_1's multi_logloss: 0.92428           \n",
      "[7]\ttraining's multi_logloss: 0.819473\tvalid_1's multi_logloss: 0.84955          \n",
      "[8]\ttraining's multi_logloss: 0.753091\tvalid_1's multi_logloss: 0.785887         \n",
      "[9]\ttraining's multi_logloss: 0.695917\tvalid_1's multi_logloss: 0.730886         \n",
      "[10]\ttraining's multi_logloss: 0.645703\tvalid_1's multi_logloss: 0.683286        \n",
      "[11]\ttraining's multi_logloss: 0.601135\tvalid_1's multi_logloss: 0.64086         \n",
      "[12]\ttraining's multi_logloss: 0.561519\tvalid_1's multi_logloss: 0.603797        \n",
      "[13]\ttraining's multi_logloss: 0.52671\tvalid_1's multi_logloss: 0.571239         \n",
      "[14]\ttraining's multi_logloss: 0.49587\tvalid_1's multi_logloss: 0.542674         \n",
      "[15]\ttraining's multi_logloss: 0.468149\tvalid_1's multi_logloss: 0.516695        \n",
      "[16]\ttraining's multi_logloss: 0.443261\tvalid_1's multi_logloss: 0.493785        \n",
      "[17]\ttraining's multi_logloss: 0.420916\tvalid_1's multi_logloss: 0.473566        \n",
      "[18]\ttraining's multi_logloss: 0.401083\tvalid_1's multi_logloss: 0.455423        \n",
      "[19]\ttraining's multi_logloss: 0.383054\tvalid_1's multi_logloss: 0.439159        \n",
      "[20]\ttraining's multi_logloss: 0.366417\tvalid_1's multi_logloss: 0.424038        \n",
      "[21]\ttraining's multi_logloss: 0.351528\tvalid_1's multi_logloss: 0.411037        \n",
      "[22]\ttraining's multi_logloss: 0.337876\tvalid_1's multi_logloss: 0.399368        \n",
      "[23]\ttraining's multi_logloss: 0.325807\tvalid_1's multi_logloss: 0.389744        \n",
      "[24]\ttraining's multi_logloss: 0.314426\tvalid_1's multi_logloss: 0.380288        \n",
      "[25]\ttraining's multi_logloss: 0.303931\tvalid_1's multi_logloss: 0.371842        \n",
      "[26]\ttraining's multi_logloss: 0.2946\tvalid_1's multi_logloss: 0.364286          \n",
      "[27]\ttraining's multi_logloss: 0.285476\tvalid_1's multi_logloss: 0.357215        \n",
      "[28]\ttraining's multi_logloss: 0.277332\tvalid_1's multi_logloss: 0.351362        \n",
      "[29]\ttraining's multi_logloss: 0.269427\tvalid_1's multi_logloss: 0.345891        \n",
      "[30]\ttraining's multi_logloss: 0.262317\tvalid_1's multi_logloss: 0.340669        \n",
      "[31]\ttraining's multi_logloss: 0.255674\tvalid_1's multi_logloss: 0.336408        \n",
      "[32]\ttraining's multi_logloss: 0.249245\tvalid_1's multi_logloss: 0.331932        \n",
      "[33]\ttraining's multi_logloss: 0.243296\tvalid_1's multi_logloss: 0.328285        \n",
      "[34]\ttraining's multi_logloss: 0.237659\tvalid_1's multi_logloss: 0.325041        \n",
      "[35]\ttraining's multi_logloss: 0.232507\tvalid_1's multi_logloss: 0.322328        \n",
      "[36]\ttraining's multi_logloss: 0.227317\tvalid_1's multi_logloss: 0.319049        \n",
      "[37]\ttraining's multi_logloss: 0.222488\tvalid_1's multi_logloss: 0.316748        \n",
      "[38]\ttraining's multi_logloss: 0.217943\tvalid_1's multi_logloss: 0.314211        \n",
      "[39]\ttraining's multi_logloss: 0.213402\tvalid_1's multi_logloss: 0.312152        \n",
      "[40]\ttraining's multi_logloss: 0.209199\tvalid_1's multi_logloss: 0.310462        \n",
      "[41]\ttraining's multi_logloss: 0.205331\tvalid_1's multi_logloss: 0.308764        \n",
      "[42]\ttraining's multi_logloss: 0.201441\tvalid_1's multi_logloss: 0.307066        \n",
      "[43]\ttraining's multi_logloss: 0.197715\tvalid_1's multi_logloss: 0.305203        \n",
      "[44]\ttraining's multi_logloss: 0.193967\tvalid_1's multi_logloss: 0.304002        \n",
      "[45]\ttraining's multi_logloss: 0.190511\tvalid_1's multi_logloss: 0.302838        \n",
      "[46]\ttraining's multi_logloss: 0.186875\tvalid_1's multi_logloss: 0.301226        \n",
      "[47]\ttraining's multi_logloss: 0.183652\tvalid_1's multi_logloss: 0.300169        \n",
      "[48]\ttraining's multi_logloss: 0.180552\tvalid_1's multi_logloss: 0.299172        \n",
      "[49]\ttraining's multi_logloss: 0.177467\tvalid_1's multi_logloss: 0.298396        \n",
      "[50]\ttraining's multi_logloss: 0.174624\tvalid_1's multi_logloss: 0.297266        \n",
      "[51]\ttraining's multi_logloss: 0.171625\tvalid_1's multi_logloss: 0.296874        \n",
      "[52]\ttraining's multi_logloss: 0.168701\tvalid_1's multi_logloss: 0.296105        \n",
      "[53]\ttraining's multi_logloss: 0.165894\tvalid_1's multi_logloss: 0.295472        \n",
      "[54]\ttraining's multi_logloss: 0.163285\tvalid_1's multi_logloss: 0.294769        \n",
      "[55]\ttraining's multi_logloss: 0.160706\tvalid_1's multi_logloss: 0.294077        \n",
      "[56]\ttraining's multi_logloss: 0.15823\tvalid_1's multi_logloss: 0.293386         \n",
      "[57]\ttraining's multi_logloss: 0.15575\tvalid_1's multi_logloss: 0.292867         \n",
      "[58]\ttraining's multi_logloss: 0.153272\tvalid_1's multi_logloss: 0.292409        \n",
      "[59]\ttraining's multi_logloss: 0.151012\tvalid_1's multi_logloss: 0.29184         \n",
      "[60]\ttraining's multi_logloss: 0.148697\tvalid_1's multi_logloss: 0.291523        \n",
      "[61]\ttraining's multi_logloss: 0.146472\tvalid_1's multi_logloss: 0.291189        \n",
      "[62]\ttraining's multi_logloss: 0.144158\tvalid_1's multi_logloss: 0.290869        \n",
      "[63]\ttraining's multi_logloss: 0.142119\tvalid_1's multi_logloss: 0.290646        \n",
      "[64]\ttraining's multi_logloss: 0.140051\tvalid_1's multi_logloss: 0.290601        \n",
      "[65]\ttraining's multi_logloss: 0.137837\tvalid_1's multi_logloss: 0.290165        \n",
      "[66]\ttraining's multi_logloss: 0.135982\tvalid_1's multi_logloss: 0.289942        \n",
      "[67]\ttraining's multi_logloss: 0.134133\tvalid_1's multi_logloss: 0.289742        \n",
      "[68]\ttraining's multi_logloss: 0.132162\tvalid_1's multi_logloss: 0.289726        \n",
      "[69]\ttraining's multi_logloss: 0.1303\tvalid_1's multi_logloss: 0.289613          \n",
      "[70]\ttraining's multi_logloss: 0.128507\tvalid_1's multi_logloss: 0.289782        \n",
      "[71]\ttraining's multi_logloss: 0.126668\tvalid_1's multi_logloss: 0.289451        \n",
      "[72]\ttraining's multi_logloss: 0.124938\tvalid_1's multi_logloss: 0.28945         \n",
      "[73]\ttraining's multi_logloss: 0.123395\tvalid_1's multi_logloss: 0.289638        \n",
      "[74]\ttraining's multi_logloss: 0.121741\tvalid_1's multi_logloss: 0.289753        \n",
      "[75]\ttraining's multi_logloss: 0.120208\tvalid_1's multi_logloss: 0.289643        \n",
      "[76]\ttraining's multi_logloss: 0.118625\tvalid_1's multi_logloss: 0.289569        \n",
      "[77]\ttraining's multi_logloss: 0.117117\tvalid_1's multi_logloss: 0.289507        \n",
      "[78]\ttraining's multi_logloss: 0.115602\tvalid_1's multi_logloss: 0.289682        \n",
      "[79]\ttraining's multi_logloss: 0.11417\tvalid_1's multi_logloss: 0.289813         \n",
      "[80]\ttraining's multi_logloss: 0.112796\tvalid_1's multi_logloss: 0.289944        \n",
      "[81]\ttraining's multi_logloss: 0.111249\tvalid_1's multi_logloss: 0.290139        \n",
      "[82]\ttraining's multi_logloss: 0.109982\tvalid_1's multi_logloss: 0.290271        \n",
      "[83]\ttraining's multi_logloss: 0.108607\tvalid_1's multi_logloss: 0.290616        \n",
      "[84]\ttraining's multi_logloss: 0.107341\tvalid_1's multi_logloss: 0.290847        \n",
      "[85]\ttraining's multi_logloss: 0.106076\tvalid_1's multi_logloss: 0.290852        \n",
      "[86]\ttraining's multi_logloss: 0.104824\tvalid_1's multi_logloss: 0.290838        \n",
      "[87]\ttraining's multi_logloss: 0.103625\tvalid_1's multi_logloss: 0.290951        \n",
      "[88]\ttraining's multi_logloss: 0.102451\tvalid_1's multi_logloss: 0.291023        \n",
      "[89]\ttraining's multi_logloss: 0.101204\tvalid_1's multi_logloss: 0.290994        \n",
      "[90]\ttraining's multi_logloss: 0.099935\tvalid_1's multi_logloss: 0.291364        \n",
      "[91]\ttraining's multi_logloss: 0.0987666\tvalid_1's multi_logloss: 0.291737       \n",
      "[92]\ttraining's multi_logloss: 0.0975627\tvalid_1's multi_logloss: 0.292027       \n",
      "[93]\ttraining's multi_logloss: 0.0965309\tvalid_1's multi_logloss: 0.292429       \n",
      "[94]\ttraining's multi_logloss: 0.0955525\tvalid_1's multi_logloss: 0.292586       \n",
      "[95]\ttraining's multi_logloss: 0.0944316\tvalid_1's multi_logloss: 0.29283        \n",
      "[96]\ttraining's multi_logloss: 0.0933333\tvalid_1's multi_logloss: 0.292826       \n",
      "[97]\ttraining's multi_logloss: 0.0921948\tvalid_1's multi_logloss: 0.293031       \n",
      "[98]\ttraining's multi_logloss: 0.091186\tvalid_1's multi_logloss: 0.293144        \n",
      "[99]\ttraining's multi_logloss: 0.0901297\tvalid_1's multi_logloss: 0.293294       \n",
      "[100]\ttraining's multi_logloss: 0.0891882\tvalid_1's multi_logloss: 0.293529      \n",
      "[101]\ttraining's multi_logloss: 0.0881893\tvalid_1's multi_logloss: 0.293878      \n",
      "[102]\ttraining's multi_logloss: 0.087267\tvalid_1's multi_logloss: 0.294054       \n",
      "Early stopping, best iteration is:                                               \n",
      "[72]\ttraining's multi_logloss: 0.124938\tvalid_1's multi_logloss: 0.28945\n",
      "[1]\ttraining's multi_logloss: 1.61068\tvalid_1's multi_logloss: 1.61522           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.39363\tvalid_1's multi_logloss: 1.39951           \n",
      "[3]\ttraining's multi_logloss: 1.23096\tvalid_1's multi_logloss: 1.23964           \n",
      "[4]\ttraining's multi_logloss: 1.10034\tvalid_1's multi_logloss: 1.11075           \n",
      "[5]\ttraining's multi_logloss: 0.993163\tvalid_1's multi_logloss: 1.0062           \n",
      "[6]\ttraining's multi_logloss: 0.902927\tvalid_1's multi_logloss: 0.917938         \n",
      "[7]\ttraining's multi_logloss: 0.826758\tvalid_1's multi_logloss: 0.844148         \n",
      "[8]\ttraining's multi_logloss: 0.760113\tvalid_1's multi_logloss: 0.779885         \n",
      "[9]\ttraining's multi_logloss: 0.703049\tvalid_1's multi_logloss: 0.725362         \n",
      "[10]\ttraining's multi_logloss: 0.652198\tvalid_1's multi_logloss: 0.676942        \n",
      "[11]\ttraining's multi_logloss: 0.607891\tvalid_1's multi_logloss: 0.63463         \n",
      "[12]\ttraining's multi_logloss: 0.568191\tvalid_1's multi_logloss: 0.596682        \n",
      "[13]\ttraining's multi_logloss: 0.53364\tvalid_1's multi_logloss: 0.563985         \n",
      "[14]\ttraining's multi_logloss: 0.502444\tvalid_1's multi_logloss: 0.534227        \n",
      "[15]\ttraining's multi_logloss: 0.474824\tvalid_1's multi_logloss: 0.508702        \n",
      "[16]\ttraining's multi_logloss: 0.450601\tvalid_1's multi_logloss: 0.486841        \n",
      "[17]\ttraining's multi_logloss: 0.428152\tvalid_1's multi_logloss: 0.466448        \n",
      "[18]\ttraining's multi_logloss: 0.407659\tvalid_1's multi_logloss: 0.448251        \n",
      "[19]\ttraining's multi_logloss: 0.389418\tvalid_1's multi_logloss: 0.432324        \n",
      "[20]\ttraining's multi_logloss: 0.372943\tvalid_1's multi_logloss: 0.418173        \n",
      "[21]\ttraining's multi_logloss: 0.357962\tvalid_1's multi_logloss: 0.405455        \n",
      "[22]\ttraining's multi_logloss: 0.343963\tvalid_1's multi_logloss: 0.393501        \n",
      "[23]\ttraining's multi_logloss: 0.331226\tvalid_1's multi_logloss: 0.382858        \n",
      "[24]\ttraining's multi_logloss: 0.319724\tvalid_1's multi_logloss: 0.37331         \n",
      "[25]\ttraining's multi_logloss: 0.308756\tvalid_1's multi_logloss: 0.364685        \n",
      "[26]\ttraining's multi_logloss: 0.298958\tvalid_1's multi_logloss: 0.356901        \n",
      "[27]\ttraining's multi_logloss: 0.289393\tvalid_1's multi_logloss: 0.34961         \n",
      "[28]\ttraining's multi_logloss: 0.280816\tvalid_1's multi_logloss: 0.343436        \n",
      "[29]\ttraining's multi_logloss: 0.272847\tvalid_1's multi_logloss: 0.337795        \n",
      "[30]\ttraining's multi_logloss: 0.265549\tvalid_1's multi_logloss: 0.332562        \n",
      "[31]\ttraining's multi_logloss: 0.258498\tvalid_1's multi_logloss: 0.327824        \n",
      "[32]\ttraining's multi_logloss: 0.252059\tvalid_1's multi_logloss: 0.323772        \n",
      "[33]\ttraining's multi_logloss: 0.245837\tvalid_1's multi_logloss: 0.320151        \n",
      "[34]\ttraining's multi_logloss: 0.239761\tvalid_1's multi_logloss: 0.316576        \n",
      "[35]\ttraining's multi_logloss: 0.234102\tvalid_1's multi_logloss: 0.313264        \n",
      "[36]\ttraining's multi_logloss: 0.228777\tvalid_1's multi_logloss: 0.310292        \n",
      "[37]\ttraining's multi_logloss: 0.223794\tvalid_1's multi_logloss: 0.307973        \n",
      "[38]\ttraining's multi_logloss: 0.219077\tvalid_1's multi_logloss: 0.305792        \n",
      "[39]\ttraining's multi_logloss: 0.214693\tvalid_1's multi_logloss: 0.303773        \n",
      "[40]\ttraining's multi_logloss: 0.210333\tvalid_1's multi_logloss: 0.301708        \n",
      "[41]\ttraining's multi_logloss: 0.206236\tvalid_1's multi_logloss: 0.300029        \n",
      "[42]\ttraining's multi_logloss: 0.202384\tvalid_1's multi_logloss: 0.298519        \n",
      "[43]\ttraining's multi_logloss: 0.198625\tvalid_1's multi_logloss: 0.297077        \n",
      "[44]\ttraining's multi_logloss: 0.195116\tvalid_1's multi_logloss: 0.295679        \n",
      "[45]\ttraining's multi_logloss: 0.191346\tvalid_1's multi_logloss: 0.294411        \n",
      "[46]\ttraining's multi_logloss: 0.187977\tvalid_1's multi_logloss: 0.293238        \n",
      "[47]\ttraining's multi_logloss: 0.184542\tvalid_1's multi_logloss: 0.292396        \n",
      "[48]\ttraining's multi_logloss: 0.181293\tvalid_1's multi_logloss: 0.291201        \n",
      "[49]\ttraining's multi_logloss: 0.178193\tvalid_1's multi_logloss: 0.290376        \n",
      "[50]\ttraining's multi_logloss: 0.175128\tvalid_1's multi_logloss: 0.289348        \n",
      "[51]\ttraining's multi_logloss: 0.172076\tvalid_1's multi_logloss: 0.288368        \n",
      "[52]\ttraining's multi_logloss: 0.169223\tvalid_1's multi_logloss: 0.287579        \n",
      "[53]\ttraining's multi_logloss: 0.166295\tvalid_1's multi_logloss: 0.287078        \n",
      "[54]\ttraining's multi_logloss: 0.163641\tvalid_1's multi_logloss: 0.286769        \n",
      "[55]\ttraining's multi_logloss: 0.161026\tvalid_1's multi_logloss: 0.286503        \n",
      "[56]\ttraining's multi_logloss: 0.158483\tvalid_1's multi_logloss: 0.2865          \n",
      "[57]\ttraining's multi_logloss: 0.155853\tvalid_1's multi_logloss: 0.286293        \n",
      "[58]\ttraining's multi_logloss: 0.153321\tvalid_1's multi_logloss: 0.285795        \n",
      "[59]\ttraining's multi_logloss: 0.150958\tvalid_1's multi_logloss: 0.285307        \n",
      "[60]\ttraining's multi_logloss: 0.148577\tvalid_1's multi_logloss: 0.285398        \n",
      "[61]\ttraining's multi_logloss: 0.146329\tvalid_1's multi_logloss: 0.285133        \n",
      "[62]\ttraining's multi_logloss: 0.144148\tvalid_1's multi_logloss: 0.28515         \n",
      "[63]\ttraining's multi_logloss: 0.142155\tvalid_1's multi_logloss: 0.284836        \n",
      "[64]\ttraining's multi_logloss: 0.140046\tvalid_1's multi_logloss: 0.284669        \n",
      "[65]\ttraining's multi_logloss: 0.13798\tvalid_1's multi_logloss: 0.284386         \n",
      "[66]\ttraining's multi_logloss: 0.135978\tvalid_1's multi_logloss: 0.284133        \n",
      "[67]\ttraining's multi_logloss: 0.134124\tvalid_1's multi_logloss: 0.284024        \n",
      "[68]\ttraining's multi_logloss: 0.13219\tvalid_1's multi_logloss: 0.283945         \n",
      "[69]\ttraining's multi_logloss: 0.130294\tvalid_1's multi_logloss: 0.283863        \n",
      "[70]\ttraining's multi_logloss: 0.128487\tvalid_1's multi_logloss: 0.283815        \n",
      "[71]\ttraining's multi_logloss: 0.12655\tvalid_1's multi_logloss: 0.283651         \n",
      "[72]\ttraining's multi_logloss: 0.124756\tvalid_1's multi_logloss: 0.283484        \n",
      "[73]\ttraining's multi_logloss: 0.123088\tvalid_1's multi_logloss: 0.283602        \n",
      "[74]\ttraining's multi_logloss: 0.121454\tvalid_1's multi_logloss: 0.283582        \n",
      "[75]\ttraining's multi_logloss: 0.119708\tvalid_1's multi_logloss: 0.283523        \n",
      "[76]\ttraining's multi_logloss: 0.118084\tvalid_1's multi_logloss: 0.283062        \n",
      "[77]\ttraining's multi_logloss: 0.116398\tvalid_1's multi_logloss: 0.282867        \n",
      "[78]\ttraining's multi_logloss: 0.114834\tvalid_1's multi_logloss: 0.283194        \n",
      "[79]\ttraining's multi_logloss: 0.113306\tvalid_1's multi_logloss: 0.28342         \n",
      "[80]\ttraining's multi_logloss: 0.11186\tvalid_1's multi_logloss: 0.283599         \n",
      "[81]\ttraining's multi_logloss: 0.110453\tvalid_1's multi_logloss: 0.28361         \n",
      "[82]\ttraining's multi_logloss: 0.109118\tvalid_1's multi_logloss: 0.283619        \n",
      "[83]\ttraining's multi_logloss: 0.107721\tvalid_1's multi_logloss: 0.283648        \n",
      "[84]\ttraining's multi_logloss: 0.106465\tvalid_1's multi_logloss: 0.284042        \n",
      "[85]\ttraining's multi_logloss: 0.105123\tvalid_1's multi_logloss: 0.284335        \n",
      "[86]\ttraining's multi_logloss: 0.103788\tvalid_1's multi_logloss: 0.284389        \n",
      "[87]\ttraining's multi_logloss: 0.102567\tvalid_1's multi_logloss: 0.284796        \n",
      "[88]\ttraining's multi_logloss: 0.101206\tvalid_1's multi_logloss: 0.284982        \n",
      "[89]\ttraining's multi_logloss: 0.100116\tvalid_1's multi_logloss: 0.285383        \n",
      "[90]\ttraining's multi_logloss: 0.0989411\tvalid_1's multi_logloss: 0.285797       \n",
      "[91]\ttraining's multi_logloss: 0.0978625\tvalid_1's multi_logloss: 0.286128       \n",
      "[92]\ttraining's multi_logloss: 0.0966833\tvalid_1's multi_logloss: 0.286322       \n",
      "[93]\ttraining's multi_logloss: 0.0953853\tvalid_1's multi_logloss: 0.28671        \n",
      "[94]\ttraining's multi_logloss: 0.0942233\tvalid_1's multi_logloss: 0.286889       \n",
      "[95]\ttraining's multi_logloss: 0.0931475\tvalid_1's multi_logloss: 0.28728        \n",
      "[96]\ttraining's multi_logloss: 0.0920346\tvalid_1's multi_logloss: 0.287596       \n",
      "[97]\ttraining's multi_logloss: 0.0910087\tvalid_1's multi_logloss: 0.288013       \n",
      "[98]\ttraining's multi_logloss: 0.0899546\tvalid_1's multi_logloss: 0.288232       \n",
      "[99]\ttraining's multi_logloss: 0.0888351\tvalid_1's multi_logloss: 0.288595       \n",
      "[100]\ttraining's multi_logloss: 0.0878242\tvalid_1's multi_logloss: 0.289114      \n",
      "[101]\ttraining's multi_logloss: 0.0867252\tvalid_1's multi_logloss: 0.289409      \n",
      "[102]\ttraining's multi_logloss: 0.0857748\tvalid_1's multi_logloss: 0.289684      \n",
      "[103]\ttraining's multi_logloss: 0.0848563\tvalid_1's multi_logloss: 0.29005       \n",
      "[104]\ttraining's multi_logloss: 0.0838956\tvalid_1's multi_logloss: 0.290559      \n",
      "[105]\ttraining's multi_logloss: 0.0829793\tvalid_1's multi_logloss: 0.290772      \n",
      "[106]\ttraining's multi_logloss: 0.0820742\tvalid_1's multi_logloss: 0.291249      \n",
      "[107]\ttraining's multi_logloss: 0.081144\tvalid_1's multi_logloss: 0.291548       \n",
      "Early stopping, best iteration is:                                               \n",
      "[77]\ttraining's multi_logloss: 0.116398\tvalid_1's multi_logloss: 0.282867\n",
      "[1]\ttraining's multi_logloss: 1.6124\tvalid_1's multi_logloss: 1.61657            \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.39621\tvalid_1's multi_logloss: 1.4025            \n",
      "[3]\ttraining's multi_logloss: 1.23262\tvalid_1's multi_logloss: 1.24061           \n",
      "[4]\ttraining's multi_logloss: 1.10163\tvalid_1's multi_logloss: 1.11019           \n",
      "[5]\ttraining's multi_logloss: 0.993755\tvalid_1's multi_logloss: 1.00396          \n",
      "[6]\ttraining's multi_logloss: 0.904057\tvalid_1's multi_logloss: 0.915111         \n",
      "[7]\ttraining's multi_logloss: 0.827099\tvalid_1's multi_logloss: 0.83952          \n",
      "[8]\ttraining's multi_logloss: 0.760705\tvalid_1's multi_logloss: 0.775125         \n",
      "[9]\ttraining's multi_logloss: 0.70306\tvalid_1's multi_logloss: 0.718881          \n",
      "[10]\ttraining's multi_logloss: 0.653056\tvalid_1's multi_logloss: 0.670461        \n",
      "[11]\ttraining's multi_logloss: 0.609189\tvalid_1's multi_logloss: 0.628038        \n",
      "[12]\ttraining's multi_logloss: 0.569991\tvalid_1's multi_logloss: 0.590332        \n",
      "[13]\ttraining's multi_logloss: 0.535701\tvalid_1's multi_logloss: 0.558027        \n",
      "[14]\ttraining's multi_logloss: 0.504985\tvalid_1's multi_logloss: 0.528853        \n",
      "[15]\ttraining's multi_logloss: 0.477674\tvalid_1's multi_logloss: 0.503279        \n",
      "[16]\ttraining's multi_logloss: 0.453196\tvalid_1's multi_logloss: 0.480721        \n",
      "[17]\ttraining's multi_logloss: 0.430961\tvalid_1's multi_logloss: 0.460461        \n",
      "[18]\ttraining's multi_logloss: 0.411442\tvalid_1's multi_logloss: 0.442645        \n",
      "[19]\ttraining's multi_logloss: 0.393416\tvalid_1's multi_logloss: 0.426128        \n",
      "[20]\ttraining's multi_logloss: 0.377526\tvalid_1's multi_logloss: 0.411858        \n",
      "[21]\ttraining's multi_logloss: 0.362925\tvalid_1's multi_logloss: 0.398966        \n",
      "[22]\ttraining's multi_logloss: 0.348817\tvalid_1's multi_logloss: 0.38634         \n",
      "[23]\ttraining's multi_logloss: 0.336168\tvalid_1's multi_logloss: 0.375929        \n",
      "[24]\ttraining's multi_logloss: 0.324518\tvalid_1's multi_logloss: 0.365917        \n",
      "[25]\ttraining's multi_logloss: 0.313693\tvalid_1's multi_logloss: 0.35703         \n",
      "[26]\ttraining's multi_logloss: 0.303947\tvalid_1's multi_logloss: 0.348887        \n",
      "[27]\ttraining's multi_logloss: 0.294391\tvalid_1's multi_logloss: 0.341268        \n",
      "[28]\ttraining's multi_logloss: 0.285745\tvalid_1's multi_logloss: 0.334514        \n",
      "[29]\ttraining's multi_logloss: 0.27803\tvalid_1's multi_logloss: 0.329072         \n",
      "[30]\ttraining's multi_logloss: 0.270605\tvalid_1's multi_logloss: 0.323557        \n",
      "[31]\ttraining's multi_logloss: 0.263812\tvalid_1's multi_logloss: 0.318927        \n",
      "[32]\ttraining's multi_logloss: 0.257457\tvalid_1's multi_logloss: 0.31452         \n",
      "[33]\ttraining's multi_logloss: 0.251335\tvalid_1's multi_logloss: 0.31071         \n",
      "[34]\ttraining's multi_logloss: 0.245548\tvalid_1's multi_logloss: 0.307012        \n",
      "[35]\ttraining's multi_logloss: 0.240348\tvalid_1's multi_logloss: 0.304364        \n",
      "[36]\ttraining's multi_logloss: 0.235068\tvalid_1's multi_logloss: 0.301326        \n",
      "[37]\ttraining's multi_logloss: 0.23021\tvalid_1's multi_logloss: 0.298546         \n",
      "[38]\ttraining's multi_logloss: 0.225442\tvalid_1's multi_logloss: 0.295693        \n",
      "[39]\ttraining's multi_logloss: 0.221002\tvalid_1's multi_logloss: 0.293285        \n",
      "[40]\ttraining's multi_logloss: 0.216648\tvalid_1's multi_logloss: 0.29108         \n",
      "[41]\ttraining's multi_logloss: 0.212527\tvalid_1's multi_logloss: 0.289013        \n",
      "[42]\ttraining's multi_logloss: 0.208465\tvalid_1's multi_logloss: 0.287189        \n",
      "[43]\ttraining's multi_logloss: 0.204789\tvalid_1's multi_logloss: 0.285615        \n",
      "[44]\ttraining's multi_logloss: 0.201045\tvalid_1's multi_logloss: 0.284057        \n",
      "[45]\ttraining's multi_logloss: 0.197572\tvalid_1's multi_logloss: 0.282618        \n",
      "[46]\ttraining's multi_logloss: 0.194178\tvalid_1's multi_logloss: 0.281581        \n",
      "[47]\ttraining's multi_logloss: 0.190706\tvalid_1's multi_logloss: 0.280176        \n",
      "[48]\ttraining's multi_logloss: 0.187543\tvalid_1's multi_logloss: 0.278848        \n",
      "[49]\ttraining's multi_logloss: 0.184242\tvalid_1's multi_logloss: 0.277388        \n",
      "[50]\ttraining's multi_logloss: 0.181328\tvalid_1's multi_logloss: 0.276722        \n",
      "[51]\ttraining's multi_logloss: 0.17836\tvalid_1's multi_logloss: 0.275839         \n",
      "[52]\ttraining's multi_logloss: 0.175423\tvalid_1's multi_logloss: 0.275157        \n",
      "[53]\ttraining's multi_logloss: 0.17259\tvalid_1's multi_logloss: 0.274532         \n",
      "[54]\ttraining's multi_logloss: 0.169772\tvalid_1's multi_logloss: 0.273908        \n",
      "[55]\ttraining's multi_logloss: 0.167203\tvalid_1's multi_logloss: 0.27368         \n",
      "[56]\ttraining's multi_logloss: 0.164514\tvalid_1's multi_logloss: 0.27327         \n",
      "[57]\ttraining's multi_logloss: 0.161903\tvalid_1's multi_logloss: 0.272927        \n",
      "[58]\ttraining's multi_logloss: 0.159259\tvalid_1's multi_logloss: 0.272323        \n",
      "[59]\ttraining's multi_logloss: 0.15662\tvalid_1's multi_logloss: 0.272064         \n",
      "[60]\ttraining's multi_logloss: 0.154222\tvalid_1's multi_logloss: 0.271698        \n",
      "[61]\ttraining's multi_logloss: 0.15178\tvalid_1's multi_logloss: 0.271536         \n",
      "[62]\ttraining's multi_logloss: 0.149662\tvalid_1's multi_logloss: 0.270914        \n",
      "[63]\ttraining's multi_logloss: 0.147498\tvalid_1's multi_logloss: 0.270695        \n",
      "[64]\ttraining's multi_logloss: 0.145371\tvalid_1's multi_logloss: 0.270201        \n",
      "[65]\ttraining's multi_logloss: 0.143207\tvalid_1's multi_logloss: 0.269967        \n",
      "[66]\ttraining's multi_logloss: 0.141282\tvalid_1's multi_logloss: 0.269773        \n",
      "[67]\ttraining's multi_logloss: 0.139238\tvalid_1's multi_logloss: 0.269372        \n",
      "[68]\ttraining's multi_logloss: 0.13741\tvalid_1's multi_logloss: 0.269083         \n",
      "[69]\ttraining's multi_logloss: 0.135536\tvalid_1's multi_logloss: 0.268824        \n",
      "[70]\ttraining's multi_logloss: 0.133761\tvalid_1's multi_logloss: 0.268778        \n",
      "[71]\ttraining's multi_logloss: 0.132019\tvalid_1's multi_logloss: 0.268809        \n",
      "[72]\ttraining's multi_logloss: 0.130342\tvalid_1's multi_logloss: 0.268664        \n",
      "[73]\ttraining's multi_logloss: 0.128684\tvalid_1's multi_logloss: 0.268604        \n",
      "[74]\ttraining's multi_logloss: 0.127064\tvalid_1's multi_logloss: 0.26869         \n",
      "[75]\ttraining's multi_logloss: 0.125465\tvalid_1's multi_logloss: 0.268609        \n",
      "[76]\ttraining's multi_logloss: 0.123868\tvalid_1's multi_logloss: 0.268804        \n",
      "[77]\ttraining's multi_logloss: 0.12242\tvalid_1's multi_logloss: 0.268745         \n",
      "[78]\ttraining's multi_logloss: 0.120926\tvalid_1's multi_logloss: 0.269176        \n",
      "[79]\ttraining's multi_logloss: 0.119256\tvalid_1's multi_logloss: 0.268979        \n",
      "[80]\ttraining's multi_logloss: 0.117772\tvalid_1's multi_logloss: 0.268946        \n",
      "[81]\ttraining's multi_logloss: 0.116342\tvalid_1's multi_logloss: 0.268837        \n",
      "[82]\ttraining's multi_logloss: 0.114915\tvalid_1's multi_logloss: 0.268966        \n",
      "[83]\ttraining's multi_logloss: 0.113515\tvalid_1's multi_logloss: 0.268777        \n",
      "[84]\ttraining's multi_logloss: 0.112171\tvalid_1's multi_logloss: 0.268712        \n",
      "[85]\ttraining's multi_logloss: 0.110884\tvalid_1's multi_logloss: 0.268681        \n",
      "[86]\ttraining's multi_logloss: 0.10957\tvalid_1's multi_logloss: 0.268852         \n",
      "[87]\ttraining's multi_logloss: 0.108132\tvalid_1's multi_logloss: 0.26882         \n",
      "[88]\ttraining's multi_logloss: 0.106893\tvalid_1's multi_logloss: 0.269032        \n",
      "[89]\ttraining's multi_logloss: 0.105566\tvalid_1's multi_logloss: 0.269188        \n",
      "[90]\ttraining's multi_logloss: 0.104366\tvalid_1's multi_logloss: 0.269337        \n",
      "[91]\ttraining's multi_logloss: 0.103199\tvalid_1's multi_logloss: 0.269436        \n",
      "[92]\ttraining's multi_logloss: 0.102058\tvalid_1's multi_logloss: 0.269633        \n",
      "[93]\ttraining's multi_logloss: 0.10093\tvalid_1's multi_logloss: 0.26993          \n",
      "[94]\ttraining's multi_logloss: 0.0997965\tvalid_1's multi_logloss: 0.270147       \n",
      "[95]\ttraining's multi_logloss: 0.0986998\tvalid_1's multi_logloss: 0.270181       \n",
      "[96]\ttraining's multi_logloss: 0.0976854\tvalid_1's multi_logloss: 0.270398       \n",
      "[97]\ttraining's multi_logloss: 0.0965948\tvalid_1's multi_logloss: 0.270556       \n",
      "[98]\ttraining's multi_logloss: 0.09551\tvalid_1's multi_logloss: 0.270772         \n",
      "[99]\ttraining's multi_logloss: 0.0943821\tvalid_1's multi_logloss: 0.27106        \n",
      "[100]\ttraining's multi_logloss: 0.0932171\tvalid_1's multi_logloss: 0.271187      \n",
      "[101]\ttraining's multi_logloss: 0.0921099\tvalid_1's multi_logloss: 0.27157       \n",
      "[102]\ttraining's multi_logloss: 0.0912055\tvalid_1's multi_logloss: 0.271894      \n",
      "[103]\ttraining's multi_logloss: 0.0901725\tvalid_1's multi_logloss: 0.272165      \n",
      "Early stopping, best iteration is:                                               \n",
      "[73]\ttraining's multi_logloss: 0.128684\tvalid_1's multi_logloss: 0.268604\n",
      "[1]\ttraining's multi_logloss: 1.21238\tvalid_1's multi_logloss: 1.22733           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 0.918007\tvalid_1's multi_logloss: 0.942966         \n",
      "[3]\ttraining's multi_logloss: 0.734365\tvalid_1's multi_logloss: 0.766918         \n",
      "[4]\ttraining's multi_logloss: 0.610245\tvalid_1's multi_logloss: 0.64837          \n",
      "[5]\ttraining's multi_logloss: 0.51916\tvalid_1's multi_logloss: 0.562301          \n",
      "[6]\ttraining's multi_logloss: 0.450798\tvalid_1's multi_logloss: 0.499622         \n",
      "[7]\ttraining's multi_logloss: 0.398233\tvalid_1's multi_logloss: 0.452555         \n",
      "[8]\ttraining's multi_logloss: 0.357405\tvalid_1's multi_logloss: 0.415844         \n",
      "[9]\ttraining's multi_logloss: 0.325042\tvalid_1's multi_logloss: 0.389089         \n",
      "[10]\ttraining's multi_logloss: 0.299886\tvalid_1's multi_logloss: 0.369729        \n",
      "[11]\ttraining's multi_logloss: 0.278191\tvalid_1's multi_logloss: 0.353665        \n",
      "[12]\ttraining's multi_logloss: 0.260373\tvalid_1's multi_logloss: 0.340985        \n",
      "[13]\ttraining's multi_logloss: 0.244607\tvalid_1's multi_logloss: 0.330367        \n",
      "[14]\ttraining's multi_logloss: 0.231167\tvalid_1's multi_logloss: 0.323038        \n",
      "[15]\ttraining's multi_logloss: 0.219075\tvalid_1's multi_logloss: 0.316982        \n",
      "[16]\ttraining's multi_logloss: 0.208522\tvalid_1's multi_logloss: 0.312009        \n",
      "[17]\ttraining's multi_logloss: 0.19933\tvalid_1's multi_logloss: 0.307983         \n",
      "[18]\ttraining's multi_logloss: 0.190652\tvalid_1's multi_logloss: 0.304792        \n",
      "[19]\ttraining's multi_logloss: 0.182574\tvalid_1's multi_logloss: 0.30306         \n",
      "[20]\ttraining's multi_logloss: 0.174572\tvalid_1's multi_logloss: 0.300958        \n",
      "[21]\ttraining's multi_logloss: 0.166945\tvalid_1's multi_logloss: 0.299552        \n",
      "[22]\ttraining's multi_logloss: 0.160436\tvalid_1's multi_logloss: 0.298839        \n",
      "[23]\ttraining's multi_logloss: 0.154486\tvalid_1's multi_logloss: 0.298157        \n",
      "[24]\ttraining's multi_logloss: 0.148841\tvalid_1's multi_logloss: 0.297043        \n",
      "[25]\ttraining's multi_logloss: 0.142707\tvalid_1's multi_logloss: 0.295796        \n",
      "[26]\ttraining's multi_logloss: 0.137253\tvalid_1's multi_logloss: 0.294987        \n",
      "[27]\ttraining's multi_logloss: 0.13216\tvalid_1's multi_logloss: 0.294193         \n",
      "[28]\ttraining's multi_logloss: 0.127631\tvalid_1's multi_logloss: 0.294377        \n",
      "[29]\ttraining's multi_logloss: 0.123299\tvalid_1's multi_logloss: 0.294173        \n",
      "[30]\ttraining's multi_logloss: 0.119152\tvalid_1's multi_logloss: 0.29399         \n",
      "[31]\ttraining's multi_logloss: 0.115261\tvalid_1's multi_logloss: 0.293717        \n",
      "[32]\ttraining's multi_logloss: 0.111891\tvalid_1's multi_logloss: 0.294374        \n",
      "[33]\ttraining's multi_logloss: 0.108527\tvalid_1's multi_logloss: 0.295159        \n",
      "[34]\ttraining's multi_logloss: 0.105393\tvalid_1's multi_logloss: 0.296234        \n",
      "[35]\ttraining's multi_logloss: 0.10192\tvalid_1's multi_logloss: 0.296767         \n",
      "[36]\ttraining's multi_logloss: 0.0987008\tvalid_1's multi_logloss: 0.297545       \n",
      "[37]\ttraining's multi_logloss: 0.0957014\tvalid_1's multi_logloss: 0.298529       \n",
      "[38]\ttraining's multi_logloss: 0.092967\tvalid_1's multi_logloss: 0.298827        \n",
      "[39]\ttraining's multi_logloss: 0.0901358\tvalid_1's multi_logloss: 0.299725       \n",
      "[40]\ttraining's multi_logloss: 0.0870733\tvalid_1's multi_logloss: 0.300207       \n",
      "[41]\ttraining's multi_logloss: 0.0843522\tvalid_1's multi_logloss: 0.301571       \n",
      "[42]\ttraining's multi_logloss: 0.0821204\tvalid_1's multi_logloss: 0.303153       \n",
      "[43]\ttraining's multi_logloss: 0.0798038\tvalid_1's multi_logloss: 0.304195       \n",
      "[44]\ttraining's multi_logloss: 0.0774721\tvalid_1's multi_logloss: 0.305464       \n",
      "[45]\ttraining's multi_logloss: 0.0753926\tvalid_1's multi_logloss: 0.305779       \n",
      "[46]\ttraining's multi_logloss: 0.0734329\tvalid_1's multi_logloss: 0.306974       \n",
      "[47]\ttraining's multi_logloss: 0.0712965\tvalid_1's multi_logloss: 0.308133       \n",
      "[48]\ttraining's multi_logloss: 0.0692473\tvalid_1's multi_logloss: 0.309418       \n",
      "[49]\ttraining's multi_logloss: 0.0673745\tvalid_1's multi_logloss: 0.311517       \n",
      "[50]\ttraining's multi_logloss: 0.065542\tvalid_1's multi_logloss: 0.312888        \n",
      "[51]\ttraining's multi_logloss: 0.0637127\tvalid_1's multi_logloss: 0.314475       \n",
      "[52]\ttraining's multi_logloss: 0.0620738\tvalid_1's multi_logloss: 0.316395       \n",
      "[53]\ttraining's multi_logloss: 0.0603991\tvalid_1's multi_logloss: 0.317085       \n",
      "[54]\ttraining's multi_logloss: 0.0587411\tvalid_1's multi_logloss: 0.318208       \n",
      "[55]\ttraining's multi_logloss: 0.0570862\tvalid_1's multi_logloss: 0.317795       \n",
      "[56]\ttraining's multi_logloss: 0.0556709\tvalid_1's multi_logloss: 0.318785       \n",
      "[57]\ttraining's multi_logloss: 0.0541576\tvalid_1's multi_logloss: 0.319199       \n",
      "[58]\ttraining's multi_logloss: 0.0527217\tvalid_1's multi_logloss: 0.32093        \n",
      "[59]\ttraining's multi_logloss: 0.0513407\tvalid_1's multi_logloss: 0.321035       \n",
      "[60]\ttraining's multi_logloss: 0.0500589\tvalid_1's multi_logloss: 0.322491       \n",
      "[61]\ttraining's multi_logloss: 0.0488963\tvalid_1's multi_logloss: 0.322787       \n",
      "Early stopping, best iteration is:                                               \n",
      "[31]\ttraining's multi_logloss: 0.115261\tvalid_1's multi_logloss: 0.293717\n",
      "[1]\ttraining's multi_logloss: 1.21085\tvalid_1's multi_logloss: 1.21943           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 0.920199\tvalid_1's multi_logloss: 0.934326         \n",
      "[3]\ttraining's multi_logloss: 0.739978\tvalid_1's multi_logloss: 0.759482         \n",
      "[4]\ttraining's multi_logloss: 0.614065\tvalid_1's multi_logloss: 0.639465         \n",
      "[5]\ttraining's multi_logloss: 0.52395\tvalid_1's multi_logloss: 0.55408           \n",
      "[6]\ttraining's multi_logloss: 0.455363\tvalid_1's multi_logloss: 0.491545         \n",
      "[7]\ttraining's multi_logloss: 0.402549\tvalid_1's multi_logloss: 0.44469          \n",
      "[8]\ttraining's multi_logloss: 0.362376\tvalid_1's multi_logloss: 0.409433         \n",
      "[9]\ttraining's multi_logloss: 0.330718\tvalid_1's multi_logloss: 0.382289         \n",
      "[10]\ttraining's multi_logloss: 0.303574\tvalid_1's multi_logloss: 0.36154         \n",
      "[11]\ttraining's multi_logloss: 0.281672\tvalid_1's multi_logloss: 0.345585        \n",
      "[12]\ttraining's multi_logloss: 0.26252\tvalid_1's multi_logloss: 0.332879         \n",
      "[13]\ttraining's multi_logloss: 0.24681\tvalid_1's multi_logloss: 0.322279         \n",
      "[14]\ttraining's multi_logloss: 0.233211\tvalid_1's multi_logloss: 0.31537         \n",
      "[15]\ttraining's multi_logloss: 0.221128\tvalid_1's multi_logloss: 0.309914        \n",
      "[16]\ttraining's multi_logloss: 0.21012\tvalid_1's multi_logloss: 0.305273         \n",
      "[17]\ttraining's multi_logloss: 0.200586\tvalid_1's multi_logloss: 0.302371        \n",
      "[18]\ttraining's multi_logloss: 0.191412\tvalid_1's multi_logloss: 0.299217        \n",
      "[19]\ttraining's multi_logloss: 0.183244\tvalid_1's multi_logloss: 0.297426        \n",
      "[20]\ttraining's multi_logloss: 0.175735\tvalid_1's multi_logloss: 0.295342        \n",
      "[21]\ttraining's multi_logloss: 0.168285\tvalid_1's multi_logloss: 0.293913        \n",
      "[22]\ttraining's multi_logloss: 0.160865\tvalid_1's multi_logloss: 0.292748        \n",
      "[23]\ttraining's multi_logloss: 0.15421\tvalid_1's multi_logloss: 0.291553         \n",
      "[24]\ttraining's multi_logloss: 0.14812\tvalid_1's multi_logloss: 0.291474         \n",
      "[25]\ttraining's multi_logloss: 0.142272\tvalid_1's multi_logloss: 0.290403        \n",
      "[26]\ttraining's multi_logloss: 0.137088\tvalid_1's multi_logloss: 0.290731        \n",
      "[27]\ttraining's multi_logloss: 0.132059\tvalid_1's multi_logloss: 0.290517        \n",
      "[28]\ttraining's multi_logloss: 0.127376\tvalid_1's multi_logloss: 0.290007        \n",
      "[29]\ttraining's multi_logloss: 0.12316\tvalid_1's multi_logloss: 0.290152         \n",
      "[30]\ttraining's multi_logloss: 0.119117\tvalid_1's multi_logloss: 0.289481        \n",
      "[31]\ttraining's multi_logloss: 0.115291\tvalid_1's multi_logloss: 0.289792        \n",
      "[32]\ttraining's multi_logloss: 0.11112\tvalid_1's multi_logloss: 0.290723         \n",
      "[33]\ttraining's multi_logloss: 0.107444\tvalid_1's multi_logloss: 0.291127        \n",
      "[34]\ttraining's multi_logloss: 0.103808\tvalid_1's multi_logloss: 0.291543        \n",
      "[35]\ttraining's multi_logloss: 0.100373\tvalid_1's multi_logloss: 0.291464        \n",
      "[36]\ttraining's multi_logloss: 0.0971827\tvalid_1's multi_logloss: 0.291813       \n",
      "[37]\ttraining's multi_logloss: 0.0940763\tvalid_1's multi_logloss: 0.292247       \n",
      "[38]\ttraining's multi_logloss: 0.0909406\tvalid_1's multi_logloss: 0.293529       \n",
      "[39]\ttraining's multi_logloss: 0.0882101\tvalid_1's multi_logloss: 0.29507        \n",
      "[40]\ttraining's multi_logloss: 0.0856857\tvalid_1's multi_logloss: 0.29611        \n",
      "[41]\ttraining's multi_logloss: 0.0830727\tvalid_1's multi_logloss: 0.297239       \n",
      "[42]\ttraining's multi_logloss: 0.0808713\tvalid_1's multi_logloss: 0.298217       \n",
      "[43]\ttraining's multi_logloss: 0.0787913\tvalid_1's multi_logloss: 0.298867       \n",
      "[44]\ttraining's multi_logloss: 0.0763399\tvalid_1's multi_logloss: 0.300192       \n",
      "[45]\ttraining's multi_logloss: 0.0742087\tvalid_1's multi_logloss: 0.300854       \n",
      "[46]\ttraining's multi_logloss: 0.0721744\tvalid_1's multi_logloss: 0.301758       \n",
      "[47]\ttraining's multi_logloss: 0.070065\tvalid_1's multi_logloss: 0.302931        \n",
      "[48]\ttraining's multi_logloss: 0.0682281\tvalid_1's multi_logloss: 0.303674       \n",
      "[49]\ttraining's multi_logloss: 0.0662452\tvalid_1's multi_logloss: 0.304659       \n",
      "[50]\ttraining's multi_logloss: 0.0643125\tvalid_1's multi_logloss: 0.306443       \n",
      "[51]\ttraining's multi_logloss: 0.0624508\tvalid_1's multi_logloss: 0.308414       \n",
      "[52]\ttraining's multi_logloss: 0.060772\tvalid_1's multi_logloss: 0.309336        \n",
      "[53]\ttraining's multi_logloss: 0.0592149\tvalid_1's multi_logloss: 0.310943       \n",
      "[54]\ttraining's multi_logloss: 0.0575988\tvalid_1's multi_logloss: 0.311504       \n",
      "[55]\ttraining's multi_logloss: 0.0559216\tvalid_1's multi_logloss: 0.312849       \n",
      "[56]\ttraining's multi_logloss: 0.0545835\tvalid_1's multi_logloss: 0.3142         \n",
      "[57]\ttraining's multi_logloss: 0.0531599\tvalid_1's multi_logloss: 0.315291       \n",
      "[58]\ttraining's multi_logloss: 0.0518545\tvalid_1's multi_logloss: 0.316327       \n",
      "[59]\ttraining's multi_logloss: 0.0506132\tvalid_1's multi_logloss: 0.317743       \n",
      "[60]\ttraining's multi_logloss: 0.0492897\tvalid_1's multi_logloss: 0.319644       \n",
      "Early stopping, best iteration is:                                               \n",
      "[30]\ttraining's multi_logloss: 0.119117\tvalid_1's multi_logloss: 0.289481\n",
      "[1]\ttraining's multi_logloss: 1.21574\tvalid_1's multi_logloss: 1.2234            \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 0.924106\tvalid_1's multi_logloss: 0.935363         \n",
      "[3]\ttraining's multi_logloss: 0.743252\tvalid_1's multi_logloss: 0.758349         \n",
      "[4]\ttraining's multi_logloss: 0.617056\tvalid_1's multi_logloss: 0.636418         \n",
      "[5]\ttraining's multi_logloss: 0.527114\tvalid_1's multi_logloss: 0.551345         \n",
      "[6]\ttraining's multi_logloss: 0.459683\tvalid_1's multi_logloss: 0.487062         \n",
      "[7]\ttraining's multi_logloss: 0.407893\tvalid_1's multi_logloss: 0.44011          \n",
      "[8]\ttraining's multi_logloss: 0.367608\tvalid_1's multi_logloss: 0.4041           \n",
      "[9]\ttraining's multi_logloss: 0.335095\tvalid_1's multi_logloss: 0.374994         \n",
      "[10]\ttraining's multi_logloss: 0.308894\tvalid_1's multi_logloss: 0.353195        \n",
      "[11]\ttraining's multi_logloss: 0.286422\tvalid_1's multi_logloss: 0.334665        \n",
      "[12]\ttraining's multi_logloss: 0.268385\tvalid_1's multi_logloss: 0.320755        \n",
      "[13]\ttraining's multi_logloss: 0.252759\tvalid_1's multi_logloss: 0.310027        \n",
      "[14]\ttraining's multi_logloss: 0.239776\tvalid_1's multi_logloss: 0.302143        \n",
      "[15]\ttraining's multi_logloss: 0.227868\tvalid_1's multi_logloss: 0.295669        \n",
      "[16]\ttraining's multi_logloss: 0.217461\tvalid_1's multi_logloss: 0.290268        \n",
      "[17]\ttraining's multi_logloss: 0.207534\tvalid_1's multi_logloss: 0.286025        \n",
      "[18]\ttraining's multi_logloss: 0.198212\tvalid_1's multi_logloss: 0.282739        \n",
      "[19]\ttraining's multi_logloss: 0.189732\tvalid_1's multi_logloss: 0.279816        \n",
      "[20]\ttraining's multi_logloss: 0.182421\tvalid_1's multi_logloss: 0.27816         \n",
      "[21]\ttraining's multi_logloss: 0.175242\tvalid_1's multi_logloss: 0.2764          \n",
      "[22]\ttraining's multi_logloss: 0.168661\tvalid_1's multi_logloss: 0.27523         \n",
      "[23]\ttraining's multi_logloss: 0.162369\tvalid_1's multi_logloss: 0.274137        \n",
      "[24]\ttraining's multi_logloss: 0.15583\tvalid_1's multi_logloss: 0.273788         \n",
      "[25]\ttraining's multi_logloss: 0.1501\tvalid_1's multi_logloss: 0.273278          \n",
      "[26]\ttraining's multi_logloss: 0.144618\tvalid_1's multi_logloss: 0.272626        \n",
      "[27]\ttraining's multi_logloss: 0.139196\tvalid_1's multi_logloss: 0.27205         \n",
      "[28]\ttraining's multi_logloss: 0.134519\tvalid_1's multi_logloss: 0.271601        \n",
      "[29]\ttraining's multi_logloss: 0.129858\tvalid_1's multi_logloss: 0.272079        \n",
      "[30]\ttraining's multi_logloss: 0.125634\tvalid_1's multi_logloss: 0.271742        \n",
      "[31]\ttraining's multi_logloss: 0.121498\tvalid_1's multi_logloss: 0.271125        \n",
      "[32]\ttraining's multi_logloss: 0.117373\tvalid_1's multi_logloss: 0.271133        \n",
      "[33]\ttraining's multi_logloss: 0.114059\tvalid_1's multi_logloss: 0.271595        \n",
      "[34]\ttraining's multi_logloss: 0.110562\tvalid_1's multi_logloss: 0.271243        \n",
      "[35]\ttraining's multi_logloss: 0.106979\tvalid_1's multi_logloss: 0.270542        \n",
      "[36]\ttraining's multi_logloss: 0.103525\tvalid_1's multi_logloss: 0.270523        \n",
      "[37]\ttraining's multi_logloss: 0.100258\tvalid_1's multi_logloss: 0.27141         \n",
      "[38]\ttraining's multi_logloss: 0.097417\tvalid_1's multi_logloss: 0.272295        \n",
      "[39]\ttraining's multi_logloss: 0.0946733\tvalid_1's multi_logloss: 0.272822       \n",
      "[40]\ttraining's multi_logloss: 0.091841\tvalid_1's multi_logloss: 0.272978        \n",
      "[41]\ttraining's multi_logloss: 0.0889742\tvalid_1's multi_logloss: 0.273654       \n",
      "[42]\ttraining's multi_logloss: 0.0864945\tvalid_1's multi_logloss: 0.274102       \n",
      "[43]\ttraining's multi_logloss: 0.0842162\tvalid_1's multi_logloss: 0.274396       \n",
      "[44]\ttraining's multi_logloss: 0.0818897\tvalid_1's multi_logloss: 0.275566       \n",
      "[45]\ttraining's multi_logloss: 0.0794458\tvalid_1's multi_logloss: 0.276511       \n",
      "[46]\ttraining's multi_logloss: 0.0771578\tvalid_1's multi_logloss: 0.277185       \n",
      "[47]\ttraining's multi_logloss: 0.0750999\tvalid_1's multi_logloss: 0.278189       \n",
      "[48]\ttraining's multi_logloss: 0.0730949\tvalid_1's multi_logloss: 0.278548       \n",
      "[49]\ttraining's multi_logloss: 0.0711529\tvalid_1's multi_logloss: 0.27883        \n",
      "[50]\ttraining's multi_logloss: 0.0689784\tvalid_1's multi_logloss: 0.279212       \n",
      "[51]\ttraining's multi_logloss: 0.0670199\tvalid_1's multi_logloss: 0.279767       \n",
      "[52]\ttraining's multi_logloss: 0.0654188\tvalid_1's multi_logloss: 0.280122       \n",
      "[53]\ttraining's multi_logloss: 0.0638324\tvalid_1's multi_logloss: 0.280804       \n",
      "[54]\ttraining's multi_logloss: 0.0621529\tvalid_1's multi_logloss: 0.282324       \n",
      "[55]\ttraining's multi_logloss: 0.0603542\tvalid_1's multi_logloss: 0.283078       \n",
      "[56]\ttraining's multi_logloss: 0.0588859\tvalid_1's multi_logloss: 0.283965       \n",
      "[57]\ttraining's multi_logloss: 0.0572552\tvalid_1's multi_logloss: 0.284983       \n",
      "[58]\ttraining's multi_logloss: 0.0557722\tvalid_1's multi_logloss: 0.285736       \n",
      "[59]\ttraining's multi_logloss: 0.0543151\tvalid_1's multi_logloss: 0.286809       \n",
      "[60]\ttraining's multi_logloss: 0.0528472\tvalid_1's multi_logloss: 0.288297       \n",
      "[61]\ttraining's multi_logloss: 0.0516381\tvalid_1's multi_logloss: 0.289975       \n",
      "[62]\ttraining's multi_logloss: 0.050425\tvalid_1's multi_logloss: 0.290573        \n",
      "[63]\ttraining's multi_logloss: 0.0490768\tvalid_1's multi_logloss: 0.291285       \n",
      "[64]\ttraining's multi_logloss: 0.0478405\tvalid_1's multi_logloss: 0.292299       \n",
      "[65]\ttraining's multi_logloss: 0.0467734\tvalid_1's multi_logloss: 0.293323       \n",
      "[66]\ttraining's multi_logloss: 0.0456207\tvalid_1's multi_logloss: 0.294588       \n",
      "Early stopping, best iteration is:                                               \n",
      "[36]\ttraining's multi_logloss: 0.103525\tvalid_1's multi_logloss: 0.270523\n",
      "[1]\ttraining's multi_logloss: 1.48255\tvalid_1's multi_logloss: 1.49279           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.22015\tvalid_1's multi_logloss: 1.2398            \n",
      "[3]\ttraining's multi_logloss: 1.03515\tvalid_1's multi_logloss: 1.06083           \n",
      "[4]\ttraining's multi_logloss: 0.895358\tvalid_1's multi_logloss: 0.926713         \n",
      "[5]\ttraining's multi_logloss: 0.785058\tvalid_1's multi_logloss: 0.821087         \n",
      "[6]\ttraining's multi_logloss: 0.69546\tvalid_1's multi_logloss: 0.735644          \n",
      "[7]\ttraining's multi_logloss: 0.622116\tvalid_1's multi_logloss: 0.666048         \n",
      "[8]\ttraining's multi_logloss: 0.56094\tvalid_1's multi_logloss: 0.608932          \n",
      "[9]\ttraining's multi_logloss: 0.509769\tvalid_1's multi_logloss: 0.561685         \n",
      "[10]\ttraining's multi_logloss: 0.466028\tvalid_1's multi_logloss: 0.521615        \n",
      "[11]\ttraining's multi_logloss: 0.429706\tvalid_1's multi_logloss: 0.489515        \n",
      "[12]\ttraining's multi_logloss: 0.397889\tvalid_1's multi_logloss: 0.46145         \n",
      "[13]\ttraining's multi_logloss: 0.370307\tvalid_1's multi_logloss: 0.437652        \n",
      "[14]\ttraining's multi_logloss: 0.346424\tvalid_1's multi_logloss: 0.416492        \n",
      "[15]\ttraining's multi_logloss: 0.325114\tvalid_1's multi_logloss: 0.398355        \n",
      "[16]\ttraining's multi_logloss: 0.306487\tvalid_1's multi_logloss: 0.384124        \n",
      "[17]\ttraining's multi_logloss: 0.29008\tvalid_1's multi_logloss: 0.371339         \n",
      "[18]\ttraining's multi_logloss: 0.275418\tvalid_1's multi_logloss: 0.360445        \n",
      "[19]\ttraining's multi_logloss: 0.261793\tvalid_1's multi_logloss: 0.350552        \n",
      "[20]\ttraining's multi_logloss: 0.249315\tvalid_1's multi_logloss: 0.342281        \n",
      "[21]\ttraining's multi_logloss: 0.238289\tvalid_1's multi_logloss: 0.335607        \n",
      "[22]\ttraining's multi_logloss: 0.22853\tvalid_1's multi_logloss: 0.330318         \n",
      "[23]\ttraining's multi_logloss: 0.219189\tvalid_1's multi_logloss: 0.325196        \n",
      "[24]\ttraining's multi_logloss: 0.210172\tvalid_1's multi_logloss: 0.320849        \n",
      "[25]\ttraining's multi_logloss: 0.201869\tvalid_1's multi_logloss: 0.316584        \n",
      "[26]\ttraining's multi_logloss: 0.194271\tvalid_1's multi_logloss: 0.313153        \n",
      "[27]\ttraining's multi_logloss: 0.18693\tvalid_1's multi_logloss: 0.310517         \n",
      "[28]\ttraining's multi_logloss: 0.180158\tvalid_1's multi_logloss: 0.308739        \n",
      "[29]\ttraining's multi_logloss: 0.173499\tvalid_1's multi_logloss: 0.306284        \n",
      "[30]\ttraining's multi_logloss: 0.167307\tvalid_1's multi_logloss: 0.304182        \n",
      "[31]\ttraining's multi_logloss: 0.161639\tvalid_1's multi_logloss: 0.302964        \n",
      "[32]\ttraining's multi_logloss: 0.1561\tvalid_1's multi_logloss: 0.30143           \n",
      "[33]\ttraining's multi_logloss: 0.150634\tvalid_1's multi_logloss: 0.299788        \n",
      "[34]\ttraining's multi_logloss: 0.145544\tvalid_1's multi_logloss: 0.29864         \n",
      "[35]\ttraining's multi_logloss: 0.140772\tvalid_1's multi_logloss: 0.297767        \n",
      "[36]\ttraining's multi_logloss: 0.136199\tvalid_1's multi_logloss: 0.297195        \n",
      "[37]\ttraining's multi_logloss: 0.131695\tvalid_1's multi_logloss: 0.296016        \n",
      "[38]\ttraining's multi_logloss: 0.127608\tvalid_1's multi_logloss: 0.29582         \n",
      "[39]\ttraining's multi_logloss: 0.1237\tvalid_1's multi_logloss: 0.295317          \n",
      "[40]\ttraining's multi_logloss: 0.119847\tvalid_1's multi_logloss: 0.294693        \n",
      "[41]\ttraining's multi_logloss: 0.116178\tvalid_1's multi_logloss: 0.29497         \n",
      "[42]\ttraining's multi_logloss: 0.112714\tvalid_1's multi_logloss: 0.294761        \n",
      "[43]\ttraining's multi_logloss: 0.109197\tvalid_1's multi_logloss: 0.294492        \n",
      "[44]\ttraining's multi_logloss: 0.106025\tvalid_1's multi_logloss: 0.294773        \n",
      "[45]\ttraining's multi_logloss: 0.103057\tvalid_1's multi_logloss: 0.294522        \n",
      "[46]\ttraining's multi_logloss: 0.0999466\tvalid_1's multi_logloss: 0.294813       \n",
      "[47]\ttraining's multi_logloss: 0.0968659\tvalid_1's multi_logloss: 0.29526        \n",
      "[48]\ttraining's multi_logloss: 0.0938615\tvalid_1's multi_logloss: 0.295168       \n",
      "[49]\ttraining's multi_logloss: 0.0911638\tvalid_1's multi_logloss: 0.295471       \n",
      "[50]\ttraining's multi_logloss: 0.0884299\tvalid_1's multi_logloss: 0.295488       \n",
      "[51]\ttraining's multi_logloss: 0.0859341\tvalid_1's multi_logloss: 0.296081       \n",
      "[52]\ttraining's multi_logloss: 0.0834013\tvalid_1's multi_logloss: 0.296233       \n",
      "[53]\ttraining's multi_logloss: 0.0811162\tvalid_1's multi_logloss: 0.29645        \n",
      "[54]\ttraining's multi_logloss: 0.0787523\tvalid_1's multi_logloss: 0.29696        \n",
      "[55]\ttraining's multi_logloss: 0.0766007\tvalid_1's multi_logloss: 0.297581       \n",
      "[56]\ttraining's multi_logloss: 0.0746297\tvalid_1's multi_logloss: 0.298099       \n",
      "[57]\ttraining's multi_logloss: 0.0726408\tvalid_1's multi_logloss: 0.298305       \n",
      "[58]\ttraining's multi_logloss: 0.0706348\tvalid_1's multi_logloss: 0.298976       \n",
      "[59]\ttraining's multi_logloss: 0.0687376\tvalid_1's multi_logloss: 0.299429       \n",
      "[60]\ttraining's multi_logloss: 0.0669532\tvalid_1's multi_logloss: 0.300064       \n",
      "[61]\ttraining's multi_logloss: 0.0652046\tvalid_1's multi_logloss: 0.300828       \n",
      "[62]\ttraining's multi_logloss: 0.0635892\tvalid_1's multi_logloss: 0.300937       \n",
      "[63]\ttraining's multi_logloss: 0.0619464\tvalid_1's multi_logloss: 0.301503       \n",
      "[64]\ttraining's multi_logloss: 0.0604149\tvalid_1's multi_logloss: 0.302503       \n",
      "[65]\ttraining's multi_logloss: 0.0588015\tvalid_1's multi_logloss: 0.302994       \n",
      "[66]\ttraining's multi_logloss: 0.0573624\tvalid_1's multi_logloss: 0.303866       \n",
      "[67]\ttraining's multi_logloss: 0.0558917\tvalid_1's multi_logloss: 0.304641       \n",
      "[68]\ttraining's multi_logloss: 0.054385\tvalid_1's multi_logloss: 0.305316        \n",
      "[69]\ttraining's multi_logloss: 0.0529727\tvalid_1's multi_logloss: 0.306719       \n",
      "[70]\ttraining's multi_logloss: 0.0516413\tvalid_1's multi_logloss: 0.307453       \n",
      "[71]\ttraining's multi_logloss: 0.0504318\tvalid_1's multi_logloss: 0.308727       \n",
      "[72]\ttraining's multi_logloss: 0.0491592\tvalid_1's multi_logloss: 0.309942       \n",
      "[73]\ttraining's multi_logloss: 0.0479953\tvalid_1's multi_logloss: 0.311292       \n",
      "Early stopping, best iteration is:                                               \n",
      "[43]\ttraining's multi_logloss: 0.109197\tvalid_1's multi_logloss: 0.294492\n",
      "[1]\ttraining's multi_logloss: 1.47978\tvalid_1's multi_logloss: 1.48616           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.21897\tvalid_1's multi_logloss: 1.22908           \n",
      "[3]\ttraining's multi_logloss: 1.03628\tvalid_1's multi_logloss: 1.05104           \n",
      "[4]\ttraining's multi_logloss: 0.896996\tvalid_1's multi_logloss: 0.915779         \n",
      "[5]\ttraining's multi_logloss: 0.787578\tvalid_1's multi_logloss: 0.810858         \n",
      "[6]\ttraining's multi_logloss: 0.699288\tvalid_1's multi_logloss: 0.725967         \n",
      "[7]\ttraining's multi_logloss: 0.626284\tvalid_1's multi_logloss: 0.657475         \n",
      "[8]\ttraining's multi_logloss: 0.565839\tvalid_1's multi_logloss: 0.6003           \n",
      "[9]\ttraining's multi_logloss: 0.514866\tvalid_1's multi_logloss: 0.552821         \n",
      "[10]\ttraining's multi_logloss: 0.471781\tvalid_1's multi_logloss: 0.513283        \n",
      "[11]\ttraining's multi_logloss: 0.434545\tvalid_1's multi_logloss: 0.479709        \n",
      "[12]\ttraining's multi_logloss: 0.402738\tvalid_1's multi_logloss: 0.452389        \n",
      "[13]\ttraining's multi_logloss: 0.375155\tvalid_1's multi_logloss: 0.428964        \n",
      "[14]\ttraining's multi_logloss: 0.350976\tvalid_1's multi_logloss: 0.409207        \n",
      "[15]\ttraining's multi_logloss: 0.32964\tvalid_1's multi_logloss: 0.3918           \n",
      "[16]\ttraining's multi_logloss: 0.310136\tvalid_1's multi_logloss: 0.376693        \n",
      "[17]\ttraining's multi_logloss: 0.293338\tvalid_1's multi_logloss: 0.36361         \n",
      "[18]\ttraining's multi_logloss: 0.278442\tvalid_1's multi_logloss: 0.353081        \n",
      "[19]\ttraining's multi_logloss: 0.265013\tvalid_1's multi_logloss: 0.343131        \n",
      "[20]\ttraining's multi_logloss: 0.252534\tvalid_1's multi_logloss: 0.335418        \n",
      "[21]\ttraining's multi_logloss: 0.24077\tvalid_1's multi_logloss: 0.327898         \n",
      "[22]\ttraining's multi_logloss: 0.230416\tvalid_1's multi_logloss: 0.322327        \n",
      "[23]\ttraining's multi_logloss: 0.220919\tvalid_1's multi_logloss: 0.317469        \n",
      "[24]\ttraining's multi_logloss: 0.211593\tvalid_1's multi_logloss: 0.312963        \n",
      "[25]\ttraining's multi_logloss: 0.203084\tvalid_1's multi_logloss: 0.309223        \n",
      "[26]\ttraining's multi_logloss: 0.195141\tvalid_1's multi_logloss: 0.306166        \n",
      "[27]\ttraining's multi_logloss: 0.187762\tvalid_1's multi_logloss: 0.303701        \n",
      "[28]\ttraining's multi_logloss: 0.180885\tvalid_1's multi_logloss: 0.301604        \n",
      "[29]\ttraining's multi_logloss: 0.174595\tvalid_1's multi_logloss: 0.299547        \n",
      "[30]\ttraining's multi_logloss: 0.16827\tvalid_1's multi_logloss: 0.297915         \n",
      "[31]\ttraining's multi_logloss: 0.162465\tvalid_1's multi_logloss: 0.296629        \n",
      "[32]\ttraining's multi_logloss: 0.157078\tvalid_1's multi_logloss: 0.295367        \n",
      "[33]\ttraining's multi_logloss: 0.15123\tvalid_1's multi_logloss: 0.293495         \n",
      "[34]\ttraining's multi_logloss: 0.146332\tvalid_1's multi_logloss: 0.291965        \n",
      "[35]\ttraining's multi_logloss: 0.14118\tvalid_1's multi_logloss: 0.290667         \n",
      "[36]\ttraining's multi_logloss: 0.136402\tvalid_1's multi_logloss: 0.290211        \n",
      "[37]\ttraining's multi_logloss: 0.131763\tvalid_1's multi_logloss: 0.289507        \n",
      "[38]\ttraining's multi_logloss: 0.127706\tvalid_1's multi_logloss: 0.2891          \n",
      "[39]\ttraining's multi_logloss: 0.123667\tvalid_1's multi_logloss: 0.288723        \n",
      "[40]\ttraining's multi_logloss: 0.119902\tvalid_1's multi_logloss: 0.288786        \n",
      "[41]\ttraining's multi_logloss: 0.116146\tvalid_1's multi_logloss: 0.288726        \n",
      "[42]\ttraining's multi_logloss: 0.11251\tvalid_1's multi_logloss: 0.288898         \n",
      "[43]\ttraining's multi_logloss: 0.108964\tvalid_1's multi_logloss: 0.289033        \n",
      "[44]\ttraining's multi_logloss: 0.105501\tvalid_1's multi_logloss: 0.289192        \n",
      "[45]\ttraining's multi_logloss: 0.102292\tvalid_1's multi_logloss: 0.289773        \n",
      "[46]\ttraining's multi_logloss: 0.0992866\tvalid_1's multi_logloss: 0.290012       \n",
      "[47]\ttraining's multi_logloss: 0.0962054\tvalid_1's multi_logloss: 0.290349       \n",
      "[48]\ttraining's multi_logloss: 0.0933769\tvalid_1's multi_logloss: 0.290681       \n",
      "[49]\ttraining's multi_logloss: 0.0906762\tvalid_1's multi_logloss: 0.291118       \n",
      "[50]\ttraining's multi_logloss: 0.0876289\tvalid_1's multi_logloss: 0.291436       \n",
      "[51]\ttraining's multi_logloss: 0.0849788\tvalid_1's multi_logloss: 0.292011       \n",
      "[52]\ttraining's multi_logloss: 0.0824533\tvalid_1's multi_logloss: 0.29267        \n",
      "[53]\ttraining's multi_logloss: 0.0800404\tvalid_1's multi_logloss: 0.293058       \n",
      "[54]\ttraining's multi_logloss: 0.0777838\tvalid_1's multi_logloss: 0.293439       \n",
      "[55]\ttraining's multi_logloss: 0.075577\tvalid_1's multi_logloss: 0.294246        \n",
      "[56]\ttraining's multi_logloss: 0.0735023\tvalid_1's multi_logloss: 0.294505       \n",
      "[57]\ttraining's multi_logloss: 0.0713309\tvalid_1's multi_logloss: 0.295361       \n",
      "[58]\ttraining's multi_logloss: 0.0692941\tvalid_1's multi_logloss: 0.29588        \n",
      "[59]\ttraining's multi_logloss: 0.0674358\tvalid_1's multi_logloss: 0.296863       \n",
      "[60]\ttraining's multi_logloss: 0.0655957\tvalid_1's multi_logloss: 0.29747        \n",
      "[61]\ttraining's multi_logloss: 0.0636455\tvalid_1's multi_logloss: 0.297994       \n",
      "[62]\ttraining's multi_logloss: 0.0619772\tvalid_1's multi_logloss: 0.298401       \n",
      "[63]\ttraining's multi_logloss: 0.0603942\tvalid_1's multi_logloss: 0.299218       \n",
      "[64]\ttraining's multi_logloss: 0.058676\tvalid_1's multi_logloss: 0.299858        \n",
      "[65]\ttraining's multi_logloss: 0.0571015\tvalid_1's multi_logloss: 0.300716       \n",
      "[66]\ttraining's multi_logloss: 0.0555331\tvalid_1's multi_logloss: 0.301767       \n",
      "[67]\ttraining's multi_logloss: 0.0540897\tvalid_1's multi_logloss: 0.302647       \n",
      "[68]\ttraining's multi_logloss: 0.0526852\tvalid_1's multi_logloss: 0.303          \n",
      "[69]\ttraining's multi_logloss: 0.0513337\tvalid_1's multi_logloss: 0.303578       \n",
      "Early stopping, best iteration is:                                               \n",
      "[39]\ttraining's multi_logloss: 0.123667\tvalid_1's multi_logloss: 0.288723\n",
      "[1]\ttraining's multi_logloss: 1.48156\tvalid_1's multi_logloss: 1.48777           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.22235\tvalid_1's multi_logloss: 1.23156           \n",
      "[3]\ttraining's multi_logloss: 1.03906\tvalid_1's multi_logloss: 1.05075           \n",
      "[4]\ttraining's multi_logloss: 0.89947\tvalid_1's multi_logloss: 0.913357          \n",
      "[5]\ttraining's multi_logloss: 0.79043\tvalid_1's multi_logloss: 0.806445          \n",
      "[6]\ttraining's multi_logloss: 0.701242\tvalid_1's multi_logloss: 0.720412         \n",
      "[7]\ttraining's multi_logloss: 0.628559\tvalid_1's multi_logloss: 0.650791         \n",
      "[8]\ttraining's multi_logloss: 0.568146\tvalid_1's multi_logloss: 0.593683         \n",
      "[9]\ttraining's multi_logloss: 0.516974\tvalid_1's multi_logloss: 0.545551         \n",
      "[10]\ttraining's multi_logloss: 0.474157\tvalid_1's multi_logloss: 0.506275        \n",
      "[11]\ttraining's multi_logloss: 0.43748\tvalid_1's multi_logloss: 0.473478         \n",
      "[12]\ttraining's multi_logloss: 0.40589\tvalid_1's multi_logloss: 0.44545          \n",
      "[13]\ttraining's multi_logloss: 0.378187\tvalid_1's multi_logloss: 0.421134        \n",
      "[14]\ttraining's multi_logloss: 0.354602\tvalid_1's multi_logloss: 0.400526        \n",
      "[15]\ttraining's multi_logloss: 0.332933\tvalid_1's multi_logloss: 0.382737        \n",
      "[16]\ttraining's multi_logloss: 0.313969\tvalid_1's multi_logloss: 0.367395        \n",
      "[17]\ttraining's multi_logloss: 0.297301\tvalid_1's multi_logloss: 0.354306        \n",
      "[18]\ttraining's multi_logloss: 0.282386\tvalid_1's multi_logloss: 0.343552        \n",
      "[19]\ttraining's multi_logloss: 0.268255\tvalid_1's multi_logloss: 0.33375         \n",
      "[20]\ttraining's multi_logloss: 0.255703\tvalid_1's multi_logloss: 0.325622        \n",
      "[21]\ttraining's multi_logloss: 0.244549\tvalid_1's multi_logloss: 0.318891        \n",
      "[22]\ttraining's multi_logloss: 0.234005\tvalid_1's multi_logloss: 0.312486        \n",
      "[23]\ttraining's multi_logloss: 0.22437\tvalid_1's multi_logloss: 0.307253         \n",
      "[24]\ttraining's multi_logloss: 0.215295\tvalid_1's multi_logloss: 0.302701        \n",
      "[25]\ttraining's multi_logloss: 0.207052\tvalid_1's multi_logloss: 0.298685        \n",
      "[26]\ttraining's multi_logloss: 0.199359\tvalid_1's multi_logloss: 0.295334        \n",
      "[27]\ttraining's multi_logloss: 0.192047\tvalid_1's multi_logloss: 0.292592        \n",
      "[28]\ttraining's multi_logloss: 0.185226\tvalid_1's multi_logloss: 0.28989         \n",
      "[29]\ttraining's multi_logloss: 0.178478\tvalid_1's multi_logloss: 0.288054        \n",
      "[30]\ttraining's multi_logloss: 0.172529\tvalid_1's multi_logloss: 0.28662         \n",
      "[31]\ttraining's multi_logloss: 0.166766\tvalid_1's multi_logloss: 0.284148        \n",
      "[32]\ttraining's multi_logloss: 0.161153\tvalid_1's multi_logloss: 0.282824        \n",
      "[33]\ttraining's multi_logloss: 0.155425\tvalid_1's multi_logloss: 0.281533        \n",
      "[34]\ttraining's multi_logloss: 0.150395\tvalid_1's multi_logloss: 0.280364        \n",
      "[35]\ttraining's multi_logloss: 0.145681\tvalid_1's multi_logloss: 0.279496        \n",
      "[36]\ttraining's multi_logloss: 0.14075\tvalid_1's multi_logloss: 0.279231         \n",
      "[37]\ttraining's multi_logloss: 0.136189\tvalid_1's multi_logloss: 0.278118        \n",
      "[38]\ttraining's multi_logloss: 0.131993\tvalid_1's multi_logloss: 0.277765        \n",
      "[39]\ttraining's multi_logloss: 0.127825\tvalid_1's multi_logloss: 0.27699         \n",
      "[40]\ttraining's multi_logloss: 0.123716\tvalid_1's multi_logloss: 0.276403        \n",
      "[41]\ttraining's multi_logloss: 0.119793\tvalid_1's multi_logloss: 0.275832        \n",
      "[42]\ttraining's multi_logloss: 0.115889\tvalid_1's multi_logloss: 0.275077        \n",
      "[43]\ttraining's multi_logloss: 0.112212\tvalid_1's multi_logloss: 0.274907        \n",
      "[44]\ttraining's multi_logloss: 0.1089\tvalid_1's multi_logloss: 0.274827          \n",
      "[45]\ttraining's multi_logloss: 0.105534\tvalid_1's multi_logloss: 0.274706        \n",
      "[46]\ttraining's multi_logloss: 0.102404\tvalid_1's multi_logloss: 0.274568        \n",
      "[47]\ttraining's multi_logloss: 0.0992143\tvalid_1's multi_logloss: 0.274418       \n",
      "[48]\ttraining's multi_logloss: 0.0962046\tvalid_1's multi_logloss: 0.275165       \n",
      "[49]\ttraining's multi_logloss: 0.0934283\tvalid_1's multi_logloss: 0.275656       \n",
      "[50]\ttraining's multi_logloss: 0.090581\tvalid_1's multi_logloss: 0.275639        \n",
      "[51]\ttraining's multi_logloss: 0.0880068\tvalid_1's multi_logloss: 0.275853       \n",
      "[52]\ttraining's multi_logloss: 0.0855893\tvalid_1's multi_logloss: 0.276347       \n",
      "[53]\ttraining's multi_logloss: 0.08326\tvalid_1's multi_logloss: 0.276735         \n",
      "[54]\ttraining's multi_logloss: 0.0808795\tvalid_1's multi_logloss: 0.277078       \n",
      "[55]\ttraining's multi_logloss: 0.0787204\tvalid_1's multi_logloss: 0.277461       \n",
      "[56]\ttraining's multi_logloss: 0.0764792\tvalid_1's multi_logloss: 0.277663       \n",
      "[57]\ttraining's multi_logloss: 0.0742826\tvalid_1's multi_logloss: 0.278769       \n",
      "[58]\ttraining's multi_logloss: 0.072128\tvalid_1's multi_logloss: 0.279225        \n",
      "[59]\ttraining's multi_logloss: 0.0701294\tvalid_1's multi_logloss: 0.280229       \n",
      "[60]\ttraining's multi_logloss: 0.0682413\tvalid_1's multi_logloss: 0.280903       \n",
      "[61]\ttraining's multi_logloss: 0.066366\tvalid_1's multi_logloss: 0.281363        \n",
      "[62]\ttraining's multi_logloss: 0.0645724\tvalid_1's multi_logloss: 0.281712       \n",
      "[63]\ttraining's multi_logloss: 0.0629463\tvalid_1's multi_logloss: 0.282298       \n",
      "[64]\ttraining's multi_logloss: 0.0612828\tvalid_1's multi_logloss: 0.282931       \n",
      "[65]\ttraining's multi_logloss: 0.059706\tvalid_1's multi_logloss: 0.283441        \n",
      "[66]\ttraining's multi_logloss: 0.0582685\tvalid_1's multi_logloss: 0.284191       \n",
      "[67]\ttraining's multi_logloss: 0.0568691\tvalid_1's multi_logloss: 0.284753       \n",
      "[68]\ttraining's multi_logloss: 0.0553625\tvalid_1's multi_logloss: 0.285169       \n",
      "[69]\ttraining's multi_logloss: 0.0539354\tvalid_1's multi_logloss: 0.285888       \n",
      "[70]\ttraining's multi_logloss: 0.0524777\tvalid_1's multi_logloss: 0.286292       \n",
      "[71]\ttraining's multi_logloss: 0.0510997\tvalid_1's multi_logloss: 0.286841       \n",
      "[72]\ttraining's multi_logloss: 0.049839\tvalid_1's multi_logloss: 0.288086        \n",
      "[73]\ttraining's multi_logloss: 0.0485738\tvalid_1's multi_logloss: 0.28911        \n",
      "[74]\ttraining's multi_logloss: 0.0472187\tvalid_1's multi_logloss: 0.289784       \n",
      "[75]\ttraining's multi_logloss: 0.0459317\tvalid_1's multi_logloss: 0.290894       \n",
      "[76]\ttraining's multi_logloss: 0.0448202\tvalid_1's multi_logloss: 0.291655       \n",
      "[77]\ttraining's multi_logloss: 0.0436177\tvalid_1's multi_logloss: 0.292947       \n",
      "Early stopping, best iteration is:                                               \n",
      "[47]\ttraining's multi_logloss: 0.0992143\tvalid_1's multi_logloss: 0.274418\n",
      "[1]\ttraining's multi_logloss: 1.77268\tvalid_1's multi_logloss: 1.77362           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.64098\tvalid_1's multi_logloss: 1.64495           \n",
      "[3]\ttraining's multi_logloss: 1.52854\tvalid_1's multi_logloss: 1.53504           \n",
      "[4]\ttraining's multi_logloss: 1.43128\tvalid_1's multi_logloss: 1.44041           \n",
      "[5]\ttraining's multi_logloss: 1.34555\tvalid_1's multi_logloss: 1.35711           \n",
      "[6]\ttraining's multi_logloss: 1.26859\tvalid_1's multi_logloss: 1.28273           \n",
      "[7]\ttraining's multi_logloss: 1.19965\tvalid_1's multi_logloss: 1.21593           \n",
      "[8]\ttraining's multi_logloss: 1.13776\tvalid_1's multi_logloss: 1.15586           \n",
      "[9]\ttraining's multi_logloss: 1.08069\tvalid_1's multi_logloss: 1.1008            \n",
      "[10]\ttraining's multi_logloss: 1.02868\tvalid_1's multi_logloss: 1.05024          \n",
      "[11]\ttraining's multi_logloss: 0.981078\tvalid_1's multi_logloss: 1.00441         \n",
      "[12]\ttraining's multi_logloss: 0.936739\tvalid_1's multi_logloss: 0.961567        \n",
      "[13]\ttraining's multi_logloss: 0.896008\tvalid_1's multi_logloss: 0.922403        \n",
      "[14]\ttraining's multi_logloss: 0.858314\tvalid_1's multi_logloss: 0.885835        \n",
      "[15]\ttraining's multi_logloss: 0.822637\tvalid_1's multi_logloss: 0.851648        \n",
      "[16]\ttraining's multi_logloss: 0.789784\tvalid_1's multi_logloss: 0.819802        \n",
      "[17]\ttraining's multi_logloss: 0.759168\tvalid_1's multi_logloss: 0.790158        \n",
      "[18]\ttraining's multi_logloss: 0.730594\tvalid_1's multi_logloss: 0.76271         \n",
      "[19]\ttraining's multi_logloss: 0.703797\tvalid_1's multi_logloss: 0.736938        \n",
      "[20]\ttraining's multi_logloss: 0.678537\tvalid_1's multi_logloss: 0.712555        \n",
      "[21]\ttraining's multi_logloss: 0.655003\tvalid_1's multi_logloss: 0.689836        \n",
      "[22]\ttraining's multi_logloss: 0.632804\tvalid_1's multi_logloss: 0.668699        \n",
      "[23]\ttraining's multi_logloss: 0.611918\tvalid_1's multi_logloss: 0.64882         \n",
      "[24]\ttraining's multi_logloss: 0.592088\tvalid_1's multi_logloss: 0.629987        \n",
      "[25]\ttraining's multi_logloss: 0.573239\tvalid_1's multi_logloss: 0.611988        \n",
      "[26]\ttraining's multi_logloss: 0.5556\tvalid_1's multi_logloss: 0.595273          \n",
      "[27]\ttraining's multi_logloss: 0.538957\tvalid_1's multi_logloss: 0.579545        \n",
      "[28]\ttraining's multi_logloss: 0.523315\tvalid_1's multi_logloss: 0.564861        \n",
      "[29]\ttraining's multi_logloss: 0.508431\tvalid_1's multi_logloss: 0.550799        \n",
      "[30]\ttraining's multi_logloss: 0.49436\tvalid_1's multi_logloss: 0.537888         \n",
      "[31]\ttraining's multi_logloss: 0.481124\tvalid_1's multi_logloss: 0.525608        \n",
      "[32]\ttraining's multi_logloss: 0.468321\tvalid_1's multi_logloss: 0.513716        \n",
      "[33]\ttraining's multi_logloss: 0.456212\tvalid_1's multi_logloss: 0.502567        \n",
      "[34]\ttraining's multi_logloss: 0.444708\tvalid_1's multi_logloss: 0.49201         \n",
      "[35]\ttraining's multi_logloss: 0.43377\tvalid_1's multi_logloss: 0.482155         \n",
      "[36]\ttraining's multi_logloss: 0.423308\tvalid_1's multi_logloss: 0.472705        \n",
      "[37]\ttraining's multi_logloss: 0.413424\tvalid_1's multi_logloss: 0.463671        \n",
      "[38]\ttraining's multi_logloss: 0.403948\tvalid_1's multi_logloss: 0.455167        \n",
      "[39]\ttraining's multi_logloss: 0.394916\tvalid_1's multi_logloss: 0.447058        \n",
      "[40]\ttraining's multi_logloss: 0.386371\tvalid_1's multi_logloss: 0.43949         \n",
      "[41]\ttraining's multi_logloss: 0.378177\tvalid_1's multi_logloss: 0.432163        \n",
      "[42]\ttraining's multi_logloss: 0.37038\tvalid_1's multi_logloss: 0.425276         \n",
      "[43]\ttraining's multi_logloss: 0.363032\tvalid_1's multi_logloss: 0.419053        \n",
      "[44]\ttraining's multi_logloss: 0.355955\tvalid_1's multi_logloss: 0.412857        \n",
      "[45]\ttraining's multi_logloss: 0.349262\tvalid_1's multi_logloss: 0.40727         \n",
      "[46]\ttraining's multi_logloss: 0.342738\tvalid_1's multi_logloss: 0.401688        \n",
      "[47]\ttraining's multi_logloss: 0.336314\tvalid_1's multi_logloss: 0.396451        \n",
      "[48]\ttraining's multi_logloss: 0.33039\tvalid_1's multi_logloss: 0.391573         \n",
      "[49]\ttraining's multi_logloss: 0.324717\tvalid_1's multi_logloss: 0.386999        \n",
      "[50]\ttraining's multi_logloss: 0.31921\tvalid_1's multi_logloss: 0.382666         \n",
      "[51]\ttraining's multi_logloss: 0.314023\tvalid_1's multi_logloss: 0.37843         \n",
      "[52]\ttraining's multi_logloss: 0.309061\tvalid_1's multi_logloss: 0.374357        \n",
      "[53]\ttraining's multi_logloss: 0.304153\tvalid_1's multi_logloss: 0.370466        \n",
      "[54]\ttraining's multi_logloss: 0.299306\tvalid_1's multi_logloss: 0.366678        \n",
      "[55]\ttraining's multi_logloss: 0.294824\tvalid_1's multi_logloss: 0.363145        \n",
      "[56]\ttraining's multi_logloss: 0.290493\tvalid_1's multi_logloss: 0.359887        \n",
      "[57]\ttraining's multi_logloss: 0.286139\tvalid_1's multi_logloss: 0.356591        \n",
      "[58]\ttraining's multi_logloss: 0.282025\tvalid_1's multi_logloss: 0.353743        \n",
      "[59]\ttraining's multi_logloss: 0.278063\tvalid_1's multi_logloss: 0.350888        \n",
      "[60]\ttraining's multi_logloss: 0.274114\tvalid_1's multi_logloss: 0.348066        \n",
      "[61]\ttraining's multi_logloss: 0.270449\tvalid_1's multi_logloss: 0.34549         \n",
      "[62]\ttraining's multi_logloss: 0.266832\tvalid_1's multi_logloss: 0.343174        \n",
      "[63]\ttraining's multi_logloss: 0.263409\tvalid_1's multi_logloss: 0.340782        \n",
      "[64]\ttraining's multi_logloss: 0.260063\tvalid_1's multi_logloss: 0.338534        \n",
      "[65]\ttraining's multi_logloss: 0.256592\tvalid_1's multi_logloss: 0.336148        \n",
      "[66]\ttraining's multi_logloss: 0.253247\tvalid_1's multi_logloss: 0.333978        \n",
      "[67]\ttraining's multi_logloss: 0.250007\tvalid_1's multi_logloss: 0.331763        \n",
      "[68]\ttraining's multi_logloss: 0.246803\tvalid_1's multi_logloss: 0.329973        \n",
      "[69]\ttraining's multi_logloss: 0.243754\tvalid_1's multi_logloss: 0.328085        \n",
      "[70]\ttraining's multi_logloss: 0.240764\tvalid_1's multi_logloss: 0.326326        \n",
      "[71]\ttraining's multi_logloss: 0.237803\tvalid_1's multi_logloss: 0.324576        \n",
      "[72]\ttraining's multi_logloss: 0.234933\tvalid_1's multi_logloss: 0.322898        \n",
      "[73]\ttraining's multi_logloss: 0.232301\tvalid_1's multi_logloss: 0.321449        \n",
      "[74]\ttraining's multi_logloss: 0.229659\tvalid_1's multi_logloss: 0.319948        \n",
      "[75]\ttraining's multi_logloss: 0.227094\tvalid_1's multi_logloss: 0.318567        \n",
      "[76]\ttraining's multi_logloss: 0.224437\tvalid_1's multi_logloss: 0.317318        \n",
      "[77]\ttraining's multi_logloss: 0.221956\tvalid_1's multi_logloss: 0.316153        \n",
      "[78]\ttraining's multi_logloss: 0.219512\tvalid_1's multi_logloss: 0.315136        \n",
      "[79]\ttraining's multi_logloss: 0.217145\tvalid_1's multi_logloss: 0.314176        \n",
      "[80]\ttraining's multi_logloss: 0.214842\tvalid_1's multi_logloss: 0.313047        \n",
      "[81]\ttraining's multi_logloss: 0.212543\tvalid_1's multi_logloss: 0.311865        \n",
      "[82]\ttraining's multi_logloss: 0.21037\tvalid_1's multi_logloss: 0.310949         \n",
      "[83]\ttraining's multi_logloss: 0.208155\tvalid_1's multi_logloss: 0.310004        \n",
      "[84]\ttraining's multi_logloss: 0.206008\tvalid_1's multi_logloss: 0.309073        \n",
      "[85]\ttraining's multi_logloss: 0.203926\tvalid_1's multi_logloss: 0.308232        \n",
      "[86]\ttraining's multi_logloss: 0.201799\tvalid_1's multi_logloss: 0.307308        \n",
      "[87]\ttraining's multi_logloss: 0.199823\tvalid_1's multi_logloss: 0.306498        \n",
      "[88]\ttraining's multi_logloss: 0.197863\tvalid_1's multi_logloss: 0.305665        \n",
      "[89]\ttraining's multi_logloss: 0.195911\tvalid_1's multi_logloss: 0.304993        \n",
      "[90]\ttraining's multi_logloss: 0.194106\tvalid_1's multi_logloss: 0.3042          \n",
      "[91]\ttraining's multi_logloss: 0.192202\tvalid_1's multi_logloss: 0.303609        \n",
      "[92]\ttraining's multi_logloss: 0.190371\tvalid_1's multi_logloss: 0.303053        \n",
      "[93]\ttraining's multi_logloss: 0.188553\tvalid_1's multi_logloss: 0.302295        \n",
      "[94]\ttraining's multi_logloss: 0.186752\tvalid_1's multi_logloss: 0.301766        \n",
      "[95]\ttraining's multi_logloss: 0.185047\tvalid_1's multi_logloss: 0.301335        \n",
      "[96]\ttraining's multi_logloss: 0.183292\tvalid_1's multi_logloss: 0.300812        \n",
      "[97]\ttraining's multi_logloss: 0.181638\tvalid_1's multi_logloss: 0.300317        \n",
      "[98]\ttraining's multi_logloss: 0.179923\tvalid_1's multi_logloss: 0.299907        \n",
      "[99]\ttraining's multi_logloss: 0.178298\tvalid_1's multi_logloss: 0.299455        \n",
      "[100]\ttraining's multi_logloss: 0.176655\tvalid_1's multi_logloss: 0.299087       \n",
      "[101]\ttraining's multi_logloss: 0.175059\tvalid_1's multi_logloss: 0.298689       \n",
      "[102]\ttraining's multi_logloss: 0.173295\tvalid_1's multi_logloss: 0.298184       \n",
      "[103]\ttraining's multi_logloss: 0.171635\tvalid_1's multi_logloss: 0.29778        \n",
      "[104]\ttraining's multi_logloss: 0.17011\tvalid_1's multi_logloss: 0.297549        \n",
      "[105]\ttraining's multi_logloss: 0.168413\tvalid_1's multi_logloss: 0.297251       \n",
      "[106]\ttraining's multi_logloss: 0.166833\tvalid_1's multi_logloss: 0.297005       \n",
      "[107]\ttraining's multi_logloss: 0.165272\tvalid_1's multi_logloss: 0.296541       \n",
      "[108]\ttraining's multi_logloss: 0.163705\tvalid_1's multi_logloss: 0.296321       \n",
      "[109]\ttraining's multi_logloss: 0.162176\tvalid_1's multi_logloss: 0.296105       \n",
      "[110]\ttraining's multi_logloss: 0.160673\tvalid_1's multi_logloss: 0.295957       \n",
      "[111]\ttraining's multi_logloss: 0.159157\tvalid_1's multi_logloss: 0.295522       \n",
      "[112]\ttraining's multi_logloss: 0.157745\tvalid_1's multi_logloss: 0.295101       \n",
      "[113]\ttraining's multi_logloss: 0.156317\tvalid_1's multi_logloss: 0.294788       \n",
      "[114]\ttraining's multi_logloss: 0.154917\tvalid_1's multi_logloss: 0.294463       \n",
      "[115]\ttraining's multi_logloss: 0.15349\tvalid_1's multi_logloss: 0.294245        \n",
      "[116]\ttraining's multi_logloss: 0.152197\tvalid_1's multi_logloss: 0.294159       \n",
      "[117]\ttraining's multi_logloss: 0.150866\tvalid_1's multi_logloss: 0.293893       \n",
      "[118]\ttraining's multi_logloss: 0.14943\tvalid_1's multi_logloss: 0.293679        \n",
      "[119]\ttraining's multi_logloss: 0.148067\tvalid_1's multi_logloss: 0.293607       \n",
      "[120]\ttraining's multi_logloss: 0.146735\tvalid_1's multi_logloss: 0.293334       \n",
      "[121]\ttraining's multi_logloss: 0.145373\tvalid_1's multi_logloss: 0.293029       \n",
      "[122]\ttraining's multi_logloss: 0.144107\tvalid_1's multi_logloss: 0.292904       \n",
      "[123]\ttraining's multi_logloss: 0.142786\tvalid_1's multi_logloss: 0.292758       \n",
      "[124]\ttraining's multi_logloss: 0.141409\tvalid_1's multi_logloss: 0.292736       \n",
      "[125]\ttraining's multi_logloss: 0.1401\tvalid_1's multi_logloss: 0.292651         \n",
      "[126]\ttraining's multi_logloss: 0.138797\tvalid_1's multi_logloss: 0.292569       \n",
      "[127]\ttraining's multi_logloss: 0.137415\tvalid_1's multi_logloss: 0.292396       \n",
      "[128]\ttraining's multi_logloss: 0.136146\tvalid_1's multi_logloss: 0.292232       \n",
      "[129]\ttraining's multi_logloss: 0.135007\tvalid_1's multi_logloss: 0.292181       \n",
      "[130]\ttraining's multi_logloss: 0.133768\tvalid_1's multi_logloss: 0.292042       \n",
      "[131]\ttraining's multi_logloss: 0.132643\tvalid_1's multi_logloss: 0.292022       \n",
      "[132]\ttraining's multi_logloss: 0.131472\tvalid_1's multi_logloss: 0.29195        \n",
      "[133]\ttraining's multi_logloss: 0.130288\tvalid_1's multi_logloss: 0.291865       \n",
      "[134]\ttraining's multi_logloss: 0.129123\tvalid_1's multi_logloss: 0.291775       \n",
      "[135]\ttraining's multi_logloss: 0.127946\tvalid_1's multi_logloss: 0.291566       \n",
      "[136]\ttraining's multi_logloss: 0.126728\tvalid_1's multi_logloss: 0.291699       \n",
      "[137]\ttraining's multi_logloss: 0.125562\tvalid_1's multi_logloss: 0.291847       \n",
      "[138]\ttraining's multi_logloss: 0.124432\tvalid_1's multi_logloss: 0.291978       \n",
      "[139]\ttraining's multi_logloss: 0.123373\tvalid_1's multi_logloss: 0.291986       \n",
      "[140]\ttraining's multi_logloss: 0.122317\tvalid_1's multi_logloss: 0.291915       \n",
      "[141]\ttraining's multi_logloss: 0.121092\tvalid_1's multi_logloss: 0.291934       \n",
      "[142]\ttraining's multi_logloss: 0.119965\tvalid_1's multi_logloss: 0.291871       \n",
      "[143]\ttraining's multi_logloss: 0.118845\tvalid_1's multi_logloss: 0.291779       \n",
      "[144]\ttraining's multi_logloss: 0.117762\tvalid_1's multi_logloss: 0.291605       \n",
      "[145]\ttraining's multi_logloss: 0.116641\tvalid_1's multi_logloss: 0.291476       \n",
      "[146]\ttraining's multi_logloss: 0.115612\tvalid_1's multi_logloss: 0.291524       \n",
      "[147]\ttraining's multi_logloss: 0.114576\tvalid_1's multi_logloss: 0.291366       \n",
      "[148]\ttraining's multi_logloss: 0.113617\tvalid_1's multi_logloss: 0.291363       \n",
      "[149]\ttraining's multi_logloss: 0.112508\tvalid_1's multi_logloss: 0.291182       \n",
      "[150]\ttraining's multi_logloss: 0.111561\tvalid_1's multi_logloss: 0.2914         \n",
      "[151]\ttraining's multi_logloss: 0.110598\tvalid_1's multi_logloss: 0.291141       \n",
      "[152]\ttraining's multi_logloss: 0.109571\tvalid_1's multi_logloss: 0.291157       \n",
      "[153]\ttraining's multi_logloss: 0.108653\tvalid_1's multi_logloss: 0.290947       \n",
      "[154]\ttraining's multi_logloss: 0.107705\tvalid_1's multi_logloss: 0.290933       \n",
      "[155]\ttraining's multi_logloss: 0.106709\tvalid_1's multi_logloss: 0.290874       \n",
      "[156]\ttraining's multi_logloss: 0.105816\tvalid_1's multi_logloss: 0.290868       \n",
      "[157]\ttraining's multi_logloss: 0.104877\tvalid_1's multi_logloss: 0.290727       \n",
      "[158]\ttraining's multi_logloss: 0.104026\tvalid_1's multi_logloss: 0.290645       \n",
      "[159]\ttraining's multi_logloss: 0.103116\tvalid_1's multi_logloss: 0.290747       \n",
      "[160]\ttraining's multi_logloss: 0.102223\tvalid_1's multi_logloss: 0.290746       \n",
      "[161]\ttraining's multi_logloss: 0.101234\tvalid_1's multi_logloss: 0.2909         \n",
      "[162]\ttraining's multi_logloss: 0.100404\tvalid_1's multi_logloss: 0.291021       \n",
      "[163]\ttraining's multi_logloss: 0.0995906\tvalid_1's multi_logloss: 0.291162      \n",
      "[164]\ttraining's multi_logloss: 0.0987768\tvalid_1's multi_logloss: 0.291276      \n",
      "[165]\ttraining's multi_logloss: 0.0980078\tvalid_1's multi_logloss: 0.291435      \n",
      "[166]\ttraining's multi_logloss: 0.0971625\tvalid_1's multi_logloss: 0.291437      \n",
      "[167]\ttraining's multi_logloss: 0.0963477\tvalid_1's multi_logloss: 0.291392      \n",
      "[168]\ttraining's multi_logloss: 0.0955897\tvalid_1's multi_logloss: 0.291483      \n",
      "[169]\ttraining's multi_logloss: 0.0948555\tvalid_1's multi_logloss: 0.291672      \n",
      "[170]\ttraining's multi_logloss: 0.0941222\tvalid_1's multi_logloss: 0.291852      \n",
      "[171]\ttraining's multi_logloss: 0.0934052\tvalid_1's multi_logloss: 0.291832      \n",
      "[172]\ttraining's multi_logloss: 0.0926642\tvalid_1's multi_logloss: 0.291884      \n",
      "[173]\ttraining's multi_logloss: 0.0918456\tvalid_1's multi_logloss: 0.291959      \n",
      "[174]\ttraining's multi_logloss: 0.0909863\tvalid_1's multi_logloss: 0.292061      \n",
      "[175]\ttraining's multi_logloss: 0.0903234\tvalid_1's multi_logloss: 0.292165      \n",
      "[176]\ttraining's multi_logloss: 0.0895677\tvalid_1's multi_logloss: 0.292386      \n",
      "[177]\ttraining's multi_logloss: 0.0888926\tvalid_1's multi_logloss: 0.292477      \n",
      "[178]\ttraining's multi_logloss: 0.0881523\tvalid_1's multi_logloss: 0.292649      \n",
      "[179]\ttraining's multi_logloss: 0.0874889\tvalid_1's multi_logloss: 0.292805      \n",
      "[180]\ttraining's multi_logloss: 0.0867383\tvalid_1's multi_logloss: 0.292942      \n",
      "[181]\ttraining's multi_logloss: 0.0859623\tvalid_1's multi_logloss: 0.293014      \n",
      "[182]\ttraining's multi_logloss: 0.0852202\tvalid_1's multi_logloss: 0.293185      \n",
      "[183]\ttraining's multi_logloss: 0.0845959\tvalid_1's multi_logloss: 0.293288      \n",
      "[184]\ttraining's multi_logloss: 0.0838763\tvalid_1's multi_logloss: 0.293463      \n",
      "[185]\ttraining's multi_logloss: 0.0832901\tvalid_1's multi_logloss: 0.293524      \n",
      "[186]\ttraining's multi_logloss: 0.0825379\tvalid_1's multi_logloss: 0.293741      \n",
      "[187]\ttraining's multi_logloss: 0.0818937\tvalid_1's multi_logloss: 0.293947      \n",
      "[188]\ttraining's multi_logloss: 0.081187\tvalid_1's multi_logloss: 0.29401        \n",
      "Early stopping, best iteration is:                                               \n",
      "[158]\ttraining's multi_logloss: 0.104026\tvalid_1's multi_logloss: 0.290645\n",
      "[1]\ttraining's multi_logloss: 1.7709\tvalid_1's multi_logloss: 1.77354            \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.64046\tvalid_1's multi_logloss: 1.64403           \n",
      "[3]\ttraining's multi_logloss: 1.52957\tvalid_1's multi_logloss: 1.53382           \n",
      "[4]\ttraining's multi_logloss: 1.43345\tvalid_1's multi_logloss: 1.43888           \n",
      "[5]\ttraining's multi_logloss: 1.34819\tvalid_1's multi_logloss: 1.35448           \n",
      "[6]\ttraining's multi_logloss: 1.2724\tvalid_1's multi_logloss: 1.27941            \n",
      "[7]\ttraining's multi_logloss: 1.20433\tvalid_1's multi_logloss: 1.21251           \n",
      "[8]\ttraining's multi_logloss: 1.14285\tvalid_1's multi_logloss: 1.15208           \n",
      "[9]\ttraining's multi_logloss: 1.08648\tvalid_1's multi_logloss: 1.09658           \n",
      "[10]\ttraining's multi_logloss: 1.03522\tvalid_1's multi_logloss: 1.04615          \n",
      "[11]\ttraining's multi_logloss: 0.9878\tvalid_1's multi_logloss: 0.999831          \n",
      "[12]\ttraining's multi_logloss: 0.943915\tvalid_1's multi_logloss: 0.956623        \n",
      "[13]\ttraining's multi_logloss: 0.903493\tvalid_1's multi_logloss: 0.9169          \n",
      "[14]\ttraining's multi_logloss: 0.865915\tvalid_1's multi_logloss: 0.880612        \n",
      "[15]\ttraining's multi_logloss: 0.830486\tvalid_1's multi_logloss: 0.845907        \n",
      "[16]\ttraining's multi_logloss: 0.797382\tvalid_1's multi_logloss: 0.81406         \n",
      "[17]\ttraining's multi_logloss: 0.766311\tvalid_1's multi_logloss: 0.784061        \n",
      "[18]\ttraining's multi_logloss: 0.737626\tvalid_1's multi_logloss: 0.756459        \n",
      "[19]\ttraining's multi_logloss: 0.710535\tvalid_1's multi_logloss: 0.730437        \n",
      "[20]\ttraining's multi_logloss: 0.685414\tvalid_1's multi_logloss: 0.706398        \n",
      "[21]\ttraining's multi_logloss: 0.661625\tvalid_1's multi_logloss: 0.683663        \n",
      "[22]\ttraining's multi_logloss: 0.639128\tvalid_1's multi_logloss: 0.662016        \n",
      "[23]\ttraining's multi_logloss: 0.617983\tvalid_1's multi_logloss: 0.641695        \n",
      "[24]\ttraining's multi_logloss: 0.598052\tvalid_1's multi_logloss: 0.622731        \n",
      "[25]\ttraining's multi_logloss: 0.579533\tvalid_1's multi_logloss: 0.605229        \n",
      "[26]\ttraining's multi_logloss: 0.561561\tvalid_1's multi_logloss: 0.587956        \n",
      "[27]\ttraining's multi_logloss: 0.545081\tvalid_1's multi_logloss: 0.572446        \n",
      "[28]\ttraining's multi_logloss: 0.529138\tvalid_1's multi_logloss: 0.557477        \n",
      "[29]\ttraining's multi_logloss: 0.514388\tvalid_1's multi_logloss: 0.543678        \n",
      "[30]\ttraining's multi_logloss: 0.500252\tvalid_1's multi_logloss: 0.53029         \n",
      "[31]\ttraining's multi_logloss: 0.486891\tvalid_1's multi_logloss: 0.517874        \n",
      "[32]\ttraining's multi_logloss: 0.474404\tvalid_1's multi_logloss: 0.506415        \n",
      "[33]\ttraining's multi_logloss: 0.462015\tvalid_1's multi_logloss: 0.495035        \n",
      "[34]\ttraining's multi_logloss: 0.450347\tvalid_1's multi_logloss: 0.484468        \n",
      "[35]\ttraining's multi_logloss: 0.439442\tvalid_1's multi_logloss: 0.474585        \n",
      "[36]\ttraining's multi_logloss: 0.428872\tvalid_1's multi_logloss: 0.465035        \n",
      "[37]\ttraining's multi_logloss: 0.419039\tvalid_1's multi_logloss: 0.456301        \n",
      "[38]\ttraining's multi_logloss: 0.409588\tvalid_1's multi_logloss: 0.44799         \n",
      "[39]\ttraining's multi_logloss: 0.400656\tvalid_1's multi_logloss: 0.440017        \n",
      "[40]\ttraining's multi_logloss: 0.392149\tvalid_1's multi_logloss: 0.432517        \n",
      "[41]\ttraining's multi_logloss: 0.383873\tvalid_1's multi_logloss: 0.425212        \n",
      "[42]\ttraining's multi_logloss: 0.376202\tvalid_1's multi_logloss: 0.418636        \n",
      "[43]\ttraining's multi_logloss: 0.368919\tvalid_1's multi_logloss: 0.412381        \n",
      "[44]\ttraining's multi_logloss: 0.361753\tvalid_1's multi_logloss: 0.406269        \n",
      "[45]\ttraining's multi_logloss: 0.354751\tvalid_1's multi_logloss: 0.400359        \n",
      "[46]\ttraining's multi_logloss: 0.348227\tvalid_1's multi_logloss: 0.394995        \n",
      "[47]\ttraining's multi_logloss: 0.341852\tvalid_1's multi_logloss: 0.389657        \n",
      "[48]\ttraining's multi_logloss: 0.335659\tvalid_1's multi_logloss: 0.384418        \n",
      "[49]\ttraining's multi_logloss: 0.329977\tvalid_1's multi_logloss: 0.379712        \n",
      "[50]\ttraining's multi_logloss: 0.324411\tvalid_1's multi_logloss: 0.375054        \n",
      "[51]\ttraining's multi_logloss: 0.318928\tvalid_1's multi_logloss: 0.370741        \n",
      "[52]\ttraining's multi_logloss: 0.313737\tvalid_1's multi_logloss: 0.366754        \n",
      "[53]\ttraining's multi_logloss: 0.308652\tvalid_1's multi_logloss: 0.362713        \n",
      "[54]\ttraining's multi_logloss: 0.303649\tvalid_1's multi_logloss: 0.35885         \n",
      "[55]\ttraining's multi_logloss: 0.29887\tvalid_1's multi_logloss: 0.355083         \n",
      "[56]\ttraining's multi_logloss: 0.29433\tvalid_1's multi_logloss: 0.351671         \n",
      "[57]\ttraining's multi_logloss: 0.289824\tvalid_1's multi_logloss: 0.348185        \n",
      "[58]\ttraining's multi_logloss: 0.285546\tvalid_1's multi_logloss: 0.345205        \n",
      "[59]\ttraining's multi_logloss: 0.281321\tvalid_1's multi_logloss: 0.342112        \n",
      "[60]\ttraining's multi_logloss: 0.277321\tvalid_1's multi_logloss: 0.33927         \n",
      "[61]\ttraining's multi_logloss: 0.273295\tvalid_1's multi_logloss: 0.336401        \n",
      "[62]\ttraining's multi_logloss: 0.269414\tvalid_1's multi_logloss: 0.333597        \n",
      "[63]\ttraining's multi_logloss: 0.265825\tvalid_1's multi_logloss: 0.331165        \n",
      "[64]\ttraining's multi_logloss: 0.26215\tvalid_1's multi_logloss: 0.328734         \n",
      "[65]\ttraining's multi_logloss: 0.258747\tvalid_1's multi_logloss: 0.326543        \n",
      "[66]\ttraining's multi_logloss: 0.255363\tvalid_1's multi_logloss: 0.324425        \n",
      "[67]\ttraining's multi_logloss: 0.252211\tvalid_1's multi_logloss: 0.322475        \n",
      "[68]\ttraining's multi_logloss: 0.248994\tvalid_1's multi_logloss: 0.320499        \n",
      "[69]\ttraining's multi_logloss: 0.245898\tvalid_1's multi_logloss: 0.318724        \n",
      "[70]\ttraining's multi_logloss: 0.242854\tvalid_1's multi_logloss: 0.316975        \n",
      "[71]\ttraining's multi_logloss: 0.239894\tvalid_1's multi_logloss: 0.315334        \n",
      "[72]\ttraining's multi_logloss: 0.237057\tvalid_1's multi_logloss: 0.313912        \n",
      "[73]\ttraining's multi_logloss: 0.234275\tvalid_1's multi_logloss: 0.312576        \n",
      "[74]\ttraining's multi_logloss: 0.231516\tvalid_1's multi_logloss: 0.311103        \n",
      "[75]\ttraining's multi_logloss: 0.228706\tvalid_1's multi_logloss: 0.309862        \n",
      "[76]\ttraining's multi_logloss: 0.226014\tvalid_1's multi_logloss: 0.308619        \n",
      "[77]\ttraining's multi_logloss: 0.223511\tvalid_1's multi_logloss: 0.30736         \n",
      "[78]\ttraining's multi_logloss: 0.221041\tvalid_1's multi_logloss: 0.306138        \n",
      "[79]\ttraining's multi_logloss: 0.218557\tvalid_1's multi_logloss: 0.304972        \n",
      "[80]\ttraining's multi_logloss: 0.216266\tvalid_1's multi_logloss: 0.304003        \n",
      "[81]\ttraining's multi_logloss: 0.213983\tvalid_1's multi_logloss: 0.302918        \n",
      "[82]\ttraining's multi_logloss: 0.211665\tvalid_1's multi_logloss: 0.302014        \n",
      "[83]\ttraining's multi_logloss: 0.209436\tvalid_1's multi_logloss: 0.301121        \n",
      "[84]\ttraining's multi_logloss: 0.207209\tvalid_1's multi_logloss: 0.300215        \n",
      "[85]\ttraining's multi_logloss: 0.205074\tvalid_1's multi_logloss: 0.299484        \n",
      "[86]\ttraining's multi_logloss: 0.203009\tvalid_1's multi_logloss: 0.298732        \n",
      "[87]\ttraining's multi_logloss: 0.200915\tvalid_1's multi_logloss: 0.298111        \n",
      "[88]\ttraining's multi_logloss: 0.198897\tvalid_1's multi_logloss: 0.297396        \n",
      "[89]\ttraining's multi_logloss: 0.196822\tvalid_1's multi_logloss: 0.296717        \n",
      "[90]\ttraining's multi_logloss: 0.194851\tvalid_1's multi_logloss: 0.29596         \n",
      "[91]\ttraining's multi_logloss: 0.192889\tvalid_1's multi_logloss: 0.29544         \n",
      "[92]\ttraining's multi_logloss: 0.190946\tvalid_1's multi_logloss: 0.294832        \n",
      "[93]\ttraining's multi_logloss: 0.189043\tvalid_1's multi_logloss: 0.294074        \n",
      "[94]\ttraining's multi_logloss: 0.187228\tvalid_1's multi_logloss: 0.293224        \n",
      "[95]\ttraining's multi_logloss: 0.185382\tvalid_1's multi_logloss: 0.292804        \n",
      "[96]\ttraining's multi_logloss: 0.18341\tvalid_1's multi_logloss: 0.292201         \n",
      "[97]\ttraining's multi_logloss: 0.181626\tvalid_1's multi_logloss: 0.291582        \n",
      "[98]\ttraining's multi_logloss: 0.179886\tvalid_1's multi_logloss: 0.291217        \n",
      "[99]\ttraining's multi_logloss: 0.178162\tvalid_1's multi_logloss: 0.290941        \n",
      "[100]\ttraining's multi_logloss: 0.17647\tvalid_1's multi_logloss: 0.290606        \n",
      "[101]\ttraining's multi_logloss: 0.174728\tvalid_1's multi_logloss: 0.290045       \n",
      "[102]\ttraining's multi_logloss: 0.173094\tvalid_1's multi_logloss: 0.289675       \n",
      "[103]\ttraining's multi_logloss: 0.171445\tvalid_1's multi_logloss: 0.289223       \n",
      "[104]\ttraining's multi_logloss: 0.169861\tvalid_1's multi_logloss: 0.288759       \n",
      "[105]\ttraining's multi_logloss: 0.168277\tvalid_1's multi_logloss: 0.288382       \n",
      "[106]\ttraining's multi_logloss: 0.1667\tvalid_1's multi_logloss: 0.288121         \n",
      "[107]\ttraining's multi_logloss: 0.165083\tvalid_1's multi_logloss: 0.28785        \n",
      "[108]\ttraining's multi_logloss: 0.163464\tvalid_1's multi_logloss: 0.287525       \n",
      "[109]\ttraining's multi_logloss: 0.161982\tvalid_1's multi_logloss: 0.287357       \n",
      "[110]\ttraining's multi_logloss: 0.160442\tvalid_1's multi_logloss: 0.287041       \n",
      "[111]\ttraining's multi_logloss: 0.158847\tvalid_1's multi_logloss: 0.286595       \n",
      "[112]\ttraining's multi_logloss: 0.157338\tvalid_1's multi_logloss: 0.286334       \n",
      "[113]\ttraining's multi_logloss: 0.155722\tvalid_1's multi_logloss: 0.286203       \n",
      "[114]\ttraining's multi_logloss: 0.154203\tvalid_1's multi_logloss: 0.285924       \n",
      "[115]\ttraining's multi_logloss: 0.15274\tvalid_1's multi_logloss: 0.285853        \n",
      "[116]\ttraining's multi_logloss: 0.151331\tvalid_1's multi_logloss: 0.285695       \n",
      "[117]\ttraining's multi_logloss: 0.149826\tvalid_1's multi_logloss: 0.285496       \n",
      "[118]\ttraining's multi_logloss: 0.148372\tvalid_1's multi_logloss: 0.285357       \n",
      "[119]\ttraining's multi_logloss: 0.147002\tvalid_1's multi_logloss: 0.285148       \n",
      "[120]\ttraining's multi_logloss: 0.145711\tvalid_1's multi_logloss: 0.28492        \n",
      "[121]\ttraining's multi_logloss: 0.144394\tvalid_1's multi_logloss: 0.284741       \n",
      "[122]\ttraining's multi_logloss: 0.143035\tvalid_1's multi_logloss: 0.284505       \n",
      "[123]\ttraining's multi_logloss: 0.14169\tvalid_1's multi_logloss: 0.284311        \n",
      "[124]\ttraining's multi_logloss: 0.140386\tvalid_1's multi_logloss: 0.28414        \n",
      "[125]\ttraining's multi_logloss: 0.139077\tvalid_1's multi_logloss: 0.284093       \n",
      "[126]\ttraining's multi_logloss: 0.13788\tvalid_1's multi_logloss: 0.284051        \n",
      "[127]\ttraining's multi_logloss: 0.136603\tvalid_1's multi_logloss: 0.284021       \n",
      "[128]\ttraining's multi_logloss: 0.135372\tvalid_1's multi_logloss: 0.283726       \n",
      "[129]\ttraining's multi_logloss: 0.134166\tvalid_1's multi_logloss: 0.283704       \n",
      "[130]\ttraining's multi_logloss: 0.132975\tvalid_1's multi_logloss: 0.28366        \n",
      "[131]\ttraining's multi_logloss: 0.131803\tvalid_1's multi_logloss: 0.283631       \n",
      "[132]\ttraining's multi_logloss: 0.130715\tvalid_1's multi_logloss: 0.283443       \n",
      "[133]\ttraining's multi_logloss: 0.129622\tvalid_1's multi_logloss: 0.283357       \n",
      "[134]\ttraining's multi_logloss: 0.128511\tvalid_1's multi_logloss: 0.28323        \n",
      "[135]\ttraining's multi_logloss: 0.12739\tvalid_1's multi_logloss: 0.283124        \n",
      "[136]\ttraining's multi_logloss: 0.126184\tvalid_1's multi_logloss: 0.283068       \n",
      "[137]\ttraining's multi_logloss: 0.125066\tvalid_1's multi_logloss: 0.283104       \n",
      "[138]\ttraining's multi_logloss: 0.124016\tvalid_1's multi_logloss: 0.282931       \n",
      "[139]\ttraining's multi_logloss: 0.122958\tvalid_1's multi_logloss: 0.282861       \n",
      "[140]\ttraining's multi_logloss: 0.121917\tvalid_1's multi_logloss: 0.28281        \n",
      "[141]\ttraining's multi_logloss: 0.1207\tvalid_1's multi_logloss: 0.282758         \n",
      "[142]\ttraining's multi_logloss: 0.119594\tvalid_1's multi_logloss: 0.282635       \n",
      "[143]\ttraining's multi_logloss: 0.118543\tvalid_1's multi_logloss: 0.282522       \n",
      "[144]\ttraining's multi_logloss: 0.117396\tvalid_1's multi_logloss: 0.282601       \n",
      "[145]\ttraining's multi_logloss: 0.116275\tvalid_1's multi_logloss: 0.282807       \n",
      "[146]\ttraining's multi_logloss: 0.115227\tvalid_1's multi_logloss: 0.282935       \n",
      "[147]\ttraining's multi_logloss: 0.114178\tvalid_1's multi_logloss: 0.282858       \n",
      "[148]\ttraining's multi_logloss: 0.113106\tvalid_1's multi_logloss: 0.282966       \n",
      "[149]\ttraining's multi_logloss: 0.111964\tvalid_1's multi_logloss: 0.282893       \n",
      "[150]\ttraining's multi_logloss: 0.110892\tvalid_1's multi_logloss: 0.283009       \n",
      "[151]\ttraining's multi_logloss: 0.109789\tvalid_1's multi_logloss: 0.283045       \n",
      "[152]\ttraining's multi_logloss: 0.108767\tvalid_1's multi_logloss: 0.282954       \n",
      "[153]\ttraining's multi_logloss: 0.107704\tvalid_1's multi_logloss: 0.282938       \n",
      "[154]\ttraining's multi_logloss: 0.106746\tvalid_1's multi_logloss: 0.283061       \n",
      "[155]\ttraining's multi_logloss: 0.105704\tvalid_1's multi_logloss: 0.283204       \n",
      "[156]\ttraining's multi_logloss: 0.104761\tvalid_1's multi_logloss: 0.283409       \n",
      "[157]\ttraining's multi_logloss: 0.103766\tvalid_1's multi_logloss: 0.283358       \n",
      "[158]\ttraining's multi_logloss: 0.102844\tvalid_1's multi_logloss: 0.283434       \n",
      "[159]\ttraining's multi_logloss: 0.101916\tvalid_1's multi_logloss: 0.283514       \n",
      "[160]\ttraining's multi_logloss: 0.100901\tvalid_1's multi_logloss: 0.283543       \n",
      "[161]\ttraining's multi_logloss: 0.100029\tvalid_1's multi_logloss: 0.283587       \n",
      "[162]\ttraining's multi_logloss: 0.0990441\tvalid_1's multi_logloss: 0.283584      \n",
      "[163]\ttraining's multi_logloss: 0.0981948\tvalid_1's multi_logloss: 0.283869      \n",
      "[164]\ttraining's multi_logloss: 0.0972535\tvalid_1's multi_logloss: 0.284007      \n",
      "[165]\ttraining's multi_logloss: 0.0963949\tvalid_1's multi_logloss: 0.284351      \n",
      "[166]\ttraining's multi_logloss: 0.0955522\tvalid_1's multi_logloss: 0.284523      \n",
      "[167]\ttraining's multi_logloss: 0.0946881\tvalid_1's multi_logloss: 0.284728      \n",
      "[168]\ttraining's multi_logloss: 0.0938403\tvalid_1's multi_logloss: 0.284949      \n",
      "[169]\ttraining's multi_logloss: 0.093002\tvalid_1's multi_logloss: 0.285221       \n",
      "[170]\ttraining's multi_logloss: 0.0921426\tvalid_1's multi_logloss: 0.285373      \n",
      "[171]\ttraining's multi_logloss: 0.0913519\tvalid_1's multi_logloss: 0.285531      \n",
      "[172]\ttraining's multi_logloss: 0.090529\tvalid_1's multi_logloss: 0.285719       \n",
      "[173]\ttraining's multi_logloss: 0.0897794\tvalid_1's multi_logloss: 0.28588       \n",
      "Early stopping, best iteration is:                                               \n",
      "[143]\ttraining's multi_logloss: 0.118543\tvalid_1's multi_logloss: 0.282522\n",
      "[1]\ttraining's multi_logloss: 1.77204\tvalid_1's multi_logloss: 1.77494           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.64201\tvalid_1's multi_logloss: 1.64616           \n",
      "[3]\ttraining's multi_logloss: 1.53123\tvalid_1's multi_logloss: 1.53629           \n",
      "[4]\ttraining's multi_logloss: 1.43481\tvalid_1's multi_logloss: 1.44061           \n",
      "[5]\ttraining's multi_logloss: 1.34914\tvalid_1's multi_logloss: 1.35553           \n",
      "[6]\ttraining's multi_logloss: 1.27315\tvalid_1's multi_logloss: 1.28036           \n",
      "[7]\ttraining's multi_logloss: 1.20519\tvalid_1's multi_logloss: 1.21295           \n",
      "[8]\ttraining's multi_logloss: 1.14348\tvalid_1's multi_logloss: 1.15197           \n",
      "[9]\ttraining's multi_logloss: 1.08721\tvalid_1's multi_logloss: 1.09653           \n",
      "[10]\ttraining's multi_logloss: 1.03538\tvalid_1's multi_logloss: 1.04519          \n",
      "[11]\ttraining's multi_logloss: 0.98783\tvalid_1's multi_logloss: 0.99801          \n",
      "[12]\ttraining's multi_logloss: 0.94403\tvalid_1's multi_logloss: 0.954634         \n",
      "[13]\ttraining's multi_logloss: 0.903267\tvalid_1's multi_logloss: 0.914548        \n",
      "[14]\ttraining's multi_logloss: 0.865711\tvalid_1's multi_logloss: 0.877542        \n",
      "[15]\ttraining's multi_logloss: 0.830242\tvalid_1's multi_logloss: 0.842619        \n",
      "[16]\ttraining's multi_logloss: 0.797323\tvalid_1's multi_logloss: 0.810319        \n",
      "[17]\ttraining's multi_logloss: 0.766917\tvalid_1's multi_logloss: 0.78058         \n",
      "[18]\ttraining's multi_logloss: 0.73832\tvalid_1's multi_logloss: 0.752743         \n",
      "[19]\ttraining's multi_logloss: 0.711638\tvalid_1's multi_logloss: 0.726733        \n",
      "[20]\ttraining's multi_logloss: 0.686516\tvalid_1's multi_logloss: 0.702422        \n",
      "[21]\ttraining's multi_logloss: 0.662465\tvalid_1's multi_logloss: 0.67881         \n",
      "[22]\ttraining's multi_logloss: 0.640403\tvalid_1's multi_logloss: 0.657521        \n",
      "[23]\ttraining's multi_logloss: 0.619363\tvalid_1's multi_logloss: 0.637425        \n",
      "[24]\ttraining's multi_logloss: 0.599663\tvalid_1's multi_logloss: 0.618499        \n",
      "[25]\ttraining's multi_logloss: 0.581164\tvalid_1's multi_logloss: 0.600754        \n",
      "[26]\ttraining's multi_logloss: 0.563325\tvalid_1's multi_logloss: 0.583614        \n",
      "[27]\ttraining's multi_logloss: 0.546881\tvalid_1's multi_logloss: 0.568053        \n",
      "[28]\ttraining's multi_logloss: 0.531269\tvalid_1's multi_logloss: 0.553342        \n",
      "[29]\ttraining's multi_logloss: 0.516531\tvalid_1's multi_logloss: 0.539477        \n",
      "[30]\ttraining's multi_logloss: 0.502465\tvalid_1's multi_logloss: 0.526122        \n",
      "[31]\ttraining's multi_logloss: 0.489208\tvalid_1's multi_logloss: 0.51367         \n",
      "[32]\ttraining's multi_logloss: 0.476592\tvalid_1's multi_logloss: 0.501844        \n",
      "[33]\ttraining's multi_logloss: 0.464697\tvalid_1's multi_logloss: 0.490574        \n",
      "[34]\ttraining's multi_logloss: 0.453444\tvalid_1's multi_logloss: 0.480115        \n",
      "[35]\ttraining's multi_logloss: 0.442716\tvalid_1's multi_logloss: 0.470301        \n",
      "[36]\ttraining's multi_logloss: 0.432383\tvalid_1's multi_logloss: 0.460736        \n",
      "[37]\ttraining's multi_logloss: 0.422505\tvalid_1's multi_logloss: 0.451551        \n",
      "[38]\ttraining's multi_logloss: 0.413185\tvalid_1's multi_logloss: 0.442922        \n",
      "[39]\ttraining's multi_logloss: 0.404225\tvalid_1's multi_logloss: 0.434663        \n",
      "[40]\ttraining's multi_logloss: 0.395731\tvalid_1's multi_logloss: 0.426877        \n",
      "[41]\ttraining's multi_logloss: 0.387363\tvalid_1's multi_logloss: 0.419309        \n",
      "[42]\ttraining's multi_logloss: 0.379511\tvalid_1's multi_logloss: 0.412174        \n",
      "[43]\ttraining's multi_logloss: 0.372222\tvalid_1's multi_logloss: 0.405656        \n",
      "[44]\ttraining's multi_logloss: 0.365062\tvalid_1's multi_logloss: 0.399391        \n",
      "[45]\ttraining's multi_logloss: 0.358267\tvalid_1's multi_logloss: 0.393451        \n",
      "[46]\ttraining's multi_logloss: 0.351598\tvalid_1's multi_logloss: 0.387468        \n",
      "[47]\ttraining's multi_logloss: 0.345499\tvalid_1's multi_logloss: 0.382163        \n",
      "[48]\ttraining's multi_logloss: 0.339343\tvalid_1's multi_logloss: 0.376806        \n",
      "[49]\ttraining's multi_logloss: 0.333526\tvalid_1's multi_logloss: 0.371887        \n",
      "[50]\ttraining's multi_logloss: 0.32788\tvalid_1's multi_logloss: 0.367154         \n",
      "[51]\ttraining's multi_logloss: 0.322467\tvalid_1's multi_logloss: 0.362615        \n",
      "[52]\ttraining's multi_logloss: 0.317285\tvalid_1's multi_logloss: 0.35843         \n",
      "[53]\ttraining's multi_logloss: 0.312273\tvalid_1's multi_logloss: 0.354314        \n",
      "[54]\ttraining's multi_logloss: 0.30753\tvalid_1's multi_logloss: 0.35049          \n",
      "[55]\ttraining's multi_logloss: 0.302772\tvalid_1's multi_logloss: 0.346662        \n",
      "[56]\ttraining's multi_logloss: 0.298367\tvalid_1's multi_logloss: 0.343361        \n",
      "[57]\ttraining's multi_logloss: 0.294026\tvalid_1's multi_logloss: 0.339959        \n",
      "[58]\ttraining's multi_logloss: 0.289809\tvalid_1's multi_logloss: 0.336903        \n",
      "[59]\ttraining's multi_logloss: 0.285782\tvalid_1's multi_logloss: 0.333839        \n",
      "[60]\ttraining's multi_logloss: 0.281893\tvalid_1's multi_logloss: 0.330807        \n",
      "[61]\ttraining's multi_logloss: 0.27814\tvalid_1's multi_logloss: 0.328001         \n",
      "[62]\ttraining's multi_logloss: 0.274387\tvalid_1's multi_logloss: 0.325404        \n",
      "[63]\ttraining's multi_logloss: 0.270723\tvalid_1's multi_logloss: 0.322691        \n",
      "[64]\ttraining's multi_logloss: 0.267307\tvalid_1's multi_logloss: 0.320423        \n",
      "[65]\ttraining's multi_logloss: 0.263933\tvalid_1's multi_logloss: 0.317979        \n",
      "[66]\ttraining's multi_logloss: 0.260603\tvalid_1's multi_logloss: 0.315915        \n",
      "[67]\ttraining's multi_logloss: 0.257342\tvalid_1's multi_logloss: 0.314002        \n",
      "[68]\ttraining's multi_logloss: 0.254283\tvalid_1's multi_logloss: 0.312176        \n",
      "[69]\ttraining's multi_logloss: 0.25123\tvalid_1's multi_logloss: 0.310355         \n",
      "[70]\ttraining's multi_logloss: 0.248096\tvalid_1's multi_logloss: 0.308528        \n",
      "[71]\ttraining's multi_logloss: 0.245149\tvalid_1's multi_logloss: 0.306974        \n",
      "[72]\ttraining's multi_logloss: 0.242193\tvalid_1's multi_logloss: 0.305363        \n",
      "[73]\ttraining's multi_logloss: 0.23942\tvalid_1's multi_logloss: 0.303826         \n",
      "[74]\ttraining's multi_logloss: 0.236739\tvalid_1's multi_logloss: 0.302315        \n",
      "[75]\ttraining's multi_logloss: 0.234122\tvalid_1's multi_logloss: 0.300819        \n",
      "[76]\ttraining's multi_logloss: 0.231395\tvalid_1's multi_logloss: 0.29948         \n",
      "[77]\ttraining's multi_logloss: 0.228794\tvalid_1's multi_logloss: 0.297927        \n",
      "[78]\ttraining's multi_logloss: 0.226301\tvalid_1's multi_logloss: 0.296555        \n",
      "[79]\ttraining's multi_logloss: 0.223953\tvalid_1's multi_logloss: 0.295519        \n",
      "[80]\ttraining's multi_logloss: 0.221621\tvalid_1's multi_logloss: 0.294263        \n",
      "[81]\ttraining's multi_logloss: 0.219458\tvalid_1's multi_logloss: 0.293344        \n",
      "[82]\ttraining's multi_logloss: 0.217186\tvalid_1's multi_logloss: 0.292177        \n",
      "[83]\ttraining's multi_logloss: 0.215011\tvalid_1's multi_logloss: 0.291069        \n",
      "[84]\ttraining's multi_logloss: 0.212782\tvalid_1's multi_logloss: 0.290044        \n",
      "[85]\ttraining's multi_logloss: 0.210619\tvalid_1's multi_logloss: 0.288948        \n",
      "[86]\ttraining's multi_logloss: 0.208547\tvalid_1's multi_logloss: 0.287983        \n",
      "[87]\ttraining's multi_logloss: 0.206433\tvalid_1's multi_logloss: 0.286981        \n",
      "[88]\ttraining's multi_logloss: 0.204467\tvalid_1's multi_logloss: 0.286152        \n",
      "[89]\ttraining's multi_logloss: 0.202463\tvalid_1's multi_logloss: 0.285201        \n",
      "[90]\ttraining's multi_logloss: 0.200508\tvalid_1's multi_logloss: 0.284518        \n",
      "[91]\ttraining's multi_logloss: 0.198538\tvalid_1's multi_logloss: 0.283591        \n",
      "[92]\ttraining's multi_logloss: 0.196613\tvalid_1's multi_logloss: 0.282925        \n",
      "[93]\ttraining's multi_logloss: 0.194757\tvalid_1's multi_logloss: 0.282291        \n",
      "[94]\ttraining's multi_logloss: 0.192858\tvalid_1's multi_logloss: 0.281738        \n",
      "[95]\ttraining's multi_logloss: 0.190952\tvalid_1's multi_logloss: 0.281203        \n",
      "[96]\ttraining's multi_logloss: 0.1892\tvalid_1's multi_logloss: 0.280679          \n",
      "[97]\ttraining's multi_logloss: 0.187404\tvalid_1's multi_logloss: 0.280179        \n",
      "[98]\ttraining's multi_logloss: 0.185634\tvalid_1's multi_logloss: 0.279798        \n",
      "[99]\ttraining's multi_logloss: 0.183888\tvalid_1's multi_logloss: 0.279248        \n",
      "[100]\ttraining's multi_logloss: 0.182112\tvalid_1's multi_logloss: 0.278811       \n",
      "[101]\ttraining's multi_logloss: 0.180409\tvalid_1's multi_logloss: 0.278323       \n",
      "[102]\ttraining's multi_logloss: 0.178715\tvalid_1's multi_logloss: 0.277836       \n",
      "[103]\ttraining's multi_logloss: 0.177042\tvalid_1's multi_logloss: 0.277532       \n",
      "[104]\ttraining's multi_logloss: 0.175415\tvalid_1's multi_logloss: 0.277239       \n",
      "[105]\ttraining's multi_logloss: 0.173779\tvalid_1's multi_logloss: 0.276899       \n",
      "[106]\ttraining's multi_logloss: 0.172145\tvalid_1's multi_logloss: 0.276462       \n",
      "[107]\ttraining's multi_logloss: 0.170597\tvalid_1's multi_logloss: 0.276058       \n",
      "[108]\ttraining's multi_logloss: 0.169028\tvalid_1's multi_logloss: 0.275658       \n",
      "[109]\ttraining's multi_logloss: 0.167456\tvalid_1's multi_logloss: 0.275426       \n",
      "[110]\ttraining's multi_logloss: 0.166082\tvalid_1's multi_logloss: 0.275105       \n",
      "[111]\ttraining's multi_logloss: 0.164614\tvalid_1's multi_logloss: 0.274793       \n",
      "[112]\ttraining's multi_logloss: 0.163121\tvalid_1's multi_logloss: 0.274691       \n",
      "[113]\ttraining's multi_logloss: 0.161599\tvalid_1's multi_logloss: 0.274397       \n",
      "[114]\ttraining's multi_logloss: 0.160178\tvalid_1's multi_logloss: 0.274145       \n",
      "[115]\ttraining's multi_logloss: 0.158645\tvalid_1's multi_logloss: 0.273839       \n",
      "[116]\ttraining's multi_logloss: 0.157267\tvalid_1's multi_logloss: 0.273642       \n",
      "[117]\ttraining's multi_logloss: 0.155824\tvalid_1's multi_logloss: 0.273255       \n",
      "[118]\ttraining's multi_logloss: 0.154349\tvalid_1's multi_logloss: 0.272892       \n",
      "[119]\ttraining's multi_logloss: 0.152915\tvalid_1's multi_logloss: 0.27233        \n",
      "[120]\ttraining's multi_logloss: 0.151577\tvalid_1's multi_logloss: 0.271979       \n",
      "[121]\ttraining's multi_logloss: 0.150208\tvalid_1's multi_logloss: 0.271583       \n",
      "[122]\ttraining's multi_logloss: 0.148865\tvalid_1's multi_logloss: 0.271177       \n",
      "[123]\ttraining's multi_logloss: 0.147538\tvalid_1's multi_logloss: 0.271035       \n",
      "[124]\ttraining's multi_logloss: 0.146204\tvalid_1's multi_logloss: 0.271042       \n",
      "[125]\ttraining's multi_logloss: 0.1448\tvalid_1's multi_logloss: 0.270824         \n",
      "[126]\ttraining's multi_logloss: 0.143473\tvalid_1's multi_logloss: 0.270734       \n",
      "[127]\ttraining's multi_logloss: 0.142199\tvalid_1's multi_logloss: 0.270583       \n",
      "[128]\ttraining's multi_logloss: 0.14092\tvalid_1's multi_logloss: 0.270353        \n",
      "[129]\ttraining's multi_logloss: 0.139642\tvalid_1's multi_logloss: 0.27017        \n",
      "[130]\ttraining's multi_logloss: 0.138376\tvalid_1's multi_logloss: 0.269903       \n",
      "[131]\ttraining's multi_logloss: 0.137118\tvalid_1's multi_logloss: 0.269882       \n",
      "[132]\ttraining's multi_logloss: 0.135919\tvalid_1's multi_logloss: 0.269612       \n",
      "[133]\ttraining's multi_logloss: 0.134728\tvalid_1's multi_logloss: 0.269528       \n",
      "[134]\ttraining's multi_logloss: 0.133442\tvalid_1's multi_logloss: 0.269348       \n",
      "[135]\ttraining's multi_logloss: 0.132193\tvalid_1's multi_logloss: 0.269335       \n",
      "[136]\ttraining's multi_logloss: 0.131026\tvalid_1's multi_logloss: 0.269255       \n",
      "[137]\ttraining's multi_logloss: 0.129787\tvalid_1's multi_logloss: 0.269004       \n",
      "[138]\ttraining's multi_logloss: 0.128632\tvalid_1's multi_logloss: 0.268978       \n",
      "[139]\ttraining's multi_logloss: 0.127582\tvalid_1's multi_logloss: 0.268876       \n",
      "[140]\ttraining's multi_logloss: 0.126476\tvalid_1's multi_logloss: 0.26873        \n",
      "[141]\ttraining's multi_logloss: 0.12537\tvalid_1's multi_logloss: 0.268672        \n",
      "[142]\ttraining's multi_logloss: 0.124188\tvalid_1's multi_logloss: 0.268544       \n",
      "[143]\ttraining's multi_logloss: 0.123196\tvalid_1's multi_logloss: 0.268595       \n",
      "[144]\ttraining's multi_logloss: 0.122089\tvalid_1's multi_logloss: 0.268506       \n",
      "[145]\ttraining's multi_logloss: 0.121103\tvalid_1's multi_logloss: 0.268385       \n",
      "[146]\ttraining's multi_logloss: 0.120097\tvalid_1's multi_logloss: 0.268458       \n",
      "[147]\ttraining's multi_logloss: 0.118978\tvalid_1's multi_logloss: 0.26852        \n",
      "[148]\ttraining's multi_logloss: 0.117956\tvalid_1's multi_logloss: 0.268549       \n",
      "[149]\ttraining's multi_logloss: 0.117025\tvalid_1's multi_logloss: 0.268597       \n",
      "[150]\ttraining's multi_logloss: 0.116058\tvalid_1's multi_logloss: 0.268648       \n",
      "[151]\ttraining's multi_logloss: 0.115209\tvalid_1's multi_logloss: 0.268779       \n",
      "[152]\ttraining's multi_logloss: 0.114189\tvalid_1's multi_logloss: 0.268805       \n",
      "[153]\ttraining's multi_logloss: 0.113246\tvalid_1's multi_logloss: 0.269016       \n",
      "[154]\ttraining's multi_logloss: 0.112355\tvalid_1's multi_logloss: 0.268942       \n",
      "[155]\ttraining's multi_logloss: 0.111457\tvalid_1's multi_logloss: 0.268844       \n",
      "[156]\ttraining's multi_logloss: 0.110488\tvalid_1's multi_logloss: 0.268933       \n",
      "[157]\ttraining's multi_logloss: 0.109589\tvalid_1's multi_logloss: 0.26895        \n",
      "[158]\ttraining's multi_logloss: 0.108664\tvalid_1's multi_logloss: 0.268983       \n",
      "[159]\ttraining's multi_logloss: 0.107808\tvalid_1's multi_logloss: 0.26892        \n",
      "[160]\ttraining's multi_logloss: 0.106921\tvalid_1's multi_logloss: 0.269093       \n",
      "[161]\ttraining's multi_logloss: 0.106063\tvalid_1's multi_logloss: 0.26919        \n",
      "[162]\ttraining's multi_logloss: 0.105176\tvalid_1's multi_logloss: 0.269409       \n",
      "[163]\ttraining's multi_logloss: 0.104334\tvalid_1's multi_logloss: 0.269597       \n",
      "[164]\ttraining's multi_logloss: 0.10346\tvalid_1's multi_logloss: 0.269585        \n",
      "[165]\ttraining's multi_logloss: 0.102483\tvalid_1's multi_logloss: 0.269684       \n",
      "[166]\ttraining's multi_logloss: 0.101659\tvalid_1's multi_logloss: 0.269944       \n",
      "[167]\ttraining's multi_logloss: 0.100736\tvalid_1's multi_logloss: 0.27004        \n",
      "[168]\ttraining's multi_logloss: 0.0998648\tvalid_1's multi_logloss: 0.270134      \n",
      "[169]\ttraining's multi_logloss: 0.099073\tvalid_1's multi_logloss: 0.270271       \n",
      "[170]\ttraining's multi_logloss: 0.0981406\tvalid_1's multi_logloss: 0.270416      \n",
      "[171]\ttraining's multi_logloss: 0.0973156\tvalid_1's multi_logloss: 0.270537      \n",
      "[172]\ttraining's multi_logloss: 0.0964679\tvalid_1's multi_logloss: 0.270671      \n",
      "[173]\ttraining's multi_logloss: 0.0956325\tvalid_1's multi_logloss: 0.270709      \n",
      "[174]\ttraining's multi_logloss: 0.0948373\tvalid_1's multi_logloss: 0.270873      \n",
      "[175]\ttraining's multi_logloss: 0.0940462\tvalid_1's multi_logloss: 0.270981      \n",
      "Early stopping, best iteration is:                                               \n",
      "[145]\ttraining's multi_logloss: 0.121103\tvalid_1's multi_logloss: 0.268385\n",
      "[1]\ttraining's multi_logloss: 1.14914\tvalid_1's multi_logloss: 1.16944           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 0.852715\tvalid_1's multi_logloss: 0.885571         \n",
      "[3]\ttraining's multi_logloss: 0.673565\tvalid_1's multi_logloss: 0.715838         \n",
      "[4]\ttraining's multi_logloss: 0.550732\tvalid_1's multi_logloss: 0.600934         \n",
      "[5]\ttraining's multi_logloss: 0.463877\tvalid_1's multi_logloss: 0.521828         \n",
      "[6]\ttraining's multi_logloss: 0.399339\tvalid_1's multi_logloss: 0.464049         \n",
      "[7]\ttraining's multi_logloss: 0.350426\tvalid_1's multi_logloss: 0.421884         \n",
      "[8]\ttraining's multi_logloss: 0.312396\tvalid_1's multi_logloss: 0.390255         \n",
      "[9]\ttraining's multi_logloss: 0.281735\tvalid_1's multi_logloss: 0.367312         \n",
      "[10]\ttraining's multi_logloss: 0.256776\tvalid_1's multi_logloss: 0.350611        \n",
      "[11]\ttraining's multi_logloss: 0.236153\tvalid_1's multi_logloss: 0.33755         \n",
      "[12]\ttraining's multi_logloss: 0.218338\tvalid_1's multi_logloss: 0.327086        \n",
      "[13]\ttraining's multi_logloss: 0.203039\tvalid_1's multi_logloss: 0.320397        \n",
      "[14]\ttraining's multi_logloss: 0.189353\tvalid_1's multi_logloss: 0.314523        \n",
      "[15]\ttraining's multi_logloss: 0.177443\tvalid_1's multi_logloss: 0.30983         \n",
      "[16]\ttraining's multi_logloss: 0.166159\tvalid_1's multi_logloss: 0.306453        \n",
      "[17]\ttraining's multi_logloss: 0.155893\tvalid_1's multi_logloss: 0.304678        \n",
      "[18]\ttraining's multi_logloss: 0.146676\tvalid_1's multi_logloss: 0.303319        \n",
      "[19]\ttraining's multi_logloss: 0.138435\tvalid_1's multi_logloss: 0.302731        \n",
      "[20]\ttraining's multi_logloss: 0.131275\tvalid_1's multi_logloss: 0.30331         \n",
      "[21]\ttraining's multi_logloss: 0.124006\tvalid_1's multi_logloss: 0.303           \n",
      "[22]\ttraining's multi_logloss: 0.117276\tvalid_1's multi_logloss: 0.301792        \n",
      "[23]\ttraining's multi_logloss: 0.111058\tvalid_1's multi_logloss: 0.301797        \n",
      "[24]\ttraining's multi_logloss: 0.105318\tvalid_1's multi_logloss: 0.301545        \n",
      "[25]\ttraining's multi_logloss: 0.099968\tvalid_1's multi_logloss: 0.302202        \n",
      "[26]\ttraining's multi_logloss: 0.0948528\tvalid_1's multi_logloss: 0.302819       \n",
      "[27]\ttraining's multi_logloss: 0.0898833\tvalid_1's multi_logloss: 0.303568       \n",
      "[28]\ttraining's multi_logloss: 0.0856052\tvalid_1's multi_logloss: 0.303769       \n",
      "[29]\ttraining's multi_logloss: 0.0813726\tvalid_1's multi_logloss: 0.305165       \n",
      "[30]\ttraining's multi_logloss: 0.0772661\tvalid_1's multi_logloss: 0.305721       \n",
      "[31]\ttraining's multi_logloss: 0.073655\tvalid_1's multi_logloss: 0.307205        \n",
      "[32]\ttraining's multi_logloss: 0.0705009\tvalid_1's multi_logloss: 0.308055       \n",
      "[33]\ttraining's multi_logloss: 0.0671357\tvalid_1's multi_logloss: 0.309649       \n",
      "[34]\ttraining's multi_logloss: 0.0642025\tvalid_1's multi_logloss: 0.310374       \n",
      "[35]\ttraining's multi_logloss: 0.0614283\tvalid_1's multi_logloss: 0.311844       \n",
      "[36]\ttraining's multi_logloss: 0.0587422\tvalid_1's multi_logloss: 0.313849       \n",
      "[37]\ttraining's multi_logloss: 0.0564302\tvalid_1's multi_logloss: 0.315294       \n",
      "[38]\ttraining's multi_logloss: 0.0537827\tvalid_1's multi_logloss: 0.316791       \n",
      "[39]\ttraining's multi_logloss: 0.0512946\tvalid_1's multi_logloss: 0.318703       \n",
      "[40]\ttraining's multi_logloss: 0.0487074\tvalid_1's multi_logloss: 0.320031       \n",
      "[41]\ttraining's multi_logloss: 0.0463646\tvalid_1's multi_logloss: 0.321473       \n",
      "[42]\ttraining's multi_logloss: 0.0442844\tvalid_1's multi_logloss: 0.323511       \n",
      "[43]\ttraining's multi_logloss: 0.0423294\tvalid_1's multi_logloss: 0.32455        \n",
      "[44]\ttraining's multi_logloss: 0.0405523\tvalid_1's multi_logloss: 0.32605        \n",
      "[45]\ttraining's multi_logloss: 0.0388907\tvalid_1's multi_logloss: 0.32782        \n",
      "[46]\ttraining's multi_logloss: 0.0373473\tvalid_1's multi_logloss: 0.330051       \n",
      "[47]\ttraining's multi_logloss: 0.0355664\tvalid_1's multi_logloss: 0.331588       \n",
      "[48]\ttraining's multi_logloss: 0.0339407\tvalid_1's multi_logloss: 0.332941       \n",
      "[49]\ttraining's multi_logloss: 0.0325221\tvalid_1's multi_logloss: 0.334633       \n",
      "[50]\ttraining's multi_logloss: 0.0311866\tvalid_1's multi_logloss: 0.33609        \n",
      "[51]\ttraining's multi_logloss: 0.0299497\tvalid_1's multi_logloss: 0.338176       \n",
      "[52]\ttraining's multi_logloss: 0.0286467\tvalid_1's multi_logloss: 0.339665       \n",
      "[53]\ttraining's multi_logloss: 0.0273333\tvalid_1's multi_logloss: 0.341856       \n",
      "[54]\ttraining's multi_logloss: 0.0262401\tvalid_1's multi_logloss: 0.34359        \n",
      "Early stopping, best iteration is:                                               \n",
      "[24]\ttraining's multi_logloss: 0.105318\tvalid_1's multi_logloss: 0.301545\n",
      "[1]\ttraining's multi_logloss: 1.14649\tvalid_1's multi_logloss: 1.15801           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 0.854802\tvalid_1's multi_logloss: 0.87558          \n",
      "[3]\ttraining's multi_logloss: 0.675069\tvalid_1's multi_logloss: 0.703187         \n",
      "[4]\ttraining's multi_logloss: 0.553839\tvalid_1's multi_logloss: 0.588793         \n",
      "[5]\ttraining's multi_logloss: 0.465936\tvalid_1's multi_logloss: 0.508545         \n",
      "[6]\ttraining's multi_logloss: 0.401036\tvalid_1's multi_logloss: 0.451049         \n",
      "[7]\ttraining's multi_logloss: 0.352314\tvalid_1's multi_logloss: 0.41063          \n",
      "[8]\ttraining's multi_logloss: 0.313901\tvalid_1's multi_logloss: 0.3802           \n",
      "[9]\ttraining's multi_logloss: 0.283373\tvalid_1's multi_logloss: 0.357759         \n",
      "[10]\ttraining's multi_logloss: 0.25855\tvalid_1's multi_logloss: 0.340624         \n",
      "[11]\ttraining's multi_logloss: 0.237042\tvalid_1's multi_logloss: 0.32776         \n",
      "[12]\ttraining's multi_logloss: 0.218806\tvalid_1's multi_logloss: 0.318704        \n",
      "[13]\ttraining's multi_logloss: 0.203179\tvalid_1's multi_logloss: 0.312544        \n",
      "[14]\ttraining's multi_logloss: 0.188954\tvalid_1's multi_logloss: 0.30683         \n",
      "[15]\ttraining's multi_logloss: 0.176508\tvalid_1's multi_logloss: 0.302821        \n",
      "[16]\ttraining's multi_logloss: 0.16546\tvalid_1's multi_logloss: 0.300194         \n",
      "[17]\ttraining's multi_logloss: 0.155717\tvalid_1's multi_logloss: 0.297758        \n",
      "[18]\ttraining's multi_logloss: 0.146235\tvalid_1's multi_logloss: 0.295362        \n",
      "[19]\ttraining's multi_logloss: 0.137582\tvalid_1's multi_logloss: 0.294765        \n",
      "[20]\ttraining's multi_logloss: 0.12947\tvalid_1's multi_logloss: 0.294433         \n",
      "[21]\ttraining's multi_logloss: 0.122101\tvalid_1's multi_logloss: 0.294015        \n",
      "[22]\ttraining's multi_logloss: 0.115377\tvalid_1's multi_logloss: 0.292764        \n",
      "[23]\ttraining's multi_logloss: 0.109216\tvalid_1's multi_logloss: 0.291972        \n",
      "[24]\ttraining's multi_logloss: 0.103231\tvalid_1's multi_logloss: 0.292138        \n",
      "[25]\ttraining's multi_logloss: 0.0979748\tvalid_1's multi_logloss: 0.292979       \n",
      "[26]\ttraining's multi_logloss: 0.0929616\tvalid_1's multi_logloss: 0.294174       \n",
      "[27]\ttraining's multi_logloss: 0.0882667\tvalid_1's multi_logloss: 0.294874       \n",
      "[28]\ttraining's multi_logloss: 0.0836849\tvalid_1's multi_logloss: 0.295572       \n",
      "[29]\ttraining's multi_logloss: 0.0792727\tvalid_1's multi_logloss: 0.296534       \n",
      "[30]\ttraining's multi_logloss: 0.0751873\tvalid_1's multi_logloss: 0.297589       \n",
      "[31]\ttraining's multi_logloss: 0.0715766\tvalid_1's multi_logloss: 0.298681       \n",
      "[32]\ttraining's multi_logloss: 0.0681082\tvalid_1's multi_logloss: 0.29949        \n",
      "[33]\ttraining's multi_logloss: 0.0649011\tvalid_1's multi_logloss: 0.300667       \n",
      "[34]\ttraining's multi_logloss: 0.0618565\tvalid_1's multi_logloss: 0.301728       \n",
      "[35]\ttraining's multi_logloss: 0.0589511\tvalid_1's multi_logloss: 0.302586       \n",
      "[36]\ttraining's multi_logloss: 0.0561903\tvalid_1's multi_logloss: 0.303949       \n",
      "[37]\ttraining's multi_logloss: 0.0538093\tvalid_1's multi_logloss: 0.305523       \n",
      "[38]\ttraining's multi_logloss: 0.0514812\tvalid_1's multi_logloss: 0.30716        \n",
      "[39]\ttraining's multi_logloss: 0.0493494\tvalid_1's multi_logloss: 0.308629       \n",
      "[40]\ttraining's multi_logloss: 0.0473026\tvalid_1's multi_logloss: 0.310827       \n",
      "[41]\ttraining's multi_logloss: 0.0450873\tvalid_1's multi_logloss: 0.311917       \n",
      "[42]\ttraining's multi_logloss: 0.0431817\tvalid_1's multi_logloss: 0.313974       \n",
      "[43]\ttraining's multi_logloss: 0.0414824\tvalid_1's multi_logloss: 0.315246       \n",
      "[44]\ttraining's multi_logloss: 0.039479\tvalid_1's multi_logloss: 0.316885        \n",
      "[45]\ttraining's multi_logloss: 0.0377525\tvalid_1's multi_logloss: 0.318267       \n",
      "[46]\ttraining's multi_logloss: 0.0362004\tvalid_1's multi_logloss: 0.320412       \n",
      "[47]\ttraining's multi_logloss: 0.0345379\tvalid_1's multi_logloss: 0.322965       \n",
      "[48]\ttraining's multi_logloss: 0.0329832\tvalid_1's multi_logloss: 0.324464       \n",
      "[49]\ttraining's multi_logloss: 0.0315173\tvalid_1's multi_logloss: 0.326802       \n",
      "[50]\ttraining's multi_logloss: 0.030048\tvalid_1's multi_logloss: 0.328967        \n",
      "[51]\ttraining's multi_logloss: 0.0288135\tvalid_1's multi_logloss: 0.331009       \n",
      "[52]\ttraining's multi_logloss: 0.0275619\tvalid_1's multi_logloss: 0.332995       \n",
      "[53]\ttraining's multi_logloss: 0.0262954\tvalid_1's multi_logloss: 0.335554       \n",
      "Early stopping, best iteration is:                                               \n",
      "[23]\ttraining's multi_logloss: 0.109216\tvalid_1's multi_logloss: 0.291972\n",
      "[1]\ttraining's multi_logloss: 1.14956\tvalid_1's multi_logloss: 1.15949           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 0.857686\tvalid_1's multi_logloss: 0.872269         \n",
      "[3]\ttraining's multi_logloss: 0.679696\tvalid_1's multi_logloss: 0.699703         \n",
      "[4]\ttraining's multi_logloss: 0.558123\tvalid_1's multi_logloss: 0.583362         \n",
      "[5]\ttraining's multi_logloss: 0.471704\tvalid_1's multi_logloss: 0.502334         \n",
      "[6]\ttraining's multi_logloss: 0.408324\tvalid_1's multi_logloss: 0.445292         \n",
      "[7]\ttraining's multi_logloss: 0.360074\tvalid_1's multi_logloss: 0.403271         \n",
      "[8]\ttraining's multi_logloss: 0.321995\tvalid_1's multi_logloss: 0.372421         \n",
      "[9]\ttraining's multi_logloss: 0.290729\tvalid_1's multi_logloss: 0.348674         \n",
      "[10]\ttraining's multi_logloss: 0.264222\tvalid_1's multi_logloss: 0.330354        \n",
      "[11]\ttraining's multi_logloss: 0.242877\tvalid_1's multi_logloss: 0.316646        \n",
      "[12]\ttraining's multi_logloss: 0.22463\tvalid_1's multi_logloss: 0.304924         \n",
      "[13]\ttraining's multi_logloss: 0.208085\tvalid_1's multi_logloss: 0.29782         \n",
      "[14]\ttraining's multi_logloss: 0.194942\tvalid_1's multi_logloss: 0.293091        \n",
      "[15]\ttraining's multi_logloss: 0.182082\tvalid_1's multi_logloss: 0.288629        \n",
      "[16]\ttraining's multi_logloss: 0.171092\tvalid_1's multi_logloss: 0.285745        \n",
      "[17]\ttraining's multi_logloss: 0.16082\tvalid_1's multi_logloss: 0.283706         \n",
      "[18]\ttraining's multi_logloss: 0.151654\tvalid_1's multi_logloss: 0.281789        \n",
      "[19]\ttraining's multi_logloss: 0.142518\tvalid_1's multi_logloss: 0.280646        \n",
      "[20]\ttraining's multi_logloss: 0.134603\tvalid_1's multi_logloss: 0.279548        \n",
      "[21]\ttraining's multi_logloss: 0.126932\tvalid_1's multi_logloss: 0.279393        \n",
      "[22]\ttraining's multi_logloss: 0.119449\tvalid_1's multi_logloss: 0.27889         \n",
      "[23]\ttraining's multi_logloss: 0.112878\tvalid_1's multi_logloss: 0.279502        \n",
      "[24]\ttraining's multi_logloss: 0.10696\tvalid_1's multi_logloss: 0.279126         \n",
      "[25]\ttraining's multi_logloss: 0.100981\tvalid_1's multi_logloss: 0.27911         \n",
      "[26]\ttraining's multi_logloss: 0.0957031\tvalid_1's multi_logloss: 0.280011       \n",
      "[27]\ttraining's multi_logloss: 0.0908733\tvalid_1's multi_logloss: 0.2805         \n",
      "[28]\ttraining's multi_logloss: 0.0862611\tvalid_1's multi_logloss: 0.280508       \n",
      "[29]\ttraining's multi_logloss: 0.082222\tvalid_1's multi_logloss: 0.281928        \n",
      "[30]\ttraining's multi_logloss: 0.078177\tvalid_1's multi_logloss: 0.282519        \n",
      "[31]\ttraining's multi_logloss: 0.074216\tvalid_1's multi_logloss: 0.283411        \n",
      "[32]\ttraining's multi_logloss: 0.0704517\tvalid_1's multi_logloss: 0.284875       \n",
      "[33]\ttraining's multi_logloss: 0.0671718\tvalid_1's multi_logloss: 0.285647       \n",
      "[34]\ttraining's multi_logloss: 0.0639688\tvalid_1's multi_logloss: 0.286668       \n",
      "[35]\ttraining's multi_logloss: 0.0610751\tvalid_1's multi_logloss: 0.288573       \n",
      "[36]\ttraining's multi_logloss: 0.0583603\tvalid_1's multi_logloss: 0.289493       \n",
      "[37]\ttraining's multi_logloss: 0.0558732\tvalid_1's multi_logloss: 0.290442       \n",
      "[38]\ttraining's multi_logloss: 0.0532745\tvalid_1's multi_logloss: 0.291313       \n",
      "[39]\ttraining's multi_logloss: 0.0509912\tvalid_1's multi_logloss: 0.291801       \n",
      "[40]\ttraining's multi_logloss: 0.0488267\tvalid_1's multi_logloss: 0.292592       \n",
      "[41]\ttraining's multi_logloss: 0.0468569\tvalid_1's multi_logloss: 0.294803       \n",
      "[42]\ttraining's multi_logloss: 0.0447797\tvalid_1's multi_logloss: 0.29553        \n",
      "[43]\ttraining's multi_logloss: 0.0428372\tvalid_1's multi_logloss: 0.297293       \n",
      "[44]\ttraining's multi_logloss: 0.0410227\tvalid_1's multi_logloss: 0.299002       \n",
      "[45]\ttraining's multi_logloss: 0.0392155\tvalid_1's multi_logloss: 0.301193       \n",
      "[46]\ttraining's multi_logloss: 0.0374587\tvalid_1's multi_logloss: 0.303712       \n",
      "[47]\ttraining's multi_logloss: 0.0360668\tvalid_1's multi_logloss: 0.304896       \n",
      "[48]\ttraining's multi_logloss: 0.0346206\tvalid_1's multi_logloss: 0.307201       \n",
      "[49]\ttraining's multi_logloss: 0.0332171\tvalid_1's multi_logloss: 0.308782       \n",
      "[50]\ttraining's multi_logloss: 0.0319468\tvalid_1's multi_logloss: 0.310916       \n",
      "[51]\ttraining's multi_logloss: 0.0307425\tvalid_1's multi_logloss: 0.312653       \n",
      "[52]\ttraining's multi_logloss: 0.0293243\tvalid_1's multi_logloss: 0.313981       \n",
      "Early stopping, best iteration is:                                               \n",
      "[22]\ttraining's multi_logloss: 0.119449\tvalid_1's multi_logloss: 0.27889\n",
      "[1]\ttraining's multi_logloss: 1.38129\tvalid_1's multi_logloss: 1.3921            \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.0988\tvalid_1's multi_logloss: 1.11786            \n",
      "[3]\ttraining's multi_logloss: 0.909832\tvalid_1's multi_logloss: 0.93577          \n",
      "[4]\ttraining's multi_logloss: 0.772749\tvalid_1's multi_logloss: 0.804125         \n",
      "[5]\ttraining's multi_logloss: 0.668618\tvalid_1's multi_logloss: 0.704879         \n",
      "[6]\ttraining's multi_logloss: 0.586941\tvalid_1's multi_logloss: 0.627709         \n",
      "[7]\ttraining's multi_logloss: 0.521521\tvalid_1's multi_logloss: 0.566455         \n",
      "[8]\ttraining's multi_logloss: 0.468411\tvalid_1's multi_logloss: 0.516942         \n",
      "[9]\ttraining's multi_logloss: 0.424605\tvalid_1's multi_logloss: 0.476973         \n",
      "[10]\ttraining's multi_logloss: 0.388552\tvalid_1's multi_logloss: 0.444408        \n",
      "[11]\ttraining's multi_logloss: 0.358802\tvalid_1's multi_logloss: 0.41823         \n",
      "[12]\ttraining's multi_logloss: 0.333609\tvalid_1's multi_logloss: 0.396426        \n",
      "[13]\ttraining's multi_logloss: 0.311599\tvalid_1's multi_logloss: 0.378715        \n",
      "[14]\ttraining's multi_logloss: 0.292819\tvalid_1's multi_logloss: 0.364191        \n",
      "[15]\ttraining's multi_logloss: 0.276632\tvalid_1's multi_logloss: 0.352399        \n",
      "[16]\ttraining's multi_logloss: 0.262745\tvalid_1's multi_logloss: 0.342862        \n",
      "[17]\ttraining's multi_logloss: 0.249599\tvalid_1's multi_logloss: 0.333562        \n",
      "[18]\ttraining's multi_logloss: 0.237996\tvalid_1's multi_logloss: 0.326277        \n",
      "[19]\ttraining's multi_logloss: 0.227673\tvalid_1's multi_logloss: 0.320383        \n",
      "[20]\ttraining's multi_logloss: 0.218126\tvalid_1's multi_logloss: 0.315133        \n",
      "[21]\ttraining's multi_logloss: 0.209506\tvalid_1's multi_logloss: 0.311348        \n",
      "[22]\ttraining's multi_logloss: 0.200796\tvalid_1's multi_logloss: 0.307201        \n",
      "[23]\ttraining's multi_logloss: 0.193202\tvalid_1's multi_logloss: 0.304328        \n",
      "[24]\ttraining's multi_logloss: 0.185745\tvalid_1's multi_logloss: 0.301988        \n",
      "[25]\ttraining's multi_logloss: 0.179336\tvalid_1's multi_logloss: 0.299945        \n",
      "[26]\ttraining's multi_logloss: 0.17303\tvalid_1's multi_logloss: 0.298431         \n",
      "[27]\ttraining's multi_logloss: 0.166911\tvalid_1's multi_logloss: 0.297103        \n",
      "[28]\ttraining's multi_logloss: 0.161244\tvalid_1's multi_logloss: 0.295718        \n",
      "[29]\ttraining's multi_logloss: 0.155933\tvalid_1's multi_logloss: 0.295053        \n",
      "[30]\ttraining's multi_logloss: 0.150549\tvalid_1's multi_logloss: 0.294262        \n",
      "[31]\ttraining's multi_logloss: 0.145652\tvalid_1's multi_logloss: 0.292997        \n",
      "[32]\ttraining's multi_logloss: 0.141094\tvalid_1's multi_logloss: 0.292908        \n",
      "[33]\ttraining's multi_logloss: 0.136545\tvalid_1's multi_logloss: 0.29209         \n",
      "[34]\ttraining's multi_logloss: 0.132249\tvalid_1's multi_logloss: 0.291333        \n",
      "[35]\ttraining's multi_logloss: 0.128047\tvalid_1's multi_logloss: 0.290738        \n",
      "[36]\ttraining's multi_logloss: 0.124316\tvalid_1's multi_logloss: 0.291233        \n",
      "[37]\ttraining's multi_logloss: 0.120576\tvalid_1's multi_logloss: 0.29082         \n",
      "[38]\ttraining's multi_logloss: 0.117009\tvalid_1's multi_logloss: 0.290295        \n",
      "[39]\ttraining's multi_logloss: 0.113604\tvalid_1's multi_logloss: 0.290668        \n",
      "[40]\ttraining's multi_logloss: 0.10992\tvalid_1's multi_logloss: 0.290596         \n",
      "[41]\ttraining's multi_logloss: 0.106761\tvalid_1's multi_logloss: 0.290512        \n",
      "[42]\ttraining's multi_logloss: 0.103886\tvalid_1's multi_logloss: 0.290989        \n",
      "[43]\ttraining's multi_logloss: 0.100777\tvalid_1's multi_logloss: 0.290726        \n",
      "[44]\ttraining's multi_logloss: 0.0981502\tvalid_1's multi_logloss: 0.290981       \n",
      "[45]\ttraining's multi_logloss: 0.0954926\tvalid_1's multi_logloss: 0.291268       \n",
      "[46]\ttraining's multi_logloss: 0.0929485\tvalid_1's multi_logloss: 0.291772       \n",
      "[47]\ttraining's multi_logloss: 0.0906584\tvalid_1's multi_logloss: 0.292466       \n",
      "[48]\ttraining's multi_logloss: 0.0884417\tvalid_1's multi_logloss: 0.292655       \n",
      "[49]\ttraining's multi_logloss: 0.0858789\tvalid_1's multi_logloss: 0.292948       \n",
      "[50]\ttraining's multi_logloss: 0.0838489\tvalid_1's multi_logloss: 0.293666       \n",
      "[51]\ttraining's multi_logloss: 0.0818696\tvalid_1's multi_logloss: 0.293479       \n",
      "[52]\ttraining's multi_logloss: 0.0797797\tvalid_1's multi_logloss: 0.294645       \n",
      "[53]\ttraining's multi_logloss: 0.0776341\tvalid_1's multi_logloss: 0.294998       \n",
      "[54]\ttraining's multi_logloss: 0.0756092\tvalid_1's multi_logloss: 0.296048       \n",
      "[55]\ttraining's multi_logloss: 0.0737362\tvalid_1's multi_logloss: 0.296823       \n",
      "[56]\ttraining's multi_logloss: 0.0719304\tvalid_1's multi_logloss: 0.297717       \n",
      "[57]\ttraining's multi_logloss: 0.0703114\tvalid_1's multi_logloss: 0.298255       \n",
      "[58]\ttraining's multi_logloss: 0.0684946\tvalid_1's multi_logloss: 0.29931        \n",
      "[59]\ttraining's multi_logloss: 0.066973\tvalid_1's multi_logloss: 0.300295        \n",
      "[60]\ttraining's multi_logloss: 0.0652375\tvalid_1's multi_logloss: 0.301079       \n",
      "[61]\ttraining's multi_logloss: 0.0636341\tvalid_1's multi_logloss: 0.302462       \n",
      "[62]\ttraining's multi_logloss: 0.0620446\tvalid_1's multi_logloss: 0.303639       \n",
      "[63]\ttraining's multi_logloss: 0.0603305\tvalid_1's multi_logloss: 0.304669       \n",
      "[64]\ttraining's multi_logloss: 0.0588367\tvalid_1's multi_logloss: 0.305511       \n",
      "[65]\ttraining's multi_logloss: 0.0573165\tvalid_1's multi_logloss: 0.306661       \n",
      "[66]\ttraining's multi_logloss: 0.0559793\tvalid_1's multi_logloss: 0.307294       \n",
      "[67]\ttraining's multi_logloss: 0.0547992\tvalid_1's multi_logloss: 0.308245       \n",
      "[68]\ttraining's multi_logloss: 0.0535081\tvalid_1's multi_logloss: 0.309063       \n",
      "Early stopping, best iteration is:                                               \n",
      "[38]\ttraining's multi_logloss: 0.117009\tvalid_1's multi_logloss: 0.290295\n",
      "[1]\ttraining's multi_logloss: 1.37939\tvalid_1's multi_logloss: 1.3866            \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.09987\tvalid_1's multi_logloss: 1.11055           \n",
      "[3]\ttraining's multi_logloss: 0.914476\tvalid_1's multi_logloss: 0.928792         \n",
      "[4]\ttraining's multi_logloss: 0.778837\tvalid_1's multi_logloss: 0.797162         \n",
      "[5]\ttraining's multi_logloss: 0.674787\tvalid_1's multi_logloss: 0.698024         \n",
      "[6]\ttraining's multi_logloss: 0.592224\tvalid_1's multi_logloss: 0.619798         \n",
      "[7]\ttraining's multi_logloss: 0.526924\tvalid_1's multi_logloss: 0.558428         \n",
      "[8]\ttraining's multi_logloss: 0.473809\tvalid_1's multi_logloss: 0.509001         \n",
      "[9]\ttraining's multi_logloss: 0.43031\tvalid_1's multi_logloss: 0.470503          \n",
      "[10]\ttraining's multi_logloss: 0.393923\tvalid_1's multi_logloss: 0.438783        \n",
      "[11]\ttraining's multi_logloss: 0.364163\tvalid_1's multi_logloss: 0.413626        \n",
      "[12]\ttraining's multi_logloss: 0.339152\tvalid_1's multi_logloss: 0.393347        \n",
      "[13]\ttraining's multi_logloss: 0.316357\tvalid_1's multi_logloss: 0.374067        \n",
      "[14]\ttraining's multi_logloss: 0.297181\tvalid_1's multi_logloss: 0.358789        \n",
      "[15]\ttraining's multi_logloss: 0.279512\tvalid_1's multi_logloss: 0.345996        \n",
      "[16]\ttraining's multi_logloss: 0.264501\tvalid_1's multi_logloss: 0.336164        \n",
      "[17]\ttraining's multi_logloss: 0.251038\tvalid_1's multi_logloss: 0.327066        \n",
      "[18]\ttraining's multi_logloss: 0.239379\tvalid_1's multi_logloss: 0.319616        \n",
      "[19]\ttraining's multi_logloss: 0.228471\tvalid_1's multi_logloss: 0.313534        \n",
      "[20]\ttraining's multi_logloss: 0.218715\tvalid_1's multi_logloss: 0.309404        \n",
      "[21]\ttraining's multi_logloss: 0.209574\tvalid_1's multi_logloss: 0.305384        \n",
      "[22]\ttraining's multi_logloss: 0.201237\tvalid_1's multi_logloss: 0.302173        \n",
      "[23]\ttraining's multi_logloss: 0.193507\tvalid_1's multi_logloss: 0.299105        \n",
      "[24]\ttraining's multi_logloss: 0.186319\tvalid_1's multi_logloss: 0.29712         \n",
      "[25]\ttraining's multi_logloss: 0.179591\tvalid_1's multi_logloss: 0.295094        \n",
      "[26]\ttraining's multi_logloss: 0.172948\tvalid_1's multi_logloss: 0.29254         \n",
      "[27]\ttraining's multi_logloss: 0.167005\tvalid_1's multi_logloss: 0.291281        \n",
      "[28]\ttraining's multi_logloss: 0.160903\tvalid_1's multi_logloss: 0.289946        \n",
      "[29]\ttraining's multi_logloss: 0.155483\tvalid_1's multi_logloss: 0.289109        \n",
      "[30]\ttraining's multi_logloss: 0.150139\tvalid_1's multi_logloss: 0.28819         \n",
      "[31]\ttraining's multi_logloss: 0.144848\tvalid_1's multi_logloss: 0.287397        \n",
      "[32]\ttraining's multi_logloss: 0.140016\tvalid_1's multi_logloss: 0.286369        \n",
      "[33]\ttraining's multi_logloss: 0.13533\tvalid_1's multi_logloss: 0.286572         \n",
      "[34]\ttraining's multi_logloss: 0.131135\tvalid_1's multi_logloss: 0.286431        \n",
      "[35]\ttraining's multi_logloss: 0.127189\tvalid_1's multi_logloss: 0.28571         \n",
      "[36]\ttraining's multi_logloss: 0.123036\tvalid_1's multi_logloss: 0.285631        \n",
      "[37]\ttraining's multi_logloss: 0.119217\tvalid_1's multi_logloss: 0.28581         \n",
      "[38]\ttraining's multi_logloss: 0.115502\tvalid_1's multi_logloss: 0.285573        \n",
      "[39]\ttraining's multi_logloss: 0.111845\tvalid_1's multi_logloss: 0.285872        \n",
      "[40]\ttraining's multi_logloss: 0.10836\tvalid_1's multi_logloss: 0.286499         \n",
      "[41]\ttraining's multi_logloss: 0.105259\tvalid_1's multi_logloss: 0.287091        \n",
      "[42]\ttraining's multi_logloss: 0.102036\tvalid_1's multi_logloss: 0.28687         \n",
      "[43]\ttraining's multi_logloss: 0.0992541\tvalid_1's multi_logloss: 0.287138       \n",
      "[44]\ttraining's multi_logloss: 0.0964758\tvalid_1's multi_logloss: 0.286958       \n",
      "[45]\ttraining's multi_logloss: 0.0935481\tvalid_1's multi_logloss: 0.287837       \n",
      "[46]\ttraining's multi_logloss: 0.0907923\tvalid_1's multi_logloss: 0.288031       \n",
      "[47]\ttraining's multi_logloss: 0.0882267\tvalid_1's multi_logloss: 0.288893       \n",
      "[48]\ttraining's multi_logloss: 0.0859234\tvalid_1's multi_logloss: 0.289554       \n",
      "[49]\ttraining's multi_logloss: 0.0835757\tvalid_1's multi_logloss: 0.289388       \n",
      "[50]\ttraining's multi_logloss: 0.0813438\tvalid_1's multi_logloss: 0.289862       \n",
      "[51]\ttraining's multi_logloss: 0.0790678\tvalid_1's multi_logloss: 0.291279       \n",
      "[52]\ttraining's multi_logloss: 0.0770313\tvalid_1's multi_logloss: 0.292163       \n",
      "[53]\ttraining's multi_logloss: 0.0751035\tvalid_1's multi_logloss: 0.292756       \n",
      "[54]\ttraining's multi_logloss: 0.0730329\tvalid_1's multi_logloss: 0.293662       \n",
      "[55]\ttraining's multi_logloss: 0.0711865\tvalid_1's multi_logloss: 0.294626       \n",
      "[56]\ttraining's multi_logloss: 0.0695158\tvalid_1's multi_logloss: 0.295199       \n",
      "[57]\ttraining's multi_logloss: 0.0676008\tvalid_1's multi_logloss: 0.295615       \n",
      "[58]\ttraining's multi_logloss: 0.0658423\tvalid_1's multi_logloss: 0.296436       \n",
      "[59]\ttraining's multi_logloss: 0.0642485\tvalid_1's multi_logloss: 0.297452       \n",
      "[60]\ttraining's multi_logloss: 0.0626204\tvalid_1's multi_logloss: 0.298597       \n",
      "[61]\ttraining's multi_logloss: 0.061012\tvalid_1's multi_logloss: 0.29973         \n",
      "[62]\ttraining's multi_logloss: 0.0593463\tvalid_1's multi_logloss: 0.300845       \n",
      "[63]\ttraining's multi_logloss: 0.0579461\tvalid_1's multi_logloss: 0.301634       \n",
      "[64]\ttraining's multi_logloss: 0.0564455\tvalid_1's multi_logloss: 0.302714       \n",
      "[65]\ttraining's multi_logloss: 0.0550336\tvalid_1's multi_logloss: 0.303384       \n",
      "[66]\ttraining's multi_logloss: 0.0535954\tvalid_1's multi_logloss: 0.304848       \n",
      "[67]\ttraining's multi_logloss: 0.0522301\tvalid_1's multi_logloss: 0.306765       \n",
      "[68]\ttraining's multi_logloss: 0.051068\tvalid_1's multi_logloss: 0.307744        \n",
      "Early stopping, best iteration is:                                               \n",
      "[38]\ttraining's multi_logloss: 0.115502\tvalid_1's multi_logloss: 0.285573\n",
      "[1]\ttraining's multi_logloss: 1.38276\tvalid_1's multi_logloss: 1.38909           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.10281\tvalid_1's multi_logloss: 1.11157           \n",
      "[3]\ttraining's multi_logloss: 0.915899\tvalid_1's multi_logloss: 0.928198         \n",
      "[4]\ttraining's multi_logloss: 0.780363\tvalid_1's multi_logloss: 0.794774         \n",
      "[5]\ttraining's multi_logloss: 0.676212\tvalid_1's multi_logloss: 0.693272         \n",
      "[6]\ttraining's multi_logloss: 0.595068\tvalid_1's multi_logloss: 0.616037         \n",
      "[7]\ttraining's multi_logloss: 0.529462\tvalid_1's multi_logloss: 0.554234         \n",
      "[8]\ttraining's multi_logloss: 0.476818\tvalid_1's multi_logloss: 0.504866         \n",
      "[9]\ttraining's multi_logloss: 0.434293\tvalid_1's multi_logloss: 0.465852         \n",
      "[10]\ttraining's multi_logloss: 0.398619\tvalid_1's multi_logloss: 0.433445        \n",
      "[11]\ttraining's multi_logloss: 0.3683\tvalid_1's multi_logloss: 0.406448          \n",
      "[12]\ttraining's multi_logloss: 0.342069\tvalid_1's multi_logloss: 0.383951        \n",
      "[13]\ttraining's multi_logloss: 0.320185\tvalid_1's multi_logloss: 0.365952        \n",
      "[14]\ttraining's multi_logloss: 0.300925\tvalid_1's multi_logloss: 0.350408        \n",
      "[15]\ttraining's multi_logloss: 0.283927\tvalid_1's multi_logloss: 0.337665        \n",
      "[16]\ttraining's multi_logloss: 0.269398\tvalid_1's multi_logloss: 0.327268        \n",
      "[17]\ttraining's multi_logloss: 0.255854\tvalid_1's multi_logloss: 0.318648        \n",
      "[18]\ttraining's multi_logloss: 0.243646\tvalid_1's multi_logloss: 0.31127         \n",
      "[19]\ttraining's multi_logloss: 0.232973\tvalid_1's multi_logloss: 0.305757        \n",
      "[20]\ttraining's multi_logloss: 0.223364\tvalid_1's multi_logloss: 0.300605        \n",
      "[21]\ttraining's multi_logloss: 0.214544\tvalid_1's multi_logloss: 0.296501        \n",
      "[22]\ttraining's multi_logloss: 0.206508\tvalid_1's multi_logloss: 0.293335        \n",
      "[23]\ttraining's multi_logloss: 0.198963\tvalid_1's multi_logloss: 0.289668        \n",
      "[24]\ttraining's multi_logloss: 0.191793\tvalid_1's multi_logloss: 0.287208        \n",
      "[25]\ttraining's multi_logloss: 0.184853\tvalid_1's multi_logloss: 0.285146        \n",
      "[26]\ttraining's multi_logloss: 0.178205\tvalid_1's multi_logloss: 0.283299        \n",
      "[27]\ttraining's multi_logloss: 0.171843\tvalid_1's multi_logloss: 0.281066        \n",
      "[28]\ttraining's multi_logloss: 0.165901\tvalid_1's multi_logloss: 0.27942         \n",
      "[29]\ttraining's multi_logloss: 0.160512\tvalid_1's multi_logloss: 0.27824         \n",
      "[30]\ttraining's multi_logloss: 0.155252\tvalid_1's multi_logloss: 0.276921        \n",
      "[31]\ttraining's multi_logloss: 0.15032\tvalid_1's multi_logloss: 0.275884         \n",
      "[32]\ttraining's multi_logloss: 0.145299\tvalid_1's multi_logloss: 0.274902        \n",
      "[33]\ttraining's multi_logloss: 0.14058\tvalid_1's multi_logloss: 0.274042         \n",
      "[34]\ttraining's multi_logloss: 0.136262\tvalid_1's multi_logloss: 0.273374        \n",
      "[35]\ttraining's multi_logloss: 0.131949\tvalid_1's multi_logloss: 0.27283         \n",
      "[36]\ttraining's multi_logloss: 0.128052\tvalid_1's multi_logloss: 0.272932        \n",
      "[37]\ttraining's multi_logloss: 0.124188\tvalid_1's multi_logloss: 0.27288         \n",
      "[38]\ttraining's multi_logloss: 0.120836\tvalid_1's multi_logloss: 0.272551        \n",
      "[39]\ttraining's multi_logloss: 0.117268\tvalid_1's multi_logloss: 0.273013        \n",
      "[40]\ttraining's multi_logloss: 0.113905\tvalid_1's multi_logloss: 0.272965        \n",
      "[41]\ttraining's multi_logloss: 0.110519\tvalid_1's multi_logloss: 0.273277        \n",
      "[42]\ttraining's multi_logloss: 0.107192\tvalid_1's multi_logloss: 0.273949        \n",
      "[43]\ttraining's multi_logloss: 0.104234\tvalid_1's multi_logloss: 0.274267        \n",
      "[44]\ttraining's multi_logloss: 0.101117\tvalid_1's multi_logloss: 0.274533        \n",
      "[45]\ttraining's multi_logloss: 0.0982377\tvalid_1's multi_logloss: 0.27486        \n",
      "[46]\ttraining's multi_logloss: 0.0955755\tvalid_1's multi_logloss: 0.274709       \n",
      "[47]\ttraining's multi_logloss: 0.0932509\tvalid_1's multi_logloss: 0.275229       \n",
      "[48]\ttraining's multi_logloss: 0.0911057\tvalid_1's multi_logloss: 0.276004       \n",
      "[49]\ttraining's multi_logloss: 0.0886688\tvalid_1's multi_logloss: 0.275607       \n",
      "[50]\ttraining's multi_logloss: 0.0864068\tvalid_1's multi_logloss: 0.276321       \n",
      "[51]\ttraining's multi_logloss: 0.0841681\tvalid_1's multi_logloss: 0.276988       \n",
      "[52]\ttraining's multi_logloss: 0.0821568\tvalid_1's multi_logloss: 0.277386       \n",
      "[53]\ttraining's multi_logloss: 0.0802454\tvalid_1's multi_logloss: 0.277641       \n",
      "[54]\ttraining's multi_logloss: 0.0784274\tvalid_1's multi_logloss: 0.277899       \n",
      "[55]\ttraining's multi_logloss: 0.0763873\tvalid_1's multi_logloss: 0.278272       \n",
      "[56]\ttraining's multi_logloss: 0.0744122\tvalid_1's multi_logloss: 0.27822        \n",
      "[57]\ttraining's multi_logloss: 0.0726009\tvalid_1's multi_logloss: 0.278504       \n",
      "[58]\ttraining's multi_logloss: 0.071013\tvalid_1's multi_logloss: 0.278913        \n",
      "[59]\ttraining's multi_logloss: 0.069246\tvalid_1's multi_logloss: 0.279861        \n",
      "[60]\ttraining's multi_logloss: 0.06765\tvalid_1's multi_logloss: 0.280883         \n",
      "[61]\ttraining's multi_logloss: 0.0658166\tvalid_1's multi_logloss: 0.281519       \n",
      "[62]\ttraining's multi_logloss: 0.0642586\tvalid_1's multi_logloss: 0.281809       \n",
      "[63]\ttraining's multi_logloss: 0.0626175\tvalid_1's multi_logloss: 0.282832       \n",
      "[64]\ttraining's multi_logloss: 0.0610872\tvalid_1's multi_logloss: 0.283426       \n",
      "[65]\ttraining's multi_logloss: 0.0596698\tvalid_1's multi_logloss: 0.284485       \n",
      "[66]\ttraining's multi_logloss: 0.0582647\tvalid_1's multi_logloss: 0.285138       \n",
      "[67]\ttraining's multi_logloss: 0.0570248\tvalid_1's multi_logloss: 0.286113       \n",
      "[68]\ttraining's multi_logloss: 0.0556616\tvalid_1's multi_logloss: 0.286951       \n",
      "Early stopping, best iteration is:                                               \n",
      "[38]\ttraining's multi_logloss: 0.120836\tvalid_1's multi_logloss: 0.272551\n",
      "[1]\ttraining's multi_logloss: 1.18261\tvalid_1's multi_logloss: 1.19938            \n",
      "Training until validation scores don't improve for 30 rounds                      \n",
      "[2]\ttraining's multi_logloss: 0.887746\tvalid_1's multi_logloss: 0.915405          \n",
      "[3]\ttraining's multi_logloss: 0.707792\tvalid_1's multi_logloss: 0.742594          \n",
      "[4]\ttraining's multi_logloss: 0.58314\tvalid_1's multi_logloss: 0.623888           \n",
      "[5]\ttraining's multi_logloss: 0.495389\tvalid_1's multi_logloss: 0.541579          \n",
      "[6]\ttraining's multi_logloss: 0.429866\tvalid_1's multi_logloss: 0.480458          \n",
      "[7]\ttraining's multi_logloss: 0.379718\tvalid_1's multi_logloss: 0.435188          \n",
      "[8]\ttraining's multi_logloss: 0.342498\tvalid_1's multi_logloss: 0.402837          \n",
      "[9]\ttraining's multi_logloss: 0.312542\tvalid_1's multi_logloss: 0.378259          \n",
      "[10]\ttraining's multi_logloss: 0.28858\tvalid_1's multi_logloss: 0.359418          \n",
      "[11]\ttraining's multi_logloss: 0.268155\tvalid_1's multi_logloss: 0.344786         \n",
      "[12]\ttraining's multi_logloss: 0.251159\tvalid_1's multi_logloss: 0.332849         \n",
      "[13]\ttraining's multi_logloss: 0.236041\tvalid_1's multi_logloss: 0.323316         \n",
      "[14]\ttraining's multi_logloss: 0.223416\tvalid_1's multi_logloss: 0.316266         \n",
      "[15]\ttraining's multi_logloss: 0.21244\tvalid_1's multi_logloss: 0.311061          \n",
      "[16]\ttraining's multi_logloss: 0.202118\tvalid_1's multi_logloss: 0.306834         \n",
      "[17]\ttraining's multi_logloss: 0.193196\tvalid_1's multi_logloss: 0.304058         \n",
      "[18]\ttraining's multi_logloss: 0.184826\tvalid_1's multi_logloss: 0.300728         \n",
      "[19]\ttraining's multi_logloss: 0.177272\tvalid_1's multi_logloss: 0.299155         \n",
      "[20]\ttraining's multi_logloss: 0.170258\tvalid_1's multi_logloss: 0.297743         \n",
      "[21]\ttraining's multi_logloss: 0.163737\tvalid_1's multi_logloss: 0.296361         \n",
      "[22]\ttraining's multi_logloss: 0.15696\tvalid_1's multi_logloss: 0.295133          \n",
      "[23]\ttraining's multi_logloss: 0.150978\tvalid_1's multi_logloss: 0.293282         \n",
      "[24]\ttraining's multi_logloss: 0.145295\tvalid_1's multi_logloss: 0.293048         \n",
      "[25]\ttraining's multi_logloss: 0.140336\tvalid_1's multi_logloss: 0.291959         \n",
      "[26]\ttraining's multi_logloss: 0.135458\tvalid_1's multi_logloss: 0.292248         \n",
      "[27]\ttraining's multi_logloss: 0.130769\tvalid_1's multi_logloss: 0.29205          \n",
      "[28]\ttraining's multi_logloss: 0.126334\tvalid_1's multi_logloss: 0.291207         \n",
      "[29]\ttraining's multi_logloss: 0.12219\tvalid_1's multi_logloss: 0.292003          \n",
      "[30]\ttraining's multi_logloss: 0.118398\tvalid_1's multi_logloss: 0.292353         \n",
      "[31]\ttraining's multi_logloss: 0.114876\tvalid_1's multi_logloss: 0.292603         \n",
      "[32]\ttraining's multi_logloss: 0.111303\tvalid_1's multi_logloss: 0.292986         \n",
      "[33]\ttraining's multi_logloss: 0.108302\tvalid_1's multi_logloss: 0.293995         \n",
      "[34]\ttraining's multi_logloss: 0.105193\tvalid_1's multi_logloss: 0.294284         \n",
      "[35]\ttraining's multi_logloss: 0.102329\tvalid_1's multi_logloss: 0.295126         \n",
      "[36]\ttraining's multi_logloss: 0.0991055\tvalid_1's multi_logloss: 0.295806        \n",
      "[37]\ttraining's multi_logloss: 0.096385\tvalid_1's multi_logloss: 0.296976         \n",
      "[38]\ttraining's multi_logloss: 0.0935512\tvalid_1's multi_logloss: 0.297079        \n",
      "[39]\ttraining's multi_logloss: 0.0908696\tvalid_1's multi_logloss: 0.297621        \n",
      "[40]\ttraining's multi_logloss: 0.0884306\tvalid_1's multi_logloss: 0.298244        \n",
      "[41]\ttraining's multi_logloss: 0.0859624\tvalid_1's multi_logloss: 0.299344        \n",
      "[42]\ttraining's multi_logloss: 0.0834024\tvalid_1's multi_logloss: 0.299891        \n",
      "[43]\ttraining's multi_logloss: 0.0811166\tvalid_1's multi_logloss: 0.300417        \n",
      "[44]\ttraining's multi_logloss: 0.0788225\tvalid_1's multi_logloss: 0.301234        \n",
      "[45]\ttraining's multi_logloss: 0.0768123\tvalid_1's multi_logloss: 0.301898        \n",
      "[46]\ttraining's multi_logloss: 0.0745699\tvalid_1's multi_logloss: 0.302269        \n",
      "[47]\ttraining's multi_logloss: 0.0725056\tvalid_1's multi_logloss: 0.303673        \n",
      "[48]\ttraining's multi_logloss: 0.0707445\tvalid_1's multi_logloss: 0.304654        \n",
      "[49]\ttraining's multi_logloss: 0.0685952\tvalid_1's multi_logloss: 0.306133        \n",
      "[50]\ttraining's multi_logloss: 0.0667475\tvalid_1's multi_logloss: 0.307267        \n",
      "[51]\ttraining's multi_logloss: 0.0649579\tvalid_1's multi_logloss: 0.307889        \n",
      "[52]\ttraining's multi_logloss: 0.0633787\tvalid_1's multi_logloss: 0.309247        \n",
      "[53]\ttraining's multi_logloss: 0.0618599\tvalid_1's multi_logloss: 0.310158        \n",
      "[54]\ttraining's multi_logloss: 0.0602698\tvalid_1's multi_logloss: 0.310949        \n",
      "[55]\ttraining's multi_logloss: 0.0586561\tvalid_1's multi_logloss: 0.311861        \n",
      "[56]\ttraining's multi_logloss: 0.0573377\tvalid_1's multi_logloss: 0.313645        \n",
      "[57]\ttraining's multi_logloss: 0.0560766\tvalid_1's multi_logloss: 0.31426         \n",
      "[58]\ttraining's multi_logloss: 0.054718\tvalid_1's multi_logloss: 0.314798         \n",
      "Early stopping, best iteration is:                                                \n",
      "[28]\ttraining's multi_logloss: 0.126334\tvalid_1's multi_logloss: 0.291207\n",
      "[1]\ttraining's multi_logloss: 1.17898\tvalid_1's multi_logloss: 1.1885             \n",
      "Training until validation scores don't improve for 30 rounds                      \n",
      "[2]\ttraining's multi_logloss: 0.887772\tvalid_1's multi_logloss: 0.902893          \n",
      "[3]\ttraining's multi_logloss: 0.710879\tvalid_1's multi_logloss: 0.732317          \n",
      "[4]\ttraining's multi_logloss: 0.588234\tvalid_1's multi_logloss: 0.615883          \n",
      "[5]\ttraining's multi_logloss: 0.500727\tvalid_1's multi_logloss: 0.533926          \n",
      "[6]\ttraining's multi_logloss: 0.435038\tvalid_1's multi_logloss: 0.473602          \n",
      "[7]\ttraining's multi_logloss: 0.385067\tvalid_1's multi_logloss: 0.428109          \n",
      "[8]\ttraining's multi_logloss: 0.347066\tvalid_1's multi_logloss: 0.395624          \n",
      "[9]\ttraining's multi_logloss: 0.316127\tvalid_1's multi_logloss: 0.370146          \n",
      "[10]\ttraining's multi_logloss: 0.291347\tvalid_1's multi_logloss: 0.351181         \n",
      "[11]\ttraining's multi_logloss: 0.270123\tvalid_1's multi_logloss: 0.335963         \n",
      "[12]\ttraining's multi_logloss: 0.252893\tvalid_1's multi_logloss: 0.32603          \n",
      "[13]\ttraining's multi_logloss: 0.238212\tvalid_1's multi_logloss: 0.317803         \n",
      "[14]\ttraining's multi_logloss: 0.224921\tvalid_1's multi_logloss: 0.310557         \n",
      "[15]\ttraining's multi_logloss: 0.214172\tvalid_1's multi_logloss: 0.305913         \n",
      "[16]\ttraining's multi_logloss: 0.203718\tvalid_1's multi_logloss: 0.301707         \n",
      "[17]\ttraining's multi_logloss: 0.194184\tvalid_1's multi_logloss: 0.298838         \n",
      "[18]\ttraining's multi_logloss: 0.185244\tvalid_1's multi_logloss: 0.295414         \n",
      "[19]\ttraining's multi_logloss: 0.177434\tvalid_1's multi_logloss: 0.293889         \n",
      "[20]\ttraining's multi_logloss: 0.170288\tvalid_1's multi_logloss: 0.290973         \n",
      "[21]\ttraining's multi_logloss: 0.163895\tvalid_1's multi_logloss: 0.290409         \n",
      "[22]\ttraining's multi_logloss: 0.157339\tvalid_1's multi_logloss: 0.289517         \n",
      "[23]\ttraining's multi_logloss: 0.151321\tvalid_1's multi_logloss: 0.289285         \n",
      "[24]\ttraining's multi_logloss: 0.145565\tvalid_1's multi_logloss: 0.288585         \n",
      "[25]\ttraining's multi_logloss: 0.140204\tvalid_1's multi_logloss: 0.289231         \n",
      "[26]\ttraining's multi_logloss: 0.135261\tvalid_1's multi_logloss: 0.288833         \n",
      "[27]\ttraining's multi_logloss: 0.130162\tvalid_1's multi_logloss: 0.288991         \n",
      "[28]\ttraining's multi_logloss: 0.125697\tvalid_1's multi_logloss: 0.290134         \n",
      "[29]\ttraining's multi_logloss: 0.121538\tvalid_1's multi_logloss: 0.289797         \n",
      "[30]\ttraining's multi_logloss: 0.117247\tvalid_1's multi_logloss: 0.290452         \n",
      "[31]\ttraining's multi_logloss: 0.113387\tvalid_1's multi_logloss: 0.290676         \n",
      "[32]\ttraining's multi_logloss: 0.109622\tvalid_1's multi_logloss: 0.291002         \n",
      "[33]\ttraining's multi_logloss: 0.106256\tvalid_1's multi_logloss: 0.291396         \n",
      "[34]\ttraining's multi_logloss: 0.102927\tvalid_1's multi_logloss: 0.29268          \n",
      "[35]\ttraining's multi_logloss: 0.0996597\tvalid_1's multi_logloss: 0.292858        \n",
      "[36]\ttraining's multi_logloss: 0.0967816\tvalid_1's multi_logloss: 0.292802        \n",
      "[37]\ttraining's multi_logloss: 0.0940988\tvalid_1's multi_logloss: 0.293616        \n",
      "[38]\ttraining's multi_logloss: 0.091557\tvalid_1's multi_logloss: 0.294493         \n",
      "[39]\ttraining's multi_logloss: 0.0890509\tvalid_1's multi_logloss: 0.29555         \n",
      "[40]\ttraining's multi_logloss: 0.0862118\tvalid_1's multi_logloss: 0.296437        \n",
      "[41]\ttraining's multi_logloss: 0.0837283\tvalid_1's multi_logloss: 0.296395        \n",
      "[42]\ttraining's multi_logloss: 0.0813941\tvalid_1's multi_logloss: 0.297463        \n",
      "[43]\ttraining's multi_logloss: 0.0790416\tvalid_1's multi_logloss: 0.298275        \n",
      "[44]\ttraining's multi_logloss: 0.0768956\tvalid_1's multi_logloss: 0.299062        \n",
      "[45]\ttraining's multi_logloss: 0.074889\tvalid_1's multi_logloss: 0.299851         \n",
      "[46]\ttraining's multi_logloss: 0.0728426\tvalid_1's multi_logloss: 0.30057         \n",
      "[47]\ttraining's multi_logloss: 0.0710445\tvalid_1's multi_logloss: 0.302174        \n",
      "[48]\ttraining's multi_logloss: 0.0690901\tvalid_1's multi_logloss: 0.303021        \n",
      "[49]\ttraining's multi_logloss: 0.0674023\tvalid_1's multi_logloss: 0.304367        \n",
      "[50]\ttraining's multi_logloss: 0.0656756\tvalid_1's multi_logloss: 0.305688        \n",
      "[51]\ttraining's multi_logloss: 0.0640402\tvalid_1's multi_logloss: 0.30722         \n",
      "[52]\ttraining's multi_logloss: 0.0625705\tvalid_1's multi_logloss: 0.308176        \n",
      "[53]\ttraining's multi_logloss: 0.0609859\tvalid_1's multi_logloss: 0.309055        \n",
      "[54]\ttraining's multi_logloss: 0.059447\tvalid_1's multi_logloss: 0.309595         \n",
      "Early stopping, best iteration is:                                                \n",
      "[24]\ttraining's multi_logloss: 0.145565\tvalid_1's multi_logloss: 0.288585\n",
      "[1]\ttraining's multi_logloss: 1.18287\tvalid_1's multi_logloss: 1.19016            \n",
      "Training until validation scores don't improve for 30 rounds                      \n",
      "[2]\ttraining's multi_logloss: 0.893285\tvalid_1's multi_logloss: 0.906188          \n",
      "[3]\ttraining's multi_logloss: 0.714411\tvalid_1's multi_logloss: 0.731282          \n",
      "[4]\ttraining's multi_logloss: 0.591209\tvalid_1's multi_logloss: 0.61174           \n",
      "[5]\ttraining's multi_logloss: 0.504521\tvalid_1's multi_logloss: 0.528672          \n",
      "[6]\ttraining's multi_logloss: 0.44028\tvalid_1's multi_logloss: 0.468947           \n",
      "[7]\ttraining's multi_logloss: 0.391138\tvalid_1's multi_logloss: 0.423929          \n",
      "[8]\ttraining's multi_logloss: 0.352902\tvalid_1's multi_logloss: 0.390048          \n",
      "[9]\ttraining's multi_logloss: 0.321515\tvalid_1's multi_logloss: 0.363295          \n",
      "[10]\ttraining's multi_logloss: 0.296465\tvalid_1's multi_logloss: 0.343414         \n",
      "[11]\ttraining's multi_logloss: 0.276347\tvalid_1's multi_logloss: 0.327395         \n",
      "[12]\ttraining's multi_logloss: 0.259156\tvalid_1's multi_logloss: 0.316727         \n",
      "[13]\ttraining's multi_logloss: 0.244419\tvalid_1's multi_logloss: 0.307558         \n",
      "[14]\ttraining's multi_logloss: 0.2311\tvalid_1's multi_logloss: 0.300454           \n",
      "[15]\ttraining's multi_logloss: 0.219612\tvalid_1's multi_logloss: 0.294739         \n",
      "[16]\ttraining's multi_logloss: 0.209617\tvalid_1's multi_logloss: 0.290248         \n",
      "[17]\ttraining's multi_logloss: 0.200691\tvalid_1's multi_logloss: 0.286828         \n",
      "[18]\ttraining's multi_logloss: 0.192272\tvalid_1's multi_logloss: 0.283739         \n",
      "[19]\ttraining's multi_logloss: 0.184414\tvalid_1's multi_logloss: 0.281588         \n",
      "[20]\ttraining's multi_logloss: 0.177341\tvalid_1's multi_logloss: 0.27971          \n",
      "[21]\ttraining's multi_logloss: 0.170778\tvalid_1's multi_logloss: 0.278615         \n",
      "[22]\ttraining's multi_logloss: 0.164229\tvalid_1's multi_logloss: 0.277275         \n",
      "[23]\ttraining's multi_logloss: 0.157783\tvalid_1's multi_logloss: 0.276563         \n",
      "[24]\ttraining's multi_logloss: 0.151761\tvalid_1's multi_logloss: 0.275977         \n",
      "[25]\ttraining's multi_logloss: 0.146651\tvalid_1's multi_logloss: 0.274613         \n",
      "[26]\ttraining's multi_logloss: 0.141606\tvalid_1's multi_logloss: 0.274402         \n",
      "[27]\ttraining's multi_logloss: 0.136798\tvalid_1's multi_logloss: 0.273793         \n",
      "[28]\ttraining's multi_logloss: 0.132418\tvalid_1's multi_logloss: 0.27336          \n",
      "[29]\ttraining's multi_logloss: 0.12794\tvalid_1's multi_logloss: 0.273859          \n",
      "[30]\ttraining's multi_logloss: 0.123997\tvalid_1's multi_logloss: 0.273702         \n",
      "[31]\ttraining's multi_logloss: 0.119932\tvalid_1's multi_logloss: 0.273539         \n",
      "[32]\ttraining's multi_logloss: 0.116201\tvalid_1's multi_logloss: 0.273006         \n",
      "[33]\ttraining's multi_logloss: 0.112745\tvalid_1's multi_logloss: 0.273839         \n",
      "[34]\ttraining's multi_logloss: 0.109481\tvalid_1's multi_logloss: 0.274335         \n",
      "[35]\ttraining's multi_logloss: 0.106314\tvalid_1's multi_logloss: 0.274906         \n",
      "[36]\ttraining's multi_logloss: 0.10313\tvalid_1's multi_logloss: 0.274876          \n",
      "[37]\ttraining's multi_logloss: 0.100429\tvalid_1's multi_logloss: 0.275178         \n",
      "[38]\ttraining's multi_logloss: 0.0977111\tvalid_1's multi_logloss: 0.275801        \n",
      "[39]\ttraining's multi_logloss: 0.0947461\tvalid_1's multi_logloss: 0.276134        \n",
      "[40]\ttraining's multi_logloss: 0.0923305\tvalid_1's multi_logloss: 0.277434        \n",
      "[41]\ttraining's multi_logloss: 0.0899799\tvalid_1's multi_logloss: 0.27811         \n",
      "[42]\ttraining's multi_logloss: 0.0875989\tvalid_1's multi_logloss: 0.27865         \n",
      "[43]\ttraining's multi_logloss: 0.0855316\tvalid_1's multi_logloss: 0.279431        \n",
      "[44]\ttraining's multi_logloss: 0.0833492\tvalid_1's multi_logloss: 0.280403        \n",
      "[45]\ttraining's multi_logloss: 0.081149\tvalid_1's multi_logloss: 0.280179         \n",
      "[46]\ttraining's multi_logloss: 0.0791642\tvalid_1's multi_logloss: 0.280879        \n",
      "[47]\ttraining's multi_logloss: 0.0772059\tvalid_1's multi_logloss: 0.281589        \n",
      "[48]\ttraining's multi_logloss: 0.0752631\tvalid_1's multi_logloss: 0.282477        \n",
      "[49]\ttraining's multi_logloss: 0.0733169\tvalid_1's multi_logloss: 0.282769        \n",
      "[50]\ttraining's multi_logloss: 0.0715098\tvalid_1's multi_logloss: 0.283417        \n",
      "[51]\ttraining's multi_logloss: 0.0697156\tvalid_1's multi_logloss: 0.284318        \n",
      "[52]\ttraining's multi_logloss: 0.0679222\tvalid_1's multi_logloss: 0.28566         \n",
      "[53]\ttraining's multi_logloss: 0.0662442\tvalid_1's multi_logloss: 0.286315        \n",
      "[54]\ttraining's multi_logloss: 0.0645599\tvalid_1's multi_logloss: 0.286565        \n",
      "[55]\ttraining's multi_logloss: 0.062725\tvalid_1's multi_logloss: 0.287212         \n",
      "[56]\ttraining's multi_logloss: 0.0610899\tvalid_1's multi_logloss: 0.288053        \n",
      "[57]\ttraining's multi_logloss: 0.0596186\tvalid_1's multi_logloss: 0.289215        \n",
      "[58]\ttraining's multi_logloss: 0.0582569\tvalid_1's multi_logloss: 0.289903        \n",
      "[59]\ttraining's multi_logloss: 0.0568983\tvalid_1's multi_logloss: 0.290746        \n",
      "[60]\ttraining's multi_logloss: 0.0555097\tvalid_1's multi_logloss: 0.29201         \n",
      "[61]\ttraining's multi_logloss: 0.0541012\tvalid_1's multi_logloss: 0.292567        \n",
      "[62]\ttraining's multi_logloss: 0.0527953\tvalid_1's multi_logloss: 0.293222        \n",
      "Early stopping, best iteration is:                                                \n",
      "[32]\ttraining's multi_logloss: 0.116201\tvalid_1's multi_logloss: 0.273006\n",
      "[1]\ttraining's multi_logloss: 1.67611\tvalid_1's multi_logloss: 1.68077            \n",
      "Training until validation scores don't improve for 30 rounds                      \n",
      "[2]\ttraining's multi_logloss: 1.48571\tvalid_1's multi_logloss: 1.49605            \n",
      "[3]\ttraining's multi_logloss: 1.33622\tvalid_1's multi_logloss: 1.35186            \n",
      "[4]\ttraining's multi_logloss: 1.21232\tvalid_1's multi_logloss: 1.23198            \n",
      "[5]\ttraining's multi_logloss: 1.10807\tvalid_1's multi_logloss: 1.13103            \n",
      "[6]\ttraining's multi_logloss: 1.01899\tvalid_1's multi_logloss: 1.04505            \n",
      "[7]\ttraining's multi_logloss: 0.941899\tvalid_1's multi_logloss: 0.971021          \n",
      "[8]\ttraining's multi_logloss: 0.874111\tvalid_1's multi_logloss: 0.906001          \n",
      "[9]\ttraining's multi_logloss: 0.814046\tvalid_1's multi_logloss: 0.848403          \n",
      "[10]\ttraining's multi_logloss: 0.760346\tvalid_1's multi_logloss: 0.797003         \n",
      "[11]\ttraining's multi_logloss: 0.712452\tvalid_1's multi_logloss: 0.751193         \n",
      "[12]\ttraining's multi_logloss: 0.669516\tvalid_1's multi_logloss: 0.709792         \n",
      "[13]\ttraining's multi_logloss: 0.630545\tvalid_1's multi_logloss: 0.673203         \n",
      "[14]\ttraining's multi_logloss: 0.595346\tvalid_1's multi_logloss: 0.640041         \n",
      "[15]\ttraining's multi_logloss: 0.563483\tvalid_1's multi_logloss: 0.610258         \n",
      "[16]\ttraining's multi_logloss: 0.534483\tvalid_1's multi_logloss: 0.583328         \n",
      "[17]\ttraining's multi_logloss: 0.507738\tvalid_1's multi_logloss: 0.558698         \n",
      "[18]\ttraining's multi_logloss: 0.483643\tvalid_1's multi_logloss: 0.536691         \n",
      "[19]\ttraining's multi_logloss: 0.461583\tvalid_1's multi_logloss: 0.516872         \n",
      "[20]\ttraining's multi_logloss: 0.441107\tvalid_1's multi_logloss: 0.498485         \n",
      "[21]\ttraining's multi_logloss: 0.422295\tvalid_1's multi_logloss: 0.481597         \n",
      "[22]\ttraining's multi_logloss: 0.404957\tvalid_1's multi_logloss: 0.466194         \n",
      "[23]\ttraining's multi_logloss: 0.389043\tvalid_1's multi_logloss: 0.452417         \n",
      "[24]\ttraining's multi_logloss: 0.374227\tvalid_1's multi_logloss: 0.439144         \n",
      "[25]\ttraining's multi_logloss: 0.360519\tvalid_1's multi_logloss: 0.427097         \n",
      "[26]\ttraining's multi_logloss: 0.347799\tvalid_1's multi_logloss: 0.416436         \n",
      "[27]\ttraining's multi_logloss: 0.336225\tvalid_1's multi_logloss: 0.406597         \n",
      "[28]\ttraining's multi_logloss: 0.325285\tvalid_1's multi_logloss: 0.397502         \n",
      "[29]\ttraining's multi_logloss: 0.31511\tvalid_1's multi_logloss: 0.389185          \n",
      "[30]\ttraining's multi_logloss: 0.305772\tvalid_1's multi_logloss: 0.381942         \n",
      "[31]\ttraining's multi_logloss: 0.296663\tvalid_1's multi_logloss: 0.374655         \n",
      "[32]\ttraining's multi_logloss: 0.288126\tvalid_1's multi_logloss: 0.368161         \n",
      "[33]\ttraining's multi_logloss: 0.280226\tvalid_1's multi_logloss: 0.362219         \n",
      "[34]\ttraining's multi_logloss: 0.27272\tvalid_1's multi_logloss: 0.356745          \n",
      "[35]\ttraining's multi_logloss: 0.265344\tvalid_1's multi_logloss: 0.351369         \n",
      "[36]\ttraining's multi_logloss: 0.258833\tvalid_1's multi_logloss: 0.346888         \n",
      "[37]\ttraining's multi_logloss: 0.252561\tvalid_1's multi_logloss: 0.342511         \n",
      "[38]\ttraining's multi_logloss: 0.246605\tvalid_1's multi_logloss: 0.33859          \n",
      "[39]\ttraining's multi_logloss: 0.241039\tvalid_1's multi_logloss: 0.335061         \n",
      "[40]\ttraining's multi_logloss: 0.235625\tvalid_1's multi_logloss: 0.331857         \n",
      "[41]\ttraining's multi_logloss: 0.230272\tvalid_1's multi_logloss: 0.32872          \n",
      "[42]\ttraining's multi_logloss: 0.225343\tvalid_1's multi_logloss: 0.325988         \n",
      "[43]\ttraining's multi_logloss: 0.220496\tvalid_1's multi_logloss: 0.323364         \n",
      "[44]\ttraining's multi_logloss: 0.215881\tvalid_1's multi_logloss: 0.321021         \n",
      "[45]\ttraining's multi_logloss: 0.211571\tvalid_1's multi_logloss: 0.318897         \n",
      "[46]\ttraining's multi_logloss: 0.207212\tvalid_1's multi_logloss: 0.316418         \n",
      "[47]\ttraining's multi_logloss: 0.203167\tvalid_1's multi_logloss: 0.314392         \n",
      "[48]\ttraining's multi_logloss: 0.199228\tvalid_1's multi_logloss: 0.312613         \n",
      "[49]\ttraining's multi_logloss: 0.195449\tvalid_1's multi_logloss: 0.311254         \n",
      "[50]\ttraining's multi_logloss: 0.191807\tvalid_1's multi_logloss: 0.30961          \n",
      "[51]\ttraining's multi_logloss: 0.188107\tvalid_1's multi_logloss: 0.308283         \n",
      "[52]\ttraining's multi_logloss: 0.184782\tvalid_1's multi_logloss: 0.307206         \n",
      "[53]\ttraining's multi_logloss: 0.181158\tvalid_1's multi_logloss: 0.305964         \n",
      "[54]\ttraining's multi_logloss: 0.177904\tvalid_1's multi_logloss: 0.304796         \n",
      "[55]\ttraining's multi_logloss: 0.174726\tvalid_1's multi_logloss: 0.303837         \n",
      "[56]\ttraining's multi_logloss: 0.17163\tvalid_1's multi_logloss: 0.302773          \n",
      "[57]\ttraining's multi_logloss: 0.168521\tvalid_1's multi_logloss: 0.301893         \n",
      "[58]\ttraining's multi_logloss: 0.165659\tvalid_1's multi_logloss: 0.301126         \n",
      "[59]\ttraining's multi_logloss: 0.162782\tvalid_1's multi_logloss: 0.300475         \n",
      "[60]\ttraining's multi_logloss: 0.159949\tvalid_1's multi_logloss: 0.299666         \n",
      "[61]\ttraining's multi_logloss: 0.157222\tvalid_1's multi_logloss: 0.298905         \n",
      "[62]\ttraining's multi_logloss: 0.15459\tvalid_1's multi_logloss: 0.298246          \n",
      "[63]\ttraining's multi_logloss: 0.152104\tvalid_1's multi_logloss: 0.297566         \n",
      "[64]\ttraining's multi_logloss: 0.149578\tvalid_1's multi_logloss: 0.29677          \n",
      "[65]\ttraining's multi_logloss: 0.14707\tvalid_1's multi_logloss: 0.296263          \n",
      "[66]\ttraining's multi_logloss: 0.144681\tvalid_1's multi_logloss: 0.295981         \n",
      "[67]\ttraining's multi_logloss: 0.142284\tvalid_1's multi_logloss: 0.295561         \n",
      "[68]\ttraining's multi_logloss: 0.140016\tvalid_1's multi_logloss: 0.295251         \n",
      "[69]\ttraining's multi_logloss: 0.137711\tvalid_1's multi_logloss: 0.294665         \n",
      "[70]\ttraining's multi_logloss: 0.135481\tvalid_1's multi_logloss: 0.294207         \n",
      "[71]\ttraining's multi_logloss: 0.13329\tvalid_1's multi_logloss: 0.29381           \n",
      "[72]\ttraining's multi_logloss: 0.131067\tvalid_1's multi_logloss: 0.293312         \n",
      "[73]\ttraining's multi_logloss: 0.129073\tvalid_1's multi_logloss: 0.292782         \n",
      "[74]\ttraining's multi_logloss: 0.127118\tvalid_1's multi_logloss: 0.292495         \n",
      "[75]\ttraining's multi_logloss: 0.125223\tvalid_1's multi_logloss: 0.292371         \n",
      "[76]\ttraining's multi_logloss: 0.123331\tvalid_1's multi_logloss: 0.292013         \n",
      "[77]\ttraining's multi_logloss: 0.12152\tvalid_1's multi_logloss: 0.292077          \n",
      "[78]\ttraining's multi_logloss: 0.119695\tvalid_1's multi_logloss: 0.291941         \n",
      "[79]\ttraining's multi_logloss: 0.117855\tvalid_1's multi_logloss: 0.291935         \n",
      "[80]\ttraining's multi_logloss: 0.116058\tvalid_1's multi_logloss: 0.291839         \n",
      "[81]\ttraining's multi_logloss: 0.114392\tvalid_1's multi_logloss: 0.291915         \n",
      "[82]\ttraining's multi_logloss: 0.112729\tvalid_1's multi_logloss: 0.292111         \n",
      "[83]\ttraining's multi_logloss: 0.110931\tvalid_1's multi_logloss: 0.292174         \n",
      "[84]\ttraining's multi_logloss: 0.109414\tvalid_1's multi_logloss: 0.292203         \n",
      "[85]\ttraining's multi_logloss: 0.107866\tvalid_1's multi_logloss: 0.29215          \n",
      "[86]\ttraining's multi_logloss: 0.106288\tvalid_1's multi_logloss: 0.29237          \n",
      "[87]\ttraining's multi_logloss: 0.104796\tvalid_1's multi_logloss: 0.292365         \n",
      "[88]\ttraining's multi_logloss: 0.103274\tvalid_1's multi_logloss: 0.292238         \n",
      "[89]\ttraining's multi_logloss: 0.10179\tvalid_1's multi_logloss: 0.292531          \n",
      "[90]\ttraining's multi_logloss: 0.100313\tvalid_1's multi_logloss: 0.292596         \n",
      "[91]\ttraining's multi_logloss: 0.0989037\tvalid_1's multi_logloss: 0.292785        \n",
      "[92]\ttraining's multi_logloss: 0.0975276\tvalid_1's multi_logloss: 0.292783        \n",
      "[93]\ttraining's multi_logloss: 0.09622\tvalid_1's multi_logloss: 0.292898          \n",
      "[94]\ttraining's multi_logloss: 0.0949875\tvalid_1's multi_logloss: 0.29308         \n",
      "[95]\ttraining's multi_logloss: 0.0936918\tvalid_1's multi_logloss: 0.293522        \n",
      "[96]\ttraining's multi_logloss: 0.092375\tvalid_1's multi_logloss: 0.293541         \n",
      "[97]\ttraining's multi_logloss: 0.0912295\tvalid_1's multi_logloss: 0.293666        \n",
      "[98]\ttraining's multi_logloss: 0.0899664\tvalid_1's multi_logloss: 0.293938        \n",
      "[99]\ttraining's multi_logloss: 0.0888147\tvalid_1's multi_logloss: 0.294008        \n",
      "[100]\ttraining's multi_logloss: 0.0876964\tvalid_1's multi_logloss: 0.294177       \n",
      "[101]\ttraining's multi_logloss: 0.0865922\tvalid_1's multi_logloss: 0.294435       \n",
      "[102]\ttraining's multi_logloss: 0.0854787\tvalid_1's multi_logloss: 0.294713       \n",
      "[103]\ttraining's multi_logloss: 0.0844119\tvalid_1's multi_logloss: 0.295078       \n",
      "[104]\ttraining's multi_logloss: 0.0833161\tvalid_1's multi_logloss: 0.295385       \n",
      "[105]\ttraining's multi_logloss: 0.0823421\tvalid_1's multi_logloss: 0.295569       \n",
      "[106]\ttraining's multi_logloss: 0.0812628\tvalid_1's multi_logloss: 0.29578        \n",
      "[107]\ttraining's multi_logloss: 0.0802237\tvalid_1's multi_logloss: 0.295973       \n",
      "[108]\ttraining's multi_logloss: 0.0792444\tvalid_1's multi_logloss: 0.296397       \n",
      "[109]\ttraining's multi_logloss: 0.0782489\tvalid_1's multi_logloss: 0.29676        \n",
      "[110]\ttraining's multi_logloss: 0.0773108\tvalid_1's multi_logloss: 0.297053       \n",
      "Early stopping, best iteration is:                                                \n",
      "[80]\ttraining's multi_logloss: 0.116058\tvalid_1's multi_logloss: 0.291839\n",
      "[1]\ttraining's multi_logloss: 1.67392\tvalid_1's multi_logloss: 1.67764            \n",
      "Training until validation scores don't improve for 30 rounds                      \n",
      "[2]\ttraining's multi_logloss: 1.48578\tvalid_1's multi_logloss: 1.49135            \n",
      "[3]\ttraining's multi_logloss: 1.33637\tvalid_1's multi_logloss: 1.34408            \n",
      "[4]\ttraining's multi_logloss: 1.21439\tvalid_1's multi_logloss: 1.22429            \n",
      "[5]\ttraining's multi_logloss: 1.11094\tvalid_1's multi_logloss: 1.12345            \n",
      "[6]\ttraining's multi_logloss: 1.02235\tvalid_1's multi_logloss: 1.03638            \n",
      "[7]\ttraining's multi_logloss: 0.945541\tvalid_1's multi_logloss: 0.961794          \n",
      "[8]\ttraining's multi_logloss: 0.87786\tvalid_1's multi_logloss: 0.896046           \n",
      "[9]\ttraining's multi_logloss: 0.817847\tvalid_1's multi_logloss: 0.838292          \n",
      "[10]\ttraining's multi_logloss: 0.764457\tvalid_1's multi_logloss: 0.78727          \n",
      "[11]\ttraining's multi_logloss: 0.716697\tvalid_1's multi_logloss: 0.741566         \n",
      "[12]\ttraining's multi_logloss: 0.673951\tvalid_1's multi_logloss: 0.700754         \n",
      "[13]\ttraining's multi_logloss: 0.634843\tvalid_1's multi_logloss: 0.66387          \n",
      "[14]\ttraining's multi_logloss: 0.599584\tvalid_1's multi_logloss: 0.630467         \n",
      "[15]\ttraining's multi_logloss: 0.56749\tvalid_1's multi_logloss: 0.600449          \n",
      "[16]\ttraining's multi_logloss: 0.538266\tvalid_1's multi_logloss: 0.572959         \n",
      "[17]\ttraining's multi_logloss: 0.512068\tvalid_1's multi_logloss: 0.548607         \n",
      "[18]\ttraining's multi_logloss: 0.487847\tvalid_1's multi_logloss: 0.52646          \n",
      "[19]\ttraining's multi_logloss: 0.465671\tvalid_1's multi_logloss: 0.505936         \n",
      "[20]\ttraining's multi_logloss: 0.445488\tvalid_1's multi_logloss: 0.487876         \n",
      "[21]\ttraining's multi_logloss: 0.426876\tvalid_1's multi_logloss: 0.471393         \n",
      "[22]\ttraining's multi_logloss: 0.409737\tvalid_1's multi_logloss: 0.456494         \n",
      "[23]\ttraining's multi_logloss: 0.39405\tvalid_1's multi_logloss: 0.443036          \n",
      "[24]\ttraining's multi_logloss: 0.379285\tvalid_1's multi_logloss: 0.43046          \n",
      "[25]\ttraining's multi_logloss: 0.365754\tvalid_1's multi_logloss: 0.419125         \n",
      "[26]\ttraining's multi_logloss: 0.352853\tvalid_1's multi_logloss: 0.408319         \n",
      "[27]\ttraining's multi_logloss: 0.340977\tvalid_1's multi_logloss: 0.398725         \n",
      "[28]\ttraining's multi_logloss: 0.329921\tvalid_1's multi_logloss: 0.390023         \n",
      "[29]\ttraining's multi_logloss: 0.31954\tvalid_1's multi_logloss: 0.381604          \n",
      "[30]\ttraining's multi_logloss: 0.30957\tvalid_1's multi_logloss: 0.373758          \n",
      "[31]\ttraining's multi_logloss: 0.30046\tvalid_1's multi_logloss: 0.366499          \n",
      "[32]\ttraining's multi_logloss: 0.291855\tvalid_1's multi_logloss: 0.359955         \n",
      "[33]\ttraining's multi_logloss: 0.28379\tvalid_1's multi_logloss: 0.354257          \n",
      "[34]\ttraining's multi_logloss: 0.275998\tvalid_1's multi_logloss: 0.348683         \n",
      "[35]\ttraining's multi_logloss: 0.268807\tvalid_1's multi_logloss: 0.343447         \n",
      "[36]\ttraining's multi_logloss: 0.261926\tvalid_1's multi_logloss: 0.338875         \n",
      "[37]\ttraining's multi_logloss: 0.255416\tvalid_1's multi_logloss: 0.334767         \n",
      "[38]\ttraining's multi_logloss: 0.249409\tvalid_1's multi_logloss: 0.330979         \n",
      "[39]\ttraining's multi_logloss: 0.243427\tvalid_1's multi_logloss: 0.327194         \n",
      "[40]\ttraining's multi_logloss: 0.237995\tvalid_1's multi_logloss: 0.324074         \n",
      "[41]\ttraining's multi_logloss: 0.232726\tvalid_1's multi_logloss: 0.321073         \n",
      "[42]\ttraining's multi_logloss: 0.22747\tvalid_1's multi_logloss: 0.318201          \n",
      "[43]\ttraining's multi_logloss: 0.222544\tvalid_1's multi_logloss: 0.315471         \n",
      "[44]\ttraining's multi_logloss: 0.217786\tvalid_1's multi_logloss: 0.313336         \n",
      "[45]\ttraining's multi_logloss: 0.213336\tvalid_1's multi_logloss: 0.311187         \n",
      "[46]\ttraining's multi_logloss: 0.208867\tvalid_1's multi_logloss: 0.308834         \n",
      "[47]\ttraining's multi_logloss: 0.20466\tvalid_1's multi_logloss: 0.307112          \n",
      "[48]\ttraining's multi_logloss: 0.200565\tvalid_1's multi_logloss: 0.305213         \n",
      "[49]\ttraining's multi_logloss: 0.196654\tvalid_1's multi_logloss: 0.303603         \n",
      "[50]\ttraining's multi_logloss: 0.192839\tvalid_1's multi_logloss: 0.302296         \n",
      "[51]\ttraining's multi_logloss: 0.18914\tvalid_1's multi_logloss: 0.301034          \n",
      "[52]\ttraining's multi_logloss: 0.185663\tvalid_1's multi_logloss: 0.299925         \n",
      "[53]\ttraining's multi_logloss: 0.182354\tvalid_1's multi_logloss: 0.298735         \n",
      "[54]\ttraining's multi_logloss: 0.17893\tvalid_1's multi_logloss: 0.29758           \n",
      "[55]\ttraining's multi_logloss: 0.175583\tvalid_1's multi_logloss: 0.29618          \n",
      "[56]\ttraining's multi_logloss: 0.172441\tvalid_1's multi_logloss: 0.295059         \n",
      "[57]\ttraining's multi_logloss: 0.169313\tvalid_1's multi_logloss: 0.294233         \n",
      "[58]\ttraining's multi_logloss: 0.166284\tvalid_1's multi_logloss: 0.293703         \n",
      "[59]\ttraining's multi_logloss: 0.163271\tvalid_1's multi_logloss: 0.292908         \n",
      "[60]\ttraining's multi_logloss: 0.160479\tvalid_1's multi_logloss: 0.292373         \n",
      "[61]\ttraining's multi_logloss: 0.157707\tvalid_1's multi_logloss: 0.2917           \n",
      "[62]\ttraining's multi_logloss: 0.155005\tvalid_1's multi_logloss: 0.290933         \n",
      "[63]\ttraining's multi_logloss: 0.152418\tvalid_1's multi_logloss: 0.290333         \n",
      "[64]\ttraining's multi_logloss: 0.14971\tvalid_1's multi_logloss: 0.28974           \n",
      "[65]\ttraining's multi_logloss: 0.147178\tvalid_1's multi_logloss: 0.289058         \n",
      "[66]\ttraining's multi_logloss: 0.144737\tvalid_1's multi_logloss: 0.288433         \n",
      "[67]\ttraining's multi_logloss: 0.142398\tvalid_1's multi_logloss: 0.28801          \n",
      "[68]\ttraining's multi_logloss: 0.139999\tvalid_1's multi_logloss: 0.287731         \n",
      "[69]\ttraining's multi_logloss: 0.137705\tvalid_1's multi_logloss: 0.28745          \n",
      "[70]\ttraining's multi_logloss: 0.135481\tvalid_1's multi_logloss: 0.286989         \n",
      "[71]\ttraining's multi_logloss: 0.133442\tvalid_1's multi_logloss: 0.286847         \n",
      "[72]\ttraining's multi_logloss: 0.131252\tvalid_1's multi_logloss: 0.286615         \n",
      "[73]\ttraining's multi_logloss: 0.129086\tvalid_1's multi_logloss: 0.286712         \n",
      "[74]\ttraining's multi_logloss: 0.126911\tvalid_1's multi_logloss: 0.286323         \n",
      "[75]\ttraining's multi_logloss: 0.124813\tvalid_1's multi_logloss: 0.286238         \n",
      "[76]\ttraining's multi_logloss: 0.122992\tvalid_1's multi_logloss: 0.286263         \n",
      "[77]\ttraining's multi_logloss: 0.121104\tvalid_1's multi_logloss: 0.286288         \n",
      "[78]\ttraining's multi_logloss: 0.119235\tvalid_1's multi_logloss: 0.28636          \n",
      "[79]\ttraining's multi_logloss: 0.11749\tvalid_1's multi_logloss: 0.286648          \n",
      "[80]\ttraining's multi_logloss: 0.115772\tvalid_1's multi_logloss: 0.286686         \n",
      "[81]\ttraining's multi_logloss: 0.113966\tvalid_1's multi_logloss: 0.286586         \n",
      "[82]\ttraining's multi_logloss: 0.112249\tvalid_1's multi_logloss: 0.286714         \n",
      "[83]\ttraining's multi_logloss: 0.110589\tvalid_1's multi_logloss: 0.286856         \n",
      "[84]\ttraining's multi_logloss: 0.108757\tvalid_1's multi_logloss: 0.286863         \n",
      "[85]\ttraining's multi_logloss: 0.107072\tvalid_1's multi_logloss: 0.286773         \n",
      "[86]\ttraining's multi_logloss: 0.105582\tvalid_1's multi_logloss: 0.286925         \n",
      "[87]\ttraining's multi_logloss: 0.103976\tvalid_1's multi_logloss: 0.286994         \n",
      "[88]\ttraining's multi_logloss: 0.102371\tvalid_1's multi_logloss: 0.286969         \n",
      "[89]\ttraining's multi_logloss: 0.101045\tvalid_1's multi_logloss: 0.286997         \n",
      "[90]\ttraining's multi_logloss: 0.0997143\tvalid_1's multi_logloss: 0.287221        \n",
      "[91]\ttraining's multi_logloss: 0.0982247\tvalid_1's multi_logloss: 0.287419        \n",
      "[92]\ttraining's multi_logloss: 0.0968919\tvalid_1's multi_logloss: 0.287724        \n",
      "[93]\ttraining's multi_logloss: 0.0954682\tvalid_1's multi_logloss: 0.287889        \n",
      "[94]\ttraining's multi_logloss: 0.0941112\tvalid_1's multi_logloss: 0.288076        \n",
      "[95]\ttraining's multi_logloss: 0.0928372\tvalid_1's multi_logloss: 0.288313        \n",
      "[96]\ttraining's multi_logloss: 0.0915395\tvalid_1's multi_logloss: 0.288336        \n",
      "[97]\ttraining's multi_logloss: 0.0903152\tvalid_1's multi_logloss: 0.288473        \n",
      "[98]\ttraining's multi_logloss: 0.0891099\tvalid_1's multi_logloss: 0.288886        \n",
      "[99]\ttraining's multi_logloss: 0.087858\tvalid_1's multi_logloss: 0.289235         \n",
      "[100]\ttraining's multi_logloss: 0.0866517\tvalid_1's multi_logloss: 0.289493       \n",
      "[101]\ttraining's multi_logloss: 0.085515\tvalid_1's multi_logloss: 0.289895        \n",
      "[102]\ttraining's multi_logloss: 0.0842975\tvalid_1's multi_logloss: 0.290272       \n",
      "[103]\ttraining's multi_logloss: 0.0831402\tvalid_1's multi_logloss: 0.290708       \n",
      "[104]\ttraining's multi_logloss: 0.0819243\tvalid_1's multi_logloss: 0.290631       \n",
      "[105]\ttraining's multi_logloss: 0.0808897\tvalid_1's multi_logloss: 0.290967       \n",
      "Early stopping, best iteration is:                                                \n",
      "[75]\ttraining's multi_logloss: 0.124813\tvalid_1's multi_logloss: 0.286238\n",
      "[1]\ttraining's multi_logloss: 1.67488\tvalid_1's multi_logloss: 1.67921            \n",
      "Training until validation scores don't improve for 30 rounds                      \n",
      "[2]\ttraining's multi_logloss: 1.48769\tvalid_1's multi_logloss: 1.49465            \n",
      "[3]\ttraining's multi_logloss: 1.33943\tvalid_1's multi_logloss: 1.34836            \n",
      "[4]\ttraining's multi_logloss: 1.21648\tvalid_1's multi_logloss: 1.2267             \n",
      "[5]\ttraining's multi_logloss: 1.11361\tvalid_1's multi_logloss: 1.12543            \n",
      "[6]\ttraining's multi_logloss: 1.02492\tvalid_1's multi_logloss: 1.03802            \n",
      "[7]\ttraining's multi_logloss: 0.947817\tvalid_1's multi_logloss: 0.962197          \n",
      "[8]\ttraining's multi_logloss: 0.880041\tvalid_1's multi_logloss: 0.895546          \n",
      "[9]\ttraining's multi_logloss: 0.819871\tvalid_1's multi_logloss: 0.83668           \n",
      "[10]\ttraining's multi_logloss: 0.766974\tvalid_1's multi_logloss: 0.784981         \n",
      "[11]\ttraining's multi_logloss: 0.719171\tvalid_1's multi_logloss: 0.738546         \n",
      "[12]\ttraining's multi_logloss: 0.676321\tvalid_1's multi_logloss: 0.697112         \n",
      "[13]\ttraining's multi_logloss: 0.637777\tvalid_1's multi_logloss: 0.660269         \n",
      "[14]\ttraining's multi_logloss: 0.602753\tvalid_1's multi_logloss: 0.627007         \n",
      "[15]\ttraining's multi_logloss: 0.570892\tvalid_1's multi_logloss: 0.596621         \n",
      "[16]\ttraining's multi_logloss: 0.541933\tvalid_1's multi_logloss: 0.56963          \n",
      "[17]\ttraining's multi_logloss: 0.515994\tvalid_1's multi_logloss: 0.545632         \n",
      "[18]\ttraining's multi_logloss: 0.492258\tvalid_1's multi_logloss: 0.52352          \n",
      "[19]\ttraining's multi_logloss: 0.470383\tvalid_1's multi_logloss: 0.503308         \n",
      "[20]\ttraining's multi_logloss: 0.450093\tvalid_1's multi_logloss: 0.484699         \n",
      "[21]\ttraining's multi_logloss: 0.431695\tvalid_1's multi_logloss: 0.46809          \n",
      "[22]\ttraining's multi_logloss: 0.4145\tvalid_1's multi_logloss: 0.452492           \n",
      "[23]\ttraining's multi_logloss: 0.398766\tvalid_1's multi_logloss: 0.438569         \n",
      "[24]\ttraining's multi_logloss: 0.384012\tvalid_1's multi_logloss: 0.425957         \n",
      "[25]\ttraining's multi_logloss: 0.370345\tvalid_1's multi_logloss: 0.413956         \n",
      "[26]\ttraining's multi_logloss: 0.357598\tvalid_1's multi_logloss: 0.403038         \n",
      "[27]\ttraining's multi_logloss: 0.345976\tvalid_1's multi_logloss: 0.393301         \n",
      "[28]\ttraining's multi_logloss: 0.334753\tvalid_1's multi_logloss: 0.384042         \n",
      "[29]\ttraining's multi_logloss: 0.324492\tvalid_1's multi_logloss: 0.375253         \n",
      "[30]\ttraining's multi_logloss: 0.314719\tvalid_1's multi_logloss: 0.36729          \n",
      "[31]\ttraining's multi_logloss: 0.305612\tvalid_1's multi_logloss: 0.36007          \n",
      "[32]\ttraining's multi_logloss: 0.297009\tvalid_1's multi_logloss: 0.353448         \n",
      "[33]\ttraining's multi_logloss: 0.288857\tvalid_1's multi_logloss: 0.347495         \n",
      "[34]\ttraining's multi_logloss: 0.281025\tvalid_1's multi_logloss: 0.341402         \n",
      "[35]\ttraining's multi_logloss: 0.27367\tvalid_1's multi_logloss: 0.335953          \n",
      "[36]\ttraining's multi_logloss: 0.266739\tvalid_1's multi_logloss: 0.331034         \n",
      "[37]\ttraining's multi_logloss: 0.260374\tvalid_1's multi_logloss: 0.326643         \n",
      "[38]\ttraining's multi_logloss: 0.254236\tvalid_1's multi_logloss: 0.322668         \n",
      "[39]\ttraining's multi_logloss: 0.248437\tvalid_1's multi_logloss: 0.318687         \n",
      "[40]\ttraining's multi_logloss: 0.242778\tvalid_1's multi_logloss: 0.315102         \n",
      "[41]\ttraining's multi_logloss: 0.237509\tvalid_1's multi_logloss: 0.311936         \n",
      "[42]\ttraining's multi_logloss: 0.232422\tvalid_1's multi_logloss: 0.308969         \n",
      "[43]\ttraining's multi_logloss: 0.227622\tvalid_1's multi_logloss: 0.305983         \n",
      "[44]\ttraining's multi_logloss: 0.222971\tvalid_1's multi_logloss: 0.303465         \n",
      "[45]\ttraining's multi_logloss: 0.218331\tvalid_1's multi_logloss: 0.300845         \n",
      "[46]\ttraining's multi_logloss: 0.21411\tvalid_1's multi_logloss: 0.298812          \n",
      "[47]\ttraining's multi_logloss: 0.209922\tvalid_1's multi_logloss: 0.29671          \n",
      "[48]\ttraining's multi_logloss: 0.205793\tvalid_1's multi_logloss: 0.294642         \n",
      "[49]\ttraining's multi_logloss: 0.201824\tvalid_1's multi_logloss: 0.292716         \n",
      "[50]\ttraining's multi_logloss: 0.197978\tvalid_1's multi_logloss: 0.291046         \n",
      "[51]\ttraining's multi_logloss: 0.194428\tvalid_1's multi_logloss: 0.28936          \n",
      "[52]\ttraining's multi_logloss: 0.190806\tvalid_1's multi_logloss: 0.288227         \n",
      "[53]\ttraining's multi_logloss: 0.1873\tvalid_1's multi_logloss: 0.287031           \n",
      "[54]\ttraining's multi_logloss: 0.18395\tvalid_1's multi_logloss: 0.285895          \n",
      "[55]\ttraining's multi_logloss: 0.180613\tvalid_1's multi_logloss: 0.284743         \n",
      "[56]\ttraining's multi_logloss: 0.177647\tvalid_1's multi_logloss: 0.283908         \n",
      "[57]\ttraining's multi_logloss: 0.174776\tvalid_1's multi_logloss: 0.282985         \n",
      "[58]\ttraining's multi_logloss: 0.171853\tvalid_1's multi_logloss: 0.28223          \n",
      "[59]\ttraining's multi_logloss: 0.168855\tvalid_1's multi_logloss: 0.281418         \n",
      "[60]\ttraining's multi_logloss: 0.165978\tvalid_1's multi_logloss: 0.280728         \n",
      "[61]\ttraining's multi_logloss: 0.163157\tvalid_1's multi_logloss: 0.280215         \n",
      "[62]\ttraining's multi_logloss: 0.160347\tvalid_1's multi_logloss: 0.279646         \n",
      "[63]\ttraining's multi_logloss: 0.157633\tvalid_1's multi_logloss: 0.278972         \n",
      "[64]\ttraining's multi_logloss: 0.155039\tvalid_1's multi_logloss: 0.278385         \n",
      "[65]\ttraining's multi_logloss: 0.152384\tvalid_1's multi_logloss: 0.277827         \n",
      "[66]\ttraining's multi_logloss: 0.149905\tvalid_1's multi_logloss: 0.277356         \n",
      "[67]\ttraining's multi_logloss: 0.147673\tvalid_1's multi_logloss: 0.276956         \n",
      "[68]\ttraining's multi_logloss: 0.145363\tvalid_1's multi_logloss: 0.276662         \n",
      "[69]\ttraining's multi_logloss: 0.14296\tvalid_1's multi_logloss: 0.276168          \n",
      "[70]\ttraining's multi_logloss: 0.140816\tvalid_1's multi_logloss: 0.275927         \n",
      "[71]\ttraining's multi_logloss: 0.138571\tvalid_1's multi_logloss: 0.275634         \n",
      "[72]\ttraining's multi_logloss: 0.136463\tvalid_1's multi_logloss: 0.275175         \n",
      "[73]\ttraining's multi_logloss: 0.134386\tvalid_1's multi_logloss: 0.275234         \n",
      "[74]\ttraining's multi_logloss: 0.132351\tvalid_1's multi_logloss: 0.274977         \n",
      "[75]\ttraining's multi_logloss: 0.130406\tvalid_1's multi_logloss: 0.274849         \n",
      "[76]\ttraining's multi_logloss: 0.128353\tvalid_1's multi_logloss: 0.274358         \n",
      "[77]\ttraining's multi_logloss: 0.126442\tvalid_1's multi_logloss: 0.27398          \n",
      "[78]\ttraining's multi_logloss: 0.124614\tvalid_1's multi_logloss: 0.273717         \n",
      "[79]\ttraining's multi_logloss: 0.122671\tvalid_1's multi_logloss: 0.273466         \n",
      "[80]\ttraining's multi_logloss: 0.120793\tvalid_1's multi_logloss: 0.273178         \n",
      "[81]\ttraining's multi_logloss: 0.118901\tvalid_1's multi_logloss: 0.27283          \n",
      "[82]\ttraining's multi_logloss: 0.117219\tvalid_1's multi_logloss: 0.272761         \n",
      "[83]\ttraining's multi_logloss: 0.115469\tvalid_1's multi_logloss: 0.27252          \n",
      "[84]\ttraining's multi_logloss: 0.113681\tvalid_1's multi_logloss: 0.272111         \n",
      "[85]\ttraining's multi_logloss: 0.112028\tvalid_1's multi_logloss: 0.27184          \n",
      "[86]\ttraining's multi_logloss: 0.110415\tvalid_1's multi_logloss: 0.271877         \n",
      "[87]\ttraining's multi_logloss: 0.108892\tvalid_1's multi_logloss: 0.271877         \n",
      "[88]\ttraining's multi_logloss: 0.107285\tvalid_1's multi_logloss: 0.271625         \n",
      "[89]\ttraining's multi_logloss: 0.105752\tvalid_1's multi_logloss: 0.271473         \n",
      "[90]\ttraining's multi_logloss: 0.104343\tvalid_1's multi_logloss: 0.271379         \n",
      "[91]\ttraining's multi_logloss: 0.102851\tvalid_1's multi_logloss: 0.271272         \n",
      "[92]\ttraining's multi_logloss: 0.101434\tvalid_1's multi_logloss: 0.271399         \n",
      "[93]\ttraining's multi_logloss: 0.100105\tvalid_1's multi_logloss: 0.271428         \n",
      "[94]\ttraining's multi_logloss: 0.0988104\tvalid_1's multi_logloss: 0.271304        \n",
      "[95]\ttraining's multi_logloss: 0.0974739\tvalid_1's multi_logloss: 0.27121         \n",
      "[96]\ttraining's multi_logloss: 0.0961861\tvalid_1's multi_logloss: 0.27137         \n",
      "[97]\ttraining's multi_logloss: 0.0948761\tvalid_1's multi_logloss: 0.271409        \n",
      "[98]\ttraining's multi_logloss: 0.0936347\tvalid_1's multi_logloss: 0.271647        \n",
      "[99]\ttraining's multi_logloss: 0.0923876\tvalid_1's multi_logloss: 0.271827        \n",
      "[100]\ttraining's multi_logloss: 0.0912319\tvalid_1's multi_logloss: 0.271962       \n",
      "[101]\ttraining's multi_logloss: 0.0900545\tvalid_1's multi_logloss: 0.27191        \n",
      "[102]\ttraining's multi_logloss: 0.0889481\tvalid_1's multi_logloss: 0.27205        \n",
      "[103]\ttraining's multi_logloss: 0.087777\tvalid_1's multi_logloss: 0.272309        \n",
      "[104]\ttraining's multi_logloss: 0.0866801\tvalid_1's multi_logloss: 0.272567       \n",
      "[105]\ttraining's multi_logloss: 0.085539\tvalid_1's multi_logloss: 0.272788        \n",
      "[106]\ttraining's multi_logloss: 0.0844277\tvalid_1's multi_logloss: 0.272929       \n",
      "[107]\ttraining's multi_logloss: 0.0833624\tvalid_1's multi_logloss: 0.273104       \n",
      "[108]\ttraining's multi_logloss: 0.082397\tvalid_1's multi_logloss: 0.273343        \n",
      "[109]\ttraining's multi_logloss: 0.0813055\tvalid_1's multi_logloss: 0.273587       \n",
      "[110]\ttraining's multi_logloss: 0.0802708\tvalid_1's multi_logloss: 0.273943       \n",
      "[111]\ttraining's multi_logloss: 0.0792634\tvalid_1's multi_logloss: 0.274097       \n",
      "[112]\ttraining's multi_logloss: 0.0782941\tvalid_1's multi_logloss: 0.274375       \n",
      "[113]\ttraining's multi_logloss: 0.077312\tvalid_1's multi_logloss: 0.274642        \n",
      "[114]\ttraining's multi_logloss: 0.0763528\tvalid_1's multi_logloss: 0.274939       \n",
      "[115]\ttraining's multi_logloss: 0.0754673\tvalid_1's multi_logloss: 0.275288       \n",
      "[116]\ttraining's multi_logloss: 0.0745566\tvalid_1's multi_logloss: 0.275494       \n",
      "[117]\ttraining's multi_logloss: 0.0736462\tvalid_1's multi_logloss: 0.275846       \n",
      "[118]\ttraining's multi_logloss: 0.0727787\tvalid_1's multi_logloss: 0.276021       \n",
      "[119]\ttraining's multi_logloss: 0.0719605\tvalid_1's multi_logloss: 0.276272       \n",
      "[120]\ttraining's multi_logloss: 0.071001\tvalid_1's multi_logloss: 0.276247        \n",
      "[121]\ttraining's multi_logloss: 0.0701739\tvalid_1's multi_logloss: 0.276505       \n",
      "[122]\ttraining's multi_logloss: 0.0693472\tvalid_1's multi_logloss: 0.276865       \n",
      "[123]\ttraining's multi_logloss: 0.0684932\tvalid_1's multi_logloss: 0.276967       \n",
      "[124]\ttraining's multi_logloss: 0.0676356\tvalid_1's multi_logloss: 0.277059       \n",
      "[125]\ttraining's multi_logloss: 0.0668414\tvalid_1's multi_logloss: 0.277299       \n",
      "Early stopping, best iteration is:                                                \n",
      "[95]\ttraining's multi_logloss: 0.0974739\tvalid_1's multi_logloss: 0.27121\n",
      "[1]\ttraining's multi_logloss: 1.27633\tvalid_1's multi_logloss: 1.28966            \n",
      "Training until validation scores don't improve for 30 rounds                      \n",
      "[2]\ttraining's multi_logloss: 0.98466\tvalid_1's multi_logloss: 1.00695            \n",
      "[3]\ttraining's multi_logloss: 0.7984\tvalid_1's multi_logloss: 0.828519            \n",
      "[4]\ttraining's multi_logloss: 0.667669\tvalid_1's multi_logloss: 0.703165          \n",
      "[5]\ttraining's multi_logloss: 0.57087\tvalid_1's multi_logloss: 0.611681           \n",
      "[6]\ttraining's multi_logloss: 0.497148\tvalid_1's multi_logloss: 0.54173           \n",
      "[7]\ttraining's multi_logloss: 0.440765\tvalid_1's multi_logloss: 0.489903          \n",
      "[8]\ttraining's multi_logloss: 0.39536\tvalid_1's multi_logloss: 0.449286           \n",
      "[9]\ttraining's multi_logloss: 0.358692\tvalid_1's multi_logloss: 0.416824          \n",
      "[10]\ttraining's multi_logloss: 0.329084\tvalid_1's multi_logloss: 0.391874         \n",
      "[11]\ttraining's multi_logloss: 0.304333\tvalid_1's multi_logloss: 0.372342         \n",
      "[12]\ttraining's multi_logloss: 0.283038\tvalid_1's multi_logloss: 0.356856         \n",
      "[13]\ttraining's multi_logloss: 0.265515\tvalid_1's multi_logloss: 0.344795         \n",
      "[14]\ttraining's multi_logloss: 0.249373\tvalid_1's multi_logloss: 0.333437         \n",
      "[15]\ttraining's multi_logloss: 0.235722\tvalid_1's multi_logloss: 0.325007         \n",
      "[16]\ttraining's multi_logloss: 0.22338\tvalid_1's multi_logloss: 0.318973          \n",
      "[17]\ttraining's multi_logloss: 0.212616\tvalid_1's multi_logloss: 0.313219         \n",
      "[18]\ttraining's multi_logloss: 0.202358\tvalid_1's multi_logloss: 0.309305         \n",
      "[19]\ttraining's multi_logloss: 0.193052\tvalid_1's multi_logloss: 0.305097         \n",
      "[20]\ttraining's multi_logloss: 0.184489\tvalid_1's multi_logloss: 0.302107         \n",
      "[21]\ttraining's multi_logloss: 0.176458\tvalid_1's multi_logloss: 0.299759         \n",
      "[22]\ttraining's multi_logloss: 0.16907\tvalid_1's multi_logloss: 0.298258          \n",
      "[23]\ttraining's multi_logloss: 0.16215\tvalid_1's multi_logloss: 0.297167          \n",
      "[24]\ttraining's multi_logloss: 0.155559\tvalid_1's multi_logloss: 0.296329         \n",
      "[25]\ttraining's multi_logloss: 0.149203\tvalid_1's multi_logloss: 0.294557         \n",
      "[26]\ttraining's multi_logloss: 0.142987\tvalid_1's multi_logloss: 0.294419         \n",
      "[27]\ttraining's multi_logloss: 0.137108\tvalid_1's multi_logloss: 0.29395          \n",
      "[28]\ttraining's multi_logloss: 0.131487\tvalid_1's multi_logloss: 0.293388         \n",
      "[29]\ttraining's multi_logloss: 0.126087\tvalid_1's multi_logloss: 0.293268         \n",
      "[30]\ttraining's multi_logloss: 0.121413\tvalid_1's multi_logloss: 0.293872         \n",
      "[31]\ttraining's multi_logloss: 0.116849\tvalid_1's multi_logloss: 0.293537         \n",
      "[32]\ttraining's multi_logloss: 0.112492\tvalid_1's multi_logloss: 0.292904         \n",
      "[33]\ttraining's multi_logloss: 0.107721\tvalid_1's multi_logloss: 0.293409         \n",
      "[34]\ttraining's multi_logloss: 0.103777\tvalid_1's multi_logloss: 0.293594         \n",
      "[35]\ttraining's multi_logloss: 0.0999951\tvalid_1's multi_logloss: 0.29404         \n",
      "[36]\ttraining's multi_logloss: 0.0964979\tvalid_1's multi_logloss: 0.294799        \n",
      "[37]\ttraining's multi_logloss: 0.0928243\tvalid_1's multi_logloss: 0.295797        \n",
      "[38]\ttraining's multi_logloss: 0.0894236\tvalid_1's multi_logloss: 0.296585        \n",
      "[39]\ttraining's multi_logloss: 0.0863177\tvalid_1's multi_logloss: 0.297702        \n",
      "[40]\ttraining's multi_logloss: 0.0831118\tvalid_1's multi_logloss: 0.298275        \n",
      "[41]\ttraining's multi_logloss: 0.0802796\tvalid_1's multi_logloss: 0.299173        \n",
      "[42]\ttraining's multi_logloss: 0.0775392\tvalid_1's multi_logloss: 0.299988        \n",
      "[43]\ttraining's multi_logloss: 0.0750937\tvalid_1's multi_logloss: 0.300892        \n",
      "[44]\ttraining's multi_logloss: 0.0721438\tvalid_1's multi_logloss: 0.300798        \n",
      "[45]\ttraining's multi_logloss: 0.0698305\tvalid_1's multi_logloss: 0.302032        \n",
      "[46]\ttraining's multi_logloss: 0.0674558\tvalid_1's multi_logloss: 0.302483        \n",
      "[47]\ttraining's multi_logloss: 0.0647974\tvalid_1's multi_logloss: 0.303109        \n",
      "[48]\ttraining's multi_logloss: 0.0626983\tvalid_1's multi_logloss: 0.304805        \n",
      "[49]\ttraining's multi_logloss: 0.0607288\tvalid_1's multi_logloss: 0.306373        \n",
      "[50]\ttraining's multi_logloss: 0.0585285\tvalid_1's multi_logloss: 0.307177        \n",
      "[51]\ttraining's multi_logloss: 0.056728\tvalid_1's multi_logloss: 0.308451         \n",
      "[52]\ttraining's multi_logloss: 0.0548828\tvalid_1's multi_logloss: 0.310087        \n",
      "[53]\ttraining's multi_logloss: 0.0530445\tvalid_1's multi_logloss: 0.31159         \n",
      "[54]\ttraining's multi_logloss: 0.051507\tvalid_1's multi_logloss: 0.313282         \n",
      "[55]\ttraining's multi_logloss: 0.0496311\tvalid_1's multi_logloss: 0.314592        \n",
      "[56]\ttraining's multi_logloss: 0.0479306\tvalid_1's multi_logloss: 0.315833        \n",
      "[57]\ttraining's multi_logloss: 0.0462223\tvalid_1's multi_logloss: 0.317694        \n",
      "[58]\ttraining's multi_logloss: 0.0445513\tvalid_1's multi_logloss: 0.319043        \n",
      "[59]\ttraining's multi_logloss: 0.0429479\tvalid_1's multi_logloss: 0.320944        \n",
      "[60]\ttraining's multi_logloss: 0.0414041\tvalid_1's multi_logloss: 0.321976        \n",
      "[61]\ttraining's multi_logloss: 0.0399789\tvalid_1's multi_logloss: 0.323768        \n",
      "[62]\ttraining's multi_logloss: 0.0385586\tvalid_1's multi_logloss: 0.325069        \n",
      "Early stopping, best iteration is:                                                \n",
      "[32]\ttraining's multi_logloss: 0.112492\tvalid_1's multi_logloss: 0.292904\n",
      "[1]\ttraining's multi_logloss: 1.27526\tvalid_1's multi_logloss: 1.28283            \n",
      "Training until validation scores don't improve for 30 rounds                      \n",
      "[2]\ttraining's multi_logloss: 0.986291\tvalid_1's multi_logloss: 0.99828           \n",
      "[3]\ttraining's multi_logloss: 0.803102\tvalid_1's multi_logloss: 0.819797          \n",
      "[4]\ttraining's multi_logloss: 0.671152\tvalid_1's multi_logloss: 0.693638          \n",
      "[5]\ttraining's multi_logloss: 0.575369\tvalid_1's multi_logloss: 0.602921          \n",
      "[6]\ttraining's multi_logloss: 0.501043\tvalid_1's multi_logloss: 0.532076          \n",
      "[7]\ttraining's multi_logloss: 0.443544\tvalid_1's multi_logloss: 0.479414          \n",
      "[8]\ttraining's multi_logloss: 0.398215\tvalid_1's multi_logloss: 0.440594          \n",
      "[9]\ttraining's multi_logloss: 0.361548\tvalid_1's multi_logloss: 0.408711          \n",
      "[10]\ttraining's multi_logloss: 0.331275\tvalid_1's multi_logloss: 0.383499         \n",
      "[11]\ttraining's multi_logloss: 0.306849\tvalid_1's multi_logloss: 0.363903         \n",
      "[12]\ttraining's multi_logloss: 0.28512\tvalid_1's multi_logloss: 0.34789           \n",
      "[13]\ttraining's multi_logloss: 0.266207\tvalid_1's multi_logloss: 0.334606         \n",
      "[14]\ttraining's multi_logloss: 0.250323\tvalid_1's multi_logloss: 0.324948         \n",
      "[15]\ttraining's multi_logloss: 0.236161\tvalid_1's multi_logloss: 0.317187         \n",
      "[16]\ttraining's multi_logloss: 0.224372\tvalid_1's multi_logloss: 0.309942         \n",
      "[17]\ttraining's multi_logloss: 0.213437\tvalid_1's multi_logloss: 0.305288         \n",
      "[18]\ttraining's multi_logloss: 0.202847\tvalid_1's multi_logloss: 0.301602         \n",
      "[19]\ttraining's multi_logloss: 0.193587\tvalid_1's multi_logloss: 0.299133         \n",
      "[20]\ttraining's multi_logloss: 0.18473\tvalid_1's multi_logloss: 0.296004          \n",
      "[21]\ttraining's multi_logloss: 0.176486\tvalid_1's multi_logloss: 0.293827         \n",
      "[22]\ttraining's multi_logloss: 0.168432\tvalid_1's multi_logloss: 0.29176          \n",
      "[23]\ttraining's multi_logloss: 0.160891\tvalid_1's multi_logloss: 0.289892         \n",
      "[24]\ttraining's multi_logloss: 0.153998\tvalid_1's multi_logloss: 0.289151         \n",
      "[25]\ttraining's multi_logloss: 0.147736\tvalid_1's multi_logloss: 0.288358         \n",
      "[26]\ttraining's multi_logloss: 0.141009\tvalid_1's multi_logloss: 0.28721          \n",
      "[27]\ttraining's multi_logloss: 0.134897\tvalid_1's multi_logloss: 0.286612         \n",
      "[28]\ttraining's multi_logloss: 0.129313\tvalid_1's multi_logloss: 0.286519         \n",
      "[29]\ttraining's multi_logloss: 0.12404\tvalid_1's multi_logloss: 0.287228          \n",
      "[30]\ttraining's multi_logloss: 0.118602\tvalid_1's multi_logloss: 0.28769          \n",
      "[31]\ttraining's multi_logloss: 0.113752\tvalid_1's multi_logloss: 0.287679         \n",
      "[32]\ttraining's multi_logloss: 0.109252\tvalid_1's multi_logloss: 0.288843         \n",
      "[33]\ttraining's multi_logloss: 0.104903\tvalid_1's multi_logloss: 0.288883         \n",
      "[34]\ttraining's multi_logloss: 0.100708\tvalid_1's multi_logloss: 0.28926          \n",
      "[35]\ttraining's multi_logloss: 0.0967804\tvalid_1's multi_logloss: 0.28973         \n",
      "[36]\ttraining's multi_logloss: 0.0928744\tvalid_1's multi_logloss: 0.290595        \n",
      "[37]\ttraining's multi_logloss: 0.0896472\tvalid_1's multi_logloss: 0.290704        \n",
      "[38]\ttraining's multi_logloss: 0.0860298\tvalid_1's multi_logloss: 0.291872        \n",
      "[39]\ttraining's multi_logloss: 0.0826628\tvalid_1's multi_logloss: 0.292969        \n",
      "[40]\ttraining's multi_logloss: 0.0797701\tvalid_1's multi_logloss: 0.294459        \n",
      "[41]\ttraining's multi_logloss: 0.0768148\tvalid_1's multi_logloss: 0.295565        \n",
      "[42]\ttraining's multi_logloss: 0.0741139\tvalid_1's multi_logloss: 0.297014        \n",
      "[43]\ttraining's multi_logloss: 0.0716087\tvalid_1's multi_logloss: 0.297534        \n",
      "[44]\ttraining's multi_logloss: 0.0689867\tvalid_1's multi_logloss: 0.298215        \n",
      "[45]\ttraining's multi_logloss: 0.0662042\tvalid_1's multi_logloss: 0.299321        \n",
      "[46]\ttraining's multi_logloss: 0.0639826\tvalid_1's multi_logloss: 0.300379        \n",
      "[47]\ttraining's multi_logloss: 0.0616021\tvalid_1's multi_logloss: 0.302089        \n",
      "[48]\ttraining's multi_logloss: 0.0592437\tvalid_1's multi_logloss: 0.30318         \n",
      "[49]\ttraining's multi_logloss: 0.0573179\tvalid_1's multi_logloss: 0.304786        \n",
      "[50]\ttraining's multi_logloss: 0.0553378\tvalid_1's multi_logloss: 0.306187        \n",
      "[51]\ttraining's multi_logloss: 0.0532221\tvalid_1's multi_logloss: 0.306777        \n",
      "[52]\ttraining's multi_logloss: 0.0515664\tvalid_1's multi_logloss: 0.307901        \n",
      "[53]\ttraining's multi_logloss: 0.0498363\tvalid_1's multi_logloss: 0.309859        \n",
      "[54]\ttraining's multi_logloss: 0.0482495\tvalid_1's multi_logloss: 0.311245        \n",
      "[55]\ttraining's multi_logloss: 0.0465627\tvalid_1's multi_logloss: 0.312637        \n",
      "[56]\ttraining's multi_logloss: 0.0450224\tvalid_1's multi_logloss: 0.314331        \n",
      "[57]\ttraining's multi_logloss: 0.0433753\tvalid_1's multi_logloss: 0.316169        \n",
      "[58]\ttraining's multi_logloss: 0.0419013\tvalid_1's multi_logloss: 0.31777         \n",
      "Early stopping, best iteration is:                                                \n",
      "[28]\ttraining's multi_logloss: 0.129313\tvalid_1's multi_logloss: 0.286519\n",
      "[1]\ttraining's multi_logloss: 1.28063\tvalid_1's multi_logloss: 1.28716            \n",
      "Training until validation scores don't improve for 30 rounds                      \n",
      "[2]\ttraining's multi_logloss: 0.992362\tvalid_1's multi_logloss: 1.00199           \n",
      "[3]\ttraining's multi_logloss: 0.808328\tvalid_1's multi_logloss: 0.821839          \n",
      "[4]\ttraining's multi_logloss: 0.676939\tvalid_1's multi_logloss: 0.694041          \n",
      "[5]\ttraining's multi_logloss: 0.581972\tvalid_1's multi_logloss: 0.602575          \n",
      "[6]\ttraining's multi_logloss: 0.508562\tvalid_1's multi_logloss: 0.533576          \n",
      "[7]\ttraining's multi_logloss: 0.450407\tvalid_1's multi_logloss: 0.479788          \n",
      "[8]\ttraining's multi_logloss: 0.405912\tvalid_1's multi_logloss: 0.439341          \n",
      "[9]\ttraining's multi_logloss: 0.368675\tvalid_1's multi_logloss: 0.405915          \n",
      "[10]\ttraining's multi_logloss: 0.338642\tvalid_1's multi_logloss: 0.379631         \n",
      "[11]\ttraining's multi_logloss: 0.313232\tvalid_1's multi_logloss: 0.359031         \n",
      "[12]\ttraining's multi_logloss: 0.291877\tvalid_1's multi_logloss: 0.342641         \n",
      "[13]\ttraining's multi_logloss: 0.273568\tvalid_1's multi_logloss: 0.330032         \n",
      "[14]\ttraining's multi_logloss: 0.258041\tvalid_1's multi_logloss: 0.318924         \n",
      "[15]\ttraining's multi_logloss: 0.243531\tvalid_1's multi_logloss: 0.310091         \n",
      "[16]\ttraining's multi_logloss: 0.230851\tvalid_1's multi_logloss: 0.303172         \n",
      "[17]\ttraining's multi_logloss: 0.219639\tvalid_1's multi_logloss: 0.297824         \n",
      "[18]\ttraining's multi_logloss: 0.209392\tvalid_1's multi_logloss: 0.293151         \n",
      "[19]\ttraining's multi_logloss: 0.199638\tvalid_1's multi_logloss: 0.289443         \n",
      "[20]\ttraining's multi_logloss: 0.190818\tvalid_1's multi_logloss: 0.286239         \n",
      "[21]\ttraining's multi_logloss: 0.182602\tvalid_1's multi_logloss: 0.283466         \n",
      "[22]\ttraining's multi_logloss: 0.174283\tvalid_1's multi_logloss: 0.281277         \n",
      "[23]\ttraining's multi_logloss: 0.167102\tvalid_1's multi_logloss: 0.279737         \n",
      "[24]\ttraining's multi_logloss: 0.16006\tvalid_1's multi_logloss: 0.278645          \n",
      "[25]\ttraining's multi_logloss: 0.153589\tvalid_1's multi_logloss: 0.277382         \n",
      "[26]\ttraining's multi_logloss: 0.147107\tvalid_1's multi_logloss: 0.276174         \n",
      "[27]\ttraining's multi_logloss: 0.14086\tvalid_1's multi_logloss: 0.275432          \n",
      "[28]\ttraining's multi_logloss: 0.13502\tvalid_1's multi_logloss: 0.274935          \n",
      "[29]\ttraining's multi_logloss: 0.129126\tvalid_1's multi_logloss: 0.274159         \n",
      "[30]\ttraining's multi_logloss: 0.123833\tvalid_1's multi_logloss: 0.27384          \n",
      "[31]\ttraining's multi_logloss: 0.118874\tvalid_1's multi_logloss: 0.274363         \n",
      "[32]\ttraining's multi_logloss: 0.114344\tvalid_1's multi_logloss: 0.274662         \n",
      "[33]\ttraining's multi_logloss: 0.110272\tvalid_1's multi_logloss: 0.274626         \n",
      "[34]\ttraining's multi_logloss: 0.106502\tvalid_1's multi_logloss: 0.274867         \n",
      "[35]\ttraining's multi_logloss: 0.102796\tvalid_1's multi_logloss: 0.275318         \n",
      "[36]\ttraining's multi_logloss: 0.0991383\tvalid_1's multi_logloss: 0.275211        \n",
      "[37]\ttraining's multi_logloss: 0.0955938\tvalid_1's multi_logloss: 0.276335        \n",
      "[38]\ttraining's multi_logloss: 0.0919179\tvalid_1's multi_logloss: 0.27675         \n",
      "[39]\ttraining's multi_logloss: 0.088747\tvalid_1's multi_logloss: 0.277256         \n",
      "[40]\ttraining's multi_logloss: 0.0853791\tvalid_1's multi_logloss: 0.278147        \n",
      "[41]\ttraining's multi_logloss: 0.0822831\tvalid_1's multi_logloss: 0.278295        \n",
      "[42]\ttraining's multi_logloss: 0.0795764\tvalid_1's multi_logloss: 0.279349        \n",
      "[43]\ttraining's multi_logloss: 0.0765634\tvalid_1's multi_logloss: 0.280107        \n",
      "[44]\ttraining's multi_logloss: 0.0737044\tvalid_1's multi_logloss: 0.280232        \n",
      "[45]\ttraining's multi_logloss: 0.0713189\tvalid_1's multi_logloss: 0.2809          \n",
      "[46]\ttraining's multi_logloss: 0.0688604\tvalid_1's multi_logloss: 0.28116         \n",
      "[47]\ttraining's multi_logloss: 0.0666437\tvalid_1's multi_logloss: 0.282074        \n",
      "[48]\ttraining's multi_logloss: 0.0644045\tvalid_1's multi_logloss: 0.283124        \n",
      "[49]\ttraining's multi_logloss: 0.0624571\tvalid_1's multi_logloss: 0.283924        \n",
      "[50]\ttraining's multi_logloss: 0.0603972\tvalid_1's multi_logloss: 0.284755        \n",
      "[51]\ttraining's multi_logloss: 0.0585948\tvalid_1's multi_logloss: 0.286107        \n",
      "[52]\ttraining's multi_logloss: 0.0566441\tvalid_1's multi_logloss: 0.286852        \n",
      "[53]\ttraining's multi_logloss: 0.055049\tvalid_1's multi_logloss: 0.288571         \n",
      "[54]\ttraining's multi_logloss: 0.0533571\tvalid_1's multi_logloss: 0.289769        \n",
      "[55]\ttraining's multi_logloss: 0.0515763\tvalid_1's multi_logloss: 0.290697        \n",
      "[56]\ttraining's multi_logloss: 0.0499248\tvalid_1's multi_logloss: 0.291643        \n",
      "[57]\ttraining's multi_logloss: 0.0481516\tvalid_1's multi_logloss: 0.292812        \n",
      "[58]\ttraining's multi_logloss: 0.0466037\tvalid_1's multi_logloss: 0.294705        \n",
      "[59]\ttraining's multi_logloss: 0.0450361\tvalid_1's multi_logloss: 0.295767        \n",
      "[60]\ttraining's multi_logloss: 0.0435635\tvalid_1's multi_logloss: 0.297031        \n",
      "Early stopping, best iteration is:                                                \n",
      "[30]\ttraining's multi_logloss: 0.123833\tvalid_1's multi_logloss: 0.27384\n",
      "[1]\ttraining's multi_logloss: 1.30285\tvalid_1's multi_logloss: 1.31859            \n",
      "Training until validation scores don't improve for 30 rounds                      \n",
      "[2]\ttraining's multi_logloss: 1.01086\tvalid_1's multi_logloss: 1.037              \n",
      "[3]\ttraining's multi_logloss: 0.821554\tvalid_1's multi_logloss: 0.855265          \n",
      "[4]\ttraining's multi_logloss: 0.686938\tvalid_1's multi_logloss: 0.726584          \n",
      "[5]\ttraining's multi_logloss: 0.586542\tvalid_1's multi_logloss: 0.632175          \n",
      "[6]\ttraining's multi_logloss: 0.509876\tvalid_1's multi_logloss: 0.560608          \n",
      "[7]\ttraining's multi_logloss: 0.449847\tvalid_1's multi_logloss: 0.506085          \n",
      "[8]\ttraining's multi_logloss: 0.401889\tvalid_1's multi_logloss: 0.463739          \n",
      "[9]\ttraining's multi_logloss: 0.362758\tvalid_1's multi_logloss: 0.42993           \n",
      "[10]\ttraining's multi_logloss: 0.331184\tvalid_1's multi_logloss: 0.402652         \n",
      "[11]\ttraining's multi_logloss: 0.305021\tvalid_1's multi_logloss: 0.381554         \n",
      "[12]\ttraining's multi_logloss: 0.282958\tvalid_1's multi_logloss: 0.364749         \n",
      "[13]\ttraining's multi_logloss: 0.264469\tvalid_1's multi_logloss: 0.351202         \n",
      "[14]\ttraining's multi_logloss: 0.248372\tvalid_1's multi_logloss: 0.340461         \n",
      "[15]\ttraining's multi_logloss: 0.234187\tvalid_1's multi_logloss: 0.331371         \n",
      "[16]\ttraining's multi_logloss: 0.221676\tvalid_1's multi_logloss: 0.324876         \n",
      "[17]\ttraining's multi_logloss: 0.210151\tvalid_1's multi_logloss: 0.318669         \n",
      "[18]\ttraining's multi_logloss: 0.199768\tvalid_1's multi_logloss: 0.315096         \n",
      "[19]\ttraining's multi_logloss: 0.190097\tvalid_1's multi_logloss: 0.310621         \n",
      "[20]\ttraining's multi_logloss: 0.181001\tvalid_1's multi_logloss: 0.306736         \n",
      "[21]\ttraining's multi_logloss: 0.173014\tvalid_1's multi_logloss: 0.304297         \n",
      "[22]\ttraining's multi_logloss: 0.165222\tvalid_1's multi_logloss: 0.302938         \n",
      "[23]\ttraining's multi_logloss: 0.158249\tvalid_1's multi_logloss: 0.301001         \n",
      "[24]\ttraining's multi_logloss: 0.151407\tvalid_1's multi_logloss: 0.299738         \n",
      "[25]\ttraining's multi_logloss: 0.145322\tvalid_1's multi_logloss: 0.299076         \n",
      "[26]\ttraining's multi_logloss: 0.13943\tvalid_1's multi_logloss: 0.297999          \n",
      "[27]\ttraining's multi_logloss: 0.133859\tvalid_1's multi_logloss: 0.297079         \n",
      "[28]\ttraining's multi_logloss: 0.128822\tvalid_1's multi_logloss: 0.296985         \n",
      "[29]\ttraining's multi_logloss: 0.124064\tvalid_1's multi_logloss: 0.296246         \n",
      "[30]\ttraining's multi_logloss: 0.119586\tvalid_1's multi_logloss: 0.29573          \n",
      "[31]\ttraining's multi_logloss: 0.114927\tvalid_1's multi_logloss: 0.295921         \n",
      "[32]\ttraining's multi_logloss: 0.110471\tvalid_1's multi_logloss: 0.296214         \n",
      "[33]\ttraining's multi_logloss: 0.106662\tvalid_1's multi_logloss: 0.295846         \n",
      "[34]\ttraining's multi_logloss: 0.102754\tvalid_1's multi_logloss: 0.296637         \n",
      "[35]\ttraining's multi_logloss: 0.0992312\tvalid_1's multi_logloss: 0.296914        \n",
      "[36]\ttraining's multi_logloss: 0.095922\tvalid_1's multi_logloss: 0.296861         \n",
      "[37]\ttraining's multi_logloss: 0.092679\tvalid_1's multi_logloss: 0.297092         \n",
      "[38]\ttraining's multi_logloss: 0.0898298\tvalid_1's multi_logloss: 0.297837        \n",
      "[39]\ttraining's multi_logloss: 0.0870177\tvalid_1's multi_logloss: 0.298481        \n",
      "[40]\ttraining's multi_logloss: 0.0842832\tvalid_1's multi_logloss: 0.299353        \n",
      "[41]\ttraining's multi_logloss: 0.0816322\tvalid_1's multi_logloss: 0.299898        \n",
      "[42]\ttraining's multi_logloss: 0.0792153\tvalid_1's multi_logloss: 0.30055         \n",
      "[43]\ttraining's multi_logloss: 0.0767372\tvalid_1's multi_logloss: 0.301045        \n",
      "[44]\ttraining's multi_logloss: 0.0743337\tvalid_1's multi_logloss: 0.302007        \n",
      "[45]\ttraining's multi_logloss: 0.0718459\tvalid_1's multi_logloss: 0.302419        \n",
      "[46]\ttraining's multi_logloss: 0.0698139\tvalid_1's multi_logloss: 0.303553        \n",
      "[47]\ttraining's multi_logloss: 0.0677936\tvalid_1's multi_logloss: 0.304112        \n",
      "[48]\ttraining's multi_logloss: 0.0655393\tvalid_1's multi_logloss: 0.304564        \n",
      "[49]\ttraining's multi_logloss: 0.0634218\tvalid_1's multi_logloss: 0.305155        \n",
      "[50]\ttraining's multi_logloss: 0.061745\tvalid_1's multi_logloss: 0.305587         \n",
      "[51]\ttraining's multi_logloss: 0.0597569\tvalid_1's multi_logloss: 0.306213        \n",
      "[52]\ttraining's multi_logloss: 0.0577413\tvalid_1's multi_logloss: 0.307879        \n",
      "[53]\ttraining's multi_logloss: 0.0560871\tvalid_1's multi_logloss: 0.308997        \n",
      "[54]\ttraining's multi_logloss: 0.0543297\tvalid_1's multi_logloss: 0.31028         \n",
      "[55]\ttraining's multi_logloss: 0.0527907\tvalid_1's multi_logloss: 0.311455        \n",
      "[56]\ttraining's multi_logloss: 0.0513166\tvalid_1's multi_logloss: 0.312436        \n",
      "[57]\ttraining's multi_logloss: 0.0499574\tvalid_1's multi_logloss: 0.313396        \n",
      "[58]\ttraining's multi_logloss: 0.0484466\tvalid_1's multi_logloss: 0.314464        \n",
      "[59]\ttraining's multi_logloss: 0.0471524\tvalid_1's multi_logloss: 0.315819        \n",
      "[60]\ttraining's multi_logloss: 0.0457767\tvalid_1's multi_logloss: 0.317293        \n",
      "Early stopping, best iteration is:                                                \n",
      "[30]\ttraining's multi_logloss: 0.119586\tvalid_1's multi_logloss: 0.29573\n",
      "[1]\ttraining's multi_logloss: 1.29976\tvalid_1's multi_logloss: 1.3073             \n",
      "Training until validation scores don't improve for 30 rounds                      \n",
      "[2]\ttraining's multi_logloss: 1.01095\tvalid_1's multi_logloss: 1.02406            \n",
      "[3]\ttraining's multi_logloss: 0.822631\tvalid_1's multi_logloss: 0.843007          \n",
      "[4]\ttraining's multi_logloss: 0.689496\tvalid_1's multi_logloss: 0.715777          \n",
      "[5]\ttraining's multi_logloss: 0.59013\tvalid_1's multi_logloss: 0.621631           \n",
      "[6]\ttraining's multi_logloss: 0.513517\tvalid_1's multi_logloss: 0.549285          \n",
      "[7]\ttraining's multi_logloss: 0.45297\tvalid_1's multi_logloss: 0.494412           \n",
      "[8]\ttraining's multi_logloss: 0.405682\tvalid_1's multi_logloss: 0.452156          \n",
      "[9]\ttraining's multi_logloss: 0.367189\tvalid_1's multi_logloss: 0.419084          \n",
      "[10]\ttraining's multi_logloss: 0.335367\tvalid_1's multi_logloss: 0.393206         \n",
      "[11]\ttraining's multi_logloss: 0.308184\tvalid_1's multi_logloss: 0.37191          \n",
      "[12]\ttraining's multi_logloss: 0.285755\tvalid_1's multi_logloss: 0.355539         \n",
      "[13]\ttraining's multi_logloss: 0.266578\tvalid_1's multi_logloss: 0.342037         \n",
      "[14]\ttraining's multi_logloss: 0.249659\tvalid_1's multi_logloss: 0.331141         \n",
      "[15]\ttraining's multi_logloss: 0.234736\tvalid_1's multi_logloss: 0.322606         \n",
      "[16]\ttraining's multi_logloss: 0.221757\tvalid_1's multi_logloss: 0.315313         \n",
      "[17]\ttraining's multi_logloss: 0.209768\tvalid_1's multi_logloss: 0.309227         \n",
      "[18]\ttraining's multi_logloss: 0.19929\tvalid_1's multi_logloss: 0.304904          \n",
      "[19]\ttraining's multi_logloss: 0.189765\tvalid_1's multi_logloss: 0.301307         \n",
      "[20]\ttraining's multi_logloss: 0.181344\tvalid_1's multi_logloss: 0.29809          \n",
      "[21]\ttraining's multi_logloss: 0.173216\tvalid_1's multi_logloss: 0.295822         \n",
      "[22]\ttraining's multi_logloss: 0.165791\tvalid_1's multi_logloss: 0.29394          \n",
      "[23]\ttraining's multi_logloss: 0.158142\tvalid_1's multi_logloss: 0.291717         \n",
      "[24]\ttraining's multi_logloss: 0.151416\tvalid_1's multi_logloss: 0.290254         \n",
      "[25]\ttraining's multi_logloss: 0.145375\tvalid_1's multi_logloss: 0.289262         \n",
      "[26]\ttraining's multi_logloss: 0.139474\tvalid_1's multi_logloss: 0.288865         \n",
      "[27]\ttraining's multi_logloss: 0.134085\tvalid_1's multi_logloss: 0.288384         \n",
      "[28]\ttraining's multi_logloss: 0.128576\tvalid_1's multi_logloss: 0.288027         \n",
      "[29]\ttraining's multi_logloss: 0.123378\tvalid_1's multi_logloss: 0.287219         \n",
      "[30]\ttraining's multi_logloss: 0.118433\tvalid_1's multi_logloss: 0.286885         \n",
      "[31]\ttraining's multi_logloss: 0.113821\tvalid_1's multi_logloss: 0.287444         \n",
      "[32]\ttraining's multi_logloss: 0.10947\tvalid_1's multi_logloss: 0.287549          \n",
      "[33]\ttraining's multi_logloss: 0.105344\tvalid_1's multi_logloss: 0.28756          \n",
      "[34]\ttraining's multi_logloss: 0.101503\tvalid_1's multi_logloss: 0.288706         \n",
      "[35]\ttraining's multi_logloss: 0.0981508\tvalid_1's multi_logloss: 0.289099        \n",
      "[36]\ttraining's multi_logloss: 0.0948052\tvalid_1's multi_logloss: 0.289566        \n",
      "[37]\ttraining's multi_logloss: 0.0913572\tvalid_1's multi_logloss: 0.290126        \n",
      "[38]\ttraining's multi_logloss: 0.0885684\tvalid_1's multi_logloss: 0.29095         \n",
      "[39]\ttraining's multi_logloss: 0.0856254\tvalid_1's multi_logloss: 0.291607        \n",
      "[40]\ttraining's multi_logloss: 0.0827011\tvalid_1's multi_logloss: 0.292368        \n",
      "[41]\ttraining's multi_logloss: 0.0801654\tvalid_1's multi_logloss: 0.292973        \n",
      "[42]\ttraining's multi_logloss: 0.0776409\tvalid_1's multi_logloss: 0.293831        \n",
      "[43]\ttraining's multi_logloss: 0.0751532\tvalid_1's multi_logloss: 0.29462         \n",
      "[44]\ttraining's multi_logloss: 0.0726536\tvalid_1's multi_logloss: 0.29548         \n",
      "[45]\ttraining's multi_logloss: 0.070422\tvalid_1's multi_logloss: 0.295866         \n",
      "[46]\ttraining's multi_logloss: 0.0683259\tvalid_1's multi_logloss: 0.296784        \n",
      "[47]\ttraining's multi_logloss: 0.0663564\tvalid_1's multi_logloss: 0.297938        \n",
      "[48]\ttraining's multi_logloss: 0.0642203\tvalid_1's multi_logloss: 0.29869         \n",
      "[49]\ttraining's multi_logloss: 0.0624677\tvalid_1's multi_logloss: 0.299873        \n",
      "[50]\ttraining's multi_logloss: 0.0606988\tvalid_1's multi_logloss: 0.301217        \n",
      "[51]\ttraining's multi_logloss: 0.05895\tvalid_1's multi_logloss: 0.302325          \n",
      "[52]\ttraining's multi_logloss: 0.0568828\tvalid_1's multi_logloss: 0.302596        \n",
      "[53]\ttraining's multi_logloss: 0.0551646\tvalid_1's multi_logloss: 0.302873        \n",
      "[54]\ttraining's multi_logloss: 0.0535851\tvalid_1's multi_logloss: 0.304759        \n",
      "[55]\ttraining's multi_logloss: 0.052039\tvalid_1's multi_logloss: 0.305845         \n",
      "[56]\ttraining's multi_logloss: 0.0504792\tvalid_1's multi_logloss: 0.306955        \n",
      "[57]\ttraining's multi_logloss: 0.0490362\tvalid_1's multi_logloss: 0.308134        \n",
      "[58]\ttraining's multi_logloss: 0.0477295\tvalid_1's multi_logloss: 0.309334        \n",
      "[59]\ttraining's multi_logloss: 0.0465154\tvalid_1's multi_logloss: 0.311052        \n",
      "[60]\ttraining's multi_logloss: 0.0453068\tvalid_1's multi_logloss: 0.312604        \n",
      "Early stopping, best iteration is:                                                \n",
      "[30]\ttraining's multi_logloss: 0.118433\tvalid_1's multi_logloss: 0.286885\n",
      "[1]\ttraining's multi_logloss: 1.30223\tvalid_1's multi_logloss: 1.31022            \n",
      "Training until validation scores don't improve for 30 rounds                      \n",
      "[2]\ttraining's multi_logloss: 1.01482\tvalid_1's multi_logloss: 1.02628            \n",
      "[3]\ttraining's multi_logloss: 0.826367\tvalid_1's multi_logloss: 0.841215          \n",
      "[4]\ttraining's multi_logloss: 0.692711\tvalid_1's multi_logloss: 0.710725          \n",
      "[5]\ttraining's multi_logloss: 0.592817\tvalid_1's multi_logloss: 0.615121          \n",
      "[6]\ttraining's multi_logloss: 0.516678\tvalid_1's multi_logloss: 0.544418          \n",
      "[7]\ttraining's multi_logloss: 0.458269\tvalid_1's multi_logloss: 0.490976          \n",
      "[8]\ttraining's multi_logloss: 0.411068\tvalid_1's multi_logloss: 0.448084          \n",
      "[9]\ttraining's multi_logloss: 0.372222\tvalid_1's multi_logloss: 0.41274           \n",
      "[10]\ttraining's multi_logloss: 0.340349\tvalid_1's multi_logloss: 0.386007         \n",
      "[11]\ttraining's multi_logloss: 0.313555\tvalid_1's multi_logloss: 0.363786         \n",
      "[12]\ttraining's multi_logloss: 0.290739\tvalid_1's multi_logloss: 0.346132         \n",
      "[13]\ttraining's multi_logloss: 0.271932\tvalid_1's multi_logloss: 0.333254         \n",
      "[14]\ttraining's multi_logloss: 0.255109\tvalid_1's multi_logloss: 0.321397         \n",
      "[15]\ttraining's multi_logloss: 0.24079\tvalid_1's multi_logloss: 0.312518          \n",
      "[16]\ttraining's multi_logloss: 0.2278\tvalid_1's multi_logloss: 0.304883           \n",
      "[17]\ttraining's multi_logloss: 0.216373\tvalid_1's multi_logloss: 0.299083         \n",
      "[18]\ttraining's multi_logloss: 0.205884\tvalid_1's multi_logloss: 0.294102         \n",
      "[19]\ttraining's multi_logloss: 0.196343\tvalid_1's multi_logloss: 0.289796         \n",
      "[20]\ttraining's multi_logloss: 0.187232\tvalid_1's multi_logloss: 0.286606         \n",
      "[21]\ttraining's multi_logloss: 0.178899\tvalid_1's multi_logloss: 0.283302         \n",
      "[22]\ttraining's multi_logloss: 0.171423\tvalid_1's multi_logloss: 0.280732         \n",
      "[23]\ttraining's multi_logloss: 0.164145\tvalid_1's multi_logloss: 0.279262         \n",
      "[24]\ttraining's multi_logloss: 0.157431\tvalid_1's multi_logloss: 0.27784          \n",
      "[25]\ttraining's multi_logloss: 0.150905\tvalid_1's multi_logloss: 0.27612          \n",
      "[26]\ttraining's multi_logloss: 0.144883\tvalid_1's multi_logloss: 0.275402         \n",
      "[27]\ttraining's multi_logloss: 0.139072\tvalid_1's multi_logloss: 0.275006         \n",
      "[28]\ttraining's multi_logloss: 0.133797\tvalid_1's multi_logloss: 0.274746         \n",
      "[29]\ttraining's multi_logloss: 0.12864\tvalid_1's multi_logloss: 0.274348          \n",
      "[30]\ttraining's multi_logloss: 0.123853\tvalid_1's multi_logloss: 0.273966         \n",
      "[31]\ttraining's multi_logloss: 0.119275\tvalid_1's multi_logloss: 0.274053         \n",
      "[32]\ttraining's multi_logloss: 0.115158\tvalid_1's multi_logloss: 0.273909         \n",
      "[33]\ttraining's multi_logloss: 0.111114\tvalid_1's multi_logloss: 0.27328          \n",
      "[34]\ttraining's multi_logloss: 0.10731\tvalid_1's multi_logloss: 0.272844          \n",
      "[35]\ttraining's multi_logloss: 0.103547\tvalid_1's multi_logloss: 0.273044         \n",
      "[36]\ttraining's multi_logloss: 0.0998473\tvalid_1's multi_logloss: 0.273825        \n",
      "[37]\ttraining's multi_logloss: 0.0965499\tvalid_1's multi_logloss: 0.274965        \n",
      "[38]\ttraining's multi_logloss: 0.0933296\tvalid_1's multi_logloss: 0.275614        \n",
      "[39]\ttraining's multi_logloss: 0.0904069\tvalid_1's multi_logloss: 0.275896        \n",
      "[40]\ttraining's multi_logloss: 0.0874552\tvalid_1's multi_logloss: 0.276841        \n",
      "[41]\ttraining's multi_logloss: 0.0847137\tvalid_1's multi_logloss: 0.277548        \n",
      "[42]\ttraining's multi_logloss: 0.0820851\tvalid_1's multi_logloss: 0.278058        \n",
      "[43]\ttraining's multi_logloss: 0.0796589\tvalid_1's multi_logloss: 0.278967        \n",
      "[44]\ttraining's multi_logloss: 0.0772362\tvalid_1's multi_logloss: 0.279266        \n",
      "[45]\ttraining's multi_logloss: 0.0748559\tvalid_1's multi_logloss: 0.279609        \n",
      "[46]\ttraining's multi_logloss: 0.0727115\tvalid_1's multi_logloss: 0.280274        \n",
      "[47]\ttraining's multi_logloss: 0.0703837\tvalid_1's multi_logloss: 0.281079        \n",
      "[48]\ttraining's multi_logloss: 0.0682912\tvalid_1's multi_logloss: 0.281974        \n",
      "[49]\ttraining's multi_logloss: 0.0661276\tvalid_1's multi_logloss: 0.282352        \n",
      "[50]\ttraining's multi_logloss: 0.0641956\tvalid_1's multi_logloss: 0.282979        \n",
      "[51]\ttraining's multi_logloss: 0.0624303\tvalid_1's multi_logloss: 0.283611        \n",
      "[52]\ttraining's multi_logloss: 0.0606798\tvalid_1's multi_logloss: 0.284469        \n",
      "[53]\ttraining's multi_logloss: 0.0589636\tvalid_1's multi_logloss: 0.285427        \n",
      "[54]\ttraining's multi_logloss: 0.0573098\tvalid_1's multi_logloss: 0.286308        \n",
      "[55]\ttraining's multi_logloss: 0.0556077\tvalid_1's multi_logloss: 0.287249        \n",
      "[56]\ttraining's multi_logloss: 0.0539386\tvalid_1's multi_logloss: 0.288087        \n",
      "[57]\ttraining's multi_logloss: 0.052488\tvalid_1's multi_logloss: 0.289329         \n",
      "[58]\ttraining's multi_logloss: 0.0508925\tvalid_1's multi_logloss: 0.291007        \n",
      "[59]\ttraining's multi_logloss: 0.0495267\tvalid_1's multi_logloss: 0.29148         \n",
      "[60]\ttraining's multi_logloss: 0.0481985\tvalid_1's multi_logloss: 0.292374        \n",
      "[61]\ttraining's multi_logloss: 0.0468007\tvalid_1's multi_logloss: 0.293322        \n",
      "[62]\ttraining's multi_logloss: 0.0455792\tvalid_1's multi_logloss: 0.294669        \n",
      "[63]\ttraining's multi_logloss: 0.0444268\tvalid_1's multi_logloss: 0.295744        \n",
      "[64]\ttraining's multi_logloss: 0.043282\tvalid_1's multi_logloss: 0.296974         \n",
      "Early stopping, best iteration is:                                                \n",
      "[34]\ttraining's multi_logloss: 0.10731\tvalid_1's multi_logloss: 0.272844\n",
      "[1]\ttraining's multi_logloss: 1.79397\tvalid_1's multi_logloss: 1.79517            \n",
      "Training until validation scores don't improve for 30 rounds                      \n",
      "[2]\ttraining's multi_logloss: 1.67673\tvalid_1's multi_logloss: 1.6814             \n",
      "[3]\ttraining's multi_logloss: 1.57472\tvalid_1's multi_logloss: 1.58243            \n",
      "[4]\ttraining's multi_logloss: 1.48455\tvalid_1's multi_logloss: 1.49541            \n",
      "[5]\ttraining's multi_logloss: 1.40431\tvalid_1's multi_logloss: 1.41798            \n",
      "[6]\ttraining's multi_logloss: 1.33147\tvalid_1's multi_logloss: 1.34743            \n",
      "[7]\ttraining's multi_logloss: 1.26536\tvalid_1's multi_logloss: 1.2833             \n",
      "[8]\ttraining's multi_logloss: 1.205\tvalid_1's multi_logloss: 1.22485              \n",
      "[9]\ttraining's multi_logloss: 1.14948\tvalid_1's multi_logloss: 1.17133            \n",
      "[10]\ttraining's multi_logloss: 1.09821\tvalid_1's multi_logloss: 1.12188           \n",
      "[11]\ttraining's multi_logloss: 1.05101\tvalid_1's multi_logloss: 1.07647           \n",
      "[12]\ttraining's multi_logloss: 1.00711\tvalid_1's multi_logloss: 1.03425           \n",
      "[13]\ttraining's multi_logloss: 0.966305\tvalid_1's multi_logloss: 0.995204         \n",
      "[14]\ttraining's multi_logloss: 0.927968\tvalid_1's multi_logloss: 0.958354         \n",
      "[15]\ttraining's multi_logloss: 0.892372\tvalid_1's multi_logloss: 0.924078         \n",
      "[16]\ttraining's multi_logloss: 0.858834\tvalid_1's multi_logloss: 0.892212         \n",
      "[17]\ttraining's multi_logloss: 0.827466\tvalid_1's multi_logloss: 0.862221         \n",
      "[18]\ttraining's multi_logloss: 0.797559\tvalid_1's multi_logloss: 0.833601         \n",
      "[19]\ttraining's multi_logloss: 0.76931\tvalid_1's multi_logloss: 0.806577          \n",
      "[20]\ttraining's multi_logloss: 0.742927\tvalid_1's multi_logloss: 0.781286         \n",
      "[21]\ttraining's multi_logloss: 0.71787\tvalid_1's multi_logloss: 0.757366          \n",
      "[22]\ttraining's multi_logloss: 0.694204\tvalid_1's multi_logloss: 0.734748         \n",
      "[23]\ttraining's multi_logloss: 0.671765\tvalid_1's multi_logloss: 0.713488         \n",
      "[24]\ttraining's multi_logloss: 0.650531\tvalid_1's multi_logloss: 0.693485         \n",
      "[25]\ttraining's multi_logloss: 0.630455\tvalid_1's multi_logloss: 0.674599         \n",
      "[26]\ttraining's multi_logloss: 0.611474\tvalid_1's multi_logloss: 0.656788         \n",
      "[27]\ttraining's multi_logloss: 0.593419\tvalid_1's multi_logloss: 0.639925         \n",
      "[28]\ttraining's multi_logloss: 0.576112\tvalid_1's multi_logloss: 0.62388          \n",
      "[29]\ttraining's multi_logloss: 0.559773\tvalid_1's multi_logloss: 0.608654         \n",
      "[30]\ttraining's multi_logloss: 0.544132\tvalid_1's multi_logloss: 0.594236         \n",
      "[31]\ttraining's multi_logloss: 0.529132\tvalid_1's multi_logloss: 0.580434         \n",
      "[32]\ttraining's multi_logloss: 0.514829\tvalid_1's multi_logloss: 0.567293         \n",
      "[33]\ttraining's multi_logloss: 0.501461\tvalid_1's multi_logloss: 0.555127         \n",
      "[34]\ttraining's multi_logloss: 0.488335\tvalid_1's multi_logloss: 0.543075         \n",
      "[35]\ttraining's multi_logloss: 0.475989\tvalid_1's multi_logloss: 0.53187          \n",
      "[36]\ttraining's multi_logloss: 0.46412\tvalid_1's multi_logloss: 0.521085          \n",
      "[37]\ttraining's multi_logloss: 0.452882\tvalid_1's multi_logloss: 0.510956         \n",
      "[38]\ttraining's multi_logloss: 0.442024\tvalid_1's multi_logloss: 0.5013           \n",
      "[39]\ttraining's multi_logloss: 0.431624\tvalid_1's multi_logloss: 0.492021         \n",
      "[40]\ttraining's multi_logloss: 0.42174\tvalid_1's multi_logloss: 0.483272          \n",
      "[41]\ttraining's multi_logloss: 0.412172\tvalid_1's multi_logloss: 0.474815         \n",
      "[42]\ttraining's multi_logloss: 0.40293\tvalid_1's multi_logloss: 0.466751          \n",
      "[43]\ttraining's multi_logloss: 0.394147\tvalid_1's multi_logloss: 0.459167         \n",
      "[44]\ttraining's multi_logloss: 0.385868\tvalid_1's multi_logloss: 0.451975         \n",
      "[45]\ttraining's multi_logloss: 0.377835\tvalid_1's multi_logloss: 0.445053         \n",
      "[46]\ttraining's multi_logloss: 0.37002\tvalid_1's multi_logloss: 0.438241          \n",
      "[47]\ttraining's multi_logloss: 0.362674\tvalid_1's multi_logloss: 0.432018         \n",
      "[48]\ttraining's multi_logloss: 0.355631\tvalid_1's multi_logloss: 0.426197         \n",
      "[49]\ttraining's multi_logloss: 0.348753\tvalid_1's multi_logloss: 0.42033          \n",
      "[50]\ttraining's multi_logloss: 0.342069\tvalid_1's multi_logloss: 0.414728         \n",
      "[51]\ttraining's multi_logloss: 0.335759\tvalid_1's multi_logloss: 0.409498         \n",
      "[52]\ttraining's multi_logloss: 0.329619\tvalid_1's multi_logloss: 0.404429         \n",
      "[53]\ttraining's multi_logloss: 0.323844\tvalid_1's multi_logloss: 0.39975          \n",
      "[54]\ttraining's multi_logloss: 0.318266\tvalid_1's multi_logloss: 0.395226         \n",
      "[55]\ttraining's multi_logloss: 0.312689\tvalid_1's multi_logloss: 0.390877         \n",
      "[56]\ttraining's multi_logloss: 0.307509\tvalid_1's multi_logloss: 0.38682          \n",
      "[57]\ttraining's multi_logloss: 0.302453\tvalid_1's multi_logloss: 0.382938         \n",
      "[58]\ttraining's multi_logloss: 0.29746\tvalid_1's multi_logloss: 0.378985          \n",
      "[59]\ttraining's multi_logloss: 0.292684\tvalid_1's multi_logloss: 0.375319         \n",
      "[60]\ttraining's multi_logloss: 0.288016\tvalid_1's multi_logloss: 0.371756         \n",
      "[61]\ttraining's multi_logloss: 0.283572\tvalid_1's multi_logloss: 0.368364         \n",
      "[62]\ttraining's multi_logloss: 0.279205\tvalid_1's multi_logloss: 0.365029         \n",
      "[63]\ttraining's multi_logloss: 0.275106\tvalid_1's multi_logloss: 0.362074         \n",
      "[64]\ttraining's multi_logloss: 0.270837\tvalid_1's multi_logloss: 0.35901          \n",
      "[65]\ttraining's multi_logloss: 0.26686\tvalid_1's multi_logloss: 0.356148          \n",
      "[66]\ttraining's multi_logloss: 0.263002\tvalid_1's multi_logloss: 0.353412         \n",
      "[67]\ttraining's multi_logloss: 0.259287\tvalid_1's multi_logloss: 0.350861         \n",
      "[68]\ttraining's multi_logloss: 0.255587\tvalid_1's multi_logloss: 0.348367         \n",
      "[69]\ttraining's multi_logloss: 0.252015\tvalid_1's multi_logloss: 0.345962         \n",
      "[70]\ttraining's multi_logloss: 0.248662\tvalid_1's multi_logloss: 0.343726         \n",
      "[71]\ttraining's multi_logloss: 0.245272\tvalid_1's multi_logloss: 0.341614         \n",
      "[72]\ttraining's multi_logloss: 0.242014\tvalid_1's multi_logloss: 0.339485         \n",
      "[73]\ttraining's multi_logloss: 0.238895\tvalid_1's multi_logloss: 0.337492         \n",
      "[74]\ttraining's multi_logloss: 0.235828\tvalid_1's multi_logloss: 0.33568          \n",
      "[75]\ttraining's multi_logloss: 0.232828\tvalid_1's multi_logloss: 0.333883         \n",
      "[76]\ttraining's multi_logloss: 0.229874\tvalid_1's multi_logloss: 0.332058         \n",
      "[77]\ttraining's multi_logloss: 0.226985\tvalid_1's multi_logloss: 0.330372         \n",
      "[78]\ttraining's multi_logloss: 0.224193\tvalid_1's multi_logloss: 0.328839         \n",
      "[79]\ttraining's multi_logloss: 0.221433\tvalid_1's multi_logloss: 0.327263         \n",
      "[80]\ttraining's multi_logloss: 0.218627\tvalid_1's multi_logloss: 0.325827         \n",
      "[81]\ttraining's multi_logloss: 0.215984\tvalid_1's multi_logloss: 0.324482         \n",
      "[82]\ttraining's multi_logloss: 0.213279\tvalid_1's multi_logloss: 0.323062         \n",
      "[83]\ttraining's multi_logloss: 0.210721\tvalid_1's multi_logloss: 0.321767         \n",
      "[84]\ttraining's multi_logloss: 0.208203\tvalid_1's multi_logloss: 0.320485         \n",
      "[85]\ttraining's multi_logloss: 0.205703\tvalid_1's multi_logloss: 0.319114         \n",
      "[86]\ttraining's multi_logloss: 0.203318\tvalid_1's multi_logloss: 0.318091         \n",
      "[87]\ttraining's multi_logloss: 0.200993\tvalid_1's multi_logloss: 0.317094         \n",
      "[88]\ttraining's multi_logloss: 0.198613\tvalid_1's multi_logloss: 0.31596          \n",
      "[89]\ttraining's multi_logloss: 0.196356\tvalid_1's multi_logloss: 0.314778         \n",
      "[90]\ttraining's multi_logloss: 0.194077\tvalid_1's multi_logloss: 0.313774         \n",
      "[91]\ttraining's multi_logloss: 0.191986\tvalid_1's multi_logloss: 0.313056         \n",
      "[92]\ttraining's multi_logloss: 0.189891\tvalid_1's multi_logloss: 0.312246         \n",
      "[93]\ttraining's multi_logloss: 0.187693\tvalid_1's multi_logloss: 0.311357         \n",
      "[94]\ttraining's multi_logloss: 0.185589\tvalid_1's multi_logloss: 0.310505         \n",
      "[95]\ttraining's multi_logloss: 0.183515\tvalid_1's multi_logloss: 0.309828         \n",
      "[96]\ttraining's multi_logloss: 0.18143\tvalid_1's multi_logloss: 0.309251          \n",
      "[97]\ttraining's multi_logloss: 0.179417\tvalid_1's multi_logloss: 0.308669         \n",
      "[98]\ttraining's multi_logloss: 0.177436\tvalid_1's multi_logloss: 0.307925         \n",
      "[99]\ttraining's multi_logloss: 0.175531\tvalid_1's multi_logloss: 0.307441         \n",
      "[100]\ttraining's multi_logloss: 0.173621\tvalid_1's multi_logloss: 0.306711        \n",
      "[101]\ttraining's multi_logloss: 0.171734\tvalid_1's multi_logloss: 0.306037        \n",
      "[102]\ttraining's multi_logloss: 0.1699\tvalid_1's multi_logloss: 0.305459          \n",
      "[103]\ttraining's multi_logloss: 0.168148\tvalid_1's multi_logloss: 0.305019        \n",
      "[104]\ttraining's multi_logloss: 0.166455\tvalid_1's multi_logloss: 0.304415        \n",
      "[105]\ttraining's multi_logloss: 0.16481\tvalid_1's multi_logloss: 0.303929         \n",
      "[106]\ttraining's multi_logloss: 0.163077\tvalid_1's multi_logloss: 0.303329        \n",
      "[107]\ttraining's multi_logloss: 0.161461\tvalid_1's multi_logloss: 0.302814        \n",
      "[108]\ttraining's multi_logloss: 0.15971\tvalid_1's multi_logloss: 0.302227         \n",
      "[109]\ttraining's multi_logloss: 0.158164\tvalid_1's multi_logloss: 0.301891        \n",
      "[110]\ttraining's multi_logloss: 0.156576\tvalid_1's multi_logloss: 0.301441        \n",
      "[111]\ttraining's multi_logloss: 0.154992\tvalid_1's multi_logloss: 0.300973        \n",
      "[112]\ttraining's multi_logloss: 0.153479\tvalid_1's multi_logloss: 0.300598        \n",
      "[113]\ttraining's multi_logloss: 0.151931\tvalid_1's multi_logloss: 0.30023         \n",
      "[114]\ttraining's multi_logloss: 0.150461\tvalid_1's multi_logloss: 0.299882        \n",
      "[115]\ttraining's multi_logloss: 0.149024\tvalid_1's multi_logloss: 0.29954         \n",
      "[116]\ttraining's multi_logloss: 0.147549\tvalid_1's multi_logloss: 0.299132        \n",
      "[117]\ttraining's multi_logloss: 0.146144\tvalid_1's multi_logloss: 0.298795        \n",
      "[118]\ttraining's multi_logloss: 0.144659\tvalid_1's multi_logloss: 0.29861         \n",
      "[119]\ttraining's multi_logloss: 0.143356\tvalid_1's multi_logloss: 0.29829         \n",
      "[120]\ttraining's multi_logloss: 0.141977\tvalid_1's multi_logloss: 0.297849        \n",
      "[121]\ttraining's multi_logloss: 0.140622\tvalid_1's multi_logloss: 0.297628        \n",
      "[122]\ttraining's multi_logloss: 0.139327\tvalid_1's multi_logloss: 0.297297        \n",
      "[123]\ttraining's multi_logloss: 0.138037\tvalid_1's multi_logloss: 0.297178        \n",
      "[124]\ttraining's multi_logloss: 0.136717\tvalid_1's multi_logloss: 0.297079        \n",
      "[125]\ttraining's multi_logloss: 0.13543\tvalid_1's multi_logloss: 0.296777         \n",
      "[126]\ttraining's multi_logloss: 0.134114\tvalid_1's multi_logloss: 0.296506        \n",
      "[127]\ttraining's multi_logloss: 0.132877\tvalid_1's multi_logloss: 0.296424        \n",
      "[128]\ttraining's multi_logloss: 0.131704\tvalid_1's multi_logloss: 0.296231        \n",
      "[129]\ttraining's multi_logloss: 0.130504\tvalid_1's multi_logloss: 0.296139        \n",
      "[130]\ttraining's multi_logloss: 0.129298\tvalid_1's multi_logloss: 0.295847        \n",
      "[131]\ttraining's multi_logloss: 0.128064\tvalid_1's multi_logloss: 0.295585        \n",
      "[132]\ttraining's multi_logloss: 0.126827\tvalid_1's multi_logloss: 0.295314        \n",
      "[133]\ttraining's multi_logloss: 0.125678\tvalid_1's multi_logloss: 0.295094        \n",
      "[134]\ttraining's multi_logloss: 0.124566\tvalid_1's multi_logloss: 0.29493         \n",
      "[135]\ttraining's multi_logloss: 0.123385\tvalid_1's multi_logloss: 0.294737        \n",
      "[136]\ttraining's multi_logloss: 0.122309\tvalid_1's multi_logloss: 0.294652        \n",
      "[137]\ttraining's multi_logloss: 0.121227\tvalid_1's multi_logloss: 0.294477        \n",
      "[138]\ttraining's multi_logloss: 0.120111\tvalid_1's multi_logloss: 0.294409        \n",
      "[139]\ttraining's multi_logloss: 0.119005\tvalid_1's multi_logloss: 0.294272        \n",
      "[140]\ttraining's multi_logloss: 0.117889\tvalid_1's multi_logloss: 0.294133        \n",
      "[141]\ttraining's multi_logloss: 0.116887\tvalid_1's multi_logloss: 0.294049        \n",
      "[142]\ttraining's multi_logloss: 0.115882\tvalid_1's multi_logloss: 0.294138        \n",
      "[143]\ttraining's multi_logloss: 0.114823\tvalid_1's multi_logloss: 0.293992        \n",
      "[144]\ttraining's multi_logloss: 0.113792\tvalid_1's multi_logloss: 0.293801        \n",
      "[145]\ttraining's multi_logloss: 0.112759\tvalid_1's multi_logloss: 0.293868        \n",
      "[146]\ttraining's multi_logloss: 0.111773\tvalid_1's multi_logloss: 0.293848        \n",
      "[147]\ttraining's multi_logloss: 0.110834\tvalid_1's multi_logloss: 0.293815        \n",
      "[148]\ttraining's multi_logloss: 0.109877\tvalid_1's multi_logloss: 0.293751        \n",
      "[149]\ttraining's multi_logloss: 0.10895\tvalid_1's multi_logloss: 0.293646         \n",
      "[150]\ttraining's multi_logloss: 0.107979\tvalid_1's multi_logloss: 0.293537        \n",
      "[151]\ttraining's multi_logloss: 0.107047\tvalid_1's multi_logloss: 0.293512        \n",
      "[152]\ttraining's multi_logloss: 0.106141\tvalid_1's multi_logloss: 0.293458        \n",
      "[153]\ttraining's multi_logloss: 0.105224\tvalid_1's multi_logloss: 0.293496        \n",
      "[154]\ttraining's multi_logloss: 0.104309\tvalid_1's multi_logloss: 0.293489        \n",
      "[155]\ttraining's multi_logloss: 0.103426\tvalid_1's multi_logloss: 0.293548        \n",
      "[156]\ttraining's multi_logloss: 0.102552\tvalid_1's multi_logloss: 0.293546        \n",
      "[157]\ttraining's multi_logloss: 0.101682\tvalid_1's multi_logloss: 0.293486        \n",
      "[158]\ttraining's multi_logloss: 0.100804\tvalid_1's multi_logloss: 0.293523        \n",
      "[159]\ttraining's multi_logloss: 0.0999073\tvalid_1's multi_logloss: 0.293637       \n",
      "[160]\ttraining's multi_logloss: 0.0990636\tvalid_1's multi_logloss: 0.293776       \n",
      "[161]\ttraining's multi_logloss: 0.0982139\tvalid_1's multi_logloss: 0.293801       \n",
      "[162]\ttraining's multi_logloss: 0.0973781\tvalid_1's multi_logloss: 0.293848       \n",
      "[163]\ttraining's multi_logloss: 0.0965219\tvalid_1's multi_logloss: 0.293778       \n",
      "[164]\ttraining's multi_logloss: 0.095725\tvalid_1's multi_logloss: 0.293811        \n",
      "[165]\ttraining's multi_logloss: 0.0948591\tvalid_1's multi_logloss: 0.293878       \n",
      "[166]\ttraining's multi_logloss: 0.0940469\tvalid_1's multi_logloss: 0.293932       \n",
      "[167]\ttraining's multi_logloss: 0.0932567\tvalid_1's multi_logloss: 0.29396        \n",
      "[168]\ttraining's multi_logloss: 0.0924767\tvalid_1's multi_logloss: 0.293943       \n",
      "[169]\ttraining's multi_logloss: 0.0916935\tvalid_1's multi_logloss: 0.294034       \n",
      "[170]\ttraining's multi_logloss: 0.0909563\tvalid_1's multi_logloss: 0.294178       \n",
      "[171]\ttraining's multi_logloss: 0.0902031\tvalid_1's multi_logloss: 0.294215       \n",
      "[172]\ttraining's multi_logloss: 0.0894558\tvalid_1's multi_logloss: 0.294284       \n",
      "[173]\ttraining's multi_logloss: 0.088739\tvalid_1's multi_logloss: 0.294501        \n",
      "[174]\ttraining's multi_logloss: 0.0879885\tvalid_1's multi_logloss: 0.294522       \n",
      "[175]\ttraining's multi_logloss: 0.0872652\tvalid_1's multi_logloss: 0.294635       \n",
      "[176]\ttraining's multi_logloss: 0.0865504\tvalid_1's multi_logloss: 0.29481        \n",
      "[177]\ttraining's multi_logloss: 0.08586\tvalid_1's multi_logloss: 0.294869         \n",
      "[178]\ttraining's multi_logloss: 0.0851874\tvalid_1's multi_logloss: 0.294878       \n",
      "[179]\ttraining's multi_logloss: 0.0845537\tvalid_1's multi_logloss: 0.294994       \n",
      "[180]\ttraining's multi_logloss: 0.083901\tvalid_1's multi_logloss: 0.295122        \n",
      "[181]\ttraining's multi_logloss: 0.0832374\tvalid_1's multi_logloss: 0.29525        \n",
      "[182]\ttraining's multi_logloss: 0.0826232\tvalid_1's multi_logloss: 0.295327       \n",
      "Early stopping, best iteration is:                                                \n",
      "[152]\ttraining's multi_logloss: 0.106141\tvalid_1's multi_logloss: 0.293458\n",
      "[1]\ttraining's multi_logloss: 1.79237\tvalid_1's multi_logloss: 1.79542            \n",
      "Training until validation scores don't improve for 30 rounds                      \n",
      "[2]\ttraining's multi_logloss: 1.67581\tvalid_1's multi_logloss: 1.68014            \n",
      "[3]\ttraining's multi_logloss: 1.5745\tvalid_1's multi_logloss: 1.57989             \n",
      "[4]\ttraining's multi_logloss: 1.4849\tvalid_1's multi_logloss: 1.49126             \n",
      "[5]\ttraining's multi_logloss: 1.4048\tvalid_1's multi_logloss: 1.41241             \n",
      "[6]\ttraining's multi_logloss: 1.3325\tvalid_1's multi_logloss: 1.34147             \n",
      "[7]\ttraining's multi_logloss: 1.26709\tvalid_1's multi_logloss: 1.27737            \n",
      "[8]\ttraining's multi_logloss: 1.20702\tvalid_1's multi_logloss: 1.21837            \n",
      "[9]\ttraining's multi_logloss: 1.15213\tvalid_1's multi_logloss: 1.16486            \n",
      "[10]\ttraining's multi_logloss: 1.10146\tvalid_1's multi_logloss: 1.1154            \n",
      "[11]\ttraining's multi_logloss: 1.05433\tvalid_1's multi_logloss: 1.0692            \n",
      "[12]\ttraining's multi_logloss: 1.01076\tvalid_1's multi_logloss: 1.02683           \n",
      "[13]\ttraining's multi_logloss: 0.969848\tvalid_1's multi_logloss: 0.987022         \n",
      "[14]\ttraining's multi_logloss: 0.931764\tvalid_1's multi_logloss: 0.950177         \n",
      "[15]\ttraining's multi_logloss: 0.895844\tvalid_1's multi_logloss: 0.915505         \n",
      "[16]\ttraining's multi_logloss: 0.862413\tvalid_1's multi_logloss: 0.883003         \n",
      "[17]\ttraining's multi_logloss: 0.83081\tvalid_1's multi_logloss: 0.852785          \n",
      "[18]\ttraining's multi_logloss: 0.800974\tvalid_1's multi_logloss: 0.824175         \n",
      "[19]\ttraining's multi_logloss: 0.773033\tvalid_1's multi_logloss: 0.797277         \n",
      "[20]\ttraining's multi_logloss: 0.746642\tvalid_1's multi_logloss: 0.771903         \n",
      "[21]\ttraining's multi_logloss: 0.721564\tvalid_1's multi_logloss: 0.747815         \n",
      "[22]\ttraining's multi_logloss: 0.698047\tvalid_1's multi_logloss: 0.725466         \n",
      "[23]\ttraining's multi_logloss: 0.675817\tvalid_1's multi_logloss: 0.704271         \n",
      "[24]\ttraining's multi_logloss: 0.654615\tvalid_1's multi_logloss: 0.684278         \n",
      "[25]\ttraining's multi_logloss: 0.634552\tvalid_1's multi_logloss: 0.665344         \n",
      "[26]\ttraining's multi_logloss: 0.615254\tvalid_1's multi_logloss: 0.647243         \n",
      "[27]\ttraining's multi_logloss: 0.59689\tvalid_1's multi_logloss: 0.630066          \n",
      "[28]\ttraining's multi_logloss: 0.579546\tvalid_1's multi_logloss: 0.613975         \n",
      "[29]\ttraining's multi_logloss: 0.563164\tvalid_1's multi_logloss: 0.59867          \n",
      "[30]\ttraining's multi_logloss: 0.547488\tvalid_1's multi_logloss: 0.58387          \n",
      "[31]\ttraining's multi_logloss: 0.532509\tvalid_1's multi_logloss: 0.570022         \n",
      "[32]\ttraining's multi_logloss: 0.518341\tvalid_1's multi_logloss: 0.556875         \n",
      "[33]\ttraining's multi_logloss: 0.504844\tvalid_1's multi_logloss: 0.544462         \n",
      "[34]\ttraining's multi_logloss: 0.491994\tvalid_1's multi_logloss: 0.532736         \n",
      "[35]\ttraining's multi_logloss: 0.479766\tvalid_1's multi_logloss: 0.521392         \n",
      "[36]\ttraining's multi_logloss: 0.467994\tvalid_1's multi_logloss: 0.510851         \n",
      "[37]\ttraining's multi_logloss: 0.456668\tvalid_1's multi_logloss: 0.500698         \n",
      "[38]\ttraining's multi_logloss: 0.445834\tvalid_1's multi_logloss: 0.490933         \n",
      "[39]\ttraining's multi_logloss: 0.435411\tvalid_1's multi_logloss: 0.481761         \n",
      "[40]\ttraining's multi_logloss: 0.42563\tvalid_1's multi_logloss: 0.473018          \n",
      "[41]\ttraining's multi_logloss: 0.41621\tvalid_1's multi_logloss: 0.464798          \n",
      "[42]\ttraining's multi_logloss: 0.407198\tvalid_1's multi_logloss: 0.456959         \n",
      "[43]\ttraining's multi_logloss: 0.398484\tvalid_1's multi_logloss: 0.449458         \n",
      "[44]\ttraining's multi_logloss: 0.390218\tvalid_1's multi_logloss: 0.442378         \n",
      "[45]\ttraining's multi_logloss: 0.382222\tvalid_1's multi_logloss: 0.435507         \n",
      "[46]\ttraining's multi_logloss: 0.374519\tvalid_1's multi_logloss: 0.429118         \n",
      "[47]\ttraining's multi_logloss: 0.367045\tvalid_1's multi_logloss: 0.422903         \n",
      "[48]\ttraining's multi_logloss: 0.360015\tvalid_1's multi_logloss: 0.416863         \n",
      "[49]\ttraining's multi_logloss: 0.353026\tvalid_1's multi_logloss: 0.411328         \n",
      "[50]\ttraining's multi_logloss: 0.3465\tvalid_1's multi_logloss: 0.406097           \n",
      "[51]\ttraining's multi_logloss: 0.34011\tvalid_1's multi_logloss: 0.40078           \n",
      "[52]\ttraining's multi_logloss: 0.333932\tvalid_1's multi_logloss: 0.395938         \n",
      "[53]\ttraining's multi_logloss: 0.327959\tvalid_1's multi_logloss: 0.391218         \n",
      "[54]\ttraining's multi_logloss: 0.322215\tvalid_1's multi_logloss: 0.386695         \n",
      "[55]\ttraining's multi_logloss: 0.316726\tvalid_1's multi_logloss: 0.382321         \n",
      "[56]\ttraining's multi_logloss: 0.311296\tvalid_1's multi_logloss: 0.378025         \n",
      "[57]\ttraining's multi_logloss: 0.306084\tvalid_1's multi_logloss: 0.374048         \n",
      "[58]\ttraining's multi_logloss: 0.300936\tvalid_1's multi_logloss: 0.370051         \n",
      "[59]\ttraining's multi_logloss: 0.296096\tvalid_1's multi_logloss: 0.366578         \n",
      "[60]\ttraining's multi_logloss: 0.291363\tvalid_1's multi_logloss: 0.363121         \n",
      "[61]\ttraining's multi_logloss: 0.286835\tvalid_1's multi_logloss: 0.359856         \n",
      "[62]\ttraining's multi_logloss: 0.28238\tvalid_1's multi_logloss: 0.35667           \n",
      "[63]\ttraining's multi_logloss: 0.278169\tvalid_1's multi_logloss: 0.35372          \n",
      "[64]\ttraining's multi_logloss: 0.274073\tvalid_1's multi_logloss: 0.350793         \n",
      "[65]\ttraining's multi_logloss: 0.270035\tvalid_1's multi_logloss: 0.348096         \n",
      "[66]\ttraining's multi_logloss: 0.266067\tvalid_1's multi_logloss: 0.345395         \n",
      "[67]\ttraining's multi_logloss: 0.262215\tvalid_1's multi_logloss: 0.342684         \n",
      "[68]\ttraining's multi_logloss: 0.258447\tvalid_1's multi_logloss: 0.340251         \n",
      "[69]\ttraining's multi_logloss: 0.254831\tvalid_1's multi_logloss: 0.337926         \n",
      "[70]\ttraining's multi_logloss: 0.251218\tvalid_1's multi_logloss: 0.335554         \n",
      "[71]\ttraining's multi_logloss: 0.247668\tvalid_1's multi_logloss: 0.333279         \n",
      "[72]\ttraining's multi_logloss: 0.244395\tvalid_1's multi_logloss: 0.331267         \n",
      "[73]\ttraining's multi_logloss: 0.241148\tvalid_1's multi_logloss: 0.329288         \n",
      "[74]\ttraining's multi_logloss: 0.238031\tvalid_1's multi_logloss: 0.327332         \n",
      "[75]\ttraining's multi_logloss: 0.234931\tvalid_1's multi_logloss: 0.325392         \n",
      "[76]\ttraining's multi_logloss: 0.231945\tvalid_1's multi_logloss: 0.323807         \n",
      "[77]\ttraining's multi_logloss: 0.228981\tvalid_1's multi_logloss: 0.321892         \n",
      "[78]\ttraining's multi_logloss: 0.226113\tvalid_1's multi_logloss: 0.320269         \n",
      "[79]\ttraining's multi_logloss: 0.223322\tvalid_1's multi_logloss: 0.318812         \n",
      "[80]\ttraining's multi_logloss: 0.22055\tvalid_1's multi_logloss: 0.317297          \n",
      "[81]\ttraining's multi_logloss: 0.217916\tvalid_1's multi_logloss: 0.315842         \n",
      "[82]\ttraining's multi_logloss: 0.215262\tvalid_1's multi_logloss: 0.314495         \n",
      "[83]\ttraining's multi_logloss: 0.212761\tvalid_1's multi_logloss: 0.313274         \n",
      "[84]\ttraining's multi_logloss: 0.210218\tvalid_1's multi_logloss: 0.312158         \n",
      "[85]\ttraining's multi_logloss: 0.207715\tvalid_1's multi_logloss: 0.310956         \n",
      "[86]\ttraining's multi_logloss: 0.205261\tvalid_1's multi_logloss: 0.309893         \n",
      "[87]\ttraining's multi_logloss: 0.202819\tvalid_1's multi_logloss: 0.308735         \n",
      "[88]\ttraining's multi_logloss: 0.200449\tvalid_1's multi_logloss: 0.307771         \n",
      "[89]\ttraining's multi_logloss: 0.198159\tvalid_1's multi_logloss: 0.306712         \n",
      "[90]\ttraining's multi_logloss: 0.195966\tvalid_1's multi_logloss: 0.30594          \n",
      "[91]\ttraining's multi_logloss: 0.193682\tvalid_1's multi_logloss: 0.305034         \n",
      "[92]\ttraining's multi_logloss: 0.191494\tvalid_1's multi_logloss: 0.304027         \n",
      "[93]\ttraining's multi_logloss: 0.189379\tvalid_1's multi_logloss: 0.303232         \n",
      "[94]\ttraining's multi_logloss: 0.187234\tvalid_1's multi_logloss: 0.302552         \n",
      "[95]\ttraining's multi_logloss: 0.185244\tvalid_1's multi_logloss: 0.301776         \n",
      "[96]\ttraining's multi_logloss: 0.183229\tvalid_1's multi_logloss: 0.301141         \n",
      "[97]\ttraining's multi_logloss: 0.181276\tvalid_1's multi_logloss: 0.300507         \n",
      "[98]\ttraining's multi_logloss: 0.179305\tvalid_1's multi_logloss: 0.299735         \n",
      "[99]\ttraining's multi_logloss: 0.177374\tvalid_1's multi_logloss: 0.298995         \n",
      "[100]\ttraining's multi_logloss: 0.175509\tvalid_1's multi_logloss: 0.298518        \n",
      "[101]\ttraining's multi_logloss: 0.173725\tvalid_1's multi_logloss: 0.297767        \n",
      "[102]\ttraining's multi_logloss: 0.171887\tvalid_1's multi_logloss: 0.29725         \n",
      "[103]\ttraining's multi_logloss: 0.170116\tvalid_1's multi_logloss: 0.296693        \n",
      "[104]\ttraining's multi_logloss: 0.168343\tvalid_1's multi_logloss: 0.296158        \n",
      "[105]\ttraining's multi_logloss: 0.166714\tvalid_1's multi_logloss: 0.295674        \n",
      "[106]\ttraining's multi_logloss: 0.164961\tvalid_1's multi_logloss: 0.295047        \n",
      "[107]\ttraining's multi_logloss: 0.163306\tvalid_1's multi_logloss: 0.294531        \n",
      "[108]\ttraining's multi_logloss: 0.161682\tvalid_1's multi_logloss: 0.294048        \n",
      "[109]\ttraining's multi_logloss: 0.16005\tvalid_1's multi_logloss: 0.293691         \n",
      "[110]\ttraining's multi_logloss: 0.158487\tvalid_1's multi_logloss: 0.29339         \n",
      "[111]\ttraining's multi_logloss: 0.156905\tvalid_1's multi_logloss: 0.292944        \n",
      "[112]\ttraining's multi_logloss: 0.155294\tvalid_1's multi_logloss: 0.292511        \n",
      "[113]\ttraining's multi_logloss: 0.153863\tvalid_1's multi_logloss: 0.292094        \n",
      "[114]\ttraining's multi_logloss: 0.152315\tvalid_1's multi_logloss: 0.291632        \n",
      "[115]\ttraining's multi_logloss: 0.150782\tvalid_1's multi_logloss: 0.291235        \n",
      "[116]\ttraining's multi_logloss: 0.149254\tvalid_1's multi_logloss: 0.290832        \n",
      "[117]\ttraining's multi_logloss: 0.147794\tvalid_1's multi_logloss: 0.290502        \n",
      "[118]\ttraining's multi_logloss: 0.146329\tvalid_1's multi_logloss: 0.290118        \n",
      "[119]\ttraining's multi_logloss: 0.144857\tvalid_1's multi_logloss: 0.289826        \n",
      "[120]\ttraining's multi_logloss: 0.143383\tvalid_1's multi_logloss: 0.289511        \n",
      "[121]\ttraining's multi_logloss: 0.142013\tvalid_1's multi_logloss: 0.289291        \n",
      "[122]\ttraining's multi_logloss: 0.1406\tvalid_1's multi_logloss: 0.288939          \n",
      "[123]\ttraining's multi_logloss: 0.139206\tvalid_1's multi_logloss: 0.288642        \n",
      "[124]\ttraining's multi_logloss: 0.137879\tvalid_1's multi_logloss: 0.288518        \n",
      "[125]\ttraining's multi_logloss: 0.136479\tvalid_1's multi_logloss: 0.288293        \n",
      "[126]\ttraining's multi_logloss: 0.135188\tvalid_1's multi_logloss: 0.288159        \n",
      "[127]\ttraining's multi_logloss: 0.133933\tvalid_1's multi_logloss: 0.287967        \n",
      "[128]\ttraining's multi_logloss: 0.132658\tvalid_1's multi_logloss: 0.287751        \n",
      "[129]\ttraining's multi_logloss: 0.131422\tvalid_1's multi_logloss: 0.28762         \n",
      "[130]\ttraining's multi_logloss: 0.13018\tvalid_1's multi_logloss: 0.287494         \n",
      "[131]\ttraining's multi_logloss: 0.128945\tvalid_1's multi_logloss: 0.287534        \n",
      "[132]\ttraining's multi_logloss: 0.127785\tvalid_1's multi_logloss: 0.287464        \n",
      "[133]\ttraining's multi_logloss: 0.126544\tvalid_1's multi_logloss: 0.287375        \n",
      "[134]\ttraining's multi_logloss: 0.125426\tvalid_1's multi_logloss: 0.287266        \n",
      "[135]\ttraining's multi_logloss: 0.124233\tvalid_1's multi_logloss: 0.28718         \n",
      "[136]\ttraining's multi_logloss: 0.123066\tvalid_1's multi_logloss: 0.287001        \n",
      "[137]\ttraining's multi_logloss: 0.121951\tvalid_1's multi_logloss: 0.286847        \n",
      "[138]\ttraining's multi_logloss: 0.120849\tvalid_1's multi_logloss: 0.286832        \n",
      "[139]\ttraining's multi_logloss: 0.119782\tvalid_1's multi_logloss: 0.28674         \n",
      "[140]\ttraining's multi_logloss: 0.118671\tvalid_1's multi_logloss: 0.286576        \n",
      "[141]\ttraining's multi_logloss: 0.117563\tvalid_1's multi_logloss: 0.286574        \n",
      "[142]\ttraining's multi_logloss: 0.116434\tvalid_1's multi_logloss: 0.286534        \n",
      "[143]\ttraining's multi_logloss: 0.115409\tvalid_1's multi_logloss: 0.286444        \n",
      "[144]\ttraining's multi_logloss: 0.114359\tvalid_1's multi_logloss: 0.286354        \n",
      "[145]\ttraining's multi_logloss: 0.113248\tvalid_1's multi_logloss: 0.286488        \n",
      "[146]\ttraining's multi_logloss: 0.11219\tvalid_1's multi_logloss: 0.286458         \n",
      "[147]\ttraining's multi_logloss: 0.111231\tvalid_1's multi_logloss: 0.286531        \n",
      "[148]\ttraining's multi_logloss: 0.110229\tvalid_1's multi_logloss: 0.286515        \n",
      "[149]\ttraining's multi_logloss: 0.109244\tvalid_1's multi_logloss: 0.286515        \n",
      "[150]\ttraining's multi_logloss: 0.108219\tvalid_1's multi_logloss: 0.286615        \n",
      "[151]\ttraining's multi_logloss: 0.107269\tvalid_1's multi_logloss: 0.286663        \n",
      "[152]\ttraining's multi_logloss: 0.106301\tvalid_1's multi_logloss: 0.286776        \n",
      "[153]\ttraining's multi_logloss: 0.105383\tvalid_1's multi_logloss: 0.286699        \n",
      "[154]\ttraining's multi_logloss: 0.104462\tvalid_1's multi_logloss: 0.286878        \n",
      "[155]\ttraining's multi_logloss: 0.103548\tvalid_1's multi_logloss: 0.28692         \n",
      "[156]\ttraining's multi_logloss: 0.102711\tvalid_1's multi_logloss: 0.287008        \n",
      "[157]\ttraining's multi_logloss: 0.101839\tvalid_1's multi_logloss: 0.287048        \n",
      "[158]\ttraining's multi_logloss: 0.100985\tvalid_1's multi_logloss: 0.287149        \n",
      "[159]\ttraining's multi_logloss: 0.100058\tvalid_1's multi_logloss: 0.287042        \n",
      "[160]\ttraining's multi_logloss: 0.0992025\tvalid_1's multi_logloss: 0.287066       \n",
      "[161]\ttraining's multi_logloss: 0.0983185\tvalid_1's multi_logloss: 0.287137       \n",
      "[162]\ttraining's multi_logloss: 0.0974553\tvalid_1's multi_logloss: 0.287046       \n",
      "[163]\ttraining's multi_logloss: 0.0966628\tvalid_1's multi_logloss: 0.286995       \n",
      "[164]\ttraining's multi_logloss: 0.09579\tvalid_1's multi_logloss: 0.28706          \n",
      "[165]\ttraining's multi_logloss: 0.094985\tvalid_1's multi_logloss: 0.287149        \n",
      "[166]\ttraining's multi_logloss: 0.0941706\tvalid_1's multi_logloss: 0.287301       \n",
      "[167]\ttraining's multi_logloss: 0.0933905\tvalid_1's multi_logloss: 0.28727        \n",
      "[168]\ttraining's multi_logloss: 0.0926058\tvalid_1's multi_logloss: 0.287359       \n",
      "[169]\ttraining's multi_logloss: 0.0917965\tvalid_1's multi_logloss: 0.287362       \n",
      "[170]\ttraining's multi_logloss: 0.0910075\tvalid_1's multi_logloss: 0.28745        \n",
      "[171]\ttraining's multi_logloss: 0.0902389\tvalid_1's multi_logloss: 0.287556       \n",
      "[172]\ttraining's multi_logloss: 0.0895019\tvalid_1's multi_logloss: 0.287608       \n",
      "[173]\ttraining's multi_logloss: 0.0887925\tvalid_1's multi_logloss: 0.287798       \n",
      "[174]\ttraining's multi_logloss: 0.0880653\tvalid_1's multi_logloss: 0.28798        \n",
      "Early stopping, best iteration is:                                                \n",
      "[144]\ttraining's multi_logloss: 0.114359\tvalid_1's multi_logloss: 0.286354\n",
      "[1]\ttraining's multi_logloss: 1.79267\tvalid_1's multi_logloss: 1.79585            \n",
      "Training until validation scores don't improve for 30 rounds                      \n",
      "[2]\ttraining's multi_logloss: 1.67634\tvalid_1's multi_logloss: 1.68083            \n",
      "[3]\ttraining's multi_logloss: 1.57561\tvalid_1's multi_logloss: 1.58165            \n",
      "[4]\ttraining's multi_logloss: 1.48647\tvalid_1's multi_logloss: 1.49355            \n",
      "[5]\ttraining's multi_logloss: 1.40666\tvalid_1's multi_logloss: 1.41482            \n",
      "[6]\ttraining's multi_logloss: 1.33433\tvalid_1's multi_logloss: 1.34332            \n",
      "[7]\ttraining's multi_logloss: 1.26862\tvalid_1's multi_logloss: 1.27841            \n",
      "[8]\ttraining's multi_logloss: 1.20882\tvalid_1's multi_logloss: 1.21933            \n",
      "[9]\ttraining's multi_logloss: 1.15391\tvalid_1's multi_logloss: 1.1652             \n",
      "[10]\ttraining's multi_logloss: 1.10309\tvalid_1's multi_logloss: 1.11514           \n",
      "[11]\ttraining's multi_logloss: 1.05598\tvalid_1's multi_logloss: 1.06878           \n",
      "[12]\ttraining's multi_logloss: 1.0121\tvalid_1's multi_logloss: 1.02559            \n",
      "[13]\ttraining's multi_logloss: 0.971006\tvalid_1's multi_logloss: 0.985104         \n",
      "[14]\ttraining's multi_logloss: 0.932831\tvalid_1's multi_logloss: 0.947685         \n",
      "[15]\ttraining's multi_logloss: 0.897147\tvalid_1's multi_logloss: 0.912629         \n",
      "[16]\ttraining's multi_logloss: 0.863435\tvalid_1's multi_logloss: 0.879806         \n",
      "[17]\ttraining's multi_logloss: 0.831969\tvalid_1's multi_logloss: 0.849032         \n",
      "[18]\ttraining's multi_logloss: 0.80233\tvalid_1's multi_logloss: 0.820145          \n",
      "[19]\ttraining's multi_logloss: 0.774617\tvalid_1's multi_logloss: 0.793115         \n",
      "[20]\ttraining's multi_logloss: 0.748276\tvalid_1's multi_logloss: 0.767703         \n",
      "[21]\ttraining's multi_logloss: 0.723321\tvalid_1's multi_logloss: 0.743447         \n",
      "[22]\ttraining's multi_logloss: 0.699715\tvalid_1's multi_logloss: 0.720606         \n",
      "[23]\ttraining's multi_logloss: 0.677454\tvalid_1's multi_logloss: 0.699079         \n",
      "[24]\ttraining's multi_logloss: 0.656365\tvalid_1's multi_logloss: 0.679001         \n",
      "[25]\ttraining's multi_logloss: 0.636367\tvalid_1's multi_logloss: 0.659825         \n",
      "[26]\ttraining's multi_logloss: 0.617406\tvalid_1's multi_logloss: 0.641855         \n",
      "[27]\ttraining's multi_logloss: 0.599356\tvalid_1's multi_logloss: 0.624619         \n",
      "[28]\ttraining's multi_logloss: 0.582268\tvalid_1's multi_logloss: 0.608474         \n",
      "[29]\ttraining's multi_logloss: 0.566034\tvalid_1's multi_logloss: 0.593157         \n",
      "[30]\ttraining's multi_logloss: 0.55066\tvalid_1's multi_logloss: 0.578764          \n",
      "[31]\ttraining's multi_logloss: 0.53593\tvalid_1's multi_logloss: 0.565082          \n",
      "[32]\ttraining's multi_logloss: 0.521992\tvalid_1's multi_logloss: 0.55209          \n",
      "[33]\ttraining's multi_logloss: 0.508658\tvalid_1's multi_logloss: 0.539766         \n",
      "[34]\ttraining's multi_logloss: 0.496003\tvalid_1's multi_logloss: 0.528304         \n",
      "[35]\ttraining's multi_logloss: 0.483881\tvalid_1's multi_logloss: 0.517229         \n",
      "[36]\ttraining's multi_logloss: 0.47217\tvalid_1's multi_logloss: 0.50645           \n",
      "[37]\ttraining's multi_logloss: 0.461133\tvalid_1's multi_logloss: 0.496472         \n",
      "[38]\ttraining's multi_logloss: 0.450457\tvalid_1's multi_logloss: 0.486819         \n",
      "[39]\ttraining's multi_logloss: 0.440245\tvalid_1's multi_logloss: 0.477473         \n",
      "[40]\ttraining's multi_logloss: 0.430488\tvalid_1's multi_logloss: 0.468662         \n",
      "[41]\ttraining's multi_logloss: 0.42101\tvalid_1's multi_logloss: 0.460162          \n",
      "[42]\ttraining's multi_logloss: 0.412041\tvalid_1's multi_logloss: 0.452154         \n",
      "[43]\ttraining's multi_logloss: 0.403622\tvalid_1's multi_logloss: 0.444584         \n",
      "[44]\ttraining's multi_logloss: 0.395283\tvalid_1's multi_logloss: 0.437095         \n",
      "[45]\ttraining's multi_logloss: 0.387308\tvalid_1's multi_logloss: 0.430077         \n",
      "[46]\ttraining's multi_logloss: 0.379616\tvalid_1's multi_logloss: 0.423368         \n",
      "[47]\ttraining's multi_logloss: 0.372274\tvalid_1's multi_logloss: 0.416929         \n",
      "[48]\ttraining's multi_logloss: 0.365158\tvalid_1's multi_logloss: 0.410813         \n",
      "[49]\ttraining's multi_logloss: 0.358318\tvalid_1's multi_logloss: 0.40509          \n",
      "[50]\ttraining's multi_logloss: 0.351616\tvalid_1's multi_logloss: 0.399295         \n",
      "[51]\ttraining's multi_logloss: 0.345204\tvalid_1's multi_logloss: 0.393794         \n",
      "[52]\ttraining's multi_logloss: 0.339049\tvalid_1's multi_logloss: 0.388727         \n",
      "[53]\ttraining's multi_logloss: 0.333092\tvalid_1's multi_logloss: 0.383825         \n",
      "[54]\ttraining's multi_logloss: 0.327479\tvalid_1's multi_logloss: 0.37922          \n",
      "[55]\ttraining's multi_logloss: 0.321845\tvalid_1's multi_logloss: 0.374788         \n",
      "[56]\ttraining's multi_logloss: 0.316448\tvalid_1's multi_logloss: 0.370636         \n",
      "[57]\ttraining's multi_logloss: 0.311407\tvalid_1's multi_logloss: 0.366728         \n",
      "[58]\ttraining's multi_logloss: 0.306316\tvalid_1's multi_logloss: 0.362749         \n",
      "[59]\ttraining's multi_logloss: 0.30136\tvalid_1's multi_logloss: 0.358904          \n",
      "[60]\ttraining's multi_logloss: 0.296571\tvalid_1's multi_logloss: 0.355375         \n",
      "[61]\ttraining's multi_logloss: 0.292019\tvalid_1's multi_logloss: 0.35181          \n",
      "[62]\ttraining's multi_logloss: 0.287526\tvalid_1's multi_logloss: 0.34855          \n",
      "[63]\ttraining's multi_logloss: 0.283157\tvalid_1's multi_logloss: 0.34546          \n",
      "[64]\ttraining's multi_logloss: 0.278915\tvalid_1's multi_logloss: 0.342547         \n",
      "[65]\ttraining's multi_logloss: 0.274863\tvalid_1's multi_logloss: 0.339725         \n",
      "[66]\ttraining's multi_logloss: 0.270822\tvalid_1's multi_logloss: 0.337055         \n",
      "[67]\ttraining's multi_logloss: 0.267015\tvalid_1's multi_logloss: 0.334387         \n",
      "[68]\ttraining's multi_logloss: 0.263264\tvalid_1's multi_logloss: 0.332028         \n",
      "[69]\ttraining's multi_logloss: 0.259636\tvalid_1's multi_logloss: 0.329502         \n",
      "[70]\ttraining's multi_logloss: 0.256132\tvalid_1's multi_logloss: 0.327083         \n",
      "[71]\ttraining's multi_logloss: 0.252583\tvalid_1's multi_logloss: 0.324613         \n",
      "[72]\ttraining's multi_logloss: 0.249192\tvalid_1's multi_logloss: 0.322445         \n",
      "[73]\ttraining's multi_logloss: 0.246028\tvalid_1's multi_logloss: 0.320472         \n",
      "[74]\ttraining's multi_logloss: 0.24285\tvalid_1's multi_logloss: 0.318354          \n",
      "[75]\ttraining's multi_logloss: 0.239837\tvalid_1's multi_logloss: 0.316406         \n",
      "[76]\ttraining's multi_logloss: 0.236871\tvalid_1's multi_logloss: 0.314672         \n",
      "[77]\ttraining's multi_logloss: 0.233948\tvalid_1's multi_logloss: 0.31279          \n",
      "[78]\ttraining's multi_logloss: 0.231136\tvalid_1's multi_logloss: 0.311095         \n",
      "[79]\ttraining's multi_logloss: 0.228377\tvalid_1's multi_logloss: 0.309462         \n",
      "[80]\ttraining's multi_logloss: 0.225633\tvalid_1's multi_logloss: 0.307783         \n",
      "[81]\ttraining's multi_logloss: 0.222945\tvalid_1's multi_logloss: 0.30623          \n",
      "[82]\ttraining's multi_logloss: 0.220305\tvalid_1's multi_logloss: 0.304681         \n",
      "[83]\ttraining's multi_logloss: 0.217779\tvalid_1's multi_logloss: 0.303353         \n",
      "[84]\ttraining's multi_logloss: 0.215216\tvalid_1's multi_logloss: 0.302031         \n",
      "[85]\ttraining's multi_logloss: 0.212777\tvalid_1's multi_logloss: 0.300833         \n",
      "[86]\ttraining's multi_logloss: 0.210323\tvalid_1's multi_logloss: 0.29967          \n",
      "[87]\ttraining's multi_logloss: 0.207926\tvalid_1's multi_logloss: 0.298373         \n",
      "[88]\ttraining's multi_logloss: 0.205518\tvalid_1's multi_logloss: 0.297293         \n",
      "[89]\ttraining's multi_logloss: 0.203142\tvalid_1's multi_logloss: 0.296278         \n",
      "[90]\ttraining's multi_logloss: 0.200884\tvalid_1's multi_logloss: 0.295275         \n",
      "[91]\ttraining's multi_logloss: 0.198716\tvalid_1's multi_logloss: 0.294187         \n",
      "[92]\ttraining's multi_logloss: 0.196541\tvalid_1's multi_logloss: 0.293388         \n",
      "[93]\ttraining's multi_logloss: 0.194466\tvalid_1's multi_logloss: 0.292544         \n",
      "[94]\ttraining's multi_logloss: 0.192464\tvalid_1's multi_logloss: 0.291726         \n",
      "[95]\ttraining's multi_logloss: 0.190415\tvalid_1's multi_logloss: 0.290727         \n",
      "[96]\ttraining's multi_logloss: 0.188437\tvalid_1's multi_logloss: 0.289868         \n",
      "[97]\ttraining's multi_logloss: 0.186376\tvalid_1's multi_logloss: 0.289077         \n",
      "[98]\ttraining's multi_logloss: 0.184392\tvalid_1's multi_logloss: 0.288466         \n",
      "[99]\ttraining's multi_logloss: 0.182434\tvalid_1's multi_logloss: 0.287894         \n",
      "[100]\ttraining's multi_logloss: 0.18055\tvalid_1's multi_logloss: 0.28725          \n",
      "[101]\ttraining's multi_logloss: 0.178689\tvalid_1's multi_logloss: 0.28659         \n",
      "[102]\ttraining's multi_logloss: 0.176866\tvalid_1's multi_logloss: 0.286022        \n",
      "[103]\ttraining's multi_logloss: 0.17499\tvalid_1's multi_logloss: 0.285552         \n",
      "[104]\ttraining's multi_logloss: 0.173225\tvalid_1's multi_logloss: 0.285021        \n",
      "[105]\ttraining's multi_logloss: 0.171534\tvalid_1's multi_logloss: 0.284453        \n",
      "[106]\ttraining's multi_logloss: 0.169796\tvalid_1's multi_logloss: 0.283704        \n",
      "[107]\ttraining's multi_logloss: 0.168201\tvalid_1's multi_logloss: 0.283148        \n",
      "[108]\ttraining's multi_logloss: 0.166561\tvalid_1's multi_logloss: 0.28254         \n",
      "[109]\ttraining's multi_logloss: 0.164932\tvalid_1's multi_logloss: 0.282159        \n",
      "[110]\ttraining's multi_logloss: 0.16337\tvalid_1's multi_logloss: 0.281652         \n",
      "[111]\ttraining's multi_logloss: 0.161745\tvalid_1's multi_logloss: 0.281265        \n",
      "[112]\ttraining's multi_logloss: 0.160188\tvalid_1's multi_logloss: 0.280861        \n",
      "[113]\ttraining's multi_logloss: 0.158583\tvalid_1's multi_logloss: 0.28045         \n",
      "[114]\ttraining's multi_logloss: 0.157037\tvalid_1's multi_logloss: 0.280247        \n",
      "[115]\ttraining's multi_logloss: 0.155517\tvalid_1's multi_logloss: 0.279963        \n",
      "[116]\ttraining's multi_logloss: 0.15401\tvalid_1's multi_logloss: 0.279513         \n",
      "[117]\ttraining's multi_logloss: 0.152576\tvalid_1's multi_logloss: 0.279154        \n",
      "[118]\ttraining's multi_logloss: 0.151142\tvalid_1's multi_logloss: 0.278838        \n",
      "[119]\ttraining's multi_logloss: 0.149704\tvalid_1's multi_logloss: 0.27854         \n",
      "[120]\ttraining's multi_logloss: 0.14826\tvalid_1's multi_logloss: 0.278401         \n",
      "[121]\ttraining's multi_logloss: 0.14688\tvalid_1's multi_logloss: 0.278035         \n",
      "[122]\ttraining's multi_logloss: 0.145439\tvalid_1's multi_logloss: 0.277752        \n",
      "[123]\ttraining's multi_logloss: 0.14404\tvalid_1's multi_logloss: 0.277527         \n",
      "[124]\ttraining's multi_logloss: 0.142669\tvalid_1's multi_logloss: 0.277075        \n",
      "[125]\ttraining's multi_logloss: 0.141334\tvalid_1's multi_logloss: 0.276816        \n",
      "[126]\ttraining's multi_logloss: 0.140063\tvalid_1's multi_logloss: 0.2765          \n",
      "[127]\ttraining's multi_logloss: 0.138794\tvalid_1's multi_logloss: 0.276199        \n",
      "[128]\ttraining's multi_logloss: 0.137488\tvalid_1's multi_logloss: 0.276039        \n",
      "[129]\ttraining's multi_logloss: 0.136167\tvalid_1's multi_logloss: 0.27582         \n",
      "[130]\ttraining's multi_logloss: 0.134962\tvalid_1's multi_logloss: 0.275688        \n",
      "[131]\ttraining's multi_logloss: 0.133729\tvalid_1's multi_logloss: 0.27543         \n",
      "[132]\ttraining's multi_logloss: 0.132526\tvalid_1's multi_logloss: 0.275272        \n",
      "[133]\ttraining's multi_logloss: 0.131285\tvalid_1's multi_logloss: 0.27501         \n",
      "[134]\ttraining's multi_logloss: 0.130056\tvalid_1's multi_logloss: 0.274785        \n",
      "[135]\ttraining's multi_logloss: 0.128854\tvalid_1's multi_logloss: 0.274559        \n",
      "[136]\ttraining's multi_logloss: 0.127667\tvalid_1's multi_logloss: 0.274294        \n",
      "[137]\ttraining's multi_logloss: 0.126519\tvalid_1's multi_logloss: 0.274185        \n",
      "[138]\ttraining's multi_logloss: 0.125332\tvalid_1's multi_logloss: 0.27401         \n",
      "[139]\ttraining's multi_logloss: 0.124245\tvalid_1's multi_logloss: 0.273999        \n",
      "[140]\ttraining's multi_logloss: 0.123089\tvalid_1's multi_logloss: 0.27384         \n",
      "[141]\ttraining's multi_logloss: 0.121941\tvalid_1's multi_logloss: 0.273726        \n",
      "[142]\ttraining's multi_logloss: 0.120843\tvalid_1's multi_logloss: 0.273593        \n",
      "[143]\ttraining's multi_logloss: 0.119781\tvalid_1's multi_logloss: 0.273507        \n",
      "[144]\ttraining's multi_logloss: 0.118707\tvalid_1's multi_logloss: 0.273383        \n",
      "[145]\ttraining's multi_logloss: 0.117611\tvalid_1's multi_logloss: 0.273096        \n",
      "[146]\ttraining's multi_logloss: 0.116587\tvalid_1's multi_logloss: 0.272877        \n",
      "[147]\ttraining's multi_logloss: 0.115568\tvalid_1's multi_logloss: 0.272769        \n",
      "[148]\ttraining's multi_logloss: 0.114512\tvalid_1's multi_logloss: 0.272711        \n",
      "[149]\ttraining's multi_logloss: 0.113496\tvalid_1's multi_logloss: 0.272782        \n",
      "[150]\ttraining's multi_logloss: 0.11252\tvalid_1's multi_logloss: 0.272625         \n",
      "[151]\ttraining's multi_logloss: 0.111481\tvalid_1's multi_logloss: 0.272575        \n",
      "[152]\ttraining's multi_logloss: 0.110546\tvalid_1's multi_logloss: 0.27249         \n",
      "[153]\ttraining's multi_logloss: 0.109567\tvalid_1's multi_logloss: 0.272428        \n",
      "[154]\ttraining's multi_logloss: 0.108559\tvalid_1's multi_logloss: 0.272476        \n",
      "[155]\ttraining's multi_logloss: 0.107563\tvalid_1's multi_logloss: 0.27248         \n",
      "[156]\ttraining's multi_logloss: 0.106614\tvalid_1's multi_logloss: 0.272438        \n",
      "[157]\ttraining's multi_logloss: 0.105689\tvalid_1's multi_logloss: 0.272518        \n",
      "[158]\ttraining's multi_logloss: 0.104727\tvalid_1's multi_logloss: 0.272416        \n",
      "[159]\ttraining's multi_logloss: 0.103789\tvalid_1's multi_logloss: 0.272268        \n",
      "[160]\ttraining's multi_logloss: 0.102891\tvalid_1's multi_logloss: 0.272191        \n",
      "[161]\ttraining's multi_logloss: 0.102007\tvalid_1's multi_logloss: 0.2721          \n",
      "[162]\ttraining's multi_logloss: 0.10112\tvalid_1's multi_logloss: 0.271943         \n",
      "[163]\ttraining's multi_logloss: 0.100235\tvalid_1's multi_logloss: 0.271758        \n",
      "[164]\ttraining's multi_logloss: 0.0993408\tvalid_1's multi_logloss: 0.271844       \n",
      "[165]\ttraining's multi_logloss: 0.0984768\tvalid_1's multi_logloss: 0.271873       \n",
      "[166]\ttraining's multi_logloss: 0.0976471\tvalid_1's multi_logloss: 0.271802       \n",
      "[167]\ttraining's multi_logloss: 0.0968353\tvalid_1's multi_logloss: 0.271814       \n",
      "[168]\ttraining's multi_logloss: 0.0959905\tvalid_1's multi_logloss: 0.271717       \n",
      "[169]\ttraining's multi_logloss: 0.0952069\tvalid_1's multi_logloss: 0.271826       \n",
      "[170]\ttraining's multi_logloss: 0.0943751\tvalid_1's multi_logloss: 0.271777       \n",
      "[171]\ttraining's multi_logloss: 0.0935568\tvalid_1's multi_logloss: 0.271828       \n",
      "[172]\ttraining's multi_logloss: 0.0928067\tvalid_1's multi_logloss: 0.271842       \n",
      "[173]\ttraining's multi_logloss: 0.0920171\tvalid_1's multi_logloss: 0.271762       \n",
      "[174]\ttraining's multi_logloss: 0.0913086\tvalid_1's multi_logloss: 0.271867       \n",
      "[175]\ttraining's multi_logloss: 0.0905287\tvalid_1's multi_logloss: 0.271898       \n",
      "[176]\ttraining's multi_logloss: 0.0897937\tvalid_1's multi_logloss: 0.271967       \n",
      "[177]\ttraining's multi_logloss: 0.0890931\tvalid_1's multi_logloss: 0.272059       \n",
      "[178]\ttraining's multi_logloss: 0.0883982\tvalid_1's multi_logloss: 0.272109       \n",
      "[179]\ttraining's multi_logloss: 0.0877048\tvalid_1's multi_logloss: 0.272141       \n",
      "[180]\ttraining's multi_logloss: 0.0870142\tvalid_1's multi_logloss: 0.272173       \n",
      "[181]\ttraining's multi_logloss: 0.0863145\tvalid_1's multi_logloss: 0.272232       \n",
      "[182]\ttraining's multi_logloss: 0.0856807\tvalid_1's multi_logloss: 0.272332       \n",
      "[183]\ttraining's multi_logloss: 0.0850555\tvalid_1's multi_logloss: 0.272436       \n",
      "[184]\ttraining's multi_logloss: 0.0844195\tvalid_1's multi_logloss: 0.272484       \n",
      "[185]\ttraining's multi_logloss: 0.0837739\tvalid_1's multi_logloss: 0.272559       \n",
      "[186]\ttraining's multi_logloss: 0.0831217\tvalid_1's multi_logloss: 0.272645       \n",
      "[187]\ttraining's multi_logloss: 0.082436\tvalid_1's multi_logloss: 0.272839        \n",
      "[188]\ttraining's multi_logloss: 0.0818012\tvalid_1's multi_logloss: 0.272949       \n",
      "[189]\ttraining's multi_logloss: 0.0812033\tvalid_1's multi_logloss: 0.273059       \n",
      "[190]\ttraining's multi_logloss: 0.0805924\tvalid_1's multi_logloss: 0.273183       \n",
      "[191]\ttraining's multi_logloss: 0.0799922\tvalid_1's multi_logloss: 0.273422       \n",
      "[192]\ttraining's multi_logloss: 0.0793448\tvalid_1's multi_logloss: 0.273586       \n",
      "[193]\ttraining's multi_logloss: 0.0787615\tvalid_1's multi_logloss: 0.273694       \n",
      "[194]\ttraining's multi_logloss: 0.0781532\tvalid_1's multi_logloss: 0.273781       \n",
      "[195]\ttraining's multi_logloss: 0.0776195\tvalid_1's multi_logloss: 0.273897       \n",
      "[196]\ttraining's multi_logloss: 0.0769865\tvalid_1's multi_logloss: 0.273874       \n",
      "[197]\ttraining's multi_logloss: 0.0763732\tvalid_1's multi_logloss: 0.273881       \n",
      "[198]\ttraining's multi_logloss: 0.0757351\tvalid_1's multi_logloss: 0.274028       \n",
      "Early stopping, best iteration is:                                                \n",
      "[168]\ttraining's multi_logloss: 0.0959905\tvalid_1's multi_logloss: 0.271717\n",
      "[1]\ttraining's multi_logloss: 1.23817\tvalid_1's multi_logloss: 1.25503            \n",
      "Training until validation scores don't improve for 30 rounds                      \n",
      "[2]\ttraining's multi_logloss: 0.942888\tvalid_1's multi_logloss: 0.971004          \n",
      "[3]\ttraining's multi_logloss: 0.756835\tvalid_1's multi_logloss: 0.793506          \n",
      "[4]\ttraining's multi_logloss: 0.627257\tvalid_1's multi_logloss: 0.671045          \n",
      "[5]\ttraining's multi_logloss: 0.532657\tvalid_1's multi_logloss: 0.58236           \n",
      "[6]\ttraining's multi_logloss: 0.461272\tvalid_1's multi_logloss: 0.517195          \n",
      "[7]\ttraining's multi_logloss: 0.405122\tvalid_1's multi_logloss: 0.466039          \n",
      "[8]\ttraining's multi_logloss: 0.362007\tvalid_1's multi_logloss: 0.427303          \n",
      "[9]\ttraining's multi_logloss: 0.327661\tvalid_1's multi_logloss: 0.398286          \n",
      "[10]\ttraining's multi_logloss: 0.299426\tvalid_1's multi_logloss: 0.376485         \n",
      "[11]\ttraining's multi_logloss: 0.276141\tvalid_1's multi_logloss: 0.359334         \n",
      "[12]\ttraining's multi_logloss: 0.255685\tvalid_1's multi_logloss: 0.344619         \n",
      "[13]\ttraining's multi_logloss: 0.238333\tvalid_1's multi_logloss: 0.33378          \n",
      "[14]\ttraining's multi_logloss: 0.223159\tvalid_1's multi_logloss: 0.325655         \n",
      "[15]\ttraining's multi_logloss: 0.209567\tvalid_1's multi_logloss: 0.319099         \n",
      "[16]\ttraining's multi_logloss: 0.197284\tvalid_1's multi_logloss: 0.313609         \n",
      "[17]\ttraining's multi_logloss: 0.186266\tvalid_1's multi_logloss: 0.309749         \n",
      "[18]\ttraining's multi_logloss: 0.176194\tvalid_1's multi_logloss: 0.307185         \n",
      "[19]\ttraining's multi_logloss: 0.166495\tvalid_1's multi_logloss: 0.303955         \n",
      "[20]\ttraining's multi_logloss: 0.157602\tvalid_1's multi_logloss: 0.302637         \n",
      "[21]\ttraining's multi_logloss: 0.149226\tvalid_1's multi_logloss: 0.300602         \n",
      "[22]\ttraining's multi_logloss: 0.141701\tvalid_1's multi_logloss: 0.299089         \n",
      "[23]\ttraining's multi_logloss: 0.134531\tvalid_1's multi_logloss: 0.298734         \n",
      "[24]\ttraining's multi_logloss: 0.128273\tvalid_1's multi_logloss: 0.297828         \n",
      "[25]\ttraining's multi_logloss: 0.121954\tvalid_1's multi_logloss: 0.298032         \n",
      "[26]\ttraining's multi_logloss: 0.11617\tvalid_1's multi_logloss: 0.297367          \n",
      "[27]\ttraining's multi_logloss: 0.110722\tvalid_1's multi_logloss: 0.297052         \n",
      "[28]\ttraining's multi_logloss: 0.10519\tvalid_1's multi_logloss: 0.296277          \n",
      "[29]\ttraining's multi_logloss: 0.100257\tvalid_1's multi_logloss: 0.296145         \n",
      "[30]\ttraining's multi_logloss: 0.0951672\tvalid_1's multi_logloss: 0.296039        \n",
      "[31]\ttraining's multi_logloss: 0.0908077\tvalid_1's multi_logloss: 0.295936        \n",
      "[32]\ttraining's multi_logloss: 0.0866887\tvalid_1's multi_logloss: 0.296799        \n",
      "[33]\ttraining's multi_logloss: 0.0829678\tvalid_1's multi_logloss: 0.298318        \n",
      "[34]\ttraining's multi_logloss: 0.0796496\tvalid_1's multi_logloss: 0.298769        \n",
      "[35]\ttraining's multi_logloss: 0.0763297\tvalid_1's multi_logloss: 0.299657        \n",
      "[36]\ttraining's multi_logloss: 0.0727914\tvalid_1's multi_logloss: 0.300169        \n",
      "[37]\ttraining's multi_logloss: 0.0696926\tvalid_1's multi_logloss: 0.300955        \n",
      "[38]\ttraining's multi_logloss: 0.0666169\tvalid_1's multi_logloss: 0.302349        \n",
      "[39]\ttraining's multi_logloss: 0.0639389\tvalid_1's multi_logloss: 0.302989        \n",
      "[40]\ttraining's multi_logloss: 0.0613732\tvalid_1's multi_logloss: 0.304247        \n",
      "[41]\ttraining's multi_logloss: 0.0588344\tvalid_1's multi_logloss: 0.30609         \n",
      "[42]\ttraining's multi_logloss: 0.0560674\tvalid_1's multi_logloss: 0.306567        \n",
      "[43]\ttraining's multi_logloss: 0.0538923\tvalid_1's multi_logloss: 0.308612        \n",
      "[44]\ttraining's multi_logloss: 0.051722\tvalid_1's multi_logloss: 0.309235         \n",
      "[45]\ttraining's multi_logloss: 0.0495529\tvalid_1's multi_logloss: 0.310048        \n",
      "[46]\ttraining's multi_logloss: 0.0476607\tvalid_1's multi_logloss: 0.311681        \n",
      "[47]\ttraining's multi_logloss: 0.0455065\tvalid_1's multi_logloss: 0.31259         \n",
      "[48]\ttraining's multi_logloss: 0.0437047\tvalid_1's multi_logloss: 0.314242        \n",
      "[49]\ttraining's multi_logloss: 0.0417677\tvalid_1's multi_logloss: 0.316111        \n",
      "[50]\ttraining's multi_logloss: 0.0400127\tvalid_1's multi_logloss: 0.317944        \n",
      "[51]\ttraining's multi_logloss: 0.0382928\tvalid_1's multi_logloss: 0.318704        \n",
      "[52]\ttraining's multi_logloss: 0.0366218\tvalid_1's multi_logloss: 0.320743        \n",
      "[53]\ttraining's multi_logloss: 0.0349455\tvalid_1's multi_logloss: 0.321726        \n",
      "[54]\ttraining's multi_logloss: 0.0335981\tvalid_1's multi_logloss: 0.323421        \n",
      "[55]\ttraining's multi_logloss: 0.0323819\tvalid_1's multi_logloss: 0.324615        \n",
      "[56]\ttraining's multi_logloss: 0.0309738\tvalid_1's multi_logloss: 0.325878        \n",
      "[57]\ttraining's multi_logloss: 0.0295957\tvalid_1's multi_logloss: 0.32863         \n",
      "[58]\ttraining's multi_logloss: 0.0284662\tvalid_1's multi_logloss: 0.330029        \n",
      "[59]\ttraining's multi_logloss: 0.0274599\tvalid_1's multi_logloss: 0.331925        \n",
      "[60]\ttraining's multi_logloss: 0.0263603\tvalid_1's multi_logloss: 0.334145        \n",
      "[61]\ttraining's multi_logloss: 0.0253461\tvalid_1's multi_logloss: 0.335965        \n",
      "Early stopping, best iteration is:                                                \n",
      "[31]\ttraining's multi_logloss: 0.0908077\tvalid_1's multi_logloss: 0.295936\n",
      "[1]\ttraining's multi_logloss: 1.23524\tvalid_1's multi_logloss: 1.2442             \n",
      "Training until validation scores don't improve for 30 rounds                      \n",
      "[2]\ttraining's multi_logloss: 0.944291\tvalid_1's multi_logloss: 0.958894          \n",
      "[3]\ttraining's multi_logloss: 0.760079\tvalid_1's multi_logloss: 0.781724          \n",
      "[4]\ttraining's multi_logloss: 0.631259\tvalid_1's multi_logloss: 0.65869           \n",
      "[5]\ttraining's multi_logloss: 0.536744\tvalid_1's multi_logloss: 0.569906          \n",
      "[6]\ttraining's multi_logloss: 0.465451\tvalid_1's multi_logloss: 0.504175          \n",
      "[7]\ttraining's multi_logloss: 0.409973\tvalid_1's multi_logloss: 0.455028          \n",
      "[8]\ttraining's multi_logloss: 0.366839\tvalid_1's multi_logloss: 0.419387          \n",
      "[9]\ttraining's multi_logloss: 0.331382\tvalid_1's multi_logloss: 0.390649          \n",
      "[10]\ttraining's multi_logloss: 0.302622\tvalid_1's multi_logloss: 0.368697         \n",
      "[11]\ttraining's multi_logloss: 0.278058\tvalid_1's multi_logloss: 0.350784         \n",
      "[12]\ttraining's multi_logloss: 0.257442\tvalid_1's multi_logloss: 0.337553         \n",
      "[13]\ttraining's multi_logloss: 0.239981\tvalid_1's multi_logloss: 0.327525         \n",
      "[14]\ttraining's multi_logloss: 0.22425\tvalid_1's multi_logloss: 0.319424          \n",
      "[15]\ttraining's multi_logloss: 0.21046\tvalid_1's multi_logloss: 0.31342           \n",
      "[16]\ttraining's multi_logloss: 0.197801\tvalid_1's multi_logloss: 0.308698         \n",
      "[17]\ttraining's multi_logloss: 0.18622\tvalid_1's multi_logloss: 0.303684          \n",
      "[18]\ttraining's multi_logloss: 0.176106\tvalid_1's multi_logloss: 0.301266         \n",
      "[19]\ttraining's multi_logloss: 0.166061\tvalid_1's multi_logloss: 0.297917         \n",
      "[20]\ttraining's multi_logloss: 0.157612\tvalid_1's multi_logloss: 0.296263         \n",
      "[21]\ttraining's multi_logloss: 0.149033\tvalid_1's multi_logloss: 0.294351         \n",
      "[22]\ttraining's multi_logloss: 0.141246\tvalid_1's multi_logloss: 0.292397         \n",
      "[23]\ttraining's multi_logloss: 0.133978\tvalid_1's multi_logloss: 0.292332         \n",
      "[24]\ttraining's multi_logloss: 0.127218\tvalid_1's multi_logloss: 0.293354         \n",
      "[25]\ttraining's multi_logloss: 0.120884\tvalid_1's multi_logloss: 0.293267         \n",
      "[26]\ttraining's multi_logloss: 0.115031\tvalid_1's multi_logloss: 0.293066         \n",
      "[27]\ttraining's multi_logloss: 0.109202\tvalid_1's multi_logloss: 0.293879         \n",
      "[28]\ttraining's multi_logloss: 0.103847\tvalid_1's multi_logloss: 0.293843         \n",
      "[29]\ttraining's multi_logloss: 0.0987035\tvalid_1's multi_logloss: 0.295698        \n",
      "[30]\ttraining's multi_logloss: 0.0941399\tvalid_1's multi_logloss: 0.296005        \n",
      "[31]\ttraining's multi_logloss: 0.0899692\tvalid_1's multi_logloss: 0.296047        \n",
      "[32]\ttraining's multi_logloss: 0.0860875\tvalid_1's multi_logloss: 0.296755        \n",
      "[33]\ttraining's multi_logloss: 0.0822091\tvalid_1's multi_logloss: 0.297684        \n",
      "[34]\ttraining's multi_logloss: 0.0785217\tvalid_1's multi_logloss: 0.298833        \n",
      "[35]\ttraining's multi_logloss: 0.074806\tvalid_1's multi_logloss: 0.299783         \n",
      "[36]\ttraining's multi_logloss: 0.0712303\tvalid_1's multi_logloss: 0.301002        \n",
      "[37]\ttraining's multi_logloss: 0.0681557\tvalid_1's multi_logloss: 0.301585        \n",
      "[38]\ttraining's multi_logloss: 0.0652694\tvalid_1's multi_logloss: 0.30286         \n",
      "[39]\ttraining's multi_logloss: 0.0624703\tvalid_1's multi_logloss: 0.302505        \n",
      "[40]\ttraining's multi_logloss: 0.0598329\tvalid_1's multi_logloss: 0.303512        \n",
      "[41]\ttraining's multi_logloss: 0.0573012\tvalid_1's multi_logloss: 0.304835        \n",
      "[42]\ttraining's multi_logloss: 0.0549724\tvalid_1's multi_logloss: 0.305866        \n",
      "[43]\ttraining's multi_logloss: 0.0526714\tvalid_1's multi_logloss: 0.307422        \n",
      "[44]\ttraining's multi_logloss: 0.0506039\tvalid_1's multi_logloss: 0.308853        \n",
      "[45]\ttraining's multi_logloss: 0.0486221\tvalid_1's multi_logloss: 0.310111        \n",
      "[46]\ttraining's multi_logloss: 0.0467096\tvalid_1's multi_logloss: 0.312004        \n",
      "[47]\ttraining's multi_logloss: 0.0450485\tvalid_1's multi_logloss: 0.312843        \n",
      "[48]\ttraining's multi_logloss: 0.0432555\tvalid_1's multi_logloss: 0.315133        \n",
      "[49]\ttraining's multi_logloss: 0.0415586\tvalid_1's multi_logloss: 0.3168          \n",
      "[50]\ttraining's multi_logloss: 0.0396731\tvalid_1's multi_logloss: 0.318151        \n",
      "[51]\ttraining's multi_logloss: 0.0379385\tvalid_1's multi_logloss: 0.319902        \n",
      "[52]\ttraining's multi_logloss: 0.0363638\tvalid_1's multi_logloss: 0.321686        \n",
      "[53]\ttraining's multi_logloss: 0.0350208\tvalid_1's multi_logloss: 0.324138        \n",
      "Early stopping, best iteration is:                                                \n",
      "[23]\ttraining's multi_logloss: 0.133978\tvalid_1's multi_logloss: 0.292332\n",
      "[1]\ttraining's multi_logloss: 1.23872\tvalid_1's multi_logloss: 1.24599            \n",
      "Training until validation scores don't improve for 30 rounds                      \n",
      "[2]\ttraining's multi_logloss: 0.947499\tvalid_1's multi_logloss: 0.958577          \n",
      "[3]\ttraining's multi_logloss: 0.76477\tvalid_1's multi_logloss: 0.779346           \n",
      "[4]\ttraining's multi_logloss: 0.634506\tvalid_1's multi_logloss: 0.653312          \n",
      "[5]\ttraining's multi_logloss: 0.540093\tvalid_1's multi_logloss: 0.564027          \n",
      "[6]\ttraining's multi_logloss: 0.466955\tvalid_1's multi_logloss: 0.496575          \n",
      "[7]\ttraining's multi_logloss: 0.41269\tvalid_1's multi_logloss: 0.447984           \n",
      "[8]\ttraining's multi_logloss: 0.36925\tvalid_1's multi_logloss: 0.41012            \n",
      "[9]\ttraining's multi_logloss: 0.333948\tvalid_1's multi_logloss: 0.380233          \n",
      "[10]\ttraining's multi_logloss: 0.304551\tvalid_1's multi_logloss: 0.356403         \n",
      "[11]\ttraining's multi_logloss: 0.280568\tvalid_1's multi_logloss: 0.339735         \n",
      "[12]\ttraining's multi_logloss: 0.25983\tvalid_1's multi_logloss: 0.32507           \n",
      "[13]\ttraining's multi_logloss: 0.242189\tvalid_1's multi_logloss: 0.314567         \n",
      "[14]\ttraining's multi_logloss: 0.227185\tvalid_1's multi_logloss: 0.306536         \n",
      "[15]\ttraining's multi_logloss: 0.212963\tvalid_1's multi_logloss: 0.299692         \n",
      "[16]\ttraining's multi_logloss: 0.20115\tvalid_1's multi_logloss: 0.294282          \n",
      "[17]\ttraining's multi_logloss: 0.189923\tvalid_1's multi_logloss: 0.290372         \n",
      "[18]\ttraining's multi_logloss: 0.179846\tvalid_1's multi_logloss: 0.286933         \n",
      "[19]\ttraining's multi_logloss: 0.170609\tvalid_1's multi_logloss: 0.284637         \n",
      "[20]\ttraining's multi_logloss: 0.161689\tvalid_1's multi_logloss: 0.28347          \n",
      "[21]\ttraining's multi_logloss: 0.153594\tvalid_1's multi_logloss: 0.282219         \n",
      "[22]\ttraining's multi_logloss: 0.145849\tvalid_1's multi_logloss: 0.28022          \n",
      "[23]\ttraining's multi_logloss: 0.138976\tvalid_1's multi_logloss: 0.279202         \n",
      "[24]\ttraining's multi_logloss: 0.132316\tvalid_1's multi_logloss: 0.278148         \n",
      "[25]\ttraining's multi_logloss: 0.125477\tvalid_1's multi_logloss: 0.277564         \n",
      "[26]\ttraining's multi_logloss: 0.119768\tvalid_1's multi_logloss: 0.277246         \n",
      "[27]\ttraining's multi_logloss: 0.113992\tvalid_1's multi_logloss: 0.276853         \n",
      "[28]\ttraining's multi_logloss: 0.108811\tvalid_1's multi_logloss: 0.276722         \n",
      "[29]\ttraining's multi_logloss: 0.103807\tvalid_1's multi_logloss: 0.27668          \n",
      "[30]\ttraining's multi_logloss: 0.0990376\tvalid_1's multi_logloss: 0.27658         \n",
      "[31]\ttraining's multi_logloss: 0.0946439\tvalid_1's multi_logloss: 0.276592        \n",
      "[32]\ttraining's multi_logloss: 0.0905337\tvalid_1's multi_logloss: 0.277899        \n",
      "[33]\ttraining's multi_logloss: 0.0864313\tvalid_1's multi_logloss: 0.27772         \n",
      "[34]\ttraining's multi_logloss: 0.0823833\tvalid_1's multi_logloss: 0.278511        \n",
      "[35]\ttraining's multi_logloss: 0.0787315\tvalid_1's multi_logloss: 0.279688        \n",
      "[36]\ttraining's multi_logloss: 0.0753333\tvalid_1's multi_logloss: 0.280382        \n",
      "[37]\ttraining's multi_logloss: 0.0719962\tvalid_1's multi_logloss: 0.281519        \n",
      "[38]\ttraining's multi_logloss: 0.0690331\tvalid_1's multi_logloss: 0.282207        \n",
      "[39]\ttraining's multi_logloss: 0.0657596\tvalid_1's multi_logloss: 0.283154        \n",
      "[40]\ttraining's multi_logloss: 0.0629041\tvalid_1's multi_logloss: 0.283349        \n",
      "[41]\ttraining's multi_logloss: 0.0602639\tvalid_1's multi_logloss: 0.283933        \n",
      "[42]\ttraining's multi_logloss: 0.0579192\tvalid_1's multi_logloss: 0.284906        \n",
      "[43]\ttraining's multi_logloss: 0.0554703\tvalid_1's multi_logloss: 0.285413        \n",
      "[44]\ttraining's multi_logloss: 0.0533068\tvalid_1's multi_logloss: 0.286842        \n",
      "[45]\ttraining's multi_logloss: 0.0511471\tvalid_1's multi_logloss: 0.287981        \n",
      "[46]\ttraining's multi_logloss: 0.0489202\tvalid_1's multi_logloss: 0.289337        \n",
      "[47]\ttraining's multi_logloss: 0.0466372\tvalid_1's multi_logloss: 0.290446        \n",
      "[48]\ttraining's multi_logloss: 0.0447738\tvalid_1's multi_logloss: 0.291436        \n",
      "[49]\ttraining's multi_logloss: 0.0430863\tvalid_1's multi_logloss: 0.292305        \n",
      "[50]\ttraining's multi_logloss: 0.0412293\tvalid_1's multi_logloss: 0.293589        \n",
      "[51]\ttraining's multi_logloss: 0.0395745\tvalid_1's multi_logloss: 0.295487        \n",
      "[52]\ttraining's multi_logloss: 0.0380266\tvalid_1's multi_logloss: 0.297337        \n",
      "[53]\ttraining's multi_logloss: 0.036519\tvalid_1's multi_logloss: 0.298606         \n",
      "[54]\ttraining's multi_logloss: 0.0350884\tvalid_1's multi_logloss: 0.300074        \n",
      "[55]\ttraining's multi_logloss: 0.0336469\tvalid_1's multi_logloss: 0.301761        \n",
      "[56]\ttraining's multi_logloss: 0.0323499\tvalid_1's multi_logloss: 0.303028        \n",
      "[57]\ttraining's multi_logloss: 0.031158\tvalid_1's multi_logloss: 0.304381         \n",
      "[58]\ttraining's multi_logloss: 0.0299812\tvalid_1's multi_logloss: 0.305912        \n",
      "[59]\ttraining's multi_logloss: 0.0288056\tvalid_1's multi_logloss: 0.307643        \n",
      "[60]\ttraining's multi_logloss: 0.0276051\tvalid_1's multi_logloss: 0.308724        \n",
      "Early stopping, best iteration is:                                                \n",
      "[30]\ttraining's multi_logloss: 0.0990376\tvalid_1's multi_logloss: 0.27658\n",
      "[1]\ttraining's multi_logloss: 1.63789\tvalid_1's multi_logloss: 1.64184            \n",
      "Training until validation scores don't improve for 30 rounds                      \n",
      "[2]\ttraining's multi_logloss: 1.42972\tvalid_1's multi_logloss: 1.43801            \n",
      "[3]\ttraining's multi_logloss: 1.27159\tvalid_1's multi_logloss: 1.28499            \n",
      "[4]\ttraining's multi_logloss: 1.14404\tvalid_1's multi_logloss: 1.16122            \n",
      "[5]\ttraining's multi_logloss: 1.03783\tvalid_1's multi_logloss: 1.05874            \n",
      "[6]\ttraining's multi_logloss: 0.948803\tvalid_1's multi_logloss: 0.973006          \n",
      "[7]\ttraining's multi_logloss: 0.87156\tvalid_1's multi_logloss: 0.898059           \n",
      "[8]\ttraining's multi_logloss: 0.804812\tvalid_1's multi_logloss: 0.833982          \n",
      "[9]\ttraining's multi_logloss: 0.74695\tvalid_1's multi_logloss: 0.778003           \n",
      "[10]\ttraining's multi_logloss: 0.696036\tvalid_1's multi_logloss: 0.728692         \n",
      "[11]\ttraining's multi_logloss: 0.650721\tvalid_1's multi_logloss: 0.685442         \n",
      "[12]\ttraining's multi_logloss: 0.610213\tvalid_1's multi_logloss: 0.646751         \n",
      "[13]\ttraining's multi_logloss: 0.573952\tvalid_1's multi_logloss: 0.612216         \n",
      "[14]\ttraining's multi_logloss: 0.541432\tvalid_1's multi_logloss: 0.581339         \n",
      "[15]\ttraining's multi_logloss: 0.512228\tvalid_1's multi_logloss: 0.554179         \n",
      "[16]\ttraining's multi_logloss: 0.485879\tvalid_1's multi_logloss: 0.529724         \n",
      "[17]\ttraining's multi_logloss: 0.462353\tvalid_1's multi_logloss: 0.507992         \n",
      "[18]\ttraining's multi_logloss: 0.440765\tvalid_1's multi_logloss: 0.488209         \n",
      "[19]\ttraining's multi_logloss: 0.421078\tvalid_1's multi_logloss: 0.470444         \n",
      "[20]\ttraining's multi_logloss: 0.402925\tvalid_1's multi_logloss: 0.454048         \n",
      "[21]\ttraining's multi_logloss: 0.386282\tvalid_1's multi_logloss: 0.439133         \n",
      "[22]\ttraining's multi_logloss: 0.371409\tvalid_1's multi_logloss: 0.425999         \n",
      "[23]\ttraining's multi_logloss: 0.35756\tvalid_1's multi_logloss: 0.414122          \n",
      "[24]\ttraining's multi_logloss: 0.344895\tvalid_1's multi_logloss: 0.403502         \n",
      "[25]\ttraining's multi_logloss: 0.333379\tvalid_1's multi_logloss: 0.393653         \n",
      "[26]\ttraining's multi_logloss: 0.322637\tvalid_1's multi_logloss: 0.384928         \n",
      "[27]\ttraining's multi_logloss: 0.312694\tvalid_1's multi_logloss: 0.377042         \n",
      "[28]\ttraining's multi_logloss: 0.303114\tvalid_1's multi_logloss: 0.369329         \n",
      "[29]\ttraining's multi_logloss: 0.294181\tvalid_1's multi_logloss: 0.362457         \n",
      "[30]\ttraining's multi_logloss: 0.286236\tvalid_1's multi_logloss: 0.356615         \n",
      "[31]\ttraining's multi_logloss: 0.278368\tvalid_1's multi_logloss: 0.35112          \n",
      "[32]\ttraining's multi_logloss: 0.271568\tvalid_1's multi_logloss: 0.346194         \n",
      "[33]\ttraining's multi_logloss: 0.264725\tvalid_1's multi_logloss: 0.341472         \n",
      "[34]\ttraining's multi_logloss: 0.258506\tvalid_1's multi_logloss: 0.337271         \n",
      "[35]\ttraining's multi_logloss: 0.252357\tvalid_1's multi_logloss: 0.333218         \n",
      "[36]\ttraining's multi_logloss: 0.246589\tvalid_1's multi_logloss: 0.330135         \n",
      "[37]\ttraining's multi_logloss: 0.241117\tvalid_1's multi_logloss: 0.326927         \n",
      "[38]\ttraining's multi_logloss: 0.235624\tvalid_1's multi_logloss: 0.3237           \n",
      "[39]\ttraining's multi_logloss: 0.230518\tvalid_1's multi_logloss: 0.320673         \n",
      "[40]\ttraining's multi_logloss: 0.225576\tvalid_1's multi_logloss: 0.318115         \n",
      "[41]\ttraining's multi_logloss: 0.221223\tvalid_1's multi_logloss: 0.316163         \n",
      "[42]\ttraining's multi_logloss: 0.216989\tvalid_1's multi_logloss: 0.313909         \n",
      "[43]\ttraining's multi_logloss: 0.212656\tvalid_1's multi_logloss: 0.311935         \n",
      "[44]\ttraining's multi_logloss: 0.208581\tvalid_1's multi_logloss: 0.310032         \n",
      "[45]\ttraining's multi_logloss: 0.204606\tvalid_1's multi_logloss: 0.308503         \n",
      "[46]\ttraining's multi_logloss: 0.200726\tvalid_1's multi_logloss: 0.306999         \n",
      "[47]\ttraining's multi_logloss: 0.197022\tvalid_1's multi_logloss: 0.305693         \n",
      "[48]\ttraining's multi_logloss: 0.193588\tvalid_1's multi_logloss: 0.304432         \n",
      "[49]\ttraining's multi_logloss: 0.190484\tvalid_1's multi_logloss: 0.303657         \n",
      "[50]\ttraining's multi_logloss: 0.186964\tvalid_1's multi_logloss: 0.302097         \n",
      "[51]\ttraining's multi_logloss: 0.183553\tvalid_1's multi_logloss: 0.30092          \n",
      "[52]\ttraining's multi_logloss: 0.180299\tvalid_1's multi_logloss: 0.299964         \n",
      "[53]\ttraining's multi_logloss: 0.177242\tvalid_1's multi_logloss: 0.299243         \n",
      "[54]\ttraining's multi_logloss: 0.174189\tvalid_1's multi_logloss: 0.29864          \n",
      "[55]\ttraining's multi_logloss: 0.171272\tvalid_1's multi_logloss: 0.298237         \n",
      "[56]\ttraining's multi_logloss: 0.168365\tvalid_1's multi_logloss: 0.297594         \n",
      "[57]\ttraining's multi_logloss: 0.165426\tvalid_1's multi_logloss: 0.296795         \n",
      "[58]\ttraining's multi_logloss: 0.1626\tvalid_1's multi_logloss: 0.295852           \n",
      "[59]\ttraining's multi_logloss: 0.159887\tvalid_1's multi_logloss: 0.295602         \n",
      "[60]\ttraining's multi_logloss: 0.15706\tvalid_1's multi_logloss: 0.295245          \n",
      "[61]\ttraining's multi_logloss: 0.154521\tvalid_1's multi_logloss: 0.294525         \n",
      "[62]\ttraining's multi_logloss: 0.151873\tvalid_1's multi_logloss: 0.293872         \n",
      "[63]\ttraining's multi_logloss: 0.149359\tvalid_1's multi_logloss: 0.293455         \n",
      "[64]\ttraining's multi_logloss: 0.146718\tvalid_1's multi_logloss: 0.29339          \n",
      "[65]\ttraining's multi_logloss: 0.144055\tvalid_1's multi_logloss: 0.293013         \n",
      "[66]\ttraining's multi_logloss: 0.141541\tvalid_1's multi_logloss: 0.292738         \n",
      "[67]\ttraining's multi_logloss: 0.13916\tvalid_1's multi_logloss: 0.292503          \n",
      "[68]\ttraining's multi_logloss: 0.13701\tvalid_1's multi_logloss: 0.292275          \n",
      "[69]\ttraining's multi_logloss: 0.134723\tvalid_1's multi_logloss: 0.29222          \n",
      "[70]\ttraining's multi_logloss: 0.132358\tvalid_1's multi_logloss: 0.291949         \n",
      "[71]\ttraining's multi_logloss: 0.130184\tvalid_1's multi_logloss: 0.291706         \n",
      "[72]\ttraining's multi_logloss: 0.127965\tvalid_1's multi_logloss: 0.29139          \n",
      "[73]\ttraining's multi_logloss: 0.125734\tvalid_1's multi_logloss: 0.291398         \n",
      "[74]\ttraining's multi_logloss: 0.123594\tvalid_1's multi_logloss: 0.291187         \n",
      "[75]\ttraining's multi_logloss: 0.121464\tvalid_1's multi_logloss: 0.290913         \n",
      "[76]\ttraining's multi_logloss: 0.119557\tvalid_1's multi_logloss: 0.290923         \n",
      "[77]\ttraining's multi_logloss: 0.117539\tvalid_1's multi_logloss: 0.291227         \n",
      "[78]\ttraining's multi_logloss: 0.115639\tvalid_1's multi_logloss: 0.291207         \n",
      "[79]\ttraining's multi_logloss: 0.113693\tvalid_1's multi_logloss: 0.291404         \n",
      "[80]\ttraining's multi_logloss: 0.11182\tvalid_1's multi_logloss: 0.291641          \n",
      "[81]\ttraining's multi_logloss: 0.11\tvalid_1's multi_logloss: 0.291887             \n",
      "[82]\ttraining's multi_logloss: 0.108272\tvalid_1's multi_logloss: 0.292002         \n",
      "[83]\ttraining's multi_logloss: 0.106525\tvalid_1's multi_logloss: 0.29241          \n",
      "[84]\ttraining's multi_logloss: 0.104699\tvalid_1's multi_logloss: 0.292769         \n",
      "[85]\ttraining's multi_logloss: 0.10314\tvalid_1's multi_logloss: 0.293141          \n",
      "[86]\ttraining's multi_logloss: 0.101562\tvalid_1's multi_logloss: 0.293353         \n",
      "[87]\ttraining's multi_logloss: 0.100049\tvalid_1's multi_logloss: 0.293603         \n",
      "[88]\ttraining's multi_logloss: 0.0985226\tvalid_1's multi_logloss: 0.293592        \n",
      "[89]\ttraining's multi_logloss: 0.0969039\tvalid_1's multi_logloss: 0.293576        \n",
      "[90]\ttraining's multi_logloss: 0.0953392\tvalid_1's multi_logloss: 0.293875        \n",
      "[91]\ttraining's multi_logloss: 0.0938056\tvalid_1's multi_logloss: 0.294059        \n",
      "[92]\ttraining's multi_logloss: 0.0923073\tvalid_1's multi_logloss: 0.294034        \n",
      "[93]\ttraining's multi_logloss: 0.0910038\tvalid_1's multi_logloss: 0.294223        \n",
      "[94]\ttraining's multi_logloss: 0.0895366\tvalid_1's multi_logloss: 0.294655        \n",
      "[95]\ttraining's multi_logloss: 0.0881168\tvalid_1's multi_logloss: 0.295097        \n",
      "[96]\ttraining's multi_logloss: 0.0868128\tvalid_1's multi_logloss: 0.295205        \n",
      "[97]\ttraining's multi_logloss: 0.0856267\tvalid_1's multi_logloss: 0.295796        \n",
      "[98]\ttraining's multi_logloss: 0.0842852\tvalid_1's multi_logloss: 0.29632         \n",
      "[99]\ttraining's multi_logloss: 0.0831096\tvalid_1's multi_logloss: 0.29667         \n",
      "[100]\ttraining's multi_logloss: 0.0819091\tvalid_1's multi_logloss: 0.297075       \n",
      "[101]\ttraining's multi_logloss: 0.0805393\tvalid_1's multi_logloss: 0.297307       \n",
      "[102]\ttraining's multi_logloss: 0.0791395\tvalid_1's multi_logloss: 0.297497       \n",
      "[103]\ttraining's multi_logloss: 0.0778316\tvalid_1's multi_logloss: 0.297806       \n",
      "[104]\ttraining's multi_logloss: 0.0767657\tvalid_1's multi_logloss: 0.298317       \n",
      "[105]\ttraining's multi_logloss: 0.0754874\tvalid_1's multi_logloss: 0.298713       \n",
      "Early stopping, best iteration is:                                                \n",
      "[75]\ttraining's multi_logloss: 0.121464\tvalid_1's multi_logloss: 0.290913\n",
      "[1]\ttraining's multi_logloss: 1.63635\tvalid_1's multi_logloss: 1.63973            \n",
      "Training until validation scores don't improve for 30 rounds                      \n",
      "[2]\ttraining's multi_logloss: 1.43141\tvalid_1's multi_logloss: 1.43539            \n",
      "[3]\ttraining's multi_logloss: 1.27476\tvalid_1's multi_logloss: 1.28126            \n",
      "[4]\ttraining's multi_logloss: 1.14878\tvalid_1's multi_logloss: 1.15771            \n",
      "[5]\ttraining's multi_logloss: 1.04365\tvalid_1's multi_logloss: 1.05397            \n",
      "[6]\ttraining's multi_logloss: 0.954732\tvalid_1's multi_logloss: 0.966459          \n",
      "[7]\ttraining's multi_logloss: 0.878883\tvalid_1's multi_logloss: 0.892384          \n",
      "[8]\ttraining's multi_logloss: 0.811985\tvalid_1's multi_logloss: 0.827386          \n",
      "[9]\ttraining's multi_logloss: 0.753221\tvalid_1's multi_logloss: 0.770275          \n",
      "[10]\ttraining's multi_logloss: 0.702133\tvalid_1's multi_logloss: 0.7214           \n",
      "[11]\ttraining's multi_logloss: 0.656426\tvalid_1's multi_logloss: 0.67771          \n",
      "[12]\ttraining's multi_logloss: 0.615498\tvalid_1's multi_logloss: 0.63843          \n",
      "[13]\ttraining's multi_logloss: 0.579431\tvalid_1's multi_logloss: 0.604117         \n",
      "[14]\ttraining's multi_logloss: 0.546942\tvalid_1's multi_logloss: 0.573156         \n",
      "[15]\ttraining's multi_logloss: 0.517793\tvalid_1's multi_logloss: 0.545867         \n",
      "[16]\ttraining's multi_logloss: 0.491616\tvalid_1's multi_logloss: 0.52125          \n",
      "[17]\ttraining's multi_logloss: 0.467971\tvalid_1's multi_logloss: 0.499692         \n",
      "[18]\ttraining's multi_logloss: 0.446289\tvalid_1's multi_logloss: 0.480199         \n",
      "[19]\ttraining's multi_logloss: 0.426582\tvalid_1's multi_logloss: 0.462314         \n",
      "[20]\ttraining's multi_logloss: 0.408214\tvalid_1's multi_logloss: 0.446077         \n",
      "[21]\ttraining's multi_logloss: 0.391887\tvalid_1's multi_logloss: 0.431663         \n",
      "[22]\ttraining's multi_logloss: 0.37692\tvalid_1's multi_logloss: 0.418625          \n",
      "[23]\ttraining's multi_logloss: 0.363338\tvalid_1's multi_logloss: 0.4067           \n",
      "[24]\ttraining's multi_logloss: 0.35071\tvalid_1's multi_logloss: 0.396211          \n",
      "[25]\ttraining's multi_logloss: 0.338784\tvalid_1's multi_logloss: 0.386396         \n",
      "[26]\ttraining's multi_logloss: 0.327868\tvalid_1's multi_logloss: 0.377602         \n",
      "[27]\ttraining's multi_logloss: 0.317685\tvalid_1's multi_logloss: 0.36898          \n",
      "[28]\ttraining's multi_logloss: 0.30811\tvalid_1's multi_logloss: 0.361141          \n",
      "[29]\ttraining's multi_logloss: 0.298706\tvalid_1's multi_logloss: 0.35364          \n",
      "[30]\ttraining's multi_logloss: 0.290397\tvalid_1's multi_logloss: 0.347293         \n",
      "[31]\ttraining's multi_logloss: 0.282395\tvalid_1's multi_logloss: 0.341366         \n",
      "[32]\ttraining's multi_logloss: 0.275124\tvalid_1's multi_logloss: 0.336467         \n",
      "[33]\ttraining's multi_logloss: 0.26818\tvalid_1's multi_logloss: 0.331705          \n",
      "[34]\ttraining's multi_logloss: 0.261697\tvalid_1's multi_logloss: 0.32715          \n",
      "[35]\ttraining's multi_logloss: 0.255611\tvalid_1's multi_logloss: 0.323345         \n",
      "[36]\ttraining's multi_logloss: 0.24982\tvalid_1's multi_logloss: 0.320125          \n",
      "[37]\ttraining's multi_logloss: 0.243902\tvalid_1's multi_logloss: 0.316865         \n",
      "[38]\ttraining's multi_logloss: 0.23872\tvalid_1's multi_logloss: 0.313895          \n",
      "[39]\ttraining's multi_logloss: 0.233312\tvalid_1's multi_logloss: 0.311462         \n",
      "[40]\ttraining's multi_logloss: 0.228577\tvalid_1's multi_logloss: 0.309113         \n",
      "[41]\ttraining's multi_logloss: 0.223763\tvalid_1's multi_logloss: 0.306862         \n",
      "[42]\ttraining's multi_logloss: 0.219423\tvalid_1's multi_logloss: 0.3049           \n",
      "[43]\ttraining's multi_logloss: 0.214849\tvalid_1's multi_logloss: 0.303064         \n",
      "[44]\ttraining's multi_logloss: 0.210831\tvalid_1's multi_logloss: 0.301297         \n",
      "[45]\ttraining's multi_logloss: 0.20689\tvalid_1's multi_logloss: 0.29994           \n",
      "[46]\ttraining's multi_logloss: 0.203027\tvalid_1's multi_logloss: 0.29835          \n",
      "[47]\ttraining's multi_logloss: 0.199244\tvalid_1's multi_logloss: 0.297119         \n",
      "[48]\ttraining's multi_logloss: 0.195696\tvalid_1's multi_logloss: 0.295846         \n",
      "[49]\ttraining's multi_logloss: 0.192075\tvalid_1's multi_logloss: 0.294701         \n",
      "[50]\ttraining's multi_logloss: 0.188523\tvalid_1's multi_logloss: 0.293389         \n",
      "[51]\ttraining's multi_logloss: 0.184963\tvalid_1's multi_logloss: 0.292303         \n",
      "[52]\ttraining's multi_logloss: 0.181558\tvalid_1's multi_logloss: 0.291576         \n",
      "[53]\ttraining's multi_logloss: 0.178364\tvalid_1's multi_logloss: 0.290598         \n",
      "[54]\ttraining's multi_logloss: 0.175059\tvalid_1's multi_logloss: 0.2898           \n",
      "[55]\ttraining's multi_logloss: 0.172147\tvalid_1's multi_logloss: 0.289132         \n",
      "[56]\ttraining's multi_logloss: 0.169173\tvalid_1's multi_logloss: 0.288568         \n",
      "[57]\ttraining's multi_logloss: 0.166242\tvalid_1's multi_logloss: 0.288072         \n",
      "[58]\ttraining's multi_logloss: 0.163411\tvalid_1's multi_logloss: 0.287624         \n",
      "[59]\ttraining's multi_logloss: 0.160345\tvalid_1's multi_logloss: 0.287212         \n",
      "[60]\ttraining's multi_logloss: 0.157478\tvalid_1's multi_logloss: 0.286619         \n",
      "[61]\ttraining's multi_logloss: 0.154842\tvalid_1's multi_logloss: 0.28602          \n",
      "[62]\ttraining's multi_logloss: 0.152006\tvalid_1's multi_logloss: 0.285428         \n",
      "[63]\ttraining's multi_logloss: 0.149325\tvalid_1's multi_logloss: 0.28505          \n",
      "[64]\ttraining's multi_logloss: 0.146577\tvalid_1's multi_logloss: 0.285006         \n",
      "[65]\ttraining's multi_logloss: 0.144262\tvalid_1's multi_logloss: 0.284864         \n",
      "[66]\ttraining's multi_logloss: 0.141775\tvalid_1's multi_logloss: 0.284586         \n",
      "[67]\ttraining's multi_logloss: 0.139399\tvalid_1's multi_logloss: 0.284559         \n",
      "[68]\ttraining's multi_logloss: 0.137185\tvalid_1's multi_logloss: 0.284502         \n",
      "[69]\ttraining's multi_logloss: 0.134921\tvalid_1's multi_logloss: 0.284199         \n",
      "[70]\ttraining's multi_logloss: 0.132796\tvalid_1's multi_logloss: 0.284034         \n",
      "[71]\ttraining's multi_logloss: 0.130769\tvalid_1's multi_logloss: 0.284122         \n",
      "[72]\ttraining's multi_logloss: 0.128604\tvalid_1's multi_logloss: 0.283977         \n",
      "[73]\ttraining's multi_logloss: 0.126508\tvalid_1's multi_logloss: 0.284086         \n",
      "[74]\ttraining's multi_logloss: 0.124519\tvalid_1's multi_logloss: 0.283968         \n",
      "[75]\ttraining's multi_logloss: 0.122409\tvalid_1's multi_logloss: 0.28386          \n",
      "[76]\ttraining's multi_logloss: 0.12029\tvalid_1's multi_logloss: 0.283904          \n",
      "[77]\ttraining's multi_logloss: 0.118348\tvalid_1's multi_logloss: 0.283829         \n",
      "[78]\ttraining's multi_logloss: 0.116302\tvalid_1's multi_logloss: 0.28384          \n",
      "[79]\ttraining's multi_logloss: 0.114479\tvalid_1's multi_logloss: 0.28372          \n",
      "[80]\ttraining's multi_logloss: 0.11256\tvalid_1's multi_logloss: 0.283828          \n",
      "[81]\ttraining's multi_logloss: 0.110706\tvalid_1's multi_logloss: 0.283634         \n",
      "[82]\ttraining's multi_logloss: 0.10883\tvalid_1's multi_logloss: 0.283627          \n",
      "[83]\ttraining's multi_logloss: 0.106978\tvalid_1's multi_logloss: 0.283298         \n",
      "[84]\ttraining's multi_logloss: 0.105125\tvalid_1's multi_logloss: 0.283398         \n",
      "[85]\ttraining's multi_logloss: 0.103517\tvalid_1's multi_logloss: 0.283566         \n",
      "[86]\ttraining's multi_logloss: 0.101581\tvalid_1's multi_logloss: 0.283753         \n",
      "[87]\ttraining's multi_logloss: 0.0997581\tvalid_1's multi_logloss: 0.284234        \n",
      "[88]\ttraining's multi_logloss: 0.0981464\tvalid_1's multi_logloss: 0.284439        \n",
      "[89]\ttraining's multi_logloss: 0.0965287\tvalid_1's multi_logloss: 0.284701        \n",
      "[90]\ttraining's multi_logloss: 0.0949899\tvalid_1's multi_logloss: 0.28516         \n",
      "[91]\ttraining's multi_logloss: 0.0934117\tvalid_1's multi_logloss: 0.285597        \n",
      "[92]\ttraining's multi_logloss: 0.0921113\tvalid_1's multi_logloss: 0.2857          \n",
      "[93]\ttraining's multi_logloss: 0.0907777\tvalid_1's multi_logloss: 0.28624         \n",
      "[94]\ttraining's multi_logloss: 0.089392\tvalid_1's multi_logloss: 0.286357         \n",
      "[95]\ttraining's multi_logloss: 0.0880806\tvalid_1's multi_logloss: 0.286743        \n",
      "[96]\ttraining's multi_logloss: 0.086814\tvalid_1's multi_logloss: 0.287069         \n",
      "[97]\ttraining's multi_logloss: 0.0855316\tvalid_1's multi_logloss: 0.287303        \n",
      "[98]\ttraining's multi_logloss: 0.0841986\tvalid_1's multi_logloss: 0.287511        \n",
      "[99]\ttraining's multi_logloss: 0.0829097\tvalid_1's multi_logloss: 0.287674        \n",
      "[100]\ttraining's multi_logloss: 0.0816329\tvalid_1's multi_logloss: 0.288274       \n",
      "[101]\ttraining's multi_logloss: 0.08044\tvalid_1's multi_logloss: 0.288307         \n",
      "[102]\ttraining's multi_logloss: 0.0791214\tvalid_1's multi_logloss: 0.288481       \n",
      "[103]\ttraining's multi_logloss: 0.0777455\tvalid_1's multi_logloss: 0.288686       \n",
      "[104]\ttraining's multi_logloss: 0.0764342\tvalid_1's multi_logloss: 0.289117       \n",
      "[105]\ttraining's multi_logloss: 0.0752375\tvalid_1's multi_logloss: 0.289576       \n",
      "[106]\ttraining's multi_logloss: 0.0739486\tvalid_1's multi_logloss: 0.289932       \n",
      "[107]\ttraining's multi_logloss: 0.0726803\tvalid_1's multi_logloss: 0.290253       \n",
      "[108]\ttraining's multi_logloss: 0.0715378\tvalid_1's multi_logloss: 0.290658       \n",
      "[109]\ttraining's multi_logloss: 0.0704304\tvalid_1's multi_logloss: 0.291408       \n",
      "[110]\ttraining's multi_logloss: 0.0694362\tvalid_1's multi_logloss: 0.291843       \n",
      "[111]\ttraining's multi_logloss: 0.068412\tvalid_1's multi_logloss: 0.292645        \n",
      "[112]\ttraining's multi_logloss: 0.0673462\tvalid_1's multi_logloss: 0.293193       \n",
      "[113]\ttraining's multi_logloss: 0.0663501\tvalid_1's multi_logloss: 0.293579       \n",
      "Early stopping, best iteration is:                                                \n",
      "[83]\ttraining's multi_logloss: 0.106978\tvalid_1's multi_logloss: 0.283298\n",
      "[1]\ttraining's multi_logloss: 1.63846\tvalid_1's multi_logloss: 1.64206            \n",
      "Training until validation scores don't improve for 30 rounds                      \n",
      "[2]\ttraining's multi_logloss: 1.43494\tvalid_1's multi_logloss: 1.44054            \n",
      "[3]\ttraining's multi_logloss: 1.27647\tvalid_1's multi_logloss: 1.28332            \n",
      "[4]\ttraining's multi_logloss: 1.15081\tvalid_1's multi_logloss: 1.15891            \n",
      "[5]\ttraining's multi_logloss: 1.04593\tvalid_1's multi_logloss: 1.05521            \n",
      "[6]\ttraining's multi_logloss: 0.956848\tvalid_1's multi_logloss: 0.966925          \n",
      "[7]\ttraining's multi_logloss: 0.880361\tvalid_1's multi_logloss: 0.891598          \n",
      "[8]\ttraining's multi_logloss: 0.813252\tvalid_1's multi_logloss: 0.825577          \n",
      "[9]\ttraining's multi_logloss: 0.755007\tvalid_1's multi_logloss: 0.768533          \n",
      "[10]\ttraining's multi_logloss: 0.703766\tvalid_1's multi_logloss: 0.718921         \n",
      "[11]\ttraining's multi_logloss: 0.658492\tvalid_1's multi_logloss: 0.675189         \n",
      "[12]\ttraining's multi_logloss: 0.617857\tvalid_1's multi_logloss: 0.635986         \n",
      "[13]\ttraining's multi_logloss: 0.582312\tvalid_1's multi_logloss: 0.601901         \n",
      "[14]\ttraining's multi_logloss: 0.549955\tvalid_1's multi_logloss: 0.570943         \n",
      "[15]\ttraining's multi_logloss: 0.520862\tvalid_1's multi_logloss: 0.5434           \n",
      "[16]\ttraining's multi_logloss: 0.494718\tvalid_1's multi_logloss: 0.518506         \n",
      "[17]\ttraining's multi_logloss: 0.470918\tvalid_1's multi_logloss: 0.496009         \n",
      "[18]\ttraining's multi_logloss: 0.449493\tvalid_1's multi_logloss: 0.47594          \n",
      "[19]\ttraining's multi_logloss: 0.429848\tvalid_1's multi_logloss: 0.457724         \n",
      "[20]\ttraining's multi_logloss: 0.412109\tvalid_1's multi_logloss: 0.441368         \n",
      "[21]\ttraining's multi_logloss: 0.395609\tvalid_1's multi_logloss: 0.426356         \n",
      "[22]\ttraining's multi_logloss: 0.380437\tvalid_1's multi_logloss: 0.412947         \n",
      "[23]\ttraining's multi_logloss: 0.366934\tvalid_1's multi_logloss: 0.400998         \n",
      "[24]\ttraining's multi_logloss: 0.354233\tvalid_1's multi_logloss: 0.389642         \n",
      "[25]\ttraining's multi_logloss: 0.342556\tvalid_1's multi_logloss: 0.379455         \n",
      "[26]\ttraining's multi_logloss: 0.33206\tvalid_1's multi_logloss: 0.370665          \n",
      "[27]\ttraining's multi_logloss: 0.322088\tvalid_1's multi_logloss: 0.362292         \n",
      "[28]\ttraining's multi_logloss: 0.31297\tvalid_1's multi_logloss: 0.354916          \n",
      "[29]\ttraining's multi_logloss: 0.304036\tvalid_1's multi_logloss: 0.347827         \n",
      "[30]\ttraining's multi_logloss: 0.295611\tvalid_1's multi_logloss: 0.340972         \n",
      "[31]\ttraining's multi_logloss: 0.287786\tvalid_1's multi_logloss: 0.334599         \n",
      "[32]\ttraining's multi_logloss: 0.280465\tvalid_1's multi_logloss: 0.32956          \n",
      "[33]\ttraining's multi_logloss: 0.273775\tvalid_1's multi_logloss: 0.32483          \n",
      "[34]\ttraining's multi_logloss: 0.267437\tvalid_1's multi_logloss: 0.320334         \n",
      "[35]\ttraining's multi_logloss: 0.261143\tvalid_1's multi_logloss: 0.316174         \n",
      "[36]\ttraining's multi_logloss: 0.25531\tvalid_1's multi_logloss: 0.312419          \n",
      "[37]\ttraining's multi_logloss: 0.249664\tvalid_1's multi_logloss: 0.30915          \n",
      "[38]\ttraining's multi_logloss: 0.244386\tvalid_1's multi_logloss: 0.306271         \n",
      "[39]\ttraining's multi_logloss: 0.239208\tvalid_1's multi_logloss: 0.303424         \n",
      "[40]\ttraining's multi_logloss: 0.234339\tvalid_1's multi_logloss: 0.301016         \n",
      "[41]\ttraining's multi_logloss: 0.229496\tvalid_1's multi_logloss: 0.298061         \n",
      "[42]\ttraining's multi_logloss: 0.225062\tvalid_1's multi_logloss: 0.295762         \n",
      "[43]\ttraining's multi_logloss: 0.221039\tvalid_1's multi_logloss: 0.294095         \n",
      "[44]\ttraining's multi_logloss: 0.216949\tvalid_1's multi_logloss: 0.291827         \n",
      "[45]\ttraining's multi_logloss: 0.213049\tvalid_1's multi_logloss: 0.290105         \n",
      "[46]\ttraining's multi_logloss: 0.209426\tvalid_1's multi_logloss: 0.288868         \n",
      "[47]\ttraining's multi_logloss: 0.205703\tvalid_1's multi_logloss: 0.287071         \n",
      "[48]\ttraining's multi_logloss: 0.202153\tvalid_1's multi_logloss: 0.28564          \n",
      "[49]\ttraining's multi_logloss: 0.198471\tvalid_1's multi_logloss: 0.284068         \n",
      "[50]\ttraining's multi_logloss: 0.195024\tvalid_1's multi_logloss: 0.282984         \n",
      "[51]\ttraining's multi_logloss: 0.191538\tvalid_1's multi_logloss: 0.281539         \n",
      "[52]\ttraining's multi_logloss: 0.188239\tvalid_1's multi_logloss: 0.280437         \n",
      "[53]\ttraining's multi_logloss: 0.185038\tvalid_1's multi_logloss: 0.279524         \n",
      "[54]\ttraining's multi_logloss: 0.181851\tvalid_1's multi_logloss: 0.278763         \n",
      "[55]\ttraining's multi_logloss: 0.178783\tvalid_1's multi_logloss: 0.277866         \n",
      "[56]\ttraining's multi_logloss: 0.175692\tvalid_1's multi_logloss: 0.277206         \n",
      "[57]\ttraining's multi_logloss: 0.172683\tvalid_1's multi_logloss: 0.276151         \n",
      "[58]\ttraining's multi_logloss: 0.169691\tvalid_1's multi_logloss: 0.275555         \n",
      "[59]\ttraining's multi_logloss: 0.166792\tvalid_1's multi_logloss: 0.274972         \n",
      "[60]\ttraining's multi_logloss: 0.1639\tvalid_1's multi_logloss: 0.274794           \n",
      "[61]\ttraining's multi_logloss: 0.161182\tvalid_1's multi_logloss: 0.274255         \n",
      "[62]\ttraining's multi_logloss: 0.158559\tvalid_1's multi_logloss: 0.273473         \n",
      "[63]\ttraining's multi_logloss: 0.15589\tvalid_1's multi_logloss: 0.272877          \n",
      "[64]\ttraining's multi_logloss: 0.153466\tvalid_1's multi_logloss: 0.272488         \n",
      "[65]\ttraining's multi_logloss: 0.150658\tvalid_1's multi_logloss: 0.271995         \n",
      "[66]\ttraining's multi_logloss: 0.148182\tvalid_1's multi_logloss: 0.271623         \n",
      "[67]\ttraining's multi_logloss: 0.145597\tvalid_1's multi_logloss: 0.27119          \n",
      "[68]\ttraining's multi_logloss: 0.143386\tvalid_1's multi_logloss: 0.270972         \n",
      "[69]\ttraining's multi_logloss: 0.14094\tvalid_1's multi_logloss: 0.270723          \n",
      "[70]\ttraining's multi_logloss: 0.13871\tvalid_1's multi_logloss: 0.270231          \n",
      "[71]\ttraining's multi_logloss: 0.136334\tvalid_1's multi_logloss: 0.269607         \n",
      "[72]\ttraining's multi_logloss: 0.134047\tvalid_1's multi_logloss: 0.269468         \n",
      "[73]\ttraining's multi_logloss: 0.131816\tvalid_1's multi_logloss: 0.269392         \n",
      "[74]\ttraining's multi_logloss: 0.129522\tvalid_1's multi_logloss: 0.269004         \n",
      "[75]\ttraining's multi_logloss: 0.127469\tvalid_1's multi_logloss: 0.268774         \n",
      "[76]\ttraining's multi_logloss: 0.1253\tvalid_1's multi_logloss: 0.268494           \n",
      "[77]\ttraining's multi_logloss: 0.123443\tvalid_1's multi_logloss: 0.268516         \n",
      "[78]\ttraining's multi_logloss: 0.121565\tvalid_1's multi_logloss: 0.268523         \n",
      "[79]\ttraining's multi_logloss: 0.119655\tvalid_1's multi_logloss: 0.268532         \n",
      "[80]\ttraining's multi_logloss: 0.117943\tvalid_1's multi_logloss: 0.268509         \n",
      "[81]\ttraining's multi_logloss: 0.116064\tvalid_1's multi_logloss: 0.268567         \n",
      "[82]\ttraining's multi_logloss: 0.113996\tvalid_1's multi_logloss: 0.268238         \n",
      "[83]\ttraining's multi_logloss: 0.112197\tvalid_1's multi_logloss: 0.268143         \n",
      "[84]\ttraining's multi_logloss: 0.1105\tvalid_1's multi_logloss: 0.268151           \n",
      "[85]\ttraining's multi_logloss: 0.108662\tvalid_1's multi_logloss: 0.26832          \n",
      "[86]\ttraining's multi_logloss: 0.107043\tvalid_1's multi_logloss: 0.268479         \n",
      "[87]\ttraining's multi_logloss: 0.105415\tvalid_1's multi_logloss: 0.268868         \n",
      "[88]\ttraining's multi_logloss: 0.103774\tvalid_1's multi_logloss: 0.269031         \n",
      "[89]\ttraining's multi_logloss: 0.102302\tvalid_1's multi_logloss: 0.268897         \n",
      "[90]\ttraining's multi_logloss: 0.100424\tvalid_1's multi_logloss: 0.269013         \n",
      "[91]\ttraining's multi_logloss: 0.0990106\tvalid_1's multi_logloss: 0.269305        \n",
      "[92]\ttraining's multi_logloss: 0.0974456\tvalid_1's multi_logloss: 0.269183        \n",
      "[93]\ttraining's multi_logloss: 0.0960181\tvalid_1's multi_logloss: 0.269452        \n",
      "[94]\ttraining's multi_logloss: 0.0946639\tvalid_1's multi_logloss: 0.269743        \n",
      "[95]\ttraining's multi_logloss: 0.0931123\tvalid_1's multi_logloss: 0.27015         \n",
      "[96]\ttraining's multi_logloss: 0.091563\tvalid_1's multi_logloss: 0.270088         \n",
      "[97]\ttraining's multi_logloss: 0.0902318\tvalid_1's multi_logloss: 0.270155        \n",
      "[98]\ttraining's multi_logloss: 0.0887783\tvalid_1's multi_logloss: 0.270251        \n",
      "[99]\ttraining's multi_logloss: 0.087252\tvalid_1's multi_logloss: 0.270669         \n",
      "[100]\ttraining's multi_logloss: 0.085774\tvalid_1's multi_logloss: 0.270908        \n",
      "[101]\ttraining's multi_logloss: 0.0844112\tvalid_1's multi_logloss: 0.271308       \n",
      "[102]\ttraining's multi_logloss: 0.0831494\tvalid_1's multi_logloss: 0.271748       \n",
      "[103]\ttraining's multi_logloss: 0.0820426\tvalid_1's multi_logloss: 0.271868       \n",
      "[104]\ttraining's multi_logloss: 0.0808533\tvalid_1's multi_logloss: 0.272269       \n",
      "[105]\ttraining's multi_logloss: 0.0796659\tvalid_1's multi_logloss: 0.27265        \n",
      "[106]\ttraining's multi_logloss: 0.0785178\tvalid_1's multi_logloss: 0.273073       \n",
      "[107]\ttraining's multi_logloss: 0.0774101\tvalid_1's multi_logloss: 0.273063       \n",
      "[108]\ttraining's multi_logloss: 0.0763997\tvalid_1's multi_logloss: 0.273597       \n",
      "[109]\ttraining's multi_logloss: 0.0752062\tvalid_1's multi_logloss: 0.273939       \n",
      "[110]\ttraining's multi_logloss: 0.0740947\tvalid_1's multi_logloss: 0.274163       \n",
      "[111]\ttraining's multi_logloss: 0.073043\tvalid_1's multi_logloss: 0.274241        \n",
      "[112]\ttraining's multi_logloss: 0.0719577\tvalid_1's multi_logloss: 0.274355       \n",
      "[113]\ttraining's multi_logloss: 0.0709327\tvalid_1's multi_logloss: 0.274884       \n",
      "Early stopping, best iteration is:                                                \n",
      "[83]\ttraining's multi_logloss: 0.112197\tvalid_1's multi_logloss: 0.268143\n",
      "[1]\ttraining's multi_logloss: 1.76587\tvalid_1's multi_logloss: 1.76711            \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.62897\tvalid_1's multi_logloss: 1.63357           \n",
      "[3]\ttraining's multi_logloss: 1.51264\tvalid_1's multi_logloss: 1.52044           \n",
      "[4]\ttraining's multi_logloss: 1.412\tvalid_1's multi_logloss: 1.4225              \n",
      "[5]\ttraining's multi_logloss: 1.32337\tvalid_1's multi_logloss: 1.33663           \n",
      "[6]\ttraining's multi_logloss: 1.24525\tvalid_1's multi_logloss: 1.26061           \n",
      "[7]\ttraining's multi_logloss: 1.17538\tvalid_1's multi_logloss: 1.19276           \n",
      "[8]\ttraining's multi_logloss: 1.11226\tvalid_1's multi_logloss: 1.13175           \n",
      "[9]\ttraining's multi_logloss: 1.05484\tvalid_1's multi_logloss: 1.07618           \n",
      "[10]\ttraining's multi_logloss: 1.0024\tvalid_1's multi_logloss: 1.02564           \n",
      "[11]\ttraining's multi_logloss: 0.954384\tvalid_1's multi_logloss: 0.979294        \n",
      "[12]\ttraining's multi_logloss: 0.91024\tvalid_1's multi_logloss: 0.936683         \n",
      "[13]\ttraining's multi_logloss: 0.869704\tvalid_1's multi_logloss: 0.897644        \n",
      "[14]\ttraining's multi_logloss: 0.831467\tvalid_1's multi_logloss: 0.860792        \n",
      "[15]\ttraining's multi_logloss: 0.796131\tvalid_1's multi_logloss: 0.826751        \n",
      "[16]\ttraining's multi_logloss: 0.763043\tvalid_1's multi_logloss: 0.794784        \n",
      "[17]\ttraining's multi_logloss: 0.732542\tvalid_1's multi_logloss: 0.765362        \n",
      "[18]\ttraining's multi_logloss: 0.704241\tvalid_1's multi_logloss: 0.738194        \n",
      "[19]\ttraining's multi_logloss: 0.67767\tvalid_1's multi_logloss: 0.712782         \n",
      "[20]\ttraining's multi_logloss: 0.652821\tvalid_1's multi_logloss: 0.689026        \n",
      "[21]\ttraining's multi_logloss: 0.629254\tvalid_1's multi_logloss: 0.66646         \n",
      "[22]\ttraining's multi_logloss: 0.607049\tvalid_1's multi_logloss: 0.645485        \n",
      "[23]\ttraining's multi_logloss: 0.586383\tvalid_1's multi_logloss: 0.625939        \n",
      "[24]\ttraining's multi_logloss: 0.566783\tvalid_1's multi_logloss: 0.607588        \n",
      "[25]\ttraining's multi_logloss: 0.548572\tvalid_1's multi_logloss: 0.590392        \n",
      "[26]\ttraining's multi_logloss: 0.531532\tvalid_1's multi_logloss: 0.574515        \n",
      "[27]\ttraining's multi_logloss: 0.515369\tvalid_1's multi_logloss: 0.559297        \n",
      "[28]\ttraining's multi_logloss: 0.500257\tvalid_1's multi_logloss: 0.545194        \n",
      "[29]\ttraining's multi_logloss: 0.485654\tvalid_1's multi_logloss: 0.53154         \n",
      "[30]\ttraining's multi_logloss: 0.471895\tvalid_1's multi_logloss: 0.518902        \n",
      "[31]\ttraining's multi_logloss: 0.458803\tvalid_1's multi_logloss: 0.506661        \n",
      "[32]\ttraining's multi_logloss: 0.446456\tvalid_1's multi_logloss: 0.495338        \n",
      "[33]\ttraining's multi_logloss: 0.434747\tvalid_1's multi_logloss: 0.484566        \n",
      "[34]\ttraining's multi_logloss: 0.423677\tvalid_1's multi_logloss: 0.474453        \n",
      "[35]\ttraining's multi_logloss: 0.413336\tvalid_1's multi_logloss: 0.464989        \n",
      "[36]\ttraining's multi_logloss: 0.403354\tvalid_1's multi_logloss: 0.455614        \n",
      "[37]\ttraining's multi_logloss: 0.393995\tvalid_1's multi_logloss: 0.447277        \n",
      "[38]\ttraining's multi_logloss: 0.384992\tvalid_1's multi_logloss: 0.439069        \n",
      "[39]\ttraining's multi_logloss: 0.376513\tvalid_1's multi_logloss: 0.43136         \n",
      "[40]\ttraining's multi_logloss: 0.368288\tvalid_1's multi_logloss: 0.424058        \n",
      "[41]\ttraining's multi_logloss: 0.36053\tvalid_1's multi_logloss: 0.4172           \n",
      "[42]\ttraining's multi_logloss: 0.353211\tvalid_1's multi_logloss: 0.410971        \n",
      "[43]\ttraining's multi_logloss: 0.346247\tvalid_1's multi_logloss: 0.405082        \n",
      "[44]\ttraining's multi_logloss: 0.339517\tvalid_1's multi_logloss: 0.399423        \n",
      "[45]\ttraining's multi_logloss: 0.333226\tvalid_1's multi_logloss: 0.394082        \n",
      "[46]\ttraining's multi_logloss: 0.32707\tvalid_1's multi_logloss: 0.388946         \n",
      "[47]\ttraining's multi_logloss: 0.321441\tvalid_1's multi_logloss: 0.384091        \n",
      "[48]\ttraining's multi_logloss: 0.315818\tvalid_1's multi_logloss: 0.379414        \n",
      "[49]\ttraining's multi_logloss: 0.310463\tvalid_1's multi_logloss: 0.375048        \n",
      "[50]\ttraining's multi_logloss: 0.305305\tvalid_1's multi_logloss: 0.370738        \n",
      "[51]\ttraining's multi_logloss: 0.300255\tvalid_1's multi_logloss: 0.366579        \n",
      "[52]\ttraining's multi_logloss: 0.295575\tvalid_1's multi_logloss: 0.362923        \n",
      "[53]\ttraining's multi_logloss: 0.290968\tvalid_1's multi_logloss: 0.359421        \n",
      "[54]\ttraining's multi_logloss: 0.286605\tvalid_1's multi_logloss: 0.356069        \n",
      "[55]\ttraining's multi_logloss: 0.282324\tvalid_1's multi_logloss: 0.352803        \n",
      "[56]\ttraining's multi_logloss: 0.278145\tvalid_1's multi_logloss: 0.349832        \n",
      "[57]\ttraining's multi_logloss: 0.274073\tvalid_1's multi_logloss: 0.346871        \n",
      "[58]\ttraining's multi_logloss: 0.270131\tvalid_1's multi_logloss: 0.344283        \n",
      "[59]\ttraining's multi_logloss: 0.266374\tvalid_1's multi_logloss: 0.341609        \n",
      "[60]\ttraining's multi_logloss: 0.262846\tvalid_1's multi_logloss: 0.339024        \n",
      "[61]\ttraining's multi_logloss: 0.259295\tvalid_1's multi_logloss: 0.336665        \n",
      "[62]\ttraining's multi_logloss: 0.255904\tvalid_1's multi_logloss: 0.334415        \n",
      "[63]\ttraining's multi_logloss: 0.252742\tvalid_1's multi_logloss: 0.33231         \n",
      "[64]\ttraining's multi_logloss: 0.249608\tvalid_1's multi_logloss: 0.330434        \n",
      "[65]\ttraining's multi_logloss: 0.2466\tvalid_1's multi_logloss: 0.328552          \n",
      "[66]\ttraining's multi_logloss: 0.243639\tvalid_1's multi_logloss: 0.32667         \n",
      "[67]\ttraining's multi_logloss: 0.240771\tvalid_1's multi_logloss: 0.325006        \n",
      "[68]\ttraining's multi_logloss: 0.23799\tvalid_1's multi_logloss: 0.323202         \n",
      "[69]\ttraining's multi_logloss: 0.235255\tvalid_1's multi_logloss: 0.321641        \n",
      "[70]\ttraining's multi_logloss: 0.232507\tvalid_1's multi_logloss: 0.32015         \n",
      "[71]\ttraining's multi_logloss: 0.229981\tvalid_1's multi_logloss: 0.318855        \n",
      "[72]\ttraining's multi_logloss: 0.227507\tvalid_1's multi_logloss: 0.317448        \n",
      "[73]\ttraining's multi_logloss: 0.225038\tvalid_1's multi_logloss: 0.316051        \n",
      "[74]\ttraining's multi_logloss: 0.222694\tvalid_1's multi_logloss: 0.314896        \n",
      "[75]\ttraining's multi_logloss: 0.220389\tvalid_1's multi_logloss: 0.313678        \n",
      "[76]\ttraining's multi_logloss: 0.218114\tvalid_1's multi_logloss: 0.312668        \n",
      "[77]\ttraining's multi_logloss: 0.215939\tvalid_1's multi_logloss: 0.311534        \n",
      "[78]\ttraining's multi_logloss: 0.213653\tvalid_1's multi_logloss: 0.310331        \n",
      "[79]\ttraining's multi_logloss: 0.211554\tvalid_1's multi_logloss: 0.309455        \n",
      "[80]\ttraining's multi_logloss: 0.209461\tvalid_1's multi_logloss: 0.308405        \n",
      "[81]\ttraining's multi_logloss: 0.207424\tvalid_1's multi_logloss: 0.30734         \n",
      "[82]\ttraining's multi_logloss: 0.205409\tvalid_1's multi_logloss: 0.306422        \n",
      "[83]\ttraining's multi_logloss: 0.203496\tvalid_1's multi_logloss: 0.305785        \n",
      "[84]\ttraining's multi_logloss: 0.201563\tvalid_1's multi_logloss: 0.304963        \n",
      "[85]\ttraining's multi_logloss: 0.199759\tvalid_1's multi_logloss: 0.304182        \n",
      "[86]\ttraining's multi_logloss: 0.197947\tvalid_1's multi_logloss: 0.303395        \n",
      "[87]\ttraining's multi_logloss: 0.196153\tvalid_1's multi_logloss: 0.30277         \n",
      "[88]\ttraining's multi_logloss: 0.194371\tvalid_1's multi_logloss: 0.302027        \n",
      "[89]\ttraining's multi_logloss: 0.192589\tvalid_1's multi_logloss: 0.301215        \n",
      "[90]\ttraining's multi_logloss: 0.190909\tvalid_1's multi_logloss: 0.300656        \n",
      "[91]\ttraining's multi_logloss: 0.189258\tvalid_1's multi_logloss: 0.300028        \n",
      "[92]\ttraining's multi_logloss: 0.187584\tvalid_1's multi_logloss: 0.299455        \n",
      "[93]\ttraining's multi_logloss: 0.185953\tvalid_1's multi_logloss: 0.298895        \n",
      "[94]\ttraining's multi_logloss: 0.184382\tvalid_1's multi_logloss: 0.29829         \n",
      "[95]\ttraining's multi_logloss: 0.182736\tvalid_1's multi_logloss: 0.297731        \n",
      "[96]\ttraining's multi_logloss: 0.18116\tvalid_1's multi_logloss: 0.297216         \n",
      "[97]\ttraining's multi_logloss: 0.17959\tvalid_1's multi_logloss: 0.296701         \n",
      "[98]\ttraining's multi_logloss: 0.178096\tvalid_1's multi_logloss: 0.296182        \n",
      "[99]\ttraining's multi_logloss: 0.176604\tvalid_1's multi_logloss: 0.295926        \n",
      "[100]\ttraining's multi_logloss: 0.175165\tvalid_1's multi_logloss: 0.29561        \n",
      "[101]\ttraining's multi_logloss: 0.173697\tvalid_1's multi_logloss: 0.295152       \n",
      "[102]\ttraining's multi_logloss: 0.172234\tvalid_1's multi_logloss: 0.294797       \n",
      "[103]\ttraining's multi_logloss: 0.170902\tvalid_1's multi_logloss: 0.294431       \n",
      "[104]\ttraining's multi_logloss: 0.169533\tvalid_1's multi_logloss: 0.294081       \n",
      "[105]\ttraining's multi_logloss: 0.168181\tvalid_1's multi_logloss: 0.293759       \n",
      "[106]\ttraining's multi_logloss: 0.166856\tvalid_1's multi_logloss: 0.293407       \n",
      "[107]\ttraining's multi_logloss: 0.165428\tvalid_1's multi_logloss: 0.293024       \n",
      "[108]\ttraining's multi_logloss: 0.164118\tvalid_1's multi_logloss: 0.292756       \n",
      "[109]\ttraining's multi_logloss: 0.162845\tvalid_1's multi_logloss: 0.292485       \n",
      "[110]\ttraining's multi_logloss: 0.161513\tvalid_1's multi_logloss: 0.292226       \n",
      "[111]\ttraining's multi_logloss: 0.160308\tvalid_1's multi_logloss: 0.291966       \n",
      "[112]\ttraining's multi_logloss: 0.159065\tvalid_1's multi_logloss: 0.291825       \n",
      "[113]\ttraining's multi_logloss: 0.157903\tvalid_1's multi_logloss: 0.291429       \n",
      "[114]\ttraining's multi_logloss: 0.156622\tvalid_1's multi_logloss: 0.291266       \n",
      "[115]\ttraining's multi_logloss: 0.155428\tvalid_1's multi_logloss: 0.291078       \n",
      "[116]\ttraining's multi_logloss: 0.154216\tvalid_1's multi_logloss: 0.290833       \n",
      "[117]\ttraining's multi_logloss: 0.15303\tvalid_1's multi_logloss: 0.290577        \n",
      "[118]\ttraining's multi_logloss: 0.151786\tvalid_1's multi_logloss: 0.290455       \n",
      "[119]\ttraining's multi_logloss: 0.150567\tvalid_1's multi_logloss: 0.290289       \n",
      "[120]\ttraining's multi_logloss: 0.149385\tvalid_1's multi_logloss: 0.290009       \n",
      "[121]\ttraining's multi_logloss: 0.148271\tvalid_1's multi_logloss: 0.290022       \n",
      "[122]\ttraining's multi_logloss: 0.147164\tvalid_1's multi_logloss: 0.289983       \n",
      "[123]\ttraining's multi_logloss: 0.146039\tvalid_1's multi_logloss: 0.289797       \n",
      "[124]\ttraining's multi_logloss: 0.144965\tvalid_1's multi_logloss: 0.289715       \n",
      "[125]\ttraining's multi_logloss: 0.143929\tvalid_1's multi_logloss: 0.289621       \n",
      "[126]\ttraining's multi_logloss: 0.142936\tvalid_1's multi_logloss: 0.289522       \n",
      "[127]\ttraining's multi_logloss: 0.141946\tvalid_1's multi_logloss: 0.289404       \n",
      "[128]\ttraining's multi_logloss: 0.140931\tvalid_1's multi_logloss: 0.289137       \n",
      "[129]\ttraining's multi_logloss: 0.139895\tvalid_1's multi_logloss: 0.289075       \n",
      "[130]\ttraining's multi_logloss: 0.138867\tvalid_1's multi_logloss: 0.28888        \n",
      "[131]\ttraining's multi_logloss: 0.137797\tvalid_1's multi_logloss: 0.288726       \n",
      "[132]\ttraining's multi_logloss: 0.136841\tvalid_1's multi_logloss: 0.28861        \n",
      "[133]\ttraining's multi_logloss: 0.135871\tvalid_1's multi_logloss: 0.288441       \n",
      "[134]\ttraining's multi_logloss: 0.134879\tvalid_1's multi_logloss: 0.288468       \n",
      "[135]\ttraining's multi_logloss: 0.13394\tvalid_1's multi_logloss: 0.288309        \n",
      "[136]\ttraining's multi_logloss: 0.133089\tvalid_1's multi_logloss: 0.288061       \n",
      "[137]\ttraining's multi_logloss: 0.132123\tvalid_1's multi_logloss: 0.288078       \n",
      "[138]\ttraining's multi_logloss: 0.131216\tvalid_1's multi_logloss: 0.288194       \n",
      "[139]\ttraining's multi_logloss: 0.130334\tvalid_1's multi_logloss: 0.288128       \n",
      "[140]\ttraining's multi_logloss: 0.129472\tvalid_1's multi_logloss: 0.288036       \n",
      "[141]\ttraining's multi_logloss: 0.128615\tvalid_1's multi_logloss: 0.287994       \n",
      "[142]\ttraining's multi_logloss: 0.127784\tvalid_1's multi_logloss: 0.28792        \n",
      "[143]\ttraining's multi_logloss: 0.126951\tvalid_1's multi_logloss: 0.287941       \n",
      "[144]\ttraining's multi_logloss: 0.126043\tvalid_1's multi_logloss: 0.287701       \n",
      "[145]\ttraining's multi_logloss: 0.12522\tvalid_1's multi_logloss: 0.287684        \n",
      "[146]\ttraining's multi_logloss: 0.12444\tvalid_1's multi_logloss: 0.287772        \n",
      "[147]\ttraining's multi_logloss: 0.123651\tvalid_1's multi_logloss: 0.287617       \n",
      "[148]\ttraining's multi_logloss: 0.122834\tvalid_1's multi_logloss: 0.287413       \n",
      "[149]\ttraining's multi_logloss: 0.12199\tvalid_1's multi_logloss: 0.287389        \n",
      "[150]\ttraining's multi_logloss: 0.121211\tvalid_1's multi_logloss: 0.287527       \n",
      "[151]\ttraining's multi_logloss: 0.120402\tvalid_1's multi_logloss: 0.287561       \n",
      "[152]\ttraining's multi_logloss: 0.119569\tvalid_1's multi_logloss: 0.287576       \n",
      "[153]\ttraining's multi_logloss: 0.118816\tvalid_1's multi_logloss: 0.287646       \n",
      "[154]\ttraining's multi_logloss: 0.118073\tvalid_1's multi_logloss: 0.28767        \n",
      "[155]\ttraining's multi_logloss: 0.117329\tvalid_1's multi_logloss: 0.287613       \n",
      "[156]\ttraining's multi_logloss: 0.116617\tvalid_1's multi_logloss: 0.287629       \n",
      "[157]\ttraining's multi_logloss: 0.115883\tvalid_1's multi_logloss: 0.287774       \n",
      "[158]\ttraining's multi_logloss: 0.115117\tvalid_1's multi_logloss: 0.287807       \n",
      "[159]\ttraining's multi_logloss: 0.114352\tvalid_1's multi_logloss: 0.287872       \n",
      "[160]\ttraining's multi_logloss: 0.113612\tvalid_1's multi_logloss: 0.288068       \n",
      "[161]\ttraining's multi_logloss: 0.112884\tvalid_1's multi_logloss: 0.288199       \n",
      "[162]\ttraining's multi_logloss: 0.112137\tvalid_1's multi_logloss: 0.288251       \n",
      "[163]\ttraining's multi_logloss: 0.111474\tvalid_1's multi_logloss: 0.288317       \n",
      "[164]\ttraining's multi_logloss: 0.110742\tvalid_1's multi_logloss: 0.288369       \n",
      "[165]\ttraining's multi_logloss: 0.110037\tvalid_1's multi_logloss: 0.288492       \n",
      "[166]\ttraining's multi_logloss: 0.109364\tvalid_1's multi_logloss: 0.288632       \n",
      "[167]\ttraining's multi_logloss: 0.108695\tvalid_1's multi_logloss: 0.28859        \n",
      "[168]\ttraining's multi_logloss: 0.108049\tvalid_1's multi_logloss: 0.288684       \n",
      "[169]\ttraining's multi_logloss: 0.107375\tvalid_1's multi_logloss: 0.288782       \n",
      "[170]\ttraining's multi_logloss: 0.106756\tvalid_1's multi_logloss: 0.288763       \n",
      "[171]\ttraining's multi_logloss: 0.106114\tvalid_1's multi_logloss: 0.288951       \n",
      "[172]\ttraining's multi_logloss: 0.105533\tvalid_1's multi_logloss: 0.288951       \n",
      "[173]\ttraining's multi_logloss: 0.104956\tvalid_1's multi_logloss: 0.289056       \n",
      "[174]\ttraining's multi_logloss: 0.104374\tvalid_1's multi_logloss: 0.289219       \n",
      "[175]\ttraining's multi_logloss: 0.103756\tvalid_1's multi_logloss: 0.289364       \n",
      "[176]\ttraining's multi_logloss: 0.103201\tvalid_1's multi_logloss: 0.289344       \n",
      "[177]\ttraining's multi_logloss: 0.10261\tvalid_1's multi_logloss: 0.289459        \n",
      "[178]\ttraining's multi_logloss: 0.102022\tvalid_1's multi_logloss: 0.289456       \n",
      "[179]\ttraining's multi_logloss: 0.101285\tvalid_1's multi_logloss: 0.289366       \n",
      "Early stopping, best iteration is:                                               \n",
      "[149]\ttraining's multi_logloss: 0.12199\tvalid_1's multi_logloss: 0.287389\n",
      "[1]\ttraining's multi_logloss: 1.76407\tvalid_1's multi_logloss: 1.76709           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.6284\tvalid_1's multi_logloss: 1.63223            \n",
      "[3]\ttraining's multi_logloss: 1.51358\tvalid_1's multi_logloss: 1.51822           \n",
      "[4]\ttraining's multi_logloss: 1.41403\tvalid_1's multi_logloss: 1.4198            \n",
      "[5]\ttraining's multi_logloss: 1.32695\tvalid_1's multi_logloss: 1.33411           \n",
      "[6]\ttraining's multi_logloss: 1.24961\tvalid_1's multi_logloss: 1.25797           \n",
      "[7]\ttraining's multi_logloss: 1.18023\tvalid_1's multi_logloss: 1.18991           \n",
      "[8]\ttraining's multi_logloss: 1.11747\tvalid_1's multi_logloss: 1.12832           \n",
      "[9]\ttraining's multi_logloss: 1.06016\tvalid_1's multi_logloss: 1.07215           \n",
      "[10]\ttraining's multi_logloss: 1.00792\tvalid_1's multi_logloss: 1.02106          \n",
      "[11]\ttraining's multi_logloss: 0.960014\tvalid_1's multi_logloss: 0.974264        \n",
      "[12]\ttraining's multi_logloss: 0.915755\tvalid_1's multi_logloss: 0.931234        \n",
      "[13]\ttraining's multi_logloss: 0.875256\tvalid_1's multi_logloss: 0.892062        \n",
      "[14]\ttraining's multi_logloss: 0.837623\tvalid_1's multi_logloss: 0.855484        \n",
      "[15]\ttraining's multi_logloss: 0.802163\tvalid_1's multi_logloss: 0.820837        \n",
      "[16]\ttraining's multi_logloss: 0.769579\tvalid_1's multi_logloss: 0.789342        \n",
      "[17]\ttraining's multi_logloss: 0.738958\tvalid_1's multi_logloss: 0.759654        \n",
      "[18]\ttraining's multi_logloss: 0.710289\tvalid_1's multi_logloss: 0.732365        \n",
      "[19]\ttraining's multi_logloss: 0.683288\tvalid_1's multi_logloss: 0.706684        \n",
      "[20]\ttraining's multi_logloss: 0.658357\tvalid_1's multi_logloss: 0.683022        \n",
      "[21]\ttraining's multi_logloss: 0.634762\tvalid_1's multi_logloss: 0.660362        \n",
      "[22]\ttraining's multi_logloss: 0.612592\tvalid_1's multi_logloss: 0.639097        \n",
      "[23]\ttraining's multi_logloss: 0.591653\tvalid_1's multi_logloss: 0.619079        \n",
      "[24]\ttraining's multi_logloss: 0.572144\tvalid_1's multi_logloss: 0.600662        \n",
      "[25]\ttraining's multi_logloss: 0.55386\tvalid_1's multi_logloss: 0.583197         \n",
      "[26]\ttraining's multi_logloss: 0.536558\tvalid_1's multi_logloss: 0.566859        \n",
      "[27]\ttraining's multi_logloss: 0.520467\tvalid_1's multi_logloss: 0.551823        \n",
      "[28]\ttraining's multi_logloss: 0.504824\tvalid_1's multi_logloss: 0.537145        \n",
      "[29]\ttraining's multi_logloss: 0.490272\tvalid_1's multi_logloss: 0.523473        \n",
      "[30]\ttraining's multi_logloss: 0.476688\tvalid_1's multi_logloss: 0.510889        \n",
      "[31]\ttraining's multi_logloss: 0.463823\tvalid_1's multi_logloss: 0.499022        \n",
      "[32]\ttraining's multi_logloss: 0.451501\tvalid_1's multi_logloss: 0.487938        \n",
      "[33]\ttraining's multi_logloss: 0.439802\tvalid_1's multi_logloss: 0.477164        \n",
      "[34]\ttraining's multi_logloss: 0.428822\tvalid_1's multi_logloss: 0.467306        \n",
      "[35]\ttraining's multi_logloss: 0.418259\tvalid_1's multi_logloss: 0.457747        \n",
      "[36]\ttraining's multi_logloss: 0.408322\tvalid_1's multi_logloss: 0.448883        \n",
      "[37]\ttraining's multi_logloss: 0.398976\tvalid_1's multi_logloss: 0.440792        \n",
      "[38]\ttraining's multi_logloss: 0.390131\tvalid_1's multi_logloss: 0.432972        \n",
      "[39]\ttraining's multi_logloss: 0.381654\tvalid_1's multi_logloss: 0.425501        \n",
      "[40]\ttraining's multi_logloss: 0.37334\tvalid_1's multi_logloss: 0.41824          \n",
      "[41]\ttraining's multi_logloss: 0.365489\tvalid_1's multi_logloss: 0.411451        \n",
      "[42]\ttraining's multi_logloss: 0.357908\tvalid_1's multi_logloss: 0.404788        \n",
      "[43]\ttraining's multi_logloss: 0.350726\tvalid_1's multi_logloss: 0.398805        \n",
      "[44]\ttraining's multi_logloss: 0.343858\tvalid_1's multi_logloss: 0.393007        \n",
      "[45]\ttraining's multi_logloss: 0.337282\tvalid_1's multi_logloss: 0.387561        \n",
      "[46]\ttraining's multi_logloss: 0.33096\tvalid_1's multi_logloss: 0.38234          \n",
      "[47]\ttraining's multi_logloss: 0.325041\tvalid_1's multi_logloss: 0.37735         \n",
      "[48]\ttraining's multi_logloss: 0.319387\tvalid_1's multi_logloss: 0.372773        \n",
      "[49]\ttraining's multi_logloss: 0.314016\tvalid_1's multi_logloss: 0.36849         \n",
      "[50]\ttraining's multi_logloss: 0.308595\tvalid_1's multi_logloss: 0.364333        \n",
      "[51]\ttraining's multi_logloss: 0.303308\tvalid_1's multi_logloss: 0.360215        \n",
      "[52]\ttraining's multi_logloss: 0.298501\tvalid_1's multi_logloss: 0.35651         \n",
      "[53]\ttraining's multi_logloss: 0.293716\tvalid_1's multi_logloss: 0.353009        \n",
      "[54]\ttraining's multi_logloss: 0.289204\tvalid_1's multi_logloss: 0.349483        \n",
      "[55]\ttraining's multi_logloss: 0.284581\tvalid_1's multi_logloss: 0.346044        \n",
      "[56]\ttraining's multi_logloss: 0.280296\tvalid_1's multi_logloss: 0.343051        \n",
      "[57]\ttraining's multi_logloss: 0.276343\tvalid_1's multi_logloss: 0.340085        \n",
      "[58]\ttraining's multi_logloss: 0.272454\tvalid_1's multi_logloss: 0.337366        \n",
      "[59]\ttraining's multi_logloss: 0.268745\tvalid_1's multi_logloss: 0.334714        \n",
      "[60]\ttraining's multi_logloss: 0.265171\tvalid_1's multi_logloss: 0.332322        \n",
      "[61]\ttraining's multi_logloss: 0.261735\tvalid_1's multi_logloss: 0.330023        \n",
      "[62]\ttraining's multi_logloss: 0.258201\tvalid_1's multi_logloss: 0.327814        \n",
      "[63]\ttraining's multi_logloss: 0.254901\tvalid_1's multi_logloss: 0.32562         \n",
      "[64]\ttraining's multi_logloss: 0.251655\tvalid_1's multi_logloss: 0.32355         \n",
      "[65]\ttraining's multi_logloss: 0.248556\tvalid_1's multi_logloss: 0.321654        \n",
      "[66]\ttraining's multi_logloss: 0.245633\tvalid_1's multi_logloss: 0.319958        \n",
      "[67]\ttraining's multi_logloss: 0.242768\tvalid_1's multi_logloss: 0.318357        \n",
      "[68]\ttraining's multi_logloss: 0.239882\tvalid_1's multi_logloss: 0.316843        \n",
      "[69]\ttraining's multi_logloss: 0.236983\tvalid_1's multi_logloss: 0.315244        \n",
      "[70]\ttraining's multi_logloss: 0.234166\tvalid_1's multi_logloss: 0.31373         \n",
      "[71]\ttraining's multi_logloss: 0.23156\tvalid_1's multi_logloss: 0.31227          \n",
      "[72]\ttraining's multi_logloss: 0.228957\tvalid_1's multi_logloss: 0.310902        \n",
      "[73]\ttraining's multi_logloss: 0.226409\tvalid_1's multi_logloss: 0.309646        \n",
      "[74]\ttraining's multi_logloss: 0.223909\tvalid_1's multi_logloss: 0.308435        \n",
      "[75]\ttraining's multi_logloss: 0.221535\tvalid_1's multi_logloss: 0.307175        \n",
      "[76]\ttraining's multi_logloss: 0.219271\tvalid_1's multi_logloss: 0.306149        \n",
      "[77]\ttraining's multi_logloss: 0.216949\tvalid_1's multi_logloss: 0.305198        \n",
      "[78]\ttraining's multi_logloss: 0.214817\tvalid_1's multi_logloss: 0.304219        \n",
      "[79]\ttraining's multi_logloss: 0.212564\tvalid_1's multi_logloss: 0.303496        \n",
      "[80]\ttraining's multi_logloss: 0.210521\tvalid_1's multi_logloss: 0.302777        \n",
      "[81]\ttraining's multi_logloss: 0.208428\tvalid_1's multi_logloss: 0.30197         \n",
      "[82]\ttraining's multi_logloss: 0.206466\tvalid_1's multi_logloss: 0.301108        \n",
      "[83]\ttraining's multi_logloss: 0.204498\tvalid_1's multi_logloss: 0.300372        \n",
      "[84]\ttraining's multi_logloss: 0.202604\tvalid_1's multi_logloss: 0.2996          \n",
      "[85]\ttraining's multi_logloss: 0.200712\tvalid_1's multi_logloss: 0.298877        \n",
      "[86]\ttraining's multi_logloss: 0.198778\tvalid_1's multi_logloss: 0.298231        \n",
      "[87]\ttraining's multi_logloss: 0.196931\tvalid_1's multi_logloss: 0.297501        \n",
      "[88]\ttraining's multi_logloss: 0.195135\tvalid_1's multi_logloss: 0.296889        \n",
      "[89]\ttraining's multi_logloss: 0.193318\tvalid_1's multi_logloss: 0.296376        \n",
      "[90]\ttraining's multi_logloss: 0.191626\tvalid_1's multi_logloss: 0.295684        \n",
      "[91]\ttraining's multi_logloss: 0.189896\tvalid_1's multi_logloss: 0.295045        \n",
      "[92]\ttraining's multi_logloss: 0.188107\tvalid_1's multi_logloss: 0.294333        \n",
      "[93]\ttraining's multi_logloss: 0.186427\tvalid_1's multi_logloss: 0.293752        \n",
      "[94]\ttraining's multi_logloss: 0.184773\tvalid_1's multi_logloss: 0.293316        \n",
      "[95]\ttraining's multi_logloss: 0.183216\tvalid_1's multi_logloss: 0.292849        \n",
      "[96]\ttraining's multi_logloss: 0.181526\tvalid_1's multi_logloss: 0.292342        \n",
      "[97]\ttraining's multi_logloss: 0.179834\tvalid_1's multi_logloss: 0.291713        \n",
      "[98]\ttraining's multi_logloss: 0.178344\tvalid_1's multi_logloss: 0.291264        \n",
      "[99]\ttraining's multi_logloss: 0.17685\tvalid_1's multi_logloss: 0.290896         \n",
      "[100]\ttraining's multi_logloss: 0.175339\tvalid_1's multi_logloss: 0.290554       \n",
      "[101]\ttraining's multi_logloss: 0.173827\tvalid_1's multi_logloss: 0.290119       \n",
      "[102]\ttraining's multi_logloss: 0.172419\tvalid_1's multi_logloss: 0.289915       \n",
      "[103]\ttraining's multi_logloss: 0.171019\tvalid_1's multi_logloss: 0.289548       \n",
      "[104]\ttraining's multi_logloss: 0.169658\tvalid_1's multi_logloss: 0.289355       \n",
      "[105]\ttraining's multi_logloss: 0.168121\tvalid_1's multi_logloss: 0.289058       \n",
      "[106]\ttraining's multi_logloss: 0.166609\tvalid_1's multi_logloss: 0.288552       \n",
      "[107]\ttraining's multi_logloss: 0.165341\tvalid_1's multi_logloss: 0.288525       \n",
      "[108]\ttraining's multi_logloss: 0.164009\tvalid_1's multi_logloss: 0.28837        \n",
      "[109]\ttraining's multi_logloss: 0.162641\tvalid_1's multi_logloss: 0.28803        \n",
      "[110]\ttraining's multi_logloss: 0.161324\tvalid_1's multi_logloss: 0.287818       \n",
      "[111]\ttraining's multi_logloss: 0.160027\tvalid_1's multi_logloss: 0.287443       \n",
      "[112]\ttraining's multi_logloss: 0.158752\tvalid_1's multi_logloss: 0.287324       \n",
      "[113]\ttraining's multi_logloss: 0.157534\tvalid_1's multi_logloss: 0.28704        \n",
      "[114]\ttraining's multi_logloss: 0.15629\tvalid_1's multi_logloss: 0.286928        \n",
      "[115]\ttraining's multi_logloss: 0.155095\tvalid_1's multi_logloss: 0.286699       \n",
      "[116]\ttraining's multi_logloss: 0.153845\tvalid_1's multi_logloss: 0.286537       \n",
      "[117]\ttraining's multi_logloss: 0.152661\tvalid_1's multi_logloss: 0.286368       \n",
      "[118]\ttraining's multi_logloss: 0.151462\tvalid_1's multi_logloss: 0.286125       \n",
      "[119]\ttraining's multi_logloss: 0.150282\tvalid_1's multi_logloss: 0.285952       \n",
      "[120]\ttraining's multi_logloss: 0.149066\tvalid_1's multi_logloss: 0.285587       \n",
      "[121]\ttraining's multi_logloss: 0.14794\tvalid_1's multi_logloss: 0.285495        \n",
      "[122]\ttraining's multi_logloss: 0.146792\tvalid_1's multi_logloss: 0.285261       \n",
      "[123]\ttraining's multi_logloss: 0.145584\tvalid_1's multi_logloss: 0.285099       \n",
      "[124]\ttraining's multi_logloss: 0.144459\tvalid_1's multi_logloss: 0.284913       \n",
      "[125]\ttraining's multi_logloss: 0.143443\tvalid_1's multi_logloss: 0.284801       \n",
      "[126]\ttraining's multi_logloss: 0.142365\tvalid_1's multi_logloss: 0.284787       \n",
      "[127]\ttraining's multi_logloss: 0.141344\tvalid_1's multi_logloss: 0.284725       \n",
      "[128]\ttraining's multi_logloss: 0.14027\tvalid_1's multi_logloss: 0.284608        \n",
      "[129]\ttraining's multi_logloss: 0.139202\tvalid_1's multi_logloss: 0.284674       \n",
      "[130]\ttraining's multi_logloss: 0.138184\tvalid_1's multi_logloss: 0.284539       \n",
      "[131]\ttraining's multi_logloss: 0.137184\tvalid_1's multi_logloss: 0.284567       \n",
      "[132]\ttraining's multi_logloss: 0.136215\tvalid_1's multi_logloss: 0.284386       \n",
      "[133]\ttraining's multi_logloss: 0.135292\tvalid_1's multi_logloss: 0.284318       \n",
      "[134]\ttraining's multi_logloss: 0.134333\tvalid_1's multi_logloss: 0.284304       \n",
      "[135]\ttraining's multi_logloss: 0.133418\tvalid_1's multi_logloss: 0.284403       \n",
      "[136]\ttraining's multi_logloss: 0.132524\tvalid_1's multi_logloss: 0.284379       \n",
      "[137]\ttraining's multi_logloss: 0.131575\tvalid_1's multi_logloss: 0.284259       \n",
      "[138]\ttraining's multi_logloss: 0.130693\tvalid_1's multi_logloss: 0.28432        \n",
      "[139]\ttraining's multi_logloss: 0.129714\tvalid_1's multi_logloss: 0.284446       \n",
      "[140]\ttraining's multi_logloss: 0.128835\tvalid_1's multi_logloss: 0.284397       \n",
      "[141]\ttraining's multi_logloss: 0.12789\tvalid_1's multi_logloss: 0.28427         \n",
      "[142]\ttraining's multi_logloss: 0.126946\tvalid_1's multi_logloss: 0.284364       \n",
      "[143]\ttraining's multi_logloss: 0.126004\tvalid_1's multi_logloss: 0.28445        \n",
      "[144]\ttraining's multi_logloss: 0.125178\tvalid_1's multi_logloss: 0.284351       \n",
      "[145]\ttraining's multi_logloss: 0.124333\tvalid_1's multi_logloss: 0.284437       \n",
      "[146]\ttraining's multi_logloss: 0.123424\tvalid_1's multi_logloss: 0.284317       \n",
      "[147]\ttraining's multi_logloss: 0.122585\tvalid_1's multi_logloss: 0.284397       \n",
      "[148]\ttraining's multi_logloss: 0.121752\tvalid_1's multi_logloss: 0.284244       \n",
      "[149]\ttraining's multi_logloss: 0.120988\tvalid_1's multi_logloss: 0.284163       \n",
      "[150]\ttraining's multi_logloss: 0.120112\tvalid_1's multi_logloss: 0.284223       \n",
      "[151]\ttraining's multi_logloss: 0.119333\tvalid_1's multi_logloss: 0.284252       \n",
      "[152]\ttraining's multi_logloss: 0.118555\tvalid_1's multi_logloss: 0.284405       \n",
      "[153]\ttraining's multi_logloss: 0.117681\tvalid_1's multi_logloss: 0.284341       \n",
      "[154]\ttraining's multi_logloss: 0.116927\tvalid_1's multi_logloss: 0.284498       \n",
      "[155]\ttraining's multi_logloss: 0.116115\tvalid_1's multi_logloss: 0.28453        \n",
      "[156]\ttraining's multi_logloss: 0.115336\tvalid_1's multi_logloss: 0.284635       \n",
      "[157]\ttraining's multi_logloss: 0.114514\tvalid_1's multi_logloss: 0.284542       \n",
      "[158]\ttraining's multi_logloss: 0.113816\tvalid_1's multi_logloss: 0.284739       \n",
      "[159]\ttraining's multi_logloss: 0.113119\tvalid_1's multi_logloss: 0.284907       \n",
      "[160]\ttraining's multi_logloss: 0.112328\tvalid_1's multi_logloss: 0.285079       \n",
      "[161]\ttraining's multi_logloss: 0.111589\tvalid_1's multi_logloss: 0.285172       \n",
      "[162]\ttraining's multi_logloss: 0.110832\tvalid_1's multi_logloss: 0.285241       \n",
      "[163]\ttraining's multi_logloss: 0.110096\tvalid_1's multi_logloss: 0.285165       \n",
      "[164]\ttraining's multi_logloss: 0.10939\tvalid_1's multi_logloss: 0.285233        \n",
      "[165]\ttraining's multi_logloss: 0.108687\tvalid_1's multi_logloss: 0.285184       \n",
      "[166]\ttraining's multi_logloss: 0.10791\tvalid_1's multi_logloss: 0.28532         \n",
      "[167]\ttraining's multi_logloss: 0.107184\tvalid_1's multi_logloss: 0.28534        \n",
      "[168]\ttraining's multi_logloss: 0.106467\tvalid_1's multi_logloss: 0.285393       \n",
      "[169]\ttraining's multi_logloss: 0.105757\tvalid_1's multi_logloss: 0.285438       \n",
      "[170]\ttraining's multi_logloss: 0.10511\tvalid_1's multi_logloss: 0.285491        \n",
      "[171]\ttraining's multi_logloss: 0.104393\tvalid_1's multi_logloss: 0.285533       \n",
      "[172]\ttraining's multi_logloss: 0.10376\tvalid_1's multi_logloss: 0.285573        \n",
      "[173]\ttraining's multi_logloss: 0.103136\tvalid_1's multi_logloss: 0.285656       \n",
      "[174]\ttraining's multi_logloss: 0.102458\tvalid_1's multi_logloss: 0.285839       \n",
      "[175]\ttraining's multi_logloss: 0.101836\tvalid_1's multi_logloss: 0.285864       \n",
      "[176]\ttraining's multi_logloss: 0.101211\tvalid_1's multi_logloss: 0.285858       \n",
      "[177]\ttraining's multi_logloss: 0.100526\tvalid_1's multi_logloss: 0.285907       \n",
      "[178]\ttraining's multi_logloss: 0.0998897\tvalid_1's multi_logloss: 0.286034      \n",
      "[179]\ttraining's multi_logloss: 0.0992917\tvalid_1's multi_logloss: 0.286151      \n",
      "Early stopping, best iteration is:                                               \n",
      "[149]\ttraining's multi_logloss: 0.120988\tvalid_1's multi_logloss: 0.284163\n",
      "[1]\ttraining's multi_logloss: 1.76489\tvalid_1's multi_logloss: 1.7681            \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.63004\tvalid_1's multi_logloss: 1.63416           \n",
      "[3]\ttraining's multi_logloss: 1.51572\tvalid_1's multi_logloss: 1.52104           \n",
      "[4]\ttraining's multi_logloss: 1.41651\tvalid_1's multi_logloss: 1.42263           \n",
      "[5]\ttraining's multi_logloss: 1.32932\tvalid_1's multi_logloss: 1.3363            \n",
      "[6]\ttraining's multi_logloss: 1.25177\tvalid_1's multi_logloss: 1.25938           \n",
      "[7]\ttraining's multi_logloss: 1.18185\tvalid_1's multi_logloss: 1.19009           \n",
      "[8]\ttraining's multi_logloss: 1.11905\tvalid_1's multi_logloss: 1.12802           \n",
      "[9]\ttraining's multi_logloss: 1.0618\tvalid_1's multi_logloss: 1.0714             \n",
      "[10]\ttraining's multi_logloss: 1.00976\tvalid_1's multi_logloss: 1.01993          \n",
      "[11]\ttraining's multi_logloss: 0.961866\tvalid_1's multi_logloss: 0.972552        \n",
      "[12]\ttraining's multi_logloss: 0.917583\tvalid_1's multi_logloss: 0.928847        \n",
      "[13]\ttraining's multi_logloss: 0.876367\tvalid_1's multi_logloss: 0.888292        \n",
      "[14]\ttraining's multi_logloss: 0.838329\tvalid_1's multi_logloss: 0.850974        \n",
      "[15]\ttraining's multi_logloss: 0.803071\tvalid_1's multi_logloss: 0.81616         \n",
      "[16]\ttraining's multi_logloss: 0.770464\tvalid_1's multi_logloss: 0.784362        \n",
      "[17]\ttraining's multi_logloss: 0.739997\tvalid_1's multi_logloss: 0.754611        \n",
      "[18]\ttraining's multi_logloss: 0.711543\tvalid_1's multi_logloss: 0.726824        \n",
      "[19]\ttraining's multi_logloss: 0.684857\tvalid_1's multi_logloss: 0.700881        \n",
      "[20]\ttraining's multi_logloss: 0.660214\tvalid_1's multi_logloss: 0.676969        \n",
      "[21]\ttraining's multi_logloss: 0.637121\tvalid_1's multi_logloss: 0.654653        \n",
      "[22]\ttraining's multi_logloss: 0.615366\tvalid_1's multi_logloss: 0.633649        \n",
      "[23]\ttraining's multi_logloss: 0.594737\tvalid_1's multi_logloss: 0.614104        \n",
      "[24]\ttraining's multi_logloss: 0.575404\tvalid_1's multi_logloss: 0.595551        \n",
      "[25]\ttraining's multi_logloss: 0.557586\tvalid_1's multi_logloss: 0.578679        \n",
      "[26]\ttraining's multi_logloss: 0.540482\tvalid_1's multi_logloss: 0.562569        \n",
      "[27]\ttraining's multi_logloss: 0.524471\tvalid_1's multi_logloss: 0.547504        \n",
      "[28]\ttraining's multi_logloss: 0.509319\tvalid_1's multi_logloss: 0.533186        \n",
      "[29]\ttraining's multi_logloss: 0.495148\tvalid_1's multi_logloss: 0.519704        \n",
      "[30]\ttraining's multi_logloss: 0.481642\tvalid_1's multi_logloss: 0.507008        \n",
      "[31]\ttraining's multi_logloss: 0.469029\tvalid_1's multi_logloss: 0.495119        \n",
      "[32]\ttraining's multi_logloss: 0.457045\tvalid_1's multi_logloss: 0.483986        \n",
      "[33]\ttraining's multi_logloss: 0.445594\tvalid_1's multi_logloss: 0.473304        \n",
      "[34]\ttraining's multi_logloss: 0.434627\tvalid_1's multi_logloss: 0.462998        \n",
      "[35]\ttraining's multi_logloss: 0.424293\tvalid_1's multi_logloss: 0.453425        \n",
      "[36]\ttraining's multi_logloss: 0.414337\tvalid_1's multi_logloss: 0.444247        \n",
      "[37]\ttraining's multi_logloss: 0.405051\tvalid_1's multi_logloss: 0.435637        \n",
      "[38]\ttraining's multi_logloss: 0.395771\tvalid_1's multi_logloss: 0.427108        \n",
      "[39]\ttraining's multi_logloss: 0.387292\tvalid_1's multi_logloss: 0.41937         \n",
      "[40]\ttraining's multi_logloss: 0.379316\tvalid_1's multi_logloss: 0.412164        \n",
      "[41]\ttraining's multi_logloss: 0.371303\tvalid_1's multi_logloss: 0.405012        \n",
      "[42]\ttraining's multi_logloss: 0.364138\tvalid_1's multi_logloss: 0.398703        \n",
      "[43]\ttraining's multi_logloss: 0.356778\tvalid_1's multi_logloss: 0.391832        \n",
      "[44]\ttraining's multi_logloss: 0.349703\tvalid_1's multi_logloss: 0.385403        \n",
      "[45]\ttraining's multi_logloss: 0.343251\tvalid_1's multi_logloss: 0.379675        \n",
      "[46]\ttraining's multi_logloss: 0.33712\tvalid_1's multi_logloss: 0.374429         \n",
      "[47]\ttraining's multi_logloss: 0.331187\tvalid_1's multi_logloss: 0.36938         \n",
      "[48]\ttraining's multi_logloss: 0.325633\tvalid_1's multi_logloss: 0.364656        \n",
      "[49]\ttraining's multi_logloss: 0.320152\tvalid_1's multi_logloss: 0.36004         \n",
      "[50]\ttraining's multi_logloss: 0.314739\tvalid_1's multi_logloss: 0.355583        \n",
      "[51]\ttraining's multi_logloss: 0.309637\tvalid_1's multi_logloss: 0.351521        \n",
      "[52]\ttraining's multi_logloss: 0.304725\tvalid_1's multi_logloss: 0.347491        \n",
      "[53]\ttraining's multi_logloss: 0.300158\tvalid_1's multi_logloss: 0.343874        \n",
      "[54]\ttraining's multi_logloss: 0.295659\tvalid_1's multi_logloss: 0.34042         \n",
      "[55]\ttraining's multi_logloss: 0.291256\tvalid_1's multi_logloss: 0.33718         \n",
      "[56]\ttraining's multi_logloss: 0.287184\tvalid_1's multi_logloss: 0.333946        \n",
      "[57]\ttraining's multi_logloss: 0.283132\tvalid_1's multi_logloss: 0.330935        \n",
      "[58]\ttraining's multi_logloss: 0.279317\tvalid_1's multi_logloss: 0.327992        \n",
      "[59]\ttraining's multi_logloss: 0.275658\tvalid_1's multi_logloss: 0.325197        \n",
      "[60]\ttraining's multi_logloss: 0.271868\tvalid_1's multi_logloss: 0.322527        \n",
      "[61]\ttraining's multi_logloss: 0.268474\tvalid_1's multi_logloss: 0.320204        \n",
      "[62]\ttraining's multi_logloss: 0.2652\tvalid_1's multi_logloss: 0.317846          \n",
      "[63]\ttraining's multi_logloss: 0.261894\tvalid_1's multi_logloss: 0.315547        \n",
      "[64]\ttraining's multi_logloss: 0.258736\tvalid_1's multi_logloss: 0.31323         \n",
      "[65]\ttraining's multi_logloss: 0.255693\tvalid_1's multi_logloss: 0.311135        \n",
      "[66]\ttraining's multi_logloss: 0.252754\tvalid_1's multi_logloss: 0.309281        \n",
      "[67]\ttraining's multi_logloss: 0.249803\tvalid_1's multi_logloss: 0.307428        \n",
      "[68]\ttraining's multi_logloss: 0.246845\tvalid_1's multi_logloss: 0.305516        \n",
      "[69]\ttraining's multi_logloss: 0.244119\tvalid_1's multi_logloss: 0.303905        \n",
      "[70]\ttraining's multi_logloss: 0.24146\tvalid_1's multi_logloss: 0.302286         \n",
      "[71]\ttraining's multi_logloss: 0.23893\tvalid_1's multi_logloss: 0.300842         \n",
      "[72]\ttraining's multi_logloss: 0.236295\tvalid_1's multi_logloss: 0.299238        \n",
      "[73]\ttraining's multi_logloss: 0.233865\tvalid_1's multi_logloss: 0.297929        \n",
      "[74]\ttraining's multi_logloss: 0.231377\tvalid_1's multi_logloss: 0.296506        \n",
      "[75]\ttraining's multi_logloss: 0.229008\tvalid_1's multi_logloss: 0.295428        \n",
      "[76]\ttraining's multi_logloss: 0.226652\tvalid_1's multi_logloss: 0.294112        \n",
      "[77]\ttraining's multi_logloss: 0.224345\tvalid_1's multi_logloss: 0.292938        \n",
      "[78]\ttraining's multi_logloss: 0.222122\tvalid_1's multi_logloss: 0.29181         \n",
      "[79]\ttraining's multi_logloss: 0.219971\tvalid_1's multi_logloss: 0.290691        \n",
      "[80]\ttraining's multi_logloss: 0.217799\tvalid_1's multi_logloss: 0.289585        \n",
      "[81]\ttraining's multi_logloss: 0.215798\tvalid_1's multi_logloss: 0.288588        \n",
      "[82]\ttraining's multi_logloss: 0.213777\tvalid_1's multi_logloss: 0.287769        \n",
      "[83]\ttraining's multi_logloss: 0.211864\tvalid_1's multi_logloss: 0.287125        \n",
      "[84]\ttraining's multi_logloss: 0.20989\tvalid_1's multi_logloss: 0.286276         \n",
      "[85]\ttraining's multi_logloss: 0.207983\tvalid_1's multi_logloss: 0.285319        \n",
      "[86]\ttraining's multi_logloss: 0.205985\tvalid_1's multi_logloss: 0.284475        \n",
      "[87]\ttraining's multi_logloss: 0.204188\tvalid_1's multi_logloss: 0.283715        \n",
      "[88]\ttraining's multi_logloss: 0.20231\tvalid_1's multi_logloss: 0.282888         \n",
      "[89]\ttraining's multi_logloss: 0.200575\tvalid_1's multi_logloss: 0.282344        \n",
      "[90]\ttraining's multi_logloss: 0.198796\tvalid_1's multi_logloss: 0.281572        \n",
      "[91]\ttraining's multi_logloss: 0.196912\tvalid_1's multi_logloss: 0.280875        \n",
      "[92]\ttraining's multi_logloss: 0.195124\tvalid_1's multi_logloss: 0.280228        \n",
      "[93]\ttraining's multi_logloss: 0.193393\tvalid_1's multi_logloss: 0.279708        \n",
      "[94]\ttraining's multi_logloss: 0.191696\tvalid_1's multi_logloss: 0.279153        \n",
      "[95]\ttraining's multi_logloss: 0.189959\tvalid_1's multi_logloss: 0.27858         \n",
      "[96]\ttraining's multi_logloss: 0.188334\tvalid_1's multi_logloss: 0.277924        \n",
      "[97]\ttraining's multi_logloss: 0.186758\tvalid_1's multi_logloss: 0.277199        \n",
      "[98]\ttraining's multi_logloss: 0.185151\tvalid_1's multi_logloss: 0.276863        \n",
      "[99]\ttraining's multi_logloss: 0.1837\tvalid_1's multi_logloss: 0.276577          \n",
      "[100]\ttraining's multi_logloss: 0.18219\tvalid_1's multi_logloss: 0.275986        \n",
      "[101]\ttraining's multi_logloss: 0.180732\tvalid_1's multi_logloss: 0.275518       \n",
      "[102]\ttraining's multi_logloss: 0.179249\tvalid_1's multi_logloss: 0.275098       \n",
      "[103]\ttraining's multi_logloss: 0.177785\tvalid_1's multi_logloss: 0.274652       \n",
      "[104]\ttraining's multi_logloss: 0.176325\tvalid_1's multi_logloss: 0.274338       \n",
      "[105]\ttraining's multi_logloss: 0.174844\tvalid_1's multi_logloss: 0.273836       \n",
      "[106]\ttraining's multi_logloss: 0.173422\tvalid_1's multi_logloss: 0.273383       \n",
      "[107]\ttraining's multi_logloss: 0.172037\tvalid_1's multi_logloss: 0.272996       \n",
      "[108]\ttraining's multi_logloss: 0.170615\tvalid_1's multi_logloss: 0.272708       \n",
      "[109]\ttraining's multi_logloss: 0.169235\tvalid_1's multi_logloss: 0.272289       \n",
      "[110]\ttraining's multi_logloss: 0.167912\tvalid_1's multi_logloss: 0.272089       \n",
      "[111]\ttraining's multi_logloss: 0.166618\tvalid_1's multi_logloss: 0.272054       \n",
      "[112]\ttraining's multi_logloss: 0.165369\tvalid_1's multi_logloss: 0.271924       \n",
      "[113]\ttraining's multi_logloss: 0.164067\tvalid_1's multi_logloss: 0.271641       \n",
      "[114]\ttraining's multi_logloss: 0.162876\tvalid_1's multi_logloss: 0.271471       \n",
      "[115]\ttraining's multi_logloss: 0.161521\tvalid_1's multi_logloss: 0.271165       \n",
      "[116]\ttraining's multi_logloss: 0.160256\tvalid_1's multi_logloss: 0.270978       \n",
      "[117]\ttraining's multi_logloss: 0.159042\tvalid_1's multi_logloss: 0.270832       \n",
      "[118]\ttraining's multi_logloss: 0.157969\tvalid_1's multi_logloss: 0.270638       \n",
      "[119]\ttraining's multi_logloss: 0.156775\tvalid_1's multi_logloss: 0.27048        \n",
      "[120]\ttraining's multi_logloss: 0.155613\tvalid_1's multi_logloss: 0.270397       \n",
      "[121]\ttraining's multi_logloss: 0.154491\tvalid_1's multi_logloss: 0.270257       \n",
      "[122]\ttraining's multi_logloss: 0.153372\tvalid_1's multi_logloss: 0.269957       \n",
      "[123]\ttraining's multi_logloss: 0.152238\tvalid_1's multi_logloss: 0.26986        \n",
      "[124]\ttraining's multi_logloss: 0.151118\tvalid_1's multi_logloss: 0.269792       \n",
      "[125]\ttraining's multi_logloss: 0.149996\tvalid_1's multi_logloss: 0.269634       \n",
      "[126]\ttraining's multi_logloss: 0.14892\tvalid_1's multi_logloss: 0.269524        \n",
      "[127]\ttraining's multi_logloss: 0.147872\tvalid_1's multi_logloss: 0.269412       \n",
      "[128]\ttraining's multi_logloss: 0.146789\tvalid_1's multi_logloss: 0.269254       \n",
      "[129]\ttraining's multi_logloss: 0.145716\tvalid_1's multi_logloss: 0.269103       \n",
      "[130]\ttraining's multi_logloss: 0.144623\tvalid_1's multi_logloss: 0.269118       \n",
      "[131]\ttraining's multi_logloss: 0.143577\tvalid_1's multi_logloss: 0.268984       \n",
      "[132]\ttraining's multi_logloss: 0.142539\tvalid_1's multi_logloss: 0.268918       \n",
      "[133]\ttraining's multi_logloss: 0.141536\tvalid_1's multi_logloss: 0.26875        \n",
      "[134]\ttraining's multi_logloss: 0.140565\tvalid_1's multi_logloss: 0.268612       \n",
      "[135]\ttraining's multi_logloss: 0.1396\tvalid_1's multi_logloss: 0.268414         \n",
      "[136]\ttraining's multi_logloss: 0.13868\tvalid_1's multi_logloss: 0.268378        \n",
      "[137]\ttraining's multi_logloss: 0.13771\tvalid_1's multi_logloss: 0.268145        \n",
      "[138]\ttraining's multi_logloss: 0.136787\tvalid_1's multi_logloss: 0.268212       \n",
      "[139]\ttraining's multi_logloss: 0.135933\tvalid_1's multi_logloss: 0.268027       \n",
      "[140]\ttraining's multi_logloss: 0.135061\tvalid_1's multi_logloss: 0.268094       \n",
      "[141]\ttraining's multi_logloss: 0.134132\tvalid_1's multi_logloss: 0.268001       \n",
      "[142]\ttraining's multi_logloss: 0.133157\tvalid_1's multi_logloss: 0.267974       \n",
      "[143]\ttraining's multi_logloss: 0.132342\tvalid_1's multi_logloss: 0.268015       \n",
      "[144]\ttraining's multi_logloss: 0.131505\tvalid_1's multi_logloss: 0.268054       \n",
      "[145]\ttraining's multi_logloss: 0.130628\tvalid_1's multi_logloss: 0.268066       \n",
      "[146]\ttraining's multi_logloss: 0.129769\tvalid_1's multi_logloss: 0.268041       \n",
      "[147]\ttraining's multi_logloss: 0.128871\tvalid_1's multi_logloss: 0.268046       \n",
      "[148]\ttraining's multi_logloss: 0.128106\tvalid_1's multi_logloss: 0.268009       \n",
      "[149]\ttraining's multi_logloss: 0.127277\tvalid_1's multi_logloss: 0.267901       \n",
      "[150]\ttraining's multi_logloss: 0.12644\tvalid_1's multi_logloss: 0.267893        \n",
      "[151]\ttraining's multi_logloss: 0.125666\tvalid_1's multi_logloss: 0.268021       \n",
      "[152]\ttraining's multi_logloss: 0.124842\tvalid_1's multi_logloss: 0.268076       \n",
      "[153]\ttraining's multi_logloss: 0.124109\tvalid_1's multi_logloss: 0.268039       \n",
      "[154]\ttraining's multi_logloss: 0.123348\tvalid_1's multi_logloss: 0.268129       \n",
      "[155]\ttraining's multi_logloss: 0.122612\tvalid_1's multi_logloss: 0.268211       \n",
      "[156]\ttraining's multi_logloss: 0.121874\tvalid_1's multi_logloss: 0.268249       \n",
      "[157]\ttraining's multi_logloss: 0.121167\tvalid_1's multi_logloss: 0.26845        \n",
      "[158]\ttraining's multi_logloss: 0.120441\tvalid_1's multi_logloss: 0.268448       \n",
      "[159]\ttraining's multi_logloss: 0.119732\tvalid_1's multi_logloss: 0.268542       \n",
      "[160]\ttraining's multi_logloss: 0.118927\tvalid_1's multi_logloss: 0.268423       \n",
      "[161]\ttraining's multi_logloss: 0.118171\tvalid_1's multi_logloss: 0.268455       \n",
      "[162]\ttraining's multi_logloss: 0.117408\tvalid_1's multi_logloss: 0.268575       \n",
      "[163]\ttraining's multi_logloss: 0.116676\tvalid_1's multi_logloss: 0.268588       \n",
      "[164]\ttraining's multi_logloss: 0.115938\tvalid_1's multi_logloss: 0.268645       \n",
      "[165]\ttraining's multi_logloss: 0.115221\tvalid_1's multi_logloss: 0.268619       \n",
      "[166]\ttraining's multi_logloss: 0.114538\tvalid_1's multi_logloss: 0.268732       \n",
      "[167]\ttraining's multi_logloss: 0.113864\tvalid_1's multi_logloss: 0.268776       \n",
      "[168]\ttraining's multi_logloss: 0.113158\tvalid_1's multi_logloss: 0.268791       \n",
      "[169]\ttraining's multi_logloss: 0.112494\tvalid_1's multi_logloss: 0.268865       \n",
      "[170]\ttraining's multi_logloss: 0.111832\tvalid_1's multi_logloss: 0.268925       \n",
      "[171]\ttraining's multi_logloss: 0.111163\tvalid_1's multi_logloss: 0.268983       \n",
      "[172]\ttraining's multi_logloss: 0.110503\tvalid_1's multi_logloss: 0.269088       \n",
      "[173]\ttraining's multi_logloss: 0.109755\tvalid_1's multi_logloss: 0.269123       \n",
      "[174]\ttraining's multi_logloss: 0.109103\tvalid_1's multi_logloss: 0.269162       \n",
      "[175]\ttraining's multi_logloss: 0.108388\tvalid_1's multi_logloss: 0.269266       \n",
      "[176]\ttraining's multi_logloss: 0.10772\tvalid_1's multi_logloss: 0.269395        \n",
      "[177]\ttraining's multi_logloss: 0.107097\tvalid_1's multi_logloss: 0.269473       \n",
      "[178]\ttraining's multi_logloss: 0.106466\tvalid_1's multi_logloss: 0.269471       \n",
      "[179]\ttraining's multi_logloss: 0.10586\tvalid_1's multi_logloss: 0.269444        \n",
      "[180]\ttraining's multi_logloss: 0.105246\tvalid_1's multi_logloss: 0.26956        \n",
      "Early stopping, best iteration is:                                               \n",
      "[150]\ttraining's multi_logloss: 0.12644\tvalid_1's multi_logloss: 0.267893\n",
      "[1]\ttraining's multi_logloss: 1.6025\tvalid_1's multi_logloss: 1.60906            \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.37852\tvalid_1's multi_logloss: 1.39202           \n",
      "[3]\ttraining's multi_logloss: 1.20938\tvalid_1's multi_logloss: 1.22855           \n",
      "[4]\ttraining's multi_logloss: 1.07569\tvalid_1's multi_logloss: 1.09907           \n",
      "[5]\ttraining's multi_logloss: 0.966555\tvalid_1's multi_logloss: 0.994131         \n",
      "[6]\ttraining's multi_logloss: 0.875589\tvalid_1's multi_logloss: 0.906356         \n",
      "[7]\ttraining's multi_logloss: 0.798343\tvalid_1's multi_logloss: 0.832699         \n",
      "[8]\ttraining's multi_logloss: 0.731137\tvalid_1's multi_logloss: 0.768042         \n",
      "[9]\ttraining's multi_logloss: 0.673565\tvalid_1's multi_logloss: 0.713519         \n",
      "[10]\ttraining's multi_logloss: 0.623054\tvalid_1's multi_logloss: 0.665463        \n",
      "[11]\ttraining's multi_logloss: 0.578736\tvalid_1's multi_logloss: 0.624162        \n",
      "[12]\ttraining's multi_logloss: 0.539613\tvalid_1's multi_logloss: 0.58777         \n",
      "[13]\ttraining's multi_logloss: 0.504579\tvalid_1's multi_logloss: 0.555478        \n",
      "[14]\ttraining's multi_logloss: 0.473667\tvalid_1's multi_logloss: 0.527386        \n",
      "[15]\ttraining's multi_logloss: 0.446182\tvalid_1's multi_logloss: 0.502188        \n",
      "[16]\ttraining's multi_logloss: 0.421291\tvalid_1's multi_logloss: 0.480188        \n",
      "[17]\ttraining's multi_logloss: 0.398624\tvalid_1's multi_logloss: 0.460181        \n",
      "[18]\ttraining's multi_logloss: 0.378622\tvalid_1's multi_logloss: 0.442882        \n",
      "[19]\ttraining's multi_logloss: 0.360531\tvalid_1's multi_logloss: 0.427199        \n",
      "[20]\ttraining's multi_logloss: 0.343942\tvalid_1's multi_logloss: 0.412914        \n",
      "[21]\ttraining's multi_logloss: 0.328746\tvalid_1's multi_logloss: 0.40043         \n",
      "[22]\ttraining's multi_logloss: 0.315314\tvalid_1's multi_logloss: 0.38942         \n",
      "[23]\ttraining's multi_logloss: 0.302976\tvalid_1's multi_logloss: 0.379676        \n",
      "[24]\ttraining's multi_logloss: 0.291348\tvalid_1's multi_logloss: 0.370639        \n",
      "[25]\ttraining's multi_logloss: 0.281033\tvalid_1's multi_logloss: 0.362828        \n",
      "[26]\ttraining's multi_logloss: 0.271107\tvalid_1's multi_logloss: 0.355314        \n",
      "[27]\ttraining's multi_logloss: 0.26173\tvalid_1's multi_logloss: 0.348588         \n",
      "[28]\ttraining's multi_logloss: 0.253386\tvalid_1's multi_logloss: 0.342628        \n",
      "[29]\ttraining's multi_logloss: 0.2454\tvalid_1's multi_logloss: 0.337453          \n",
      "[30]\ttraining's multi_logloss: 0.238043\tvalid_1's multi_logloss: 0.332699        \n",
      "[31]\ttraining's multi_logloss: 0.230988\tvalid_1's multi_logloss: 0.328512        \n",
      "[32]\ttraining's multi_logloss: 0.224403\tvalid_1's multi_logloss: 0.3248          \n",
      "[33]\ttraining's multi_logloss: 0.217896\tvalid_1's multi_logloss: 0.321211        \n",
      "[34]\ttraining's multi_logloss: 0.211935\tvalid_1's multi_logloss: 0.31826         \n",
      "[35]\ttraining's multi_logloss: 0.206026\tvalid_1's multi_logloss: 0.315368        \n",
      "[36]\ttraining's multi_logloss: 0.200525\tvalid_1's multi_logloss: 0.31285         \n",
      "[37]\ttraining's multi_logloss: 0.194934\tvalid_1's multi_logloss: 0.310809        \n",
      "[38]\ttraining's multi_logloss: 0.189895\tvalid_1's multi_logloss: 0.308453        \n",
      "[39]\ttraining's multi_logloss: 0.18461\tvalid_1's multi_logloss: 0.306559         \n",
      "[40]\ttraining's multi_logloss: 0.179953\tvalid_1's multi_logloss: 0.305103        \n",
      "[41]\ttraining's multi_logloss: 0.175504\tvalid_1's multi_logloss: 0.30397         \n",
      "[42]\ttraining's multi_logloss: 0.171263\tvalid_1's multi_logloss: 0.302927        \n",
      "[43]\ttraining's multi_logloss: 0.167125\tvalid_1's multi_logloss: 0.301534        \n",
      "[44]\ttraining's multi_logloss: 0.163047\tvalid_1's multi_logloss: 0.300167        \n",
      "[45]\ttraining's multi_logloss: 0.159199\tvalid_1's multi_logloss: 0.299022        \n",
      "[46]\ttraining's multi_logloss: 0.15545\tvalid_1's multi_logloss: 0.297851         \n",
      "[47]\ttraining's multi_logloss: 0.151784\tvalid_1's multi_logloss: 0.296897        \n",
      "[48]\ttraining's multi_logloss: 0.148169\tvalid_1's multi_logloss: 0.29591         \n",
      "[49]\ttraining's multi_logloss: 0.144705\tvalid_1's multi_logloss: 0.295479        \n",
      "[50]\ttraining's multi_logloss: 0.141609\tvalid_1's multi_logloss: 0.295164        \n",
      "[51]\ttraining's multi_logloss: 0.138438\tvalid_1's multi_logloss: 0.294871        \n",
      "[52]\ttraining's multi_logloss: 0.13533\tvalid_1's multi_logloss: 0.294505         \n",
      "[53]\ttraining's multi_logloss: 0.132362\tvalid_1's multi_logloss: 0.293862        \n",
      "[54]\ttraining's multi_logloss: 0.129529\tvalid_1's multi_logloss: 0.293642        \n",
      "[55]\ttraining's multi_logloss: 0.126624\tvalid_1's multi_logloss: 0.293405        \n",
      "[56]\ttraining's multi_logloss: 0.123765\tvalid_1's multi_logloss: 0.292932        \n",
      "[57]\ttraining's multi_logloss: 0.121042\tvalid_1's multi_logloss: 0.292512        \n",
      "[58]\ttraining's multi_logloss: 0.118562\tvalid_1's multi_logloss: 0.29236         \n",
      "[59]\ttraining's multi_logloss: 0.115984\tvalid_1's multi_logloss: 0.291771        \n",
      "[60]\ttraining's multi_logloss: 0.113517\tvalid_1's multi_logloss: 0.291906        \n",
      "[61]\ttraining's multi_logloss: 0.111177\tvalid_1's multi_logloss: 0.29201         \n",
      "[62]\ttraining's multi_logloss: 0.108921\tvalid_1's multi_logloss: 0.292126        \n",
      "[63]\ttraining's multi_logloss: 0.106699\tvalid_1's multi_logloss: 0.292007        \n",
      "[64]\ttraining's multi_logloss: 0.104484\tvalid_1's multi_logloss: 0.292003        \n",
      "[65]\ttraining's multi_logloss: 0.102348\tvalid_1's multi_logloss: 0.291905        \n",
      "[66]\ttraining's multi_logloss: 0.10028\tvalid_1's multi_logloss: 0.292432         \n",
      "[67]\ttraining's multi_logloss: 0.0982614\tvalid_1's multi_logloss: 0.292761       \n",
      "[68]\ttraining's multi_logloss: 0.0964381\tvalid_1's multi_logloss: 0.293135       \n",
      "[69]\ttraining's multi_logloss: 0.0946319\tvalid_1's multi_logloss: 0.293504       \n",
      "[70]\ttraining's multi_logloss: 0.092753\tvalid_1's multi_logloss: 0.293845        \n",
      "[71]\ttraining's multi_logloss: 0.0908723\tvalid_1's multi_logloss: 0.293634       \n",
      "[72]\ttraining's multi_logloss: 0.0891311\tvalid_1's multi_logloss: 0.293901       \n",
      "[73]\ttraining's multi_logloss: 0.0874847\tvalid_1's multi_logloss: 0.294          \n",
      "[74]\ttraining's multi_logloss: 0.085832\tvalid_1's multi_logloss: 0.294204        \n",
      "[75]\ttraining's multi_logloss: 0.0842303\tvalid_1's multi_logloss: 0.294551       \n",
      "[76]\ttraining's multi_logloss: 0.082614\tvalid_1's multi_logloss: 0.294651        \n",
      "[77]\ttraining's multi_logloss: 0.0810522\tvalid_1's multi_logloss: 0.295025       \n",
      "[78]\ttraining's multi_logloss: 0.0795194\tvalid_1's multi_logloss: 0.295339       \n",
      "[79]\ttraining's multi_logloss: 0.0780649\tvalid_1's multi_logloss: 0.295596       \n",
      "[80]\ttraining's multi_logloss: 0.0765879\tvalid_1's multi_logloss: 0.296186       \n",
      "[81]\ttraining's multi_logloss: 0.0752254\tvalid_1's multi_logloss: 0.296795       \n",
      "[82]\ttraining's multi_logloss: 0.0738244\tvalid_1's multi_logloss: 0.297201       \n",
      "[83]\ttraining's multi_logloss: 0.072446\tvalid_1's multi_logloss: 0.297424        \n",
      "[84]\ttraining's multi_logloss: 0.071166\tvalid_1's multi_logloss: 0.297648        \n",
      "[85]\ttraining's multi_logloss: 0.06984\tvalid_1's multi_logloss: 0.297935         \n",
      "[86]\ttraining's multi_logloss: 0.0686774\tvalid_1's multi_logloss: 0.298564       \n",
      "[87]\ttraining's multi_logloss: 0.0673619\tvalid_1's multi_logloss: 0.298815       \n",
      "[88]\ttraining's multi_logloss: 0.0661468\tvalid_1's multi_logloss: 0.299368       \n",
      "[89]\ttraining's multi_logloss: 0.0649051\tvalid_1's multi_logloss: 0.299969       \n",
      "Early stopping, best iteration is:                                               \n",
      "[59]\ttraining's multi_logloss: 0.115984\tvalid_1's multi_logloss: 0.291771\n",
      "[1]\ttraining's multi_logloss: 1.59985\tvalid_1's multi_logloss: 1.60434           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.37853\tvalid_1's multi_logloss: 1.38535           \n",
      "[3]\ttraining's multi_logloss: 1.21174\tvalid_1's multi_logloss: 1.22187           \n",
      "[4]\ttraining's multi_logloss: 1.07974\tvalid_1's multi_logloss: 1.09243           \n",
      "[5]\ttraining's multi_logloss: 0.970855\tvalid_1's multi_logloss: 0.986265         \n",
      "[6]\ttraining's multi_logloss: 0.878629\tvalid_1's multi_logloss: 0.897101         \n",
      "[7]\ttraining's multi_logloss: 0.801425\tvalid_1's multi_logloss: 0.82268          \n",
      "[8]\ttraining's multi_logloss: 0.73498\tvalid_1's multi_logloss: 0.758969          \n",
      "[9]\ttraining's multi_logloss: 0.677708\tvalid_1's multi_logloss: 0.704465         \n",
      "[10]\ttraining's multi_logloss: 0.627141\tvalid_1's multi_logloss: 0.656959        \n",
      "[11]\ttraining's multi_logloss: 0.582576\tvalid_1's multi_logloss: 0.614809        \n",
      "[12]\ttraining's multi_logloss: 0.543259\tvalid_1's multi_logloss: 0.578136        \n",
      "[13]\ttraining's multi_logloss: 0.50863\tvalid_1's multi_logloss: 0.545765         \n",
      "[14]\ttraining's multi_logloss: 0.477626\tvalid_1's multi_logloss: 0.517294        \n",
      "[15]\ttraining's multi_logloss: 0.450206\tvalid_1's multi_logloss: 0.492358        \n",
      "[16]\ttraining's multi_logloss: 0.42577\tvalid_1's multi_logloss: 0.470537         \n",
      "[17]\ttraining's multi_logloss: 0.403403\tvalid_1's multi_logloss: 0.450689        \n",
      "[18]\ttraining's multi_logloss: 0.383429\tvalid_1's multi_logloss: 0.433672        \n",
      "[19]\ttraining's multi_logloss: 0.365371\tvalid_1's multi_logloss: 0.418456        \n",
      "[20]\ttraining's multi_logloss: 0.348913\tvalid_1's multi_logloss: 0.404987        \n",
      "[21]\ttraining's multi_logloss: 0.333267\tvalid_1's multi_logloss: 0.392582        \n",
      "[22]\ttraining's multi_logloss: 0.319325\tvalid_1's multi_logloss: 0.381634        \n",
      "[23]\ttraining's multi_logloss: 0.306088\tvalid_1's multi_logloss: 0.371355        \n",
      "[24]\ttraining's multi_logloss: 0.294538\tvalid_1's multi_logloss: 0.362664        \n",
      "[25]\ttraining's multi_logloss: 0.283678\tvalid_1's multi_logloss: 0.354623        \n",
      "[26]\ttraining's multi_logloss: 0.273727\tvalid_1's multi_logloss: 0.347806        \n",
      "[27]\ttraining's multi_logloss: 0.264081\tvalid_1's multi_logloss: 0.341439        \n",
      "[28]\ttraining's multi_logloss: 0.255565\tvalid_1's multi_logloss: 0.335977        \n",
      "[29]\ttraining's multi_logloss: 0.24691\tvalid_1's multi_logloss: 0.330372         \n",
      "[30]\ttraining's multi_logloss: 0.239117\tvalid_1's multi_logloss: 0.325637        \n",
      "[31]\ttraining's multi_logloss: 0.232032\tvalid_1's multi_logloss: 0.32145         \n",
      "[32]\ttraining's multi_logloss: 0.225033\tvalid_1's multi_logloss: 0.317426        \n",
      "[33]\ttraining's multi_logloss: 0.218528\tvalid_1's multi_logloss: 0.314008        \n",
      "[34]\ttraining's multi_logloss: 0.212281\tvalid_1's multi_logloss: 0.310833        \n",
      "[35]\ttraining's multi_logloss: 0.206296\tvalid_1's multi_logloss: 0.308068        \n",
      "[36]\ttraining's multi_logloss: 0.200594\tvalid_1's multi_logloss: 0.305585        \n",
      "[37]\ttraining's multi_logloss: 0.195182\tvalid_1's multi_logloss: 0.303656        \n",
      "[38]\ttraining's multi_logloss: 0.190159\tvalid_1's multi_logloss: 0.301761        \n",
      "[39]\ttraining's multi_logloss: 0.185413\tvalid_1's multi_logloss: 0.300703        \n",
      "[40]\ttraining's multi_logloss: 0.180447\tvalid_1's multi_logloss: 0.298758        \n",
      "[41]\ttraining's multi_logloss: 0.175954\tvalid_1's multi_logloss: 0.297361        \n",
      "[42]\ttraining's multi_logloss: 0.171573\tvalid_1's multi_logloss: 0.296125        \n",
      "[43]\ttraining's multi_logloss: 0.167402\tvalid_1's multi_logloss: 0.294811        \n",
      "[44]\ttraining's multi_logloss: 0.163338\tvalid_1's multi_logloss: 0.294052        \n",
      "[45]\ttraining's multi_logloss: 0.15944\tvalid_1's multi_logloss: 0.293264         \n",
      "[46]\ttraining's multi_logloss: 0.155633\tvalid_1's multi_logloss: 0.292152        \n",
      "[47]\ttraining's multi_logloss: 0.151755\tvalid_1's multi_logloss: 0.291302        \n",
      "[48]\ttraining's multi_logloss: 0.147956\tvalid_1's multi_logloss: 0.290547        \n",
      "[49]\ttraining's multi_logloss: 0.14435\tvalid_1's multi_logloss: 0.289565         \n",
      "[50]\ttraining's multi_logloss: 0.141087\tvalid_1's multi_logloss: 0.289048        \n",
      "[51]\ttraining's multi_logloss: 0.137813\tvalid_1's multi_logloss: 0.288572        \n",
      "[52]\ttraining's multi_logloss: 0.134706\tvalid_1's multi_logloss: 0.288239        \n",
      "[53]\ttraining's multi_logloss: 0.131786\tvalid_1's multi_logloss: 0.287658        \n",
      "[54]\ttraining's multi_logloss: 0.128725\tvalid_1's multi_logloss: 0.287219        \n",
      "[55]\ttraining's multi_logloss: 0.12575\tvalid_1's multi_logloss: 0.287072         \n",
      "[56]\ttraining's multi_logloss: 0.123097\tvalid_1's multi_logloss: 0.286936        \n",
      "[57]\ttraining's multi_logloss: 0.120471\tvalid_1's multi_logloss: 0.286794        \n",
      "[58]\ttraining's multi_logloss: 0.117785\tvalid_1's multi_logloss: 0.286693        \n",
      "[59]\ttraining's multi_logloss: 0.115256\tvalid_1's multi_logloss: 0.286682        \n",
      "[60]\ttraining's multi_logloss: 0.112783\tvalid_1's multi_logloss: 0.286585        \n",
      "[61]\ttraining's multi_logloss: 0.1103\tvalid_1's multi_logloss: 0.286759          \n",
      "[62]\ttraining's multi_logloss: 0.108003\tvalid_1's multi_logloss: 0.286398        \n",
      "[63]\ttraining's multi_logloss: 0.105805\tvalid_1's multi_logloss: 0.286491        \n",
      "[64]\ttraining's multi_logloss: 0.10361\tvalid_1's multi_logloss: 0.286749         \n",
      "[65]\ttraining's multi_logloss: 0.101533\tvalid_1's multi_logloss: 0.286632        \n",
      "[66]\ttraining's multi_logloss: 0.0993274\tvalid_1's multi_logloss: 0.287057       \n",
      "[67]\ttraining's multi_logloss: 0.0971979\tvalid_1's multi_logloss: 0.287199       \n",
      "[68]\ttraining's multi_logloss: 0.0952356\tvalid_1's multi_logloss: 0.287574       \n",
      "[69]\ttraining's multi_logloss: 0.0933096\tvalid_1's multi_logloss: 0.287804       \n",
      "[70]\ttraining's multi_logloss: 0.0914481\tvalid_1's multi_logloss: 0.288183       \n",
      "[71]\ttraining's multi_logloss: 0.0896814\tvalid_1's multi_logloss: 0.288459       \n",
      "[72]\ttraining's multi_logloss: 0.087829\tvalid_1's multi_logloss: 0.28859         \n",
      "[73]\ttraining's multi_logloss: 0.0861447\tvalid_1's multi_logloss: 0.289011       \n",
      "[74]\ttraining's multi_logloss: 0.0843865\tvalid_1's multi_logloss: 0.289092       \n",
      "[75]\ttraining's multi_logloss: 0.0826333\tvalid_1's multi_logloss: 0.28984        \n",
      "[76]\ttraining's multi_logloss: 0.080864\tvalid_1's multi_logloss: 0.29014         \n",
      "[77]\ttraining's multi_logloss: 0.0792991\tvalid_1's multi_logloss: 0.290767       \n",
      "[78]\ttraining's multi_logloss: 0.0777162\tvalid_1's multi_logloss: 0.291151       \n",
      "[79]\ttraining's multi_logloss: 0.0762139\tvalid_1's multi_logloss: 0.291668       \n",
      "[80]\ttraining's multi_logloss: 0.0746925\tvalid_1's multi_logloss: 0.292274       \n",
      "[81]\ttraining's multi_logloss: 0.0733791\tvalid_1's multi_logloss: 0.292842       \n",
      "[82]\ttraining's multi_logloss: 0.0720401\tvalid_1's multi_logloss: 0.293336       \n",
      "[83]\ttraining's multi_logloss: 0.0707327\tvalid_1's multi_logloss: 0.293858       \n",
      "[84]\ttraining's multi_logloss: 0.0693737\tvalid_1's multi_logloss: 0.294455       \n",
      "[85]\ttraining's multi_logloss: 0.0680235\tvalid_1's multi_logloss: 0.294857       \n",
      "[86]\ttraining's multi_logloss: 0.0667688\tvalid_1's multi_logloss: 0.295493       \n",
      "[87]\ttraining's multi_logloss: 0.0655606\tvalid_1's multi_logloss: 0.295959       \n",
      "[88]\ttraining's multi_logloss: 0.0643616\tvalid_1's multi_logloss: 0.296537       \n",
      "[89]\ttraining's multi_logloss: 0.0632184\tvalid_1's multi_logloss: 0.29694        \n",
      "[90]\ttraining's multi_logloss: 0.0621126\tvalid_1's multi_logloss: 0.297459       \n",
      "[91]\ttraining's multi_logloss: 0.0610087\tvalid_1's multi_logloss: 0.297911       \n",
      "[92]\ttraining's multi_logloss: 0.0599109\tvalid_1's multi_logloss: 0.298364       \n",
      "Early stopping, best iteration is:                                               \n",
      "[62]\ttraining's multi_logloss: 0.108003\tvalid_1's multi_logloss: 0.286398\n",
      "[1]\ttraining's multi_logloss: 1.60125\tvalid_1's multi_logloss: 1.60582           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.38017\tvalid_1's multi_logloss: 1.3875            \n",
      "[3]\ttraining's multi_logloss: 1.21372\tvalid_1's multi_logloss: 1.22344           \n",
      "[4]\ttraining's multi_logloss: 1.08128\tvalid_1's multi_logloss: 1.09282           \n",
      "[5]\ttraining's multi_logloss: 0.972504\tvalid_1's multi_logloss: 0.985816         \n",
      "[6]\ttraining's multi_logloss: 0.881651\tvalid_1's multi_logloss: 0.896305         \n",
      "[7]\ttraining's multi_logloss: 0.803354\tvalid_1's multi_logloss: 0.820383         \n",
      "[8]\ttraining's multi_logloss: 0.736943\tvalid_1's multi_logloss: 0.75659          \n",
      "[9]\ttraining's multi_logloss: 0.679511\tvalid_1's multi_logloss: 0.700866         \n",
      "[10]\ttraining's multi_logloss: 0.629074\tvalid_1's multi_logloss: 0.652443        \n",
      "[11]\ttraining's multi_logloss: 0.584968\tvalid_1's multi_logloss: 0.610793        \n",
      "[12]\ttraining's multi_logloss: 0.546427\tvalid_1's multi_logloss: 0.574562        \n",
      "[13]\ttraining's multi_logloss: 0.511845\tvalid_1's multi_logloss: 0.541967        \n",
      "[14]\ttraining's multi_logloss: 0.481139\tvalid_1's multi_logloss: 0.51356         \n",
      "[15]\ttraining's multi_logloss: 0.453826\tvalid_1's multi_logloss: 0.488306        \n",
      "[16]\ttraining's multi_logloss: 0.429596\tvalid_1's multi_logloss: 0.46633         \n",
      "[17]\ttraining's multi_logloss: 0.407488\tvalid_1's multi_logloss: 0.44635         \n",
      "[18]\ttraining's multi_logloss: 0.387573\tvalid_1's multi_logloss: 0.428649        \n",
      "[19]\ttraining's multi_logloss: 0.369701\tvalid_1's multi_logloss: 0.412784        \n",
      "[20]\ttraining's multi_logloss: 0.353271\tvalid_1's multi_logloss: 0.398351        \n",
      "[21]\ttraining's multi_logloss: 0.338328\tvalid_1's multi_logloss: 0.386174        \n",
      "[22]\ttraining's multi_logloss: 0.324096\tvalid_1's multi_logloss: 0.374264        \n",
      "[23]\ttraining's multi_logloss: 0.311567\tvalid_1's multi_logloss: 0.364093        \n",
      "[24]\ttraining's multi_logloss: 0.299809\tvalid_1's multi_logloss: 0.354935        \n",
      "[25]\ttraining's multi_logloss: 0.288713\tvalid_1's multi_logloss: 0.346772        \n",
      "[26]\ttraining's multi_logloss: 0.278383\tvalid_1's multi_logloss: 0.339391        \n",
      "[27]\ttraining's multi_logloss: 0.268634\tvalid_1's multi_logloss: 0.332674        \n",
      "[28]\ttraining's multi_logloss: 0.259911\tvalid_1's multi_logloss: 0.327002        \n",
      "[29]\ttraining's multi_logloss: 0.251593\tvalid_1's multi_logloss: 0.321839        \n",
      "[30]\ttraining's multi_logloss: 0.243816\tvalid_1's multi_logloss: 0.316959        \n",
      "[31]\ttraining's multi_logloss: 0.236408\tvalid_1's multi_logloss: 0.311933        \n",
      "[32]\ttraining's multi_logloss: 0.229679\tvalid_1's multi_logloss: 0.308262        \n",
      "[33]\ttraining's multi_logloss: 0.223311\tvalid_1's multi_logloss: 0.304555        \n",
      "[34]\ttraining's multi_logloss: 0.216999\tvalid_1's multi_logloss: 0.301224        \n",
      "[35]\ttraining's multi_logloss: 0.210899\tvalid_1's multi_logloss: 0.29776         \n",
      "[36]\ttraining's multi_logloss: 0.20545\tvalid_1's multi_logloss: 0.295385         \n",
      "[37]\ttraining's multi_logloss: 0.200353\tvalid_1's multi_logloss: 0.292807        \n",
      "[38]\ttraining's multi_logloss: 0.194993\tvalid_1's multi_logloss: 0.290845        \n",
      "[39]\ttraining's multi_logloss: 0.190021\tvalid_1's multi_logloss: 0.288617        \n",
      "[40]\ttraining's multi_logloss: 0.185234\tvalid_1's multi_logloss: 0.287031        \n",
      "[41]\ttraining's multi_logloss: 0.180914\tvalid_1's multi_logloss: 0.285452        \n",
      "[42]\ttraining's multi_logloss: 0.176433\tvalid_1's multi_logloss: 0.284051        \n",
      "[43]\ttraining's multi_logloss: 0.172352\tvalid_1's multi_logloss: 0.282823        \n",
      "[44]\ttraining's multi_logloss: 0.168456\tvalid_1's multi_logloss: 0.281707        \n",
      "[45]\ttraining's multi_logloss: 0.164339\tvalid_1's multi_logloss: 0.28062         \n",
      "[46]\ttraining's multi_logloss: 0.160421\tvalid_1's multi_logloss: 0.280019        \n",
      "[47]\ttraining's multi_logloss: 0.156797\tvalid_1's multi_logloss: 0.279324        \n",
      "[48]\ttraining's multi_logloss: 0.153064\tvalid_1's multi_logloss: 0.278787        \n",
      "[49]\ttraining's multi_logloss: 0.149482\tvalid_1's multi_logloss: 0.277932        \n",
      "[50]\ttraining's multi_logloss: 0.14615\tvalid_1's multi_logloss: 0.277138         \n",
      "[51]\ttraining's multi_logloss: 0.143004\tvalid_1's multi_logloss: 0.276696        \n",
      "[52]\ttraining's multi_logloss: 0.139875\tvalid_1's multi_logloss: 0.276243        \n",
      "[53]\ttraining's multi_logloss: 0.136827\tvalid_1's multi_logloss: 0.275837        \n",
      "[54]\ttraining's multi_logloss: 0.133984\tvalid_1's multi_logloss: 0.275776        \n",
      "[55]\ttraining's multi_logloss: 0.131096\tvalid_1's multi_logloss: 0.275427        \n",
      "[56]\ttraining's multi_logloss: 0.128292\tvalid_1's multi_logloss: 0.275265        \n",
      "[57]\ttraining's multi_logloss: 0.125564\tvalid_1's multi_logloss: 0.27496         \n",
      "[58]\ttraining's multi_logloss: 0.122877\tvalid_1's multi_logloss: 0.274704        \n",
      "[59]\ttraining's multi_logloss: 0.120161\tvalid_1's multi_logloss: 0.27438         \n",
      "[60]\ttraining's multi_logloss: 0.11754\tvalid_1's multi_logloss: 0.274373         \n",
      "[61]\ttraining's multi_logloss: 0.115102\tvalid_1's multi_logloss: 0.274203        \n",
      "[62]\ttraining's multi_logloss: 0.11274\tvalid_1's multi_logloss: 0.273532         \n",
      "[63]\ttraining's multi_logloss: 0.110484\tvalid_1's multi_logloss: 0.273469        \n",
      "[64]\ttraining's multi_logloss: 0.108197\tvalid_1's multi_logloss: 0.273396        \n",
      "[65]\ttraining's multi_logloss: 0.105915\tvalid_1's multi_logloss: 0.273302        \n",
      "[66]\ttraining's multi_logloss: 0.103751\tvalid_1's multi_logloss: 0.273041        \n",
      "[67]\ttraining's multi_logloss: 0.101795\tvalid_1's multi_logloss: 0.272864        \n",
      "[68]\ttraining's multi_logloss: 0.0999309\tvalid_1's multi_logloss: 0.273022       \n",
      "[69]\ttraining's multi_logloss: 0.0979114\tvalid_1's multi_logloss: 0.273254       \n",
      "[70]\ttraining's multi_logloss: 0.0959594\tvalid_1's multi_logloss: 0.273417       \n",
      "[71]\ttraining's multi_logloss: 0.094139\tvalid_1's multi_logloss: 0.273818        \n",
      "[72]\ttraining's multi_logloss: 0.0923168\tvalid_1's multi_logloss: 0.273864       \n",
      "[73]\ttraining's multi_logloss: 0.0904973\tvalid_1's multi_logloss: 0.273724       \n",
      "[74]\ttraining's multi_logloss: 0.0888599\tvalid_1's multi_logloss: 0.274002       \n",
      "[75]\ttraining's multi_logloss: 0.0871851\tvalid_1's multi_logloss: 0.274224       \n",
      "[76]\ttraining's multi_logloss: 0.0855246\tvalid_1's multi_logloss: 0.274439       \n",
      "[77]\ttraining's multi_logloss: 0.0839985\tvalid_1's multi_logloss: 0.274441       \n",
      "[78]\ttraining's multi_logloss: 0.0824404\tvalid_1's multi_logloss: 0.274675       \n",
      "[79]\ttraining's multi_logloss: 0.0810001\tvalid_1's multi_logloss: 0.274934       \n",
      "[80]\ttraining's multi_logloss: 0.0794081\tvalid_1's multi_logloss: 0.275122       \n",
      "[81]\ttraining's multi_logloss: 0.077979\tvalid_1's multi_logloss: 0.275064        \n",
      "[82]\ttraining's multi_logloss: 0.0765896\tvalid_1's multi_logloss: 0.275169       \n",
      "[83]\ttraining's multi_logloss: 0.0751839\tvalid_1's multi_logloss: 0.27569        \n",
      "[84]\ttraining's multi_logloss: 0.0738576\tvalid_1's multi_logloss: 0.275874       \n",
      "[85]\ttraining's multi_logloss: 0.0724487\tvalid_1's multi_logloss: 0.276274       \n",
      "[86]\ttraining's multi_logloss: 0.0710967\tvalid_1's multi_logloss: 0.276725       \n",
      "[87]\ttraining's multi_logloss: 0.0698422\tvalid_1's multi_logloss: 0.277541       \n",
      "[88]\ttraining's multi_logloss: 0.068593\tvalid_1's multi_logloss: 0.278319        \n",
      "[89]\ttraining's multi_logloss: 0.0672144\tvalid_1's multi_logloss: 0.27845        \n",
      "[90]\ttraining's multi_logloss: 0.066037\tvalid_1's multi_logloss: 0.278684        \n",
      "[91]\ttraining's multi_logloss: 0.0647166\tvalid_1's multi_logloss: 0.279327       \n",
      "[92]\ttraining's multi_logloss: 0.0636008\tvalid_1's multi_logloss: 0.279539       \n",
      "[93]\ttraining's multi_logloss: 0.0625439\tvalid_1's multi_logloss: 0.279747       \n",
      "[94]\ttraining's multi_logloss: 0.0614415\tvalid_1's multi_logloss: 0.27972        \n",
      "[95]\ttraining's multi_logloss: 0.0603435\tvalid_1's multi_logloss: 0.279681       \n",
      "[96]\ttraining's multi_logloss: 0.0592606\tvalid_1's multi_logloss: 0.280128       \n",
      "[97]\ttraining's multi_logloss: 0.0582298\tvalid_1's multi_logloss: 0.280618       \n",
      "Early stopping, best iteration is:                                               \n",
      "[67]\ttraining's multi_logloss: 0.101795\tvalid_1's multi_logloss: 0.272864\n",
      "[1]\ttraining's multi_logloss: 1.67834\tvalid_1's multi_logloss: 1.68151           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.4913\tvalid_1's multi_logloss: 1.49847            \n",
      "[3]\ttraining's multi_logloss: 1.34251\tvalid_1's multi_logloss: 1.35423           \n",
      "[4]\ttraining's multi_logloss: 1.22129\tvalid_1's multi_logloss: 1.23667           \n",
      "[5]\ttraining's multi_logloss: 1.11923\tvalid_1's multi_logloss: 1.13774           \n",
      "[6]\ttraining's multi_logloss: 1.03079\tvalid_1's multi_logloss: 1.05189           \n",
      "[7]\ttraining's multi_logloss: 0.954363\tvalid_1's multi_logloss: 0.977943         \n",
      "[8]\ttraining's multi_logloss: 0.887847\tvalid_1's multi_logloss: 0.913403         \n",
      "[9]\ttraining's multi_logloss: 0.828457\tvalid_1's multi_logloss: 0.856725         \n",
      "[10]\ttraining's multi_logloss: 0.775757\tvalid_1's multi_logloss: 0.80579         \n",
      "[11]\ttraining's multi_logloss: 0.728427\tvalid_1's multi_logloss: 0.760069        \n",
      "[12]\ttraining's multi_logloss: 0.686788\tvalid_1's multi_logloss: 0.719805        \n",
      "[13]\ttraining's multi_logloss: 0.648139\tvalid_1's multi_logloss: 0.6828          \n",
      "[14]\ttraining's multi_logloss: 0.613883\tvalid_1's multi_logloss: 0.649855        \n",
      "[15]\ttraining's multi_logloss: 0.58268\tvalid_1's multi_logloss: 0.620335         \n",
      "[16]\ttraining's multi_logloss: 0.55388\tvalid_1's multi_logloss: 0.593099         \n",
      "[17]\ttraining's multi_logloss: 0.527834\tvalid_1's multi_logloss: 0.568682        \n",
      "[18]\ttraining's multi_logloss: 0.504294\tvalid_1's multi_logloss: 0.54663         \n",
      "[19]\ttraining's multi_logloss: 0.482645\tvalid_1's multi_logloss: 0.526474        \n",
      "[20]\ttraining's multi_logloss: 0.462545\tvalid_1's multi_logloss: 0.507853        \n",
      "[21]\ttraining's multi_logloss: 0.443831\tvalid_1's multi_logloss: 0.490589        \n",
      "[22]\ttraining's multi_logloss: 0.427029\tvalid_1's multi_logloss: 0.475146        \n",
      "[23]\ttraining's multi_logloss: 0.41137\tvalid_1's multi_logloss: 0.461144         \n",
      "[24]\ttraining's multi_logloss: 0.396683\tvalid_1's multi_logloss: 0.448163        \n",
      "[25]\ttraining's multi_logloss: 0.38298\tvalid_1's multi_logloss: 0.435769         \n",
      "[26]\ttraining's multi_logloss: 0.370852\tvalid_1's multi_logloss: 0.424999        \n",
      "[27]\ttraining's multi_logloss: 0.359463\tvalid_1's multi_logloss: 0.415648        \n",
      "[28]\ttraining's multi_logloss: 0.348701\tvalid_1's multi_logloss: 0.406453        \n",
      "[29]\ttraining's multi_logloss: 0.338795\tvalid_1's multi_logloss: 0.39819         \n",
      "[30]\ttraining's multi_logloss: 0.329724\tvalid_1's multi_logloss: 0.391047        \n",
      "[31]\ttraining's multi_logloss: 0.320705\tvalid_1's multi_logloss: 0.383503        \n",
      "[32]\ttraining's multi_logloss: 0.312152\tvalid_1's multi_logloss: 0.376251        \n",
      "[33]\ttraining's multi_logloss: 0.304462\tvalid_1's multi_logloss: 0.370197        \n",
      "[34]\ttraining's multi_logloss: 0.297075\tvalid_1's multi_logloss: 0.364585        \n",
      "[35]\ttraining's multi_logloss: 0.290221\tvalid_1's multi_logloss: 0.359486        \n",
      "[36]\ttraining's multi_logloss: 0.283719\tvalid_1's multi_logloss: 0.354825        \n",
      "[37]\ttraining's multi_logloss: 0.277732\tvalid_1's multi_logloss: 0.350369        \n",
      "[38]\ttraining's multi_logloss: 0.271867\tvalid_1's multi_logloss: 0.34601         \n",
      "[39]\ttraining's multi_logloss: 0.266322\tvalid_1's multi_logloss: 0.3422          \n",
      "[40]\ttraining's multi_logloss: 0.260948\tvalid_1's multi_logloss: 0.338648        \n",
      "[41]\ttraining's multi_logloss: 0.255726\tvalid_1's multi_logloss: 0.335131        \n",
      "[42]\ttraining's multi_logloss: 0.250751\tvalid_1's multi_logloss: 0.332025        \n",
      "[43]\ttraining's multi_logloss: 0.246063\tvalid_1's multi_logloss: 0.329205        \n",
      "[44]\ttraining's multi_logloss: 0.241499\tvalid_1's multi_logloss: 0.326382        \n",
      "[45]\ttraining's multi_logloss: 0.23698\tvalid_1's multi_logloss: 0.3236           \n",
      "[46]\ttraining's multi_logloss: 0.23261\tvalid_1's multi_logloss: 0.321291         \n",
      "[47]\ttraining's multi_logloss: 0.228766\tvalid_1's multi_logloss: 0.319303        \n",
      "[48]\ttraining's multi_logloss: 0.225048\tvalid_1's multi_logloss: 0.317403        \n",
      "[49]\ttraining's multi_logloss: 0.22137\tvalid_1's multi_logloss: 0.315705         \n",
      "[50]\ttraining's multi_logloss: 0.217828\tvalid_1's multi_logloss: 0.313955        \n",
      "[51]\ttraining's multi_logloss: 0.214375\tvalid_1's multi_logloss: 0.312405        \n",
      "[52]\ttraining's multi_logloss: 0.210964\tvalid_1's multi_logloss: 0.310653        \n",
      "[53]\ttraining's multi_logloss: 0.207812\tvalid_1's multi_logloss: 0.309233        \n",
      "[54]\ttraining's multi_logloss: 0.204448\tvalid_1's multi_logloss: 0.307885        \n",
      "[55]\ttraining's multi_logloss: 0.201275\tvalid_1's multi_logloss: 0.306599        \n",
      "[56]\ttraining's multi_logloss: 0.198476\tvalid_1's multi_logloss: 0.305436        \n",
      "[57]\ttraining's multi_logloss: 0.195548\tvalid_1's multi_logloss: 0.304633        \n",
      "[58]\ttraining's multi_logloss: 0.192837\tvalid_1's multi_logloss: 0.303753        \n",
      "[59]\ttraining's multi_logloss: 0.19009\tvalid_1's multi_logloss: 0.302606         \n",
      "[60]\ttraining's multi_logloss: 0.187371\tvalid_1's multi_logloss: 0.301788        \n",
      "[61]\ttraining's multi_logloss: 0.184751\tvalid_1's multi_logloss: 0.301079        \n",
      "[62]\ttraining's multi_logloss: 0.18222\tvalid_1's multi_logloss: 0.300644         \n",
      "[63]\ttraining's multi_logloss: 0.179649\tvalid_1's multi_logloss: 0.299986        \n",
      "[64]\ttraining's multi_logloss: 0.177031\tvalid_1's multi_logloss: 0.299495        \n",
      "[65]\ttraining's multi_logloss: 0.174447\tvalid_1's multi_logloss: 0.299118        \n",
      "[66]\ttraining's multi_logloss: 0.172062\tvalid_1's multi_logloss: 0.298487        \n",
      "[67]\ttraining's multi_logloss: 0.169612\tvalid_1's multi_logloss: 0.297945        \n",
      "[68]\ttraining's multi_logloss: 0.167103\tvalid_1's multi_logloss: 0.297476        \n",
      "[69]\ttraining's multi_logloss: 0.164736\tvalid_1's multi_logloss: 0.296853        \n",
      "[70]\ttraining's multi_logloss: 0.162455\tvalid_1's multi_logloss: 0.296304        \n",
      "[71]\ttraining's multi_logloss: 0.160198\tvalid_1's multi_logloss: 0.295727        \n",
      "[72]\ttraining's multi_logloss: 0.157981\tvalid_1's multi_logloss: 0.295246        \n",
      "[73]\ttraining's multi_logloss: 0.155702\tvalid_1's multi_logloss: 0.294819        \n",
      "[74]\ttraining's multi_logloss: 0.15362\tvalid_1's multi_logloss: 0.294404         \n",
      "[75]\ttraining's multi_logloss: 0.151277\tvalid_1's multi_logloss: 0.294063        \n",
      "[76]\ttraining's multi_logloss: 0.149196\tvalid_1's multi_logloss: 0.293543        \n",
      "[77]\ttraining's multi_logloss: 0.147039\tvalid_1's multi_logloss: 0.293326        \n",
      "[78]\ttraining's multi_logloss: 0.145016\tvalid_1's multi_logloss: 0.29348         \n",
      "[79]\ttraining's multi_logloss: 0.143078\tvalid_1's multi_logloss: 0.293186        \n",
      "[80]\ttraining's multi_logloss: 0.140986\tvalid_1's multi_logloss: 0.292785        \n",
      "[81]\ttraining's multi_logloss: 0.139059\tvalid_1's multi_logloss: 0.292713        \n",
      "[82]\ttraining's multi_logloss: 0.137173\tvalid_1's multi_logloss: 0.292632        \n",
      "[83]\ttraining's multi_logloss: 0.135292\tvalid_1's multi_logloss: 0.292373        \n",
      "[84]\ttraining's multi_logloss: 0.133439\tvalid_1's multi_logloss: 0.292194        \n",
      "[85]\ttraining's multi_logloss: 0.131535\tvalid_1's multi_logloss: 0.292062        \n",
      "[86]\ttraining's multi_logloss: 0.129638\tvalid_1's multi_logloss: 0.291926        \n",
      "[87]\ttraining's multi_logloss: 0.127873\tvalid_1's multi_logloss: 0.29204         \n",
      "[88]\ttraining's multi_logloss: 0.126161\tvalid_1's multi_logloss: 0.292124        \n",
      "[89]\ttraining's multi_logloss: 0.124268\tvalid_1's multi_logloss: 0.291995        \n",
      "[90]\ttraining's multi_logloss: 0.122456\tvalid_1's multi_logloss: 0.291849        \n",
      "[91]\ttraining's multi_logloss: 0.120795\tvalid_1's multi_logloss: 0.291601        \n",
      "[92]\ttraining's multi_logloss: 0.119126\tvalid_1's multi_logloss: 0.29155         \n",
      "[93]\ttraining's multi_logloss: 0.117518\tvalid_1's multi_logloss: 0.291483        \n",
      "[94]\ttraining's multi_logloss: 0.116006\tvalid_1's multi_logloss: 0.291702        \n",
      "[95]\ttraining's multi_logloss: 0.114426\tvalid_1's multi_logloss: 0.29149         \n",
      "[96]\ttraining's multi_logloss: 0.11282\tvalid_1's multi_logloss: 0.291435         \n",
      "[97]\ttraining's multi_logloss: 0.111304\tvalid_1's multi_logloss: 0.291504        \n",
      "[98]\ttraining's multi_logloss: 0.109837\tvalid_1's multi_logloss: 0.291598        \n",
      "[99]\ttraining's multi_logloss: 0.10822\tvalid_1's multi_logloss: 0.291525         \n",
      "[100]\ttraining's multi_logloss: 0.106826\tvalid_1's multi_logloss: 0.291535       \n",
      "[101]\ttraining's multi_logloss: 0.105384\tvalid_1's multi_logloss: 0.291512       \n",
      "[102]\ttraining's multi_logloss: 0.104071\tvalid_1's multi_logloss: 0.29165        \n",
      "[103]\ttraining's multi_logloss: 0.102675\tvalid_1's multi_logloss: 0.291925       \n",
      "[104]\ttraining's multi_logloss: 0.101302\tvalid_1's multi_logloss: 0.291812       \n",
      "[105]\ttraining's multi_logloss: 0.099871\tvalid_1's multi_logloss: 0.292002       \n",
      "[106]\ttraining's multi_logloss: 0.0985149\tvalid_1's multi_logloss: 0.292048      \n",
      "[107]\ttraining's multi_logloss: 0.0972556\tvalid_1's multi_logloss: 0.292298      \n",
      "[108]\ttraining's multi_logloss: 0.095879\tvalid_1's multi_logloss: 0.292636       \n",
      "[109]\ttraining's multi_logloss: 0.094626\tvalid_1's multi_logloss: 0.29267        \n",
      "[110]\ttraining's multi_logloss: 0.0935503\tvalid_1's multi_logloss: 0.292819      \n",
      "[111]\ttraining's multi_logloss: 0.0923805\tvalid_1's multi_logloss: 0.293234      \n",
      "[112]\ttraining's multi_logloss: 0.0911828\tvalid_1's multi_logloss: 0.293704      \n",
      "[113]\ttraining's multi_logloss: 0.0900091\tvalid_1's multi_logloss: 0.293907      \n",
      "[114]\ttraining's multi_logloss: 0.088756\tvalid_1's multi_logloss: 0.293639       \n",
      "[115]\ttraining's multi_logloss: 0.0877719\tvalid_1's multi_logloss: 0.294028      \n",
      "[116]\ttraining's multi_logloss: 0.0866641\tvalid_1's multi_logloss: 0.294321      \n",
      "[117]\ttraining's multi_logloss: 0.0856278\tvalid_1's multi_logloss: 0.294675      \n",
      "[118]\ttraining's multi_logloss: 0.0845985\tvalid_1's multi_logloss: 0.295064      \n",
      "[119]\ttraining's multi_logloss: 0.0834297\tvalid_1's multi_logloss: 0.295244      \n",
      "[120]\ttraining's multi_logloss: 0.0824961\tvalid_1's multi_logloss: 0.295747      \n",
      "[121]\ttraining's multi_logloss: 0.0815198\tvalid_1's multi_logloss: 0.296197      \n",
      "[122]\ttraining's multi_logloss: 0.0804454\tvalid_1's multi_logloss: 0.296512      \n",
      "[123]\ttraining's multi_logloss: 0.0793841\tvalid_1's multi_logloss: 0.2966        \n",
      "[124]\ttraining's multi_logloss: 0.0784372\tvalid_1's multi_logloss: 0.297221      \n",
      "[125]\ttraining's multi_logloss: 0.0775181\tvalid_1's multi_logloss: 0.297651      \n",
      "[126]\ttraining's multi_logloss: 0.0766942\tvalid_1's multi_logloss: 0.298165      \n",
      "Early stopping, best iteration is:                                               \n",
      "[96]\ttraining's multi_logloss: 0.11282\tvalid_1's multi_logloss: 0.291435\n",
      "[1]\ttraining's multi_logloss: 1.67704\tvalid_1's multi_logloss: 1.68015           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.49118\tvalid_1's multi_logloss: 1.49523           \n",
      "[3]\ttraining's multi_logloss: 1.34518\tvalid_1's multi_logloss: 1.35095           \n",
      "[4]\ttraining's multi_logloss: 1.22498\tvalid_1's multi_logloss: 1.2323            \n",
      "[5]\ttraining's multi_logloss: 1.12399\tvalid_1's multi_logloss: 1.13243           \n",
      "[6]\ttraining's multi_logloss: 1.03725\tvalid_1's multi_logloss: 1.04704           \n",
      "[7]\ttraining's multi_logloss: 0.96146\tvalid_1's multi_logloss: 0.972433          \n",
      "[8]\ttraining's multi_logloss: 0.89528\tvalid_1's multi_logloss: 0.907856          \n",
      "[9]\ttraining's multi_logloss: 0.836459\tvalid_1's multi_logloss: 0.850343         \n",
      "[10]\ttraining's multi_logloss: 0.783877\tvalid_1's multi_logloss: 0.799122        \n",
      "[11]\ttraining's multi_logloss: 0.737403\tvalid_1's multi_logloss: 0.75456         \n",
      "[12]\ttraining's multi_logloss: 0.695035\tvalid_1's multi_logloss: 0.713871        \n",
      "[13]\ttraining's multi_logloss: 0.656849\tvalid_1's multi_logloss: 0.677418        \n",
      "[14]\ttraining's multi_logloss: 0.621989\tvalid_1's multi_logloss: 0.644081        \n",
      "[15]\ttraining's multi_logloss: 0.590339\tvalid_1's multi_logloss: 0.613884        \n",
      "[16]\ttraining's multi_logloss: 0.561932\tvalid_1's multi_logloss: 0.58685         \n",
      "[17]\ttraining's multi_logloss: 0.536114\tvalid_1's multi_logloss: 0.562498        \n",
      "[18]\ttraining's multi_logloss: 0.512065\tvalid_1's multi_logloss: 0.539858        \n",
      "[19]\ttraining's multi_logloss: 0.490303\tvalid_1's multi_logloss: 0.519583        \n",
      "[20]\ttraining's multi_logloss: 0.469591\tvalid_1's multi_logloss: 0.500658        \n",
      "[21]\ttraining's multi_logloss: 0.450704\tvalid_1's multi_logloss: 0.48312         \n",
      "[22]\ttraining's multi_logloss: 0.433102\tvalid_1's multi_logloss: 0.467047        \n",
      "[23]\ttraining's multi_logloss: 0.41778\tvalid_1's multi_logloss: 0.453229         \n",
      "[24]\ttraining's multi_logloss: 0.40291\tvalid_1's multi_logloss: 0.440134         \n",
      "[25]\ttraining's multi_logloss: 0.389421\tvalid_1's multi_logloss: 0.428305        \n",
      "[26]\ttraining's multi_logloss: 0.377158\tvalid_1's multi_logloss: 0.417529        \n",
      "[27]\ttraining's multi_logloss: 0.365706\tvalid_1's multi_logloss: 0.40761         \n",
      "[28]\ttraining's multi_logloss: 0.35449\tvalid_1's multi_logloss: 0.39824          \n",
      "[29]\ttraining's multi_logloss: 0.344316\tvalid_1's multi_logloss: 0.389569        \n",
      "[30]\ttraining's multi_logloss: 0.334786\tvalid_1's multi_logloss: 0.381292        \n",
      "[31]\ttraining's multi_logloss: 0.32551\tvalid_1's multi_logloss: 0.373768         \n",
      "[32]\ttraining's multi_logloss: 0.316811\tvalid_1's multi_logloss: 0.366624        \n",
      "[33]\ttraining's multi_logloss: 0.308901\tvalid_1's multi_logloss: 0.36015         \n",
      "[34]\ttraining's multi_logloss: 0.300922\tvalid_1's multi_logloss: 0.354041        \n",
      "[35]\ttraining's multi_logloss: 0.293986\tvalid_1's multi_logloss: 0.348453        \n",
      "[36]\ttraining's multi_logloss: 0.287307\tvalid_1's multi_logloss: 0.343424        \n",
      "[37]\ttraining's multi_logloss: 0.28083\tvalid_1's multi_logloss: 0.338717         \n",
      "[38]\ttraining's multi_logloss: 0.274866\tvalid_1's multi_logloss: 0.334414        \n",
      "[39]\ttraining's multi_logloss: 0.269072\tvalid_1's multi_logloss: 0.330507        \n",
      "[40]\ttraining's multi_logloss: 0.263531\tvalid_1's multi_logloss: 0.326742        \n",
      "[41]\ttraining's multi_logloss: 0.258464\tvalid_1's multi_logloss: 0.323524        \n",
      "[42]\ttraining's multi_logloss: 0.253313\tvalid_1's multi_logloss: 0.320461        \n",
      "[43]\ttraining's multi_logloss: 0.24864\tvalid_1's multi_logloss: 0.317277         \n",
      "[44]\ttraining's multi_logloss: 0.244134\tvalid_1's multi_logloss: 0.314797        \n",
      "[45]\ttraining's multi_logloss: 0.239738\tvalid_1's multi_logloss: 0.312386        \n",
      "[46]\ttraining's multi_logloss: 0.23547\tvalid_1's multi_logloss: 0.310124         \n",
      "[47]\ttraining's multi_logloss: 0.231092\tvalid_1's multi_logloss: 0.307919        \n",
      "[48]\ttraining's multi_logloss: 0.227157\tvalid_1's multi_logloss: 0.30591         \n",
      "[49]\ttraining's multi_logloss: 0.223297\tvalid_1's multi_logloss: 0.30406         \n",
      "[50]\ttraining's multi_logloss: 0.219487\tvalid_1's multi_logloss: 0.302411        \n",
      "[51]\ttraining's multi_logloss: 0.215998\tvalid_1's multi_logloss: 0.300848        \n",
      "[52]\ttraining's multi_logloss: 0.212464\tvalid_1's multi_logloss: 0.299462        \n",
      "[53]\ttraining's multi_logloss: 0.209241\tvalid_1's multi_logloss: 0.298159        \n",
      "[54]\ttraining's multi_logloss: 0.206154\tvalid_1's multi_logloss: 0.296906        \n",
      "[55]\ttraining's multi_logloss: 0.202835\tvalid_1's multi_logloss: 0.295571        \n",
      "[56]\ttraining's multi_logloss: 0.199859\tvalid_1's multi_logloss: 0.294323        \n",
      "[57]\ttraining's multi_logloss: 0.196816\tvalid_1's multi_logloss: 0.293389        \n",
      "[58]\ttraining's multi_logloss: 0.193761\tvalid_1's multi_logloss: 0.292498        \n",
      "[59]\ttraining's multi_logloss: 0.190695\tvalid_1's multi_logloss: 0.2915          \n",
      "[60]\ttraining's multi_logloss: 0.187907\tvalid_1's multi_logloss: 0.290612        \n",
      "[61]\ttraining's multi_logloss: 0.185208\tvalid_1's multi_logloss: 0.290215        \n",
      "[62]\ttraining's multi_logloss: 0.18217\tvalid_1's multi_logloss: 0.289289         \n",
      "[63]\ttraining's multi_logloss: 0.17924\tvalid_1's multi_logloss: 0.288606         \n",
      "[64]\ttraining's multi_logloss: 0.176766\tvalid_1's multi_logloss: 0.288017        \n",
      "[65]\ttraining's multi_logloss: 0.174097\tvalid_1's multi_logloss: 0.287466        \n",
      "[66]\ttraining's multi_logloss: 0.171535\tvalid_1's multi_logloss: 0.286971        \n",
      "[67]\ttraining's multi_logloss: 0.169083\tvalid_1's multi_logloss: 0.28644         \n",
      "[68]\ttraining's multi_logloss: 0.166448\tvalid_1's multi_logloss: 0.285932        \n",
      "[69]\ttraining's multi_logloss: 0.164079\tvalid_1's multi_logloss: 0.285731        \n",
      "[70]\ttraining's multi_logloss: 0.161783\tvalid_1's multi_logloss: 0.285466        \n",
      "[71]\ttraining's multi_logloss: 0.159369\tvalid_1's multi_logloss: 0.285094        \n",
      "[72]\ttraining's multi_logloss: 0.156969\tvalid_1's multi_logloss: 0.284307        \n",
      "[73]\ttraining's multi_logloss: 0.154704\tvalid_1's multi_logloss: 0.283866        \n",
      "[74]\ttraining's multi_logloss: 0.152652\tvalid_1's multi_logloss: 0.283661        \n",
      "[75]\ttraining's multi_logloss: 0.150299\tvalid_1's multi_logloss: 0.283157        \n",
      "[76]\ttraining's multi_logloss: 0.148239\tvalid_1's multi_logloss: 0.283018        \n",
      "[77]\ttraining's multi_logloss: 0.146268\tvalid_1's multi_logloss: 0.282821        \n",
      "[78]\ttraining's multi_logloss: 0.144324\tvalid_1's multi_logloss: 0.282855        \n",
      "[79]\ttraining's multi_logloss: 0.142482\tvalid_1's multi_logloss: 0.282735        \n",
      "[80]\ttraining's multi_logloss: 0.140611\tvalid_1's multi_logloss: 0.282406        \n",
      "[81]\ttraining's multi_logloss: 0.138686\tvalid_1's multi_logloss: 0.282168        \n",
      "[82]\ttraining's multi_logloss: 0.136741\tvalid_1's multi_logloss: 0.2819          \n",
      "[83]\ttraining's multi_logloss: 0.134934\tvalid_1's multi_logloss: 0.281835        \n",
      "[84]\ttraining's multi_logloss: 0.133089\tvalid_1's multi_logloss: 0.281818        \n",
      "[85]\ttraining's multi_logloss: 0.13123\tvalid_1's multi_logloss: 0.281549         \n",
      "[86]\ttraining's multi_logloss: 0.129339\tvalid_1's multi_logloss: 0.281067        \n",
      "[87]\ttraining's multi_logloss: 0.127543\tvalid_1's multi_logloss: 0.280976        \n",
      "[88]\ttraining's multi_logloss: 0.125693\tvalid_1's multi_logloss: 0.280938        \n",
      "[89]\ttraining's multi_logloss: 0.123917\tvalid_1's multi_logloss: 0.281162        \n",
      "[90]\ttraining's multi_logloss: 0.122138\tvalid_1's multi_logloss: 0.281124        \n",
      "[91]\ttraining's multi_logloss: 0.120631\tvalid_1's multi_logloss: 0.281301        \n",
      "[92]\ttraining's multi_logloss: 0.118728\tvalid_1's multi_logloss: 0.281351        \n",
      "[93]\ttraining's multi_logloss: 0.117045\tvalid_1's multi_logloss: 0.281386        \n",
      "[94]\ttraining's multi_logloss: 0.115353\tvalid_1's multi_logloss: 0.281364        \n",
      "[95]\ttraining's multi_logloss: 0.113688\tvalid_1's multi_logloss: 0.281656        \n",
      "[96]\ttraining's multi_logloss: 0.111976\tvalid_1's multi_logloss: 0.281765        \n",
      "[97]\ttraining's multi_logloss: 0.110437\tvalid_1's multi_logloss: 0.281833        \n",
      "[98]\ttraining's multi_logloss: 0.108987\tvalid_1's multi_logloss: 0.281897        \n",
      "[99]\ttraining's multi_logloss: 0.107572\tvalid_1's multi_logloss: 0.282192        \n",
      "[100]\ttraining's multi_logloss: 0.106142\tvalid_1's multi_logloss: 0.282411       \n",
      "[101]\ttraining's multi_logloss: 0.104797\tvalid_1's multi_logloss: 0.282862       \n",
      "[102]\ttraining's multi_logloss: 0.103296\tvalid_1's multi_logloss: 0.2829         \n",
      "[103]\ttraining's multi_logloss: 0.101978\tvalid_1's multi_logloss: 0.283          \n",
      "[104]\ttraining's multi_logloss: 0.10051\tvalid_1's multi_logloss: 0.283056        \n",
      "[105]\ttraining's multi_logloss: 0.0992078\tvalid_1's multi_logloss: 0.283417      \n",
      "[106]\ttraining's multi_logloss: 0.0978723\tvalid_1's multi_logloss: 0.28368       \n",
      "[107]\ttraining's multi_logloss: 0.096545\tvalid_1's multi_logloss: 0.283865       \n",
      "[108]\ttraining's multi_logloss: 0.0952375\tvalid_1's multi_logloss: 0.283905      \n",
      "[109]\ttraining's multi_logloss: 0.0940502\tvalid_1's multi_logloss: 0.284271      \n",
      "[110]\ttraining's multi_logloss: 0.0928496\tvalid_1's multi_logloss: 0.284566      \n",
      "[111]\ttraining's multi_logloss: 0.0916696\tvalid_1's multi_logloss: 0.284638      \n",
      "[112]\ttraining's multi_logloss: 0.0906417\tvalid_1's multi_logloss: 0.285021      \n",
      "[113]\ttraining's multi_logloss: 0.089494\tvalid_1's multi_logloss: 0.28511        \n",
      "[114]\ttraining's multi_logloss: 0.0884036\tvalid_1's multi_logloss: 0.285544      \n",
      "[115]\ttraining's multi_logloss: 0.0873355\tvalid_1's multi_logloss: 0.285713      \n",
      "[116]\ttraining's multi_logloss: 0.0862129\tvalid_1's multi_logloss: 0.285831      \n",
      "[117]\ttraining's multi_logloss: 0.0849572\tvalid_1's multi_logloss: 0.285661      \n",
      "[118]\ttraining's multi_logloss: 0.0839591\tvalid_1's multi_logloss: 0.285998      \n",
      "Early stopping, best iteration is:                                               \n",
      "[88]\ttraining's multi_logloss: 0.125693\tvalid_1's multi_logloss: 0.280938\n",
      "[1]\ttraining's multi_logloss: 1.67826\tvalid_1's multi_logloss: 1.68131           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.49357\tvalid_1's multi_logloss: 1.49807           \n",
      "[3]\ttraining's multi_logloss: 1.3474\tvalid_1's multi_logloss: 1.35339            \n",
      "[4]\ttraining's multi_logloss: 1.22648\tvalid_1's multi_logloss: 1.23324           \n",
      "[5]\ttraining's multi_logloss: 1.12536\tvalid_1's multi_logloss: 1.13291           \n",
      "[6]\ttraining's multi_logloss: 1.03941\tvalid_1's multi_logloss: 1.04797           \n",
      "[7]\ttraining's multi_logloss: 0.96356\tvalid_1's multi_logloss: 0.97284           \n",
      "[8]\ttraining's multi_logloss: 0.896645\tvalid_1's multi_logloss: 0.90696          \n",
      "[9]\ttraining's multi_logloss: 0.837331\tvalid_1's multi_logloss: 0.848695         \n",
      "[10]\ttraining's multi_logloss: 0.78422\tvalid_1's multi_logloss: 0.796391         \n",
      "[11]\ttraining's multi_logloss: 0.73782\tvalid_1's multi_logloss: 0.751121         \n",
      "[12]\ttraining's multi_logloss: 0.695529\tvalid_1's multi_logloss: 0.710387        \n",
      "[13]\ttraining's multi_logloss: 0.657056\tvalid_1's multi_logloss: 0.672764        \n",
      "[14]\ttraining's multi_logloss: 0.622665\tvalid_1's multi_logloss: 0.639838        \n",
      "[15]\ttraining's multi_logloss: 0.591147\tvalid_1's multi_logloss: 0.609348        \n",
      "[16]\ttraining's multi_logloss: 0.562538\tvalid_1's multi_logloss: 0.581931        \n",
      "[17]\ttraining's multi_logloss: 0.536521\tvalid_1's multi_logloss: 0.557011        \n",
      "[18]\ttraining's multi_logloss: 0.513025\tvalid_1's multi_logloss: 0.534744        \n",
      "[19]\ttraining's multi_logloss: 0.491459\tvalid_1's multi_logloss: 0.514469        \n",
      "[20]\ttraining's multi_logloss: 0.471348\tvalid_1's multi_logloss: 0.495508        \n",
      "[21]\ttraining's multi_logloss: 0.45303\tvalid_1's multi_logloss: 0.478241         \n",
      "[22]\ttraining's multi_logloss: 0.436164\tvalid_1's multi_logloss: 0.462459        \n",
      "[23]\ttraining's multi_logloss: 0.420715\tvalid_1's multi_logloss: 0.44807         \n",
      "[24]\ttraining's multi_logloss: 0.406263\tvalid_1's multi_logloss: 0.434642        \n",
      "[25]\ttraining's multi_logloss: 0.392965\tvalid_1's multi_logloss: 0.422503        \n",
      "[26]\ttraining's multi_logloss: 0.380697\tvalid_1's multi_logloss: 0.411395        \n",
      "[27]\ttraining's multi_logloss: 0.368962\tvalid_1's multi_logloss: 0.401138        \n",
      "[28]\ttraining's multi_logloss: 0.358316\tvalid_1's multi_logloss: 0.391558        \n",
      "[29]\ttraining's multi_logloss: 0.348388\tvalid_1's multi_logloss: 0.382768        \n",
      "[30]\ttraining's multi_logloss: 0.339138\tvalid_1's multi_logloss: 0.374976        \n",
      "[31]\ttraining's multi_logloss: 0.330395\tvalid_1's multi_logloss: 0.367456        \n",
      "[32]\ttraining's multi_logloss: 0.322186\tvalid_1's multi_logloss: 0.360501        \n",
      "[33]\ttraining's multi_logloss: 0.314226\tvalid_1's multi_logloss: 0.353789        \n",
      "[34]\ttraining's multi_logloss: 0.306933\tvalid_1's multi_logloss: 0.348122        \n",
      "[35]\ttraining's multi_logloss: 0.300032\tvalid_1's multi_logloss: 0.342714        \n",
      "[36]\ttraining's multi_logloss: 0.293136\tvalid_1's multi_logloss: 0.336863        \n",
      "[37]\ttraining's multi_logloss: 0.286755\tvalid_1's multi_logloss: 0.332064        \n",
      "[38]\ttraining's multi_logloss: 0.280701\tvalid_1's multi_logloss: 0.327541        \n",
      "[39]\ttraining's multi_logloss: 0.275059\tvalid_1's multi_logloss: 0.323463        \n",
      "[40]\ttraining's multi_logloss: 0.269711\tvalid_1's multi_logloss: 0.319711        \n",
      "[41]\ttraining's multi_logloss: 0.26424\tvalid_1's multi_logloss: 0.31638          \n",
      "[42]\ttraining's multi_logloss: 0.259284\tvalid_1's multi_logloss: 0.313165        \n",
      "[43]\ttraining's multi_logloss: 0.254455\tvalid_1's multi_logloss: 0.31002         \n",
      "[44]\ttraining's multi_logloss: 0.249842\tvalid_1's multi_logloss: 0.307263        \n",
      "[45]\ttraining's multi_logloss: 0.245272\tvalid_1's multi_logloss: 0.304323        \n",
      "[46]\ttraining's multi_logloss: 0.240994\tvalid_1's multi_logloss: 0.301711        \n",
      "[47]\ttraining's multi_logloss: 0.236951\tvalid_1's multi_logloss: 0.299293        \n",
      "[48]\ttraining's multi_logloss: 0.233059\tvalid_1's multi_logloss: 0.296717        \n",
      "[49]\ttraining's multi_logloss: 0.229156\tvalid_1's multi_logloss: 0.294329        \n",
      "[50]\ttraining's multi_logloss: 0.22555\tvalid_1's multi_logloss: 0.292488         \n",
      "[51]\ttraining's multi_logloss: 0.222093\tvalid_1's multi_logloss: 0.290652        \n",
      "[52]\ttraining's multi_logloss: 0.218711\tvalid_1's multi_logloss: 0.289178        \n",
      "[53]\ttraining's multi_logloss: 0.215458\tvalid_1's multi_logloss: 0.287765        \n",
      "[54]\ttraining's multi_logloss: 0.212191\tvalid_1's multi_logloss: 0.286108        \n",
      "[55]\ttraining's multi_logloss: 0.209148\tvalid_1's multi_logloss: 0.285101        \n",
      "[56]\ttraining's multi_logloss: 0.206207\tvalid_1's multi_logloss: 0.283915        \n",
      "[57]\ttraining's multi_logloss: 0.203214\tvalid_1's multi_logloss: 0.282992        \n",
      "[58]\ttraining's multi_logloss: 0.200274\tvalid_1's multi_logloss: 0.281944        \n",
      "[59]\ttraining's multi_logloss: 0.197242\tvalid_1's multi_logloss: 0.280892        \n",
      "[60]\ttraining's multi_logloss: 0.194304\tvalid_1's multi_logloss: 0.279862        \n",
      "[61]\ttraining's multi_logloss: 0.191489\tvalid_1's multi_logloss: 0.278691        \n",
      "[62]\ttraining's multi_logloss: 0.188759\tvalid_1's multi_logloss: 0.277941        \n",
      "[63]\ttraining's multi_logloss: 0.186176\tvalid_1's multi_logloss: 0.277288        \n",
      "[64]\ttraining's multi_logloss: 0.183638\tvalid_1's multi_logloss: 0.276612        \n",
      "[65]\ttraining's multi_logloss: 0.181036\tvalid_1's multi_logloss: 0.276016        \n",
      "[66]\ttraining's multi_logloss: 0.178405\tvalid_1's multi_logloss: 0.27541         \n",
      "[67]\ttraining's multi_logloss: 0.17591\tvalid_1's multi_logloss: 0.274706         \n",
      "[68]\ttraining's multi_logloss: 0.173416\tvalid_1's multi_logloss: 0.273883        \n",
      "[69]\ttraining's multi_logloss: 0.171028\tvalid_1's multi_logloss: 0.273234        \n",
      "[70]\ttraining's multi_logloss: 0.168734\tvalid_1's multi_logloss: 0.272876        \n",
      "[71]\ttraining's multi_logloss: 0.166405\tvalid_1's multi_logloss: 0.272652        \n",
      "[72]\ttraining's multi_logloss: 0.164232\tvalid_1's multi_logloss: 0.272206        \n",
      "[73]\ttraining's multi_logloss: 0.161809\tvalid_1's multi_logloss: 0.271708        \n",
      "[74]\ttraining's multi_logloss: 0.159563\tvalid_1's multi_logloss: 0.271203        \n",
      "[75]\ttraining's multi_logloss: 0.157214\tvalid_1's multi_logloss: 0.271023        \n",
      "[76]\ttraining's multi_logloss: 0.154899\tvalid_1's multi_logloss: 0.27084         \n",
      "[77]\ttraining's multi_logloss: 0.152787\tvalid_1's multi_logloss: 0.270771        \n",
      "[78]\ttraining's multi_logloss: 0.150754\tvalid_1's multi_logloss: 0.270341        \n",
      "[79]\ttraining's multi_logloss: 0.148619\tvalid_1's multi_logloss: 0.27004         \n",
      "[80]\ttraining's multi_logloss: 0.146408\tvalid_1's multi_logloss: 0.269771        \n",
      "[81]\ttraining's multi_logloss: 0.144379\tvalid_1's multi_logloss: 0.269402        \n",
      "[82]\ttraining's multi_logloss: 0.142463\tvalid_1's multi_logloss: 0.269305        \n",
      "[83]\ttraining's multi_logloss: 0.140527\tvalid_1's multi_logloss: 0.26914         \n",
      "[84]\ttraining's multi_logloss: 0.138659\tvalid_1's multi_logloss: 0.26883         \n",
      "[85]\ttraining's multi_logloss: 0.136782\tvalid_1's multi_logloss: 0.268881        \n",
      "[86]\ttraining's multi_logloss: 0.134926\tvalid_1's multi_logloss: 0.268845        \n",
      "[87]\ttraining's multi_logloss: 0.133161\tvalid_1's multi_logloss: 0.268707        \n",
      "[88]\ttraining's multi_logloss: 0.131389\tvalid_1's multi_logloss: 0.268609        \n",
      "[89]\ttraining's multi_logloss: 0.129774\tvalid_1's multi_logloss: 0.268455        \n",
      "[90]\ttraining's multi_logloss: 0.128015\tvalid_1's multi_logloss: 0.268521        \n",
      "[91]\ttraining's multi_logloss: 0.126436\tvalid_1's multi_logloss: 0.268343        \n",
      "[92]\ttraining's multi_logloss: 0.124802\tvalid_1's multi_logloss: 0.268482        \n",
      "[93]\ttraining's multi_logloss: 0.12335\tvalid_1's multi_logloss: 0.268568         \n",
      "[94]\ttraining's multi_logloss: 0.121879\tvalid_1's multi_logloss: 0.268681        \n",
      "[95]\ttraining's multi_logloss: 0.120206\tvalid_1's multi_logloss: 0.268586        \n",
      "[96]\ttraining's multi_logloss: 0.118557\tvalid_1's multi_logloss: 0.268585        \n",
      "[97]\ttraining's multi_logloss: 0.117072\tvalid_1's multi_logloss: 0.268779        \n",
      "[98]\ttraining's multi_logloss: 0.11567\tvalid_1's multi_logloss: 0.269006         \n",
      "[99]\ttraining's multi_logloss: 0.114227\tvalid_1's multi_logloss: 0.269101        \n",
      "[100]\ttraining's multi_logloss: 0.112836\tvalid_1's multi_logloss: 0.26919        \n",
      "[101]\ttraining's multi_logloss: 0.111431\tvalid_1's multi_logloss: 0.269355       \n",
      "[102]\ttraining's multi_logloss: 0.109993\tvalid_1's multi_logloss: 0.269375       \n",
      "[103]\ttraining's multi_logloss: 0.108507\tvalid_1's multi_logloss: 0.269544       \n",
      "[104]\ttraining's multi_logloss: 0.107116\tvalid_1's multi_logloss: 0.269645       \n",
      "[105]\ttraining's multi_logloss: 0.105963\tvalid_1's multi_logloss: 0.269729       \n",
      "[106]\ttraining's multi_logloss: 0.104577\tvalid_1's multi_logloss: 0.269998       \n",
      "[107]\ttraining's multi_logloss: 0.103413\tvalid_1's multi_logloss: 0.270188       \n",
      "[108]\ttraining's multi_logloss: 0.102097\tvalid_1's multi_logloss: 0.270289       \n",
      "[109]\ttraining's multi_logloss: 0.100851\tvalid_1's multi_logloss: 0.270417       \n",
      "[110]\ttraining's multi_logloss: 0.0995699\tvalid_1's multi_logloss: 0.270519      \n",
      "[111]\ttraining's multi_logloss: 0.0983276\tvalid_1's multi_logloss: 0.270501      \n",
      "[112]\ttraining's multi_logloss: 0.0969657\tvalid_1's multi_logloss: 0.270667      \n",
      "[113]\ttraining's multi_logloss: 0.0957596\tvalid_1's multi_logloss: 0.270633      \n",
      "[114]\ttraining's multi_logloss: 0.0944508\tvalid_1's multi_logloss: 0.270576      \n",
      "[115]\ttraining's multi_logloss: 0.0932398\tvalid_1's multi_logloss: 0.27084       \n",
      "[116]\ttraining's multi_logloss: 0.0919621\tvalid_1's multi_logloss: 0.270707      \n",
      "[117]\ttraining's multi_logloss: 0.0908064\tvalid_1's multi_logloss: 0.270646      \n",
      "[118]\ttraining's multi_logloss: 0.089563\tvalid_1's multi_logloss: 0.270864       \n",
      "[119]\ttraining's multi_logloss: 0.0885215\tvalid_1's multi_logloss: 0.271206      \n",
      "[120]\ttraining's multi_logloss: 0.0872831\tvalid_1's multi_logloss: 0.271373      \n",
      "[121]\ttraining's multi_logloss: 0.0862081\tvalid_1's multi_logloss: 0.271737      \n",
      "Early stopping, best iteration is:                                               \n",
      "[91]\ttraining's multi_logloss: 0.126436\tvalid_1's multi_logloss: 0.268343\n",
      "[1]\ttraining's multi_logloss: 1.87133\tvalid_1's multi_logloss: 1.8701            \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.81499\tvalid_1's multi_logloss: 1.81519           \n",
      "[3]\ttraining's multi_logloss: 1.76237\tvalid_1's multi_logloss: 1.76392           \n",
      "[4]\ttraining's multi_logloss: 1.71292\tvalid_1's multi_logloss: 1.71567           \n",
      "[5]\ttraining's multi_logloss: 1.66621\tvalid_1's multi_logloss: 1.67016           \n",
      "[6]\ttraining's multi_logloss: 1.62211\tvalid_1's multi_logloss: 1.62727           \n",
      "[7]\ttraining's multi_logloss: 1.58033\tvalid_1's multi_logloss: 1.58677           \n",
      "[8]\ttraining's multi_logloss: 1.54075\tvalid_1's multi_logloss: 1.54835           \n",
      "[9]\ttraining's multi_logloss: 1.50282\tvalid_1's multi_logloss: 1.51147           \n",
      "[10]\ttraining's multi_logloss: 1.46675\tvalid_1's multi_logloss: 1.47644          \n",
      "[11]\ttraining's multi_logloss: 1.43239\tvalid_1's multi_logloss: 1.44303          \n",
      "[12]\ttraining's multi_logloss: 1.39929\tvalid_1's multi_logloss: 1.41087          \n",
      "[13]\ttraining's multi_logloss: 1.36766\tvalid_1's multi_logloss: 1.38005          \n",
      "[14]\ttraining's multi_logloss: 1.33741\tvalid_1's multi_logloss: 1.35066          \n",
      "[15]\ttraining's multi_logloss: 1.30833\tvalid_1's multi_logloss: 1.32237          \n",
      "[16]\ttraining's multi_logloss: 1.28044\tvalid_1's multi_logloss: 1.29528          \n",
      "[17]\ttraining's multi_logloss: 1.25361\tvalid_1's multi_logloss: 1.26921          \n",
      "[18]\ttraining's multi_logloss: 1.22787\tvalid_1's multi_logloss: 1.24423          \n",
      "[19]\ttraining's multi_logloss: 1.20299\tvalid_1's multi_logloss: 1.22015          \n",
      "[20]\ttraining's multi_logloss: 1.17915\tvalid_1's multi_logloss: 1.19708          \n",
      "[21]\ttraining's multi_logloss: 1.15606\tvalid_1's multi_logloss: 1.17468          \n",
      "[22]\ttraining's multi_logloss: 1.13385\tvalid_1's multi_logloss: 1.15314          \n",
      "[23]\ttraining's multi_logloss: 1.11231\tvalid_1's multi_logloss: 1.13243          \n",
      "[24]\ttraining's multi_logloss: 1.09141\tvalid_1's multi_logloss: 1.11224          \n",
      "[25]\ttraining's multi_logloss: 1.07123\tvalid_1's multi_logloss: 1.09274          \n",
      "[26]\ttraining's multi_logloss: 1.0516\tvalid_1's multi_logloss: 1.07388           \n",
      "[27]\ttraining's multi_logloss: 1.03262\tvalid_1's multi_logloss: 1.05546          \n",
      "[28]\ttraining's multi_logloss: 1.01423\tvalid_1's multi_logloss: 1.03775          \n",
      "[29]\ttraining's multi_logloss: 0.996435\tvalid_1's multi_logloss: 1.0206          \n",
      "[30]\ttraining's multi_logloss: 0.979163\tvalid_1's multi_logloss: 1.00391         \n",
      "[31]\ttraining's multi_logloss: 0.962396\tvalid_1's multi_logloss: 0.987743        \n",
      "[32]\ttraining's multi_logloss: 0.946088\tvalid_1's multi_logloss: 0.972016        \n",
      "[33]\ttraining's multi_logloss: 0.93023\tvalid_1's multi_logloss: 0.956665         \n",
      "[34]\ttraining's multi_logloss: 0.914745\tvalid_1's multi_logloss: 0.941736        \n",
      "[35]\ttraining's multi_logloss: 0.899836\tvalid_1's multi_logloss: 0.92741         \n",
      "[36]\ttraining's multi_logloss: 0.885142\tvalid_1's multi_logloss: 0.913271        \n",
      "[37]\ttraining's multi_logloss: 0.870952\tvalid_1's multi_logloss: 0.899569        \n",
      "[38]\ttraining's multi_logloss: 0.857009\tvalid_1's multi_logloss: 0.886113        \n",
      "[39]\ttraining's multi_logloss: 0.843368\tvalid_1's multi_logloss: 0.872966        \n",
      "[40]\ttraining's multi_logloss: 0.830097\tvalid_1's multi_logloss: 0.860157        \n",
      "[41]\ttraining's multi_logloss: 0.817246\tvalid_1's multi_logloss: 0.847745        \n",
      "[42]\ttraining's multi_logloss: 0.804673\tvalid_1's multi_logloss: 0.835647        \n",
      "[43]\ttraining's multi_logloss: 0.792439\tvalid_1's multi_logloss: 0.82387         \n",
      "[44]\ttraining's multi_logloss: 0.780365\tvalid_1's multi_logloss: 0.812253        \n",
      "[45]\ttraining's multi_logloss: 0.768769\tvalid_1's multi_logloss: 0.801113        \n",
      "[46]\ttraining's multi_logloss: 0.757288\tvalid_1's multi_logloss: 0.790077        \n",
      "[47]\ttraining's multi_logloss: 0.746219\tvalid_1's multi_logloss: 0.779434        \n",
      "[48]\ttraining's multi_logloss: 0.73532\tvalid_1's multi_logloss: 0.768918         \n",
      "[49]\ttraining's multi_logloss: 0.724898\tvalid_1's multi_logloss: 0.758901        \n",
      "[50]\ttraining's multi_logloss: 0.714604\tvalid_1's multi_logloss: 0.749042        \n",
      "[51]\ttraining's multi_logloss: 0.704596\tvalid_1's multi_logloss: 0.739417        \n",
      "[52]\ttraining's multi_logloss: 0.694803\tvalid_1's multi_logloss: 0.730047        \n",
      "[53]\ttraining's multi_logloss: 0.685233\tvalid_1's multi_logloss: 0.720889        \n",
      "[54]\ttraining's multi_logloss: 0.676009\tvalid_1's multi_logloss: 0.712053        \n",
      "[55]\ttraining's multi_logloss: 0.666915\tvalid_1's multi_logloss: 0.703389        \n",
      "[56]\ttraining's multi_logloss: 0.658068\tvalid_1's multi_logloss: 0.694975        \n",
      "[57]\ttraining's multi_logloss: 0.649348\tvalid_1's multi_logloss: 0.686705        \n",
      "[58]\ttraining's multi_logloss: 0.640844\tvalid_1's multi_logloss: 0.678643        \n",
      "[59]\ttraining's multi_logloss: 0.632522\tvalid_1's multi_logloss: 0.670732        \n",
      "[60]\ttraining's multi_logloss: 0.624395\tvalid_1's multi_logloss: 0.663029        \n",
      "[61]\ttraining's multi_logloss: 0.616433\tvalid_1's multi_logloss: 0.655525        \n",
      "[62]\ttraining's multi_logloss: 0.608508\tvalid_1's multi_logloss: 0.648079        \n",
      "[63]\ttraining's multi_logloss: 0.600809\tvalid_1's multi_logloss: 0.64086         \n",
      "[64]\ttraining's multi_logloss: 0.593316\tvalid_1's multi_logloss: 0.633834        \n",
      "[65]\ttraining's multi_logloss: 0.585897\tvalid_1's multi_logloss: 0.626818        \n",
      "[66]\ttraining's multi_logloss: 0.578846\tvalid_1's multi_logloss: 0.620204        \n",
      "[67]\ttraining's multi_logloss: 0.571805\tvalid_1's multi_logloss: 0.613635        \n",
      "[68]\ttraining's multi_logloss: 0.564999\tvalid_1's multi_logloss: 0.607268        \n",
      "[69]\ttraining's multi_logloss: 0.558337\tvalid_1's multi_logloss: 0.600964        \n",
      "[70]\ttraining's multi_logloss: 0.551716\tvalid_1's multi_logloss: 0.594769        \n",
      "[71]\ttraining's multi_logloss: 0.545391\tvalid_1's multi_logloss: 0.588825        \n",
      "[72]\ttraining's multi_logloss: 0.539125\tvalid_1's multi_logloss: 0.582933        \n",
      "[73]\ttraining's multi_logloss: 0.533003\tvalid_1's multi_logloss: 0.577237        \n",
      "[74]\ttraining's multi_logloss: 0.526975\tvalid_1's multi_logloss: 0.571545        \n",
      "[75]\ttraining's multi_logloss: 0.521181\tvalid_1's multi_logloss: 0.566202        \n",
      "[76]\ttraining's multi_logloss: 0.515391\tvalid_1's multi_logloss: 0.560805        \n",
      "[77]\ttraining's multi_logloss: 0.509743\tvalid_1's multi_logloss: 0.555538        \n",
      "[78]\ttraining's multi_logloss: 0.504178\tvalid_1's multi_logloss: 0.55043         \n",
      "[79]\ttraining's multi_logloss: 0.498762\tvalid_1's multi_logloss: 0.545356        \n",
      "[80]\ttraining's multi_logloss: 0.493497\tvalid_1's multi_logloss: 0.540542        \n",
      "[81]\ttraining's multi_logloss: 0.488331\tvalid_1's multi_logloss: 0.535817        \n",
      "[82]\ttraining's multi_logloss: 0.483262\tvalid_1's multi_logloss: 0.531126        \n",
      "[83]\ttraining's multi_logloss: 0.478241\tvalid_1's multi_logloss: 0.526494        \n",
      "[84]\ttraining's multi_logloss: 0.473267\tvalid_1's multi_logloss: 0.521932        \n",
      "[85]\ttraining's multi_logloss: 0.468508\tvalid_1's multi_logloss: 0.517606        \n",
      "[86]\ttraining's multi_logloss: 0.463768\tvalid_1's multi_logloss: 0.513289        \n",
      "[87]\ttraining's multi_logloss: 0.459175\tvalid_1's multi_logloss: 0.50909         \n",
      "[88]\ttraining's multi_logloss: 0.454585\tvalid_1's multi_logloss: 0.504934        \n",
      "[89]\ttraining's multi_logloss: 0.450077\tvalid_1's multi_logloss: 0.500805        \n",
      "[90]\ttraining's multi_logloss: 0.445651\tvalid_1's multi_logloss: 0.49682         \n",
      "[91]\ttraining's multi_logloss: 0.441275\tvalid_1's multi_logloss: 0.492855        \n",
      "[92]\ttraining's multi_logloss: 0.437009\tvalid_1's multi_logloss: 0.488941        \n",
      "[93]\ttraining's multi_logloss: 0.432817\tvalid_1's multi_logloss: 0.485155        \n",
      "[94]\ttraining's multi_logloss: 0.428721\tvalid_1's multi_logloss: 0.481439        \n",
      "[95]\ttraining's multi_logloss: 0.424723\tvalid_1's multi_logloss: 0.477897        \n",
      "[96]\ttraining's multi_logloss: 0.420788\tvalid_1's multi_logloss: 0.474266        \n",
      "[97]\ttraining's multi_logloss: 0.416937\tvalid_1's multi_logloss: 0.47077         \n",
      "[98]\ttraining's multi_logloss: 0.413178\tvalid_1's multi_logloss: 0.467359        \n",
      "[99]\ttraining's multi_logloss: 0.409461\tvalid_1's multi_logloss: 0.464059        \n",
      "[100]\ttraining's multi_logloss: 0.405861\tvalid_1's multi_logloss: 0.460813       \n",
      "[101]\ttraining's multi_logloss: 0.402309\tvalid_1's multi_logloss: 0.457567       \n",
      "[102]\ttraining's multi_logloss: 0.398773\tvalid_1's multi_logloss: 0.45443        \n",
      "[103]\ttraining's multi_logloss: 0.395337\tvalid_1's multi_logloss: 0.451393       \n",
      "[104]\ttraining's multi_logloss: 0.391951\tvalid_1's multi_logloss: 0.448363       \n",
      "[105]\ttraining's multi_logloss: 0.388605\tvalid_1's multi_logloss: 0.445295       \n",
      "[106]\ttraining's multi_logloss: 0.385343\tvalid_1's multi_logloss: 0.442391       \n",
      "[107]\ttraining's multi_logloss: 0.382098\tvalid_1's multi_logloss: 0.439489       \n",
      "[108]\ttraining's multi_logloss: 0.378935\tvalid_1's multi_logloss: 0.436686       \n",
      "[109]\ttraining's multi_logloss: 0.375822\tvalid_1's multi_logloss: 0.433894       \n",
      "[110]\ttraining's multi_logloss: 0.372787\tvalid_1's multi_logloss: 0.431182       \n",
      "[111]\ttraining's multi_logloss: 0.369819\tvalid_1's multi_logloss: 0.428549       \n",
      "[112]\ttraining's multi_logloss: 0.36688\tvalid_1's multi_logloss: 0.425963        \n",
      "[113]\ttraining's multi_logloss: 0.364027\tvalid_1's multi_logloss: 0.423453       \n",
      "[114]\ttraining's multi_logloss: 0.361215\tvalid_1's multi_logloss: 0.421007       \n",
      "[115]\ttraining's multi_logloss: 0.358458\tvalid_1's multi_logloss: 0.418587       \n",
      "[116]\ttraining's multi_logloss: 0.355755\tvalid_1's multi_logloss: 0.416292       \n",
      "[117]\ttraining's multi_logloss: 0.35312\tvalid_1's multi_logloss: 0.414023        \n",
      "[118]\ttraining's multi_logloss: 0.350493\tvalid_1's multi_logloss: 0.411782       \n",
      "[119]\ttraining's multi_logloss: 0.347928\tvalid_1's multi_logloss: 0.409654       \n",
      "[120]\ttraining's multi_logloss: 0.345394\tvalid_1's multi_logloss: 0.40748        \n",
      "[121]\ttraining's multi_logloss: 0.342893\tvalid_1's multi_logloss: 0.405418       \n",
      "[122]\ttraining's multi_logloss: 0.340429\tvalid_1's multi_logloss: 0.403353       \n",
      "[123]\ttraining's multi_logloss: 0.337956\tvalid_1's multi_logloss: 0.401356       \n",
      "[124]\ttraining's multi_logloss: 0.335582\tvalid_1's multi_logloss: 0.399334       \n",
      "[125]\ttraining's multi_logloss: 0.333238\tvalid_1's multi_logloss: 0.397393       \n",
      "[126]\ttraining's multi_logloss: 0.330893\tvalid_1's multi_logloss: 0.395543       \n",
      "[127]\ttraining's multi_logloss: 0.328619\tvalid_1's multi_logloss: 0.393668       \n",
      "[128]\ttraining's multi_logloss: 0.32643\tvalid_1's multi_logloss: 0.3919          \n",
      "[129]\ttraining's multi_logloss: 0.324215\tvalid_1's multi_logloss: 0.390125       \n",
      "[130]\ttraining's multi_logloss: 0.321995\tvalid_1's multi_logloss: 0.388287       \n",
      "[131]\ttraining's multi_logloss: 0.319909\tvalid_1's multi_logloss: 0.386611       \n",
      "[132]\ttraining's multi_logloss: 0.3178\tvalid_1's multi_logloss: 0.38489          \n",
      "[133]\ttraining's multi_logloss: 0.31577\tvalid_1's multi_logloss: 0.383241        \n",
      "[134]\ttraining's multi_logloss: 0.31373\tvalid_1's multi_logloss: 0.381594        \n",
      "[135]\ttraining's multi_logloss: 0.311742\tvalid_1's multi_logloss: 0.380002       \n",
      "[136]\ttraining's multi_logloss: 0.309711\tvalid_1's multi_logloss: 0.378419       \n",
      "[137]\ttraining's multi_logloss: 0.30778\tvalid_1's multi_logloss: 0.376901        \n",
      "[138]\ttraining's multi_logloss: 0.305842\tvalid_1's multi_logloss: 0.375353       \n",
      "[139]\ttraining's multi_logloss: 0.303962\tvalid_1's multi_logloss: 0.373868       \n",
      "[140]\ttraining's multi_logloss: 0.302055\tvalid_1's multi_logloss: 0.372363       \n",
      "[141]\ttraining's multi_logloss: 0.300251\tvalid_1's multi_logloss: 0.370911       \n",
      "[142]\ttraining's multi_logloss: 0.298374\tvalid_1's multi_logloss: 0.369476       \n",
      "[143]\ttraining's multi_logloss: 0.296631\tvalid_1's multi_logloss: 0.368096       \n",
      "[144]\ttraining's multi_logloss: 0.29484\tvalid_1's multi_logloss: 0.366691        \n",
      "[145]\ttraining's multi_logloss: 0.293073\tvalid_1's multi_logloss: 0.365366       \n",
      "[146]\ttraining's multi_logloss: 0.291366\tvalid_1's multi_logloss: 0.364054       \n",
      "[147]\ttraining's multi_logloss: 0.289613\tvalid_1's multi_logloss: 0.362715       \n",
      "[148]\ttraining's multi_logloss: 0.2879\tvalid_1's multi_logloss: 0.361455         \n",
      "[149]\ttraining's multi_logloss: 0.286203\tvalid_1's multi_logloss: 0.360181       \n",
      "[150]\ttraining's multi_logloss: 0.284535\tvalid_1's multi_logloss: 0.35891        \n",
      "[151]\ttraining's multi_logloss: 0.282967\tvalid_1's multi_logloss: 0.357711       \n",
      "[152]\ttraining's multi_logloss: 0.281348\tvalid_1's multi_logloss: 0.356509       \n",
      "[153]\ttraining's multi_logloss: 0.27975\tvalid_1's multi_logloss: 0.355318        \n",
      "[154]\ttraining's multi_logloss: 0.278185\tvalid_1's multi_logloss: 0.354152       \n",
      "[155]\ttraining's multi_logloss: 0.276667\tvalid_1's multi_logloss: 0.353021       \n",
      "[156]\ttraining's multi_logloss: 0.275131\tvalid_1's multi_logloss: 0.351911       \n",
      "[157]\ttraining's multi_logloss: 0.273661\tvalid_1's multi_logloss: 0.350877       \n",
      "[158]\ttraining's multi_logloss: 0.272211\tvalid_1's multi_logloss: 0.349792       \n",
      "[159]\ttraining's multi_logloss: 0.270779\tvalid_1's multi_logloss: 0.348807       \n",
      "[160]\ttraining's multi_logloss: 0.269371\tvalid_1's multi_logloss: 0.347813       \n",
      "[161]\ttraining's multi_logloss: 0.267935\tvalid_1's multi_logloss: 0.346848       \n",
      "[162]\ttraining's multi_logloss: 0.266546\tvalid_1's multi_logloss: 0.345898       \n",
      "[163]\ttraining's multi_logloss: 0.26517\tvalid_1's multi_logloss: 0.344925        \n",
      "[164]\ttraining's multi_logloss: 0.263828\tvalid_1's multi_logloss: 0.343961       \n",
      "[165]\ttraining's multi_logloss: 0.2625\tvalid_1's multi_logloss: 0.343046         \n",
      "[166]\ttraining's multi_logloss: 0.26119\tvalid_1's multi_logloss: 0.342109        \n",
      "[167]\ttraining's multi_logloss: 0.259892\tvalid_1's multi_logloss: 0.341147       \n",
      "[168]\ttraining's multi_logloss: 0.258545\tvalid_1's multi_logloss: 0.340249       \n",
      "[169]\ttraining's multi_logloss: 0.257267\tvalid_1's multi_logloss: 0.339398       \n",
      "[170]\ttraining's multi_logloss: 0.255964\tvalid_1's multi_logloss: 0.338521       \n",
      "[171]\ttraining's multi_logloss: 0.254682\tvalid_1's multi_logloss: 0.337589       \n",
      "[172]\ttraining's multi_logloss: 0.253424\tvalid_1's multi_logloss: 0.336722       \n",
      "[173]\ttraining's multi_logloss: 0.252202\tvalid_1's multi_logloss: 0.335921       \n",
      "[174]\ttraining's multi_logloss: 0.251005\tvalid_1's multi_logloss: 0.335097       \n",
      "[175]\ttraining's multi_logloss: 0.249798\tvalid_1's multi_logloss: 0.334291       \n",
      "[176]\ttraining's multi_logloss: 0.248606\tvalid_1's multi_logloss: 0.333528       \n",
      "[177]\ttraining's multi_logloss: 0.247434\tvalid_1's multi_logloss: 0.332747       \n",
      "[178]\ttraining's multi_logloss: 0.246251\tvalid_1's multi_logloss: 0.33206        \n",
      "[179]\ttraining's multi_logloss: 0.24511\tvalid_1's multi_logloss: 0.331374        \n",
      "[180]\ttraining's multi_logloss: 0.24395\tvalid_1's multi_logloss: 0.330661        \n",
      "[181]\ttraining's multi_logloss: 0.242822\tvalid_1's multi_logloss: 0.330034       \n",
      "[182]\ttraining's multi_logloss: 0.241688\tvalid_1's multi_logloss: 0.329311       \n",
      "[183]\ttraining's multi_logloss: 0.240584\tvalid_1's multi_logloss: 0.328643       \n",
      "[184]\ttraining's multi_logloss: 0.23947\tvalid_1's multi_logloss: 0.328007        \n",
      "[185]\ttraining's multi_logloss: 0.238382\tvalid_1's multi_logloss: 0.327358       \n",
      "[186]\ttraining's multi_logloss: 0.237291\tvalid_1's multi_logloss: 0.326696       \n",
      "[187]\ttraining's multi_logloss: 0.236167\tvalid_1's multi_logloss: 0.325992       \n",
      "[188]\ttraining's multi_logloss: 0.235132\tvalid_1's multi_logloss: 0.325405       \n",
      "[189]\ttraining's multi_logloss: 0.234041\tvalid_1's multi_logloss: 0.324756       \n",
      "[190]\ttraining's multi_logloss: 0.233\tvalid_1's multi_logloss: 0.324148          \n",
      "[191]\ttraining's multi_logloss: 0.231942\tvalid_1's multi_logloss: 0.323549       \n",
      "[192]\ttraining's multi_logloss: 0.230933\tvalid_1's multi_logloss: 0.322983       \n",
      "[193]\ttraining's multi_logloss: 0.229903\tvalid_1's multi_logloss: 0.322352       \n",
      "[194]\ttraining's multi_logloss: 0.228866\tvalid_1's multi_logloss: 0.321828       \n",
      "[195]\ttraining's multi_logloss: 0.227867\tvalid_1's multi_logloss: 0.321267       \n",
      "[196]\ttraining's multi_logloss: 0.226867\tvalid_1's multi_logloss: 0.320716       \n",
      "[197]\ttraining's multi_logloss: 0.225897\tvalid_1's multi_logloss: 0.320186       \n",
      "[198]\ttraining's multi_logloss: 0.224921\tvalid_1's multi_logloss: 0.319684       \n",
      "[199]\ttraining's multi_logloss: 0.223933\tvalid_1's multi_logloss: 0.319169       \n",
      "[200]\ttraining's multi_logloss: 0.222995\tvalid_1's multi_logloss: 0.318709       \n",
      "[201]\ttraining's multi_logloss: 0.222081\tvalid_1's multi_logloss: 0.318191       \n",
      "[202]\ttraining's multi_logloss: 0.221107\tvalid_1's multi_logloss: 0.317649       \n",
      "[203]\ttraining's multi_logloss: 0.220188\tvalid_1's multi_logloss: 0.317173       \n",
      "[204]\ttraining's multi_logloss: 0.219234\tvalid_1's multi_logloss: 0.316664       \n",
      "[205]\ttraining's multi_logloss: 0.218335\tvalid_1's multi_logloss: 0.316223       \n",
      "[206]\ttraining's multi_logloss: 0.217445\tvalid_1's multi_logloss: 0.315756       \n",
      "[207]\ttraining's multi_logloss: 0.216562\tvalid_1's multi_logloss: 0.315362       \n",
      "[208]\ttraining's multi_logloss: 0.215671\tvalid_1's multi_logloss: 0.314919       \n",
      "[209]\ttraining's multi_logloss: 0.214806\tvalid_1's multi_logloss: 0.314485       \n",
      "[210]\ttraining's multi_logloss: 0.213919\tvalid_1's multi_logloss: 0.314007       \n",
      "[211]\ttraining's multi_logloss: 0.21307\tvalid_1's multi_logloss: 0.313607        \n",
      "[212]\ttraining's multi_logloss: 0.212242\tvalid_1's multi_logloss: 0.313191       \n",
      "[213]\ttraining's multi_logloss: 0.211379\tvalid_1's multi_logloss: 0.312801       \n",
      "[214]\ttraining's multi_logloss: 0.210527\tvalid_1's multi_logloss: 0.312423       \n",
      "[215]\ttraining's multi_logloss: 0.209693\tvalid_1's multi_logloss: 0.312012       \n",
      "[216]\ttraining's multi_logloss: 0.208879\tvalid_1's multi_logloss: 0.311684       \n",
      "[217]\ttraining's multi_logloss: 0.20805\tvalid_1's multi_logloss: 0.311351        \n",
      "[218]\ttraining's multi_logloss: 0.20725\tvalid_1's multi_logloss: 0.311063        \n",
      "[219]\ttraining's multi_logloss: 0.20644\tvalid_1's multi_logloss: 0.310667        \n",
      "[220]\ttraining's multi_logloss: 0.205667\tvalid_1's multi_logloss: 0.310348       \n",
      "[221]\ttraining's multi_logloss: 0.204843\tvalid_1's multi_logloss: 0.309885       \n",
      "[222]\ttraining's multi_logloss: 0.204056\tvalid_1's multi_logloss: 0.309485       \n",
      "[223]\ttraining's multi_logloss: 0.203269\tvalid_1's multi_logloss: 0.309157       \n",
      "[224]\ttraining's multi_logloss: 0.202544\tvalid_1's multi_logloss: 0.308897       \n",
      "[225]\ttraining's multi_logloss: 0.201825\tvalid_1's multi_logloss: 0.308605       \n",
      "[226]\ttraining's multi_logloss: 0.201059\tvalid_1's multi_logloss: 0.308356       \n",
      "[227]\ttraining's multi_logloss: 0.200311\tvalid_1's multi_logloss: 0.308015       \n",
      "[228]\ttraining's multi_logloss: 0.199572\tvalid_1's multi_logloss: 0.307739       \n",
      "[229]\ttraining's multi_logloss: 0.198827\tvalid_1's multi_logloss: 0.307426       \n",
      "[230]\ttraining's multi_logloss: 0.198082\tvalid_1's multi_logloss: 0.307175       \n",
      "[231]\ttraining's multi_logloss: 0.197345\tvalid_1's multi_logloss: 0.306852       \n",
      "[232]\ttraining's multi_logloss: 0.196627\tvalid_1's multi_logloss: 0.306652       \n",
      "[233]\ttraining's multi_logloss: 0.195908\tvalid_1's multi_logloss: 0.306346       \n",
      "[234]\ttraining's multi_logloss: 0.195193\tvalid_1's multi_logloss: 0.306012       \n",
      "[235]\ttraining's multi_logloss: 0.194461\tvalid_1's multi_logloss: 0.305692       \n",
      "[236]\ttraining's multi_logloss: 0.19378\tvalid_1's multi_logloss: 0.305462        \n",
      "[237]\ttraining's multi_logloss: 0.193082\tvalid_1's multi_logloss: 0.305124       \n",
      "[238]\ttraining's multi_logloss: 0.192347\tvalid_1's multi_logloss: 0.304804       \n",
      "[239]\ttraining's multi_logloss: 0.191648\tvalid_1's multi_logloss: 0.304493       \n",
      "[240]\ttraining's multi_logloss: 0.190933\tvalid_1's multi_logloss: 0.304173       \n",
      "[241]\ttraining's multi_logloss: 0.190227\tvalid_1's multi_logloss: 0.303949       \n",
      "[242]\ttraining's multi_logloss: 0.189564\tvalid_1's multi_logloss: 0.303692       \n",
      "[243]\ttraining's multi_logloss: 0.188897\tvalid_1's multi_logloss: 0.303464       \n",
      "[244]\ttraining's multi_logloss: 0.188194\tvalid_1's multi_logloss: 0.303163       \n",
      "[245]\ttraining's multi_logloss: 0.187549\tvalid_1's multi_logloss: 0.302935       \n",
      "[246]\ttraining's multi_logloss: 0.186909\tvalid_1's multi_logloss: 0.302704       \n",
      "[247]\ttraining's multi_logloss: 0.18622\tvalid_1's multi_logloss: 0.302432        \n",
      "[248]\ttraining's multi_logloss: 0.185549\tvalid_1's multi_logloss: 0.302188       \n",
      "[249]\ttraining's multi_logloss: 0.18486\tvalid_1's multi_logloss: 0.301931        \n",
      "[250]\ttraining's multi_logloss: 0.184215\tvalid_1's multi_logloss: 0.301707       \n",
      "[251]\ttraining's multi_logloss: 0.183594\tvalid_1's multi_logloss: 0.301486       \n",
      "[252]\ttraining's multi_logloss: 0.182943\tvalid_1's multi_logloss: 0.301229       \n",
      "[253]\ttraining's multi_logloss: 0.182339\tvalid_1's multi_logloss: 0.301027       \n",
      "[254]\ttraining's multi_logloss: 0.181721\tvalid_1's multi_logloss: 0.30083        \n",
      "[255]\ttraining's multi_logloss: 0.181074\tvalid_1's multi_logloss: 0.300558       \n",
      "[256]\ttraining's multi_logloss: 0.180452\tvalid_1's multi_logloss: 0.300404       \n",
      "[257]\ttraining's multi_logloss: 0.179835\tvalid_1's multi_logloss: 0.300173       \n",
      "[258]\ttraining's multi_logloss: 0.179196\tvalid_1's multi_logloss: 0.299968       \n",
      "[259]\ttraining's multi_logloss: 0.178567\tvalid_1's multi_logloss: 0.299777       \n",
      "[260]\ttraining's multi_logloss: 0.177976\tvalid_1's multi_logloss: 0.299554       \n",
      "[261]\ttraining's multi_logloss: 0.17739\tvalid_1's multi_logloss: 0.299345        \n",
      "[262]\ttraining's multi_logloss: 0.176779\tvalid_1's multi_logloss: 0.299227       \n",
      "[263]\ttraining's multi_logloss: 0.17617\tvalid_1's multi_logloss: 0.299055        \n",
      "[264]\ttraining's multi_logloss: 0.175558\tvalid_1's multi_logloss: 0.29892        \n",
      "[265]\ttraining's multi_logloss: 0.174979\tvalid_1's multi_logloss: 0.29878        \n",
      "[266]\ttraining's multi_logloss: 0.174352\tvalid_1's multi_logloss: 0.298574       \n",
      "[267]\ttraining's multi_logloss: 0.173758\tvalid_1's multi_logloss: 0.298389       \n",
      "[268]\ttraining's multi_logloss: 0.173145\tvalid_1's multi_logloss: 0.298191       \n",
      "[269]\ttraining's multi_logloss: 0.172566\tvalid_1's multi_logloss: 0.298052       \n",
      "[270]\ttraining's multi_logloss: 0.171961\tvalid_1's multi_logloss: 0.29797        \n",
      "[271]\ttraining's multi_logloss: 0.171386\tvalid_1's multi_logloss: 0.297793       \n",
      "[272]\ttraining's multi_logloss: 0.170774\tvalid_1's multi_logloss: 0.297609       \n",
      "[273]\ttraining's multi_logloss: 0.170181\tvalid_1's multi_logloss: 0.297419       \n",
      "[274]\ttraining's multi_logloss: 0.169609\tvalid_1's multi_logloss: 0.297264       \n",
      "[275]\ttraining's multi_logloss: 0.169032\tvalid_1's multi_logloss: 0.297048       \n",
      "[276]\ttraining's multi_logloss: 0.168446\tvalid_1's multi_logloss: 0.29685        \n",
      "[277]\ttraining's multi_logloss: 0.167895\tvalid_1's multi_logloss: 0.296742       \n",
      "[278]\ttraining's multi_logloss: 0.167299\tvalid_1's multi_logloss: 0.296557       \n",
      "[279]\ttraining's multi_logloss: 0.166728\tvalid_1's multi_logloss: 0.296352       \n",
      "[280]\ttraining's multi_logloss: 0.166177\tvalid_1's multi_logloss: 0.296211       \n",
      "[281]\ttraining's multi_logloss: 0.165624\tvalid_1's multi_logloss: 0.296073       \n",
      "[282]\ttraining's multi_logloss: 0.165074\tvalid_1's multi_logloss: 0.295985       \n",
      "[283]\ttraining's multi_logloss: 0.164535\tvalid_1's multi_logloss: 0.295813       \n",
      "[284]\ttraining's multi_logloss: 0.163997\tvalid_1's multi_logloss: 0.295668       \n",
      "[285]\ttraining's multi_logloss: 0.163434\tvalid_1's multi_logloss: 0.29555        \n",
      "[286]\ttraining's multi_logloss: 0.162882\tvalid_1's multi_logloss: 0.295444       \n",
      "[287]\ttraining's multi_logloss: 0.162366\tvalid_1's multi_logloss: 0.295316       \n",
      "[288]\ttraining's multi_logloss: 0.161839\tvalid_1's multi_logloss: 0.295221       \n",
      "[289]\ttraining's multi_logloss: 0.161289\tvalid_1's multi_logloss: 0.295086       \n",
      "[290]\ttraining's multi_logloss: 0.160767\tvalid_1's multi_logloss: 0.294966       \n",
      "[291]\ttraining's multi_logloss: 0.160237\tvalid_1's multi_logloss: 0.294876       \n",
      "[292]\ttraining's multi_logloss: 0.159708\tvalid_1's multi_logloss: 0.294811       \n",
      "[293]\ttraining's multi_logloss: 0.159177\tvalid_1's multi_logloss: 0.294692       \n",
      "[294]\ttraining's multi_logloss: 0.158643\tvalid_1's multi_logloss: 0.294585       \n",
      "[295]\ttraining's multi_logloss: 0.158093\tvalid_1's multi_logloss: 0.294461       \n",
      "[296]\ttraining's multi_logloss: 0.157557\tvalid_1's multi_logloss: 0.294383       \n",
      "[297]\ttraining's multi_logloss: 0.15706\tvalid_1's multi_logloss: 0.294253        \n",
      "[298]\ttraining's multi_logloss: 0.15653\tvalid_1's multi_logloss: 0.294165        \n",
      "[299]\ttraining's multi_logloss: 0.156017\tvalid_1's multi_logloss: 0.294011       \n",
      "[300]\ttraining's multi_logloss: 0.155506\tvalid_1's multi_logloss: 0.293923       \n",
      "[301]\ttraining's multi_logloss: 0.155011\tvalid_1's multi_logloss: 0.293826       \n",
      "[302]\ttraining's multi_logloss: 0.154519\tvalid_1's multi_logloss: 0.293674       \n",
      "[303]\ttraining's multi_logloss: 0.154047\tvalid_1's multi_logloss: 0.293658       \n",
      "[304]\ttraining's multi_logloss: 0.153532\tvalid_1's multi_logloss: 0.293584       \n",
      "[305]\ttraining's multi_logloss: 0.15307\tvalid_1's multi_logloss: 0.293474        \n",
      "[306]\ttraining's multi_logloss: 0.152566\tvalid_1's multi_logloss: 0.293406       \n",
      "[307]\ttraining's multi_logloss: 0.152093\tvalid_1's multi_logloss: 0.293351       \n",
      "[308]\ttraining's multi_logloss: 0.151611\tvalid_1's multi_logloss: 0.293223       \n",
      "[309]\ttraining's multi_logloss: 0.151128\tvalid_1's multi_logloss: 0.293163       \n",
      "[310]\ttraining's multi_logloss: 0.150665\tvalid_1's multi_logloss: 0.293076       \n",
      "[311]\ttraining's multi_logloss: 0.150203\tvalid_1's multi_logloss: 0.292961       \n",
      "[312]\ttraining's multi_logloss: 0.149725\tvalid_1's multi_logloss: 0.292846       \n",
      "[313]\ttraining's multi_logloss: 0.149274\tvalid_1's multi_logloss: 0.292714       \n",
      "[314]\ttraining's multi_logloss: 0.148808\tvalid_1's multi_logloss: 0.29262        \n",
      "[315]\ttraining's multi_logloss: 0.148351\tvalid_1's multi_logloss: 0.292559       \n",
      "[316]\ttraining's multi_logloss: 0.147905\tvalid_1's multi_logloss: 0.292436       \n",
      "[317]\ttraining's multi_logloss: 0.147429\tvalid_1's multi_logloss: 0.292341       \n",
      "[318]\ttraining's multi_logloss: 0.146981\tvalid_1's multi_logloss: 0.292266       \n",
      "[319]\ttraining's multi_logloss: 0.14654\tvalid_1's multi_logloss: 0.292153        \n",
      "[320]\ttraining's multi_logloss: 0.146086\tvalid_1's multi_logloss: 0.292088       \n",
      "[321]\ttraining's multi_logloss: 0.145652\tvalid_1's multi_logloss: 0.291992       \n",
      "[322]\ttraining's multi_logloss: 0.145191\tvalid_1's multi_logloss: 0.291862       \n",
      "[323]\ttraining's multi_logloss: 0.144741\tvalid_1's multi_logloss: 0.291813       \n",
      "[324]\ttraining's multi_logloss: 0.144275\tvalid_1's multi_logloss: 0.291773       \n",
      "[325]\ttraining's multi_logloss: 0.143807\tvalid_1's multi_logloss: 0.291632       \n",
      "[326]\ttraining's multi_logloss: 0.143336\tvalid_1's multi_logloss: 0.291533       \n",
      "[327]\ttraining's multi_logloss: 0.142886\tvalid_1's multi_logloss: 0.291431       \n",
      "[328]\ttraining's multi_logloss: 0.142459\tvalid_1's multi_logloss: 0.291353       \n",
      "[329]\ttraining's multi_logloss: 0.142025\tvalid_1's multi_logloss: 0.291259       \n",
      "[330]\ttraining's multi_logloss: 0.141574\tvalid_1's multi_logloss: 0.291182       \n",
      "[331]\ttraining's multi_logloss: 0.141146\tvalid_1's multi_logloss: 0.291096       \n",
      "[332]\ttraining's multi_logloss: 0.14074\tvalid_1's multi_logloss: 0.291048        \n",
      "[333]\ttraining's multi_logloss: 0.140316\tvalid_1's multi_logloss: 0.290927       \n",
      "[334]\ttraining's multi_logloss: 0.139928\tvalid_1's multi_logloss: 0.290875       \n",
      "[335]\ttraining's multi_logloss: 0.139481\tvalid_1's multi_logloss: 0.290813       \n",
      "[336]\ttraining's multi_logloss: 0.139073\tvalid_1's multi_logloss: 0.2907         \n",
      "[337]\ttraining's multi_logloss: 0.138653\tvalid_1's multi_logloss: 0.290608       \n",
      "[338]\ttraining's multi_logloss: 0.138244\tvalid_1's multi_logloss: 0.290558       \n",
      "[339]\ttraining's multi_logloss: 0.137856\tvalid_1's multi_logloss: 0.290482       \n",
      "[340]\ttraining's multi_logloss: 0.13746\tvalid_1's multi_logloss: 0.290382        \n",
      "[341]\ttraining's multi_logloss: 0.137052\tvalid_1's multi_logloss: 0.290348       \n",
      "[342]\ttraining's multi_logloss: 0.136651\tvalid_1's multi_logloss: 0.290304       \n",
      "[343]\ttraining's multi_logloss: 0.136243\tvalid_1's multi_logloss: 0.2902         \n",
      "[344]\ttraining's multi_logloss: 0.135872\tvalid_1's multi_logloss: 0.290145       \n",
      "[345]\ttraining's multi_logloss: 0.135481\tvalid_1's multi_logloss: 0.290073       \n",
      "[346]\ttraining's multi_logloss: 0.135082\tvalid_1's multi_logloss: 0.290013       \n",
      "[347]\ttraining's multi_logloss: 0.134681\tvalid_1's multi_logloss: 0.289944       \n",
      "[348]\ttraining's multi_logloss: 0.134313\tvalid_1's multi_logloss: 0.289866       \n",
      "[349]\ttraining's multi_logloss: 0.133923\tvalid_1's multi_logloss: 0.289768       \n",
      "[350]\ttraining's multi_logloss: 0.133537\tvalid_1's multi_logloss: 0.289699       \n",
      "[351]\ttraining's multi_logloss: 0.133146\tvalid_1's multi_logloss: 0.289681       \n",
      "[352]\ttraining's multi_logloss: 0.132761\tvalid_1's multi_logloss: 0.289612       \n",
      "[353]\ttraining's multi_logloss: 0.132386\tvalid_1's multi_logloss: 0.289599       \n",
      "[354]\ttraining's multi_logloss: 0.131976\tvalid_1's multi_logloss: 0.289498       \n",
      "[355]\ttraining's multi_logloss: 0.131577\tvalid_1's multi_logloss: 0.289456       \n",
      "[356]\ttraining's multi_logloss: 0.131193\tvalid_1's multi_logloss: 0.289413       \n",
      "[357]\ttraining's multi_logloss: 0.130826\tvalid_1's multi_logloss: 0.289392       \n",
      "[358]\ttraining's multi_logloss: 0.130438\tvalid_1's multi_logloss: 0.289414       \n",
      "[359]\ttraining's multi_logloss: 0.130056\tvalid_1's multi_logloss: 0.289349       \n",
      "[360]\ttraining's multi_logloss: 0.129676\tvalid_1's multi_logloss: 0.289275       \n",
      "[361]\ttraining's multi_logloss: 0.129301\tvalid_1's multi_logloss: 0.289276       \n",
      "[362]\ttraining's multi_logloss: 0.12891\tvalid_1's multi_logloss: 0.289214        \n",
      "[363]\ttraining's multi_logloss: 0.128515\tvalid_1's multi_logloss: 0.289203       \n",
      "[364]\ttraining's multi_logloss: 0.128142\tvalid_1's multi_logloss: 0.289204       \n",
      "[365]\ttraining's multi_logloss: 0.127752\tvalid_1's multi_logloss: 0.289163       \n",
      "[366]\ttraining's multi_logloss: 0.12741\tvalid_1's multi_logloss: 0.289163        \n",
      "[367]\ttraining's multi_logloss: 0.127007\tvalid_1's multi_logloss: 0.289144       \n",
      "[368]\ttraining's multi_logloss: 0.126621\tvalid_1's multi_logloss: 0.289132       \n",
      "[369]\ttraining's multi_logloss: 0.126263\tvalid_1's multi_logloss: 0.28911        \n",
      "[370]\ttraining's multi_logloss: 0.125865\tvalid_1's multi_logloss: 0.289077       \n",
      "[371]\ttraining's multi_logloss: 0.125494\tvalid_1's multi_logloss: 0.289067       \n",
      "[372]\ttraining's multi_logloss: 0.125109\tvalid_1's multi_logloss: 0.289079       \n",
      "[373]\ttraining's multi_logloss: 0.12474\tvalid_1's multi_logloss: 0.28904         \n",
      "[374]\ttraining's multi_logloss: 0.124376\tvalid_1's multi_logloss: 0.289045       \n",
      "[375]\ttraining's multi_logloss: 0.123992\tvalid_1's multi_logloss: 0.288993       \n",
      "[376]\ttraining's multi_logloss: 0.123657\tvalid_1's multi_logloss: 0.288961       \n",
      "[377]\ttraining's multi_logloss: 0.123295\tvalid_1's multi_logloss: 0.289002       \n",
      "[378]\ttraining's multi_logloss: 0.122936\tvalid_1's multi_logloss: 0.288986       \n",
      "[379]\ttraining's multi_logloss: 0.122592\tvalid_1's multi_logloss: 0.288951       \n",
      "[380]\ttraining's multi_logloss: 0.122254\tvalid_1's multi_logloss: 0.288904       \n",
      "[381]\ttraining's multi_logloss: 0.121942\tvalid_1's multi_logloss: 0.288863       \n",
      "[382]\ttraining's multi_logloss: 0.121619\tvalid_1's multi_logloss: 0.288854       \n",
      "[383]\ttraining's multi_logloss: 0.121281\tvalid_1's multi_logloss: 0.288813       \n",
      "[384]\ttraining's multi_logloss: 0.120959\tvalid_1's multi_logloss: 0.28879        \n",
      "[385]\ttraining's multi_logloss: 0.120643\tvalid_1's multi_logloss: 0.288733       \n",
      "[386]\ttraining's multi_logloss: 0.120288\tvalid_1's multi_logloss: 0.28868        \n",
      "[387]\ttraining's multi_logloss: 0.119962\tvalid_1's multi_logloss: 0.288671       \n",
      "[388]\ttraining's multi_logloss: 0.119664\tvalid_1's multi_logloss: 0.288648       \n",
      "[389]\ttraining's multi_logloss: 0.119332\tvalid_1's multi_logloss: 0.288602       \n",
      "[390]\ttraining's multi_logloss: 0.119001\tvalid_1's multi_logloss: 0.288607       \n",
      "[391]\ttraining's multi_logloss: 0.11868\tvalid_1's multi_logloss: 0.288584        \n",
      "[392]\ttraining's multi_logloss: 0.118368\tvalid_1's multi_logloss: 0.288617       \n",
      "[393]\ttraining's multi_logloss: 0.118044\tvalid_1's multi_logloss: 0.288584       \n",
      "[394]\ttraining's multi_logloss: 0.11774\tvalid_1's multi_logloss: 0.288542        \n",
      "[395]\ttraining's multi_logloss: 0.117416\tvalid_1's multi_logloss: 0.288489       \n",
      "[396]\ttraining's multi_logloss: 0.117109\tvalid_1's multi_logloss: 0.288491       \n",
      "[397]\ttraining's multi_logloss: 0.116791\tvalid_1's multi_logloss: 0.288507       \n",
      "[398]\ttraining's multi_logloss: 0.116467\tvalid_1's multi_logloss: 0.288488       \n",
      "[399]\ttraining's multi_logloss: 0.116143\tvalid_1's multi_logloss: 0.288455       \n",
      "[400]\ttraining's multi_logloss: 0.115802\tvalid_1's multi_logloss: 0.288434       \n",
      "Did not meet early stopping. Best iteration is:                                  \n",
      "[400]\ttraining's multi_logloss: 0.115802\tvalid_1's multi_logloss: 0.288434\n",
      "[1]\ttraining's multi_logloss: 1.86979\tvalid_1's multi_logloss: 1.87192           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.81384\tvalid_1's multi_logloss: 1.81639           \n",
      "[3]\ttraining's multi_logloss: 1.76161\tvalid_1's multi_logloss: 1.76455           \n",
      "[4]\ttraining's multi_logloss: 1.71261\tvalid_1's multi_logloss: 1.71578           \n",
      "[5]\ttraining's multi_logloss: 1.66643\tvalid_1's multi_logloss: 1.66998           \n",
      "[6]\ttraining's multi_logloss: 1.62266\tvalid_1's multi_logloss: 1.62645           \n",
      "[7]\ttraining's multi_logloss: 1.58132\tvalid_1's multi_logloss: 1.58543           \n",
      "[8]\ttraining's multi_logloss: 1.5419\tvalid_1's multi_logloss: 1.5463             \n",
      "[9]\ttraining's multi_logloss: 1.5046\tvalid_1's multi_logloss: 1.50931            \n",
      "[10]\ttraining's multi_logloss: 1.46897\tvalid_1's multi_logloss: 1.47412          \n",
      "[11]\ttraining's multi_logloss: 1.43499\tvalid_1's multi_logloss: 1.44073          \n",
      "[12]\ttraining's multi_logloss: 1.40248\tvalid_1's multi_logloss: 1.40877          \n",
      "[13]\ttraining's multi_logloss: 1.37148\tvalid_1's multi_logloss: 1.3782           \n",
      "[14]\ttraining's multi_logloss: 1.34168\tvalid_1's multi_logloss: 1.34887          \n",
      "[15]\ttraining's multi_logloss: 1.31305\tvalid_1's multi_logloss: 1.32057          \n",
      "[16]\ttraining's multi_logloss: 1.28552\tvalid_1's multi_logloss: 1.2936           \n",
      "[17]\ttraining's multi_logloss: 1.25904\tvalid_1's multi_logloss: 1.26748          \n",
      "[18]\ttraining's multi_logloss: 1.23338\tvalid_1's multi_logloss: 1.24234          \n",
      "[19]\ttraining's multi_logloss: 1.20855\tvalid_1's multi_logloss: 1.21785          \n",
      "[20]\ttraining's multi_logloss: 1.18494\tvalid_1's multi_logloss: 1.19465          \n",
      "[21]\ttraining's multi_logloss: 1.16194\tvalid_1's multi_logloss: 1.17205          \n",
      "[22]\ttraining's multi_logloss: 1.13981\tvalid_1's multi_logloss: 1.15037          \n",
      "[23]\ttraining's multi_logloss: 1.11829\tvalid_1's multi_logloss: 1.12918          \n",
      "[24]\ttraining's multi_logloss: 1.09751\tvalid_1's multi_logloss: 1.10882          \n",
      "[25]\ttraining's multi_logloss: 1.07732\tvalid_1's multi_logloss: 1.08907          \n",
      "[26]\ttraining's multi_logloss: 1.05776\tvalid_1's multi_logloss: 1.06985          \n",
      "[27]\ttraining's multi_logloss: 1.03878\tvalid_1's multi_logloss: 1.05136          \n",
      "[28]\ttraining's multi_logloss: 1.02051\tvalid_1's multi_logloss: 1.03358          \n",
      "[29]\ttraining's multi_logloss: 1.0026\tvalid_1's multi_logloss: 1.01604           \n",
      "[30]\ttraining's multi_logloss: 0.985281\tvalid_1's multi_logloss: 0.999224        \n",
      "[31]\ttraining's multi_logloss: 0.968427\tvalid_1's multi_logloss: 0.982859        \n",
      "[32]\ttraining's multi_logloss: 0.952134\tvalid_1's multi_logloss: 0.966983        \n",
      "[33]\ttraining's multi_logloss: 0.936238\tvalid_1's multi_logloss: 0.951601        \n",
      "[34]\ttraining's multi_logloss: 0.92073\tvalid_1's multi_logloss: 0.936541         \n",
      "[35]\ttraining's multi_logloss: 0.905793\tvalid_1's multi_logloss: 0.922129        \n",
      "[36]\ttraining's multi_logloss: 0.891138\tvalid_1's multi_logloss: 0.907861        \n",
      "[37]\ttraining's multi_logloss: 0.876936\tvalid_1's multi_logloss: 0.894098        \n",
      "[38]\ttraining's multi_logloss: 0.863034\tvalid_1's multi_logloss: 0.880591        \n",
      "[39]\ttraining's multi_logloss: 0.849493\tvalid_1's multi_logloss: 0.867421        \n",
      "[40]\ttraining's multi_logloss: 0.83633\tvalid_1's multi_logloss: 0.854611         \n",
      "[41]\ttraining's multi_logloss: 0.823458\tvalid_1's multi_logloss: 0.84206         \n",
      "[42]\ttraining's multi_logloss: 0.810963\tvalid_1's multi_logloss: 0.829967        \n",
      "[43]\ttraining's multi_logloss: 0.79878\tvalid_1's multi_logloss: 0.818175         \n",
      "[44]\ttraining's multi_logloss: 0.786878\tvalid_1's multi_logloss: 0.80668         \n",
      "[45]\ttraining's multi_logloss: 0.775299\tvalid_1's multi_logloss: 0.795518        \n",
      "[46]\ttraining's multi_logloss: 0.763982\tvalid_1's multi_logloss: 0.784542        \n",
      "[47]\ttraining's multi_logloss: 0.752954\tvalid_1's multi_logloss: 0.773905        \n",
      "[48]\ttraining's multi_logloss: 0.742247\tvalid_1's multi_logloss: 0.763567        \n",
      "[49]\ttraining's multi_logloss: 0.731748\tvalid_1's multi_logloss: 0.753474        \n",
      "[50]\ttraining's multi_logloss: 0.721427\tvalid_1's multi_logloss: 0.743639        \n",
      "[51]\ttraining's multi_logloss: 0.711417\tvalid_1's multi_logloss: 0.734051        \n",
      "[52]\ttraining's multi_logloss: 0.701583\tvalid_1's multi_logloss: 0.724713        \n",
      "[53]\ttraining's multi_logloss: 0.69189\tvalid_1's multi_logloss: 0.715494         \n",
      "[54]\ttraining's multi_logloss: 0.682475\tvalid_1's multi_logloss: 0.706579        \n",
      "[55]\ttraining's multi_logloss: 0.67328\tvalid_1's multi_logloss: 0.697888         \n",
      "[56]\ttraining's multi_logloss: 0.664281\tvalid_1's multi_logloss: 0.689411        \n",
      "[57]\ttraining's multi_logloss: 0.655517\tvalid_1's multi_logloss: 0.681058        \n",
      "[58]\ttraining's multi_logloss: 0.64698\tvalid_1's multi_logloss: 0.672958         \n",
      "[59]\ttraining's multi_logloss: 0.638596\tvalid_1's multi_logloss: 0.66498         \n",
      "[60]\ttraining's multi_logloss: 0.630358\tvalid_1's multi_logloss: 0.6572          \n",
      "[61]\ttraining's multi_logloss: 0.622311\tvalid_1's multi_logloss: 0.649523        \n",
      "[62]\ttraining's multi_logloss: 0.614368\tvalid_1's multi_logloss: 0.641923        \n",
      "[63]\ttraining's multi_logloss: 0.606676\tvalid_1's multi_logloss: 0.634529        \n",
      "[64]\ttraining's multi_logloss: 0.599172\tvalid_1's multi_logloss: 0.627332        \n",
      "[65]\ttraining's multi_logloss: 0.591797\tvalid_1's multi_logloss: 0.62029         \n",
      "[66]\ttraining's multi_logloss: 0.584638\tvalid_1's multi_logloss: 0.613533        \n",
      "[67]\ttraining's multi_logloss: 0.577644\tvalid_1's multi_logloss: 0.606908        \n",
      "[68]\ttraining's multi_logloss: 0.570761\tvalid_1's multi_logloss: 0.600372        \n",
      "[69]\ttraining's multi_logloss: 0.564048\tvalid_1's multi_logloss: 0.594063        \n",
      "[70]\ttraining's multi_logloss: 0.557525\tvalid_1's multi_logloss: 0.587851        \n",
      "[71]\ttraining's multi_logloss: 0.551066\tvalid_1's multi_logloss: 0.581777        \n",
      "[72]\ttraining's multi_logloss: 0.544808\tvalid_1's multi_logloss: 0.575929        \n",
      "[73]\ttraining's multi_logloss: 0.53857\tvalid_1's multi_logloss: 0.570036         \n",
      "[74]\ttraining's multi_logloss: 0.532578\tvalid_1's multi_logloss: 0.564486        \n",
      "[75]\ttraining's multi_logloss: 0.526654\tvalid_1's multi_logloss: 0.558979        \n",
      "[76]\ttraining's multi_logloss: 0.520912\tvalid_1's multi_logloss: 0.553613        \n",
      "[77]\ttraining's multi_logloss: 0.515199\tvalid_1's multi_logloss: 0.548266        \n",
      "[78]\ttraining's multi_logloss: 0.5097\tvalid_1's multi_logloss: 0.543183          \n",
      "[79]\ttraining's multi_logloss: 0.504278\tvalid_1's multi_logloss: 0.538168        \n",
      "[80]\ttraining's multi_logloss: 0.499021\tvalid_1's multi_logloss: 0.533313        \n",
      "[81]\ttraining's multi_logloss: 0.493855\tvalid_1's multi_logloss: 0.528582        \n",
      "[82]\ttraining's multi_logloss: 0.488832\tvalid_1's multi_logloss: 0.523973        \n",
      "[83]\ttraining's multi_logloss: 0.483898\tvalid_1's multi_logloss: 0.519418        \n",
      "[84]\ttraining's multi_logloss: 0.479023\tvalid_1's multi_logloss: 0.514935        \n",
      "[85]\ttraining's multi_logloss: 0.474293\tvalid_1's multi_logloss: 0.510625        \n",
      "[86]\ttraining's multi_logloss: 0.469573\tvalid_1's multi_logloss: 0.506303        \n",
      "[87]\ttraining's multi_logloss: 0.464966\tvalid_1's multi_logloss: 0.50208         \n",
      "[88]\ttraining's multi_logloss: 0.460435\tvalid_1's multi_logloss: 0.498004        \n",
      "[89]\ttraining's multi_logloss: 0.456007\tvalid_1's multi_logloss: 0.493932        \n",
      "[90]\ttraining's multi_logloss: 0.45169\tvalid_1's multi_logloss: 0.490036         \n",
      "[91]\ttraining's multi_logloss: 0.447408\tvalid_1's multi_logloss: 0.486122        \n",
      "[92]\ttraining's multi_logloss: 0.443252\tvalid_1's multi_logloss: 0.482395        \n",
      "[93]\ttraining's multi_logloss: 0.439131\tvalid_1's multi_logloss: 0.478701        \n",
      "[94]\ttraining's multi_logloss: 0.435015\tvalid_1's multi_logloss: 0.474956        \n",
      "[95]\ttraining's multi_logloss: 0.430999\tvalid_1's multi_logloss: 0.471322        \n",
      "[96]\ttraining's multi_logloss: 0.427021\tvalid_1's multi_logloss: 0.467711        \n",
      "[97]\ttraining's multi_logloss: 0.42315\tvalid_1's multi_logloss: 0.464236         \n",
      "[98]\ttraining's multi_logloss: 0.419289\tvalid_1's multi_logloss: 0.460712        \n",
      "[99]\ttraining's multi_logloss: 0.415566\tvalid_1's multi_logloss: 0.45734         \n",
      "[100]\ttraining's multi_logloss: 0.411874\tvalid_1's multi_logloss: 0.454089       \n",
      "[101]\ttraining's multi_logloss: 0.408319\tvalid_1's multi_logloss: 0.450983       \n",
      "[102]\ttraining's multi_logloss: 0.404769\tvalid_1's multi_logloss: 0.447891       \n",
      "[103]\ttraining's multi_logloss: 0.401326\tvalid_1's multi_logloss: 0.444873       \n",
      "[104]\ttraining's multi_logloss: 0.397908\tvalid_1's multi_logloss: 0.441921       \n",
      "[105]\ttraining's multi_logloss: 0.394557\tvalid_1's multi_logloss: 0.439042       \n",
      "[106]\ttraining's multi_logloss: 0.391292\tvalid_1's multi_logloss: 0.436209       \n",
      "[107]\ttraining's multi_logloss: 0.388044\tvalid_1's multi_logloss: 0.433483       \n",
      "[108]\ttraining's multi_logloss: 0.384905\tvalid_1's multi_logloss: 0.430782       \n",
      "[109]\ttraining's multi_logloss: 0.38178\tvalid_1's multi_logloss: 0.42812         \n",
      "[110]\ttraining's multi_logloss: 0.378721\tvalid_1's multi_logloss: 0.425533       \n",
      "[111]\ttraining's multi_logloss: 0.375735\tvalid_1's multi_logloss: 0.422986       \n",
      "[112]\ttraining's multi_logloss: 0.372788\tvalid_1's multi_logloss: 0.420497       \n",
      "[113]\ttraining's multi_logloss: 0.369907\tvalid_1's multi_logloss: 0.418066       \n",
      "[114]\ttraining's multi_logloss: 0.367003\tvalid_1's multi_logloss: 0.415612       \n",
      "[115]\ttraining's multi_logloss: 0.364203\tvalid_1's multi_logloss: 0.413233       \n",
      "[116]\ttraining's multi_logloss: 0.361382\tvalid_1's multi_logloss: 0.410846       \n",
      "[117]\ttraining's multi_logloss: 0.358699\tvalid_1's multi_logloss: 0.408566       \n",
      "[118]\ttraining's multi_logloss: 0.355977\tvalid_1's multi_logloss: 0.406225       \n",
      "[119]\ttraining's multi_logloss: 0.353345\tvalid_1's multi_logloss: 0.404049       \n",
      "[120]\ttraining's multi_logloss: 0.350695\tvalid_1's multi_logloss: 0.401826       \n",
      "[121]\ttraining's multi_logloss: 0.348123\tvalid_1's multi_logloss: 0.399641       \n",
      "[122]\ttraining's multi_logloss: 0.345589\tvalid_1's multi_logloss: 0.397569       \n",
      "[123]\ttraining's multi_logloss: 0.343101\tvalid_1's multi_logloss: 0.395489       \n",
      "[124]\ttraining's multi_logloss: 0.340608\tvalid_1's multi_logloss: 0.393384       \n",
      "[125]\ttraining's multi_logloss: 0.338201\tvalid_1's multi_logloss: 0.391429       \n",
      "[126]\ttraining's multi_logloss: 0.335841\tvalid_1's multi_logloss: 0.389493       \n",
      "[127]\ttraining's multi_logloss: 0.333473\tvalid_1's multi_logloss: 0.387549       \n",
      "[128]\ttraining's multi_logloss: 0.33113\tvalid_1's multi_logloss: 0.385606        \n",
      "[129]\ttraining's multi_logloss: 0.328801\tvalid_1's multi_logloss: 0.383668       \n",
      "[130]\ttraining's multi_logloss: 0.326572\tvalid_1's multi_logloss: 0.381842       \n",
      "[131]\ttraining's multi_logloss: 0.324379\tvalid_1's multi_logloss: 0.380055       \n",
      "[132]\ttraining's multi_logloss: 0.322197\tvalid_1's multi_logloss: 0.378237       \n",
      "[133]\ttraining's multi_logloss: 0.320077\tvalid_1's multi_logloss: 0.376558       \n",
      "[134]\ttraining's multi_logloss: 0.318023\tvalid_1's multi_logloss: 0.3749         \n",
      "[135]\ttraining's multi_logloss: 0.315931\tvalid_1's multi_logloss: 0.373242       \n",
      "[136]\ttraining's multi_logloss: 0.313906\tvalid_1's multi_logloss: 0.371698       \n",
      "[137]\ttraining's multi_logloss: 0.311951\tvalid_1's multi_logloss: 0.370172       \n",
      "[138]\ttraining's multi_logloss: 0.310008\tvalid_1's multi_logloss: 0.368687       \n",
      "[139]\ttraining's multi_logloss: 0.308103\tvalid_1's multi_logloss: 0.3672         \n",
      "[140]\ttraining's multi_logloss: 0.306165\tvalid_1's multi_logloss: 0.365686       \n",
      "[141]\ttraining's multi_logloss: 0.304291\tvalid_1's multi_logloss: 0.364248       \n",
      "[142]\ttraining's multi_logloss: 0.302408\tvalid_1's multi_logloss: 0.362777       \n",
      "[143]\ttraining's multi_logloss: 0.300572\tvalid_1's multi_logloss: 0.361379       \n",
      "[144]\ttraining's multi_logloss: 0.298738\tvalid_1's multi_logloss: 0.359972       \n",
      "[145]\ttraining's multi_logloss: 0.29694\tvalid_1's multi_logloss: 0.358588        \n",
      "[146]\ttraining's multi_logloss: 0.295153\tvalid_1's multi_logloss: 0.35724        \n",
      "[147]\ttraining's multi_logloss: 0.293296\tvalid_1's multi_logloss: 0.355828       \n",
      "[148]\ttraining's multi_logloss: 0.291584\tvalid_1's multi_logloss: 0.354571       \n",
      "[149]\ttraining's multi_logloss: 0.289806\tvalid_1's multi_logloss: 0.353173       \n",
      "[150]\ttraining's multi_logloss: 0.288094\tvalid_1's multi_logloss: 0.351913       \n",
      "[151]\ttraining's multi_logloss: 0.286448\tvalid_1's multi_logloss: 0.350632       \n",
      "[152]\ttraining's multi_logloss: 0.284769\tvalid_1's multi_logloss: 0.349383       \n",
      "[153]\ttraining's multi_logloss: 0.283155\tvalid_1's multi_logloss: 0.348246       \n",
      "[154]\ttraining's multi_logloss: 0.28159\tvalid_1's multi_logloss: 0.347121        \n",
      "[155]\ttraining's multi_logloss: 0.279998\tvalid_1's multi_logloss: 0.345965       \n",
      "[156]\ttraining's multi_logloss: 0.278457\tvalid_1's multi_logloss: 0.344829       \n",
      "[157]\ttraining's multi_logloss: 0.276875\tvalid_1's multi_logloss: 0.343803       \n",
      "[158]\ttraining's multi_logloss: 0.275343\tvalid_1's multi_logloss: 0.342722       \n",
      "[159]\ttraining's multi_logloss: 0.273883\tvalid_1's multi_logloss: 0.34166        \n",
      "[160]\ttraining's multi_logloss: 0.272367\tvalid_1's multi_logloss: 0.34057        \n",
      "[161]\ttraining's multi_logloss: 0.270941\tvalid_1's multi_logloss: 0.339555       \n",
      "[162]\ttraining's multi_logloss: 0.269478\tvalid_1's multi_logloss: 0.338523       \n",
      "[163]\ttraining's multi_logloss: 0.267995\tvalid_1's multi_logloss: 0.337554       \n",
      "[164]\ttraining's multi_logloss: 0.266598\tvalid_1's multi_logloss: 0.336593       \n",
      "[165]\ttraining's multi_logloss: 0.265213\tvalid_1's multi_logloss: 0.335609       \n",
      "[166]\ttraining's multi_logloss: 0.263777\tvalid_1's multi_logloss: 0.334611       \n",
      "[167]\ttraining's multi_logloss: 0.262418\tvalid_1's multi_logloss: 0.333735       \n",
      "[168]\ttraining's multi_logloss: 0.261067\tvalid_1's multi_logloss: 0.332773       \n",
      "[169]\ttraining's multi_logloss: 0.259716\tvalid_1's multi_logloss: 0.331845       \n",
      "[170]\ttraining's multi_logloss: 0.258385\tvalid_1's multi_logloss: 0.330933       \n",
      "[171]\ttraining's multi_logloss: 0.257098\tvalid_1's multi_logloss: 0.330043       \n",
      "[172]\ttraining's multi_logloss: 0.255855\tvalid_1's multi_logloss: 0.329225       \n",
      "[173]\ttraining's multi_logloss: 0.254592\tvalid_1's multi_logloss: 0.328374       \n",
      "[174]\ttraining's multi_logloss: 0.253345\tvalid_1's multi_logloss: 0.327603       \n",
      "[175]\ttraining's multi_logloss: 0.252129\tvalid_1's multi_logloss: 0.326785       \n",
      "[176]\ttraining's multi_logloss: 0.250878\tvalid_1's multi_logloss: 0.326046       \n",
      "[177]\ttraining's multi_logloss: 0.249651\tvalid_1's multi_logloss: 0.325257       \n",
      "[178]\ttraining's multi_logloss: 0.248431\tvalid_1's multi_logloss: 0.324508       \n",
      "[179]\ttraining's multi_logloss: 0.247241\tvalid_1's multi_logloss: 0.323807       \n",
      "[180]\ttraining's multi_logloss: 0.246058\tvalid_1's multi_logloss: 0.323137       \n",
      "[181]\ttraining's multi_logloss: 0.244882\tvalid_1's multi_logloss: 0.322351       \n",
      "[182]\ttraining's multi_logloss: 0.243743\tvalid_1's multi_logloss: 0.321699       \n",
      "[183]\ttraining's multi_logloss: 0.242633\tvalid_1's multi_logloss: 0.321015       \n",
      "[184]\ttraining's multi_logloss: 0.241489\tvalid_1's multi_logloss: 0.32027        \n",
      "[185]\ttraining's multi_logloss: 0.24036\tvalid_1's multi_logloss: 0.319579        \n",
      "[186]\ttraining's multi_logloss: 0.239286\tvalid_1's multi_logloss: 0.318969       \n",
      "[187]\ttraining's multi_logloss: 0.238227\tvalid_1's multi_logloss: 0.318355       \n",
      "[188]\ttraining's multi_logloss: 0.237145\tvalid_1's multi_logloss: 0.317746       \n",
      "[189]\ttraining's multi_logloss: 0.236054\tvalid_1's multi_logloss: 0.317153       \n",
      "[190]\ttraining's multi_logloss: 0.235021\tvalid_1's multi_logloss: 0.316592       \n",
      "[191]\ttraining's multi_logloss: 0.234005\tvalid_1's multi_logloss: 0.316042       \n",
      "[192]\ttraining's multi_logloss: 0.232913\tvalid_1's multi_logloss: 0.315411       \n",
      "[193]\ttraining's multi_logloss: 0.231909\tvalid_1's multi_logloss: 0.314885       \n",
      "[194]\ttraining's multi_logloss: 0.230928\tvalid_1's multi_logloss: 0.314385       \n",
      "[195]\ttraining's multi_logloss: 0.229909\tvalid_1's multi_logloss: 0.313874       \n",
      "[196]\ttraining's multi_logloss: 0.228904\tvalid_1's multi_logloss: 0.313355       \n",
      "[197]\ttraining's multi_logloss: 0.227882\tvalid_1's multi_logloss: 0.312848       \n",
      "[198]\ttraining's multi_logloss: 0.226902\tvalid_1's multi_logloss: 0.312375       \n",
      "[199]\ttraining's multi_logloss: 0.225874\tvalid_1's multi_logloss: 0.311846       \n",
      "[200]\ttraining's multi_logloss: 0.224904\tvalid_1's multi_logloss: 0.311339       \n",
      "[201]\ttraining's multi_logloss: 0.223935\tvalid_1's multi_logloss: 0.310906       \n",
      "[202]\ttraining's multi_logloss: 0.22299\tvalid_1's multi_logloss: 0.310429        \n",
      "[203]\ttraining's multi_logloss: 0.222033\tvalid_1's multi_logloss: 0.310012       \n",
      "[204]\ttraining's multi_logloss: 0.221083\tvalid_1's multi_logloss: 0.309464       \n",
      "[205]\ttraining's multi_logloss: 0.220164\tvalid_1's multi_logloss: 0.309022       \n",
      "[206]\ttraining's multi_logloss: 0.219217\tvalid_1's multi_logloss: 0.30849        \n",
      "[207]\ttraining's multi_logloss: 0.218292\tvalid_1's multi_logloss: 0.308026       \n",
      "[208]\ttraining's multi_logloss: 0.217376\tvalid_1's multi_logloss: 0.307505       \n",
      "[209]\ttraining's multi_logloss: 0.216513\tvalid_1's multi_logloss: 0.307109       \n",
      "[210]\ttraining's multi_logloss: 0.215576\tvalid_1's multi_logloss: 0.306638       \n",
      "[211]\ttraining's multi_logloss: 0.214715\tvalid_1's multi_logloss: 0.306162       \n",
      "[212]\ttraining's multi_logloss: 0.21379\tvalid_1's multi_logloss: 0.305743        \n",
      "[213]\ttraining's multi_logloss: 0.21294\tvalid_1's multi_logloss: 0.305325        \n",
      "[214]\ttraining's multi_logloss: 0.212075\tvalid_1's multi_logloss: 0.304969       \n",
      "[215]\ttraining's multi_logloss: 0.211197\tvalid_1's multi_logloss: 0.304538       \n",
      "[216]\ttraining's multi_logloss: 0.210356\tvalid_1's multi_logloss: 0.304156       \n",
      "[217]\ttraining's multi_logloss: 0.209523\tvalid_1's multi_logloss: 0.303728       \n",
      "[218]\ttraining's multi_logloss: 0.208698\tvalid_1's multi_logloss: 0.303345       \n",
      "[219]\ttraining's multi_logloss: 0.207837\tvalid_1's multi_logloss: 0.302906       \n",
      "[220]\ttraining's multi_logloss: 0.207036\tvalid_1's multi_logloss: 0.302591       \n",
      "[221]\ttraining's multi_logloss: 0.206224\tvalid_1's multi_logloss: 0.302187       \n",
      "[222]\ttraining's multi_logloss: 0.205435\tvalid_1's multi_logloss: 0.30177        \n",
      "[223]\ttraining's multi_logloss: 0.204628\tvalid_1's multi_logloss: 0.3014         \n",
      "[224]\ttraining's multi_logloss: 0.203854\tvalid_1's multi_logloss: 0.301078       \n",
      "[225]\ttraining's multi_logloss: 0.203093\tvalid_1's multi_logloss: 0.300707       \n",
      "[226]\ttraining's multi_logloss: 0.202327\tvalid_1's multi_logloss: 0.300339       \n",
      "[227]\ttraining's multi_logloss: 0.201567\tvalid_1's multi_logloss: 0.300003       \n",
      "[228]\ttraining's multi_logloss: 0.200812\tvalid_1's multi_logloss: 0.299679       \n",
      "[229]\ttraining's multi_logloss: 0.200013\tvalid_1's multi_logloss: 0.29933        \n",
      "[230]\ttraining's multi_logloss: 0.19927\tvalid_1's multi_logloss: 0.299007        \n",
      "[231]\ttraining's multi_logloss: 0.198525\tvalid_1's multi_logloss: 0.298706       \n",
      "[232]\ttraining's multi_logloss: 0.197758\tvalid_1's multi_logloss: 0.29833        \n",
      "[233]\ttraining's multi_logloss: 0.197027\tvalid_1's multi_logloss: 0.298091       \n",
      "[234]\ttraining's multi_logloss: 0.196288\tvalid_1's multi_logloss: 0.297838       \n",
      "[235]\ttraining's multi_logloss: 0.195546\tvalid_1's multi_logloss: 0.29753        \n",
      "[236]\ttraining's multi_logloss: 0.194841\tvalid_1's multi_logloss: 0.297229       \n",
      "[237]\ttraining's multi_logloss: 0.194115\tvalid_1's multi_logloss: 0.296995       \n",
      "[238]\ttraining's multi_logloss: 0.193381\tvalid_1's multi_logloss: 0.296705       \n",
      "[239]\ttraining's multi_logloss: 0.192707\tvalid_1's multi_logloss: 0.296437       \n",
      "[240]\ttraining's multi_logloss: 0.191988\tvalid_1's multi_logloss: 0.296197       \n",
      "[241]\ttraining's multi_logloss: 0.191307\tvalid_1's multi_logloss: 0.295916       \n",
      "[242]\ttraining's multi_logloss: 0.190589\tvalid_1's multi_logloss: 0.295708       \n",
      "[243]\ttraining's multi_logloss: 0.189902\tvalid_1's multi_logloss: 0.29551        \n",
      "[244]\ttraining's multi_logloss: 0.189207\tvalid_1's multi_logloss: 0.295264       \n",
      "[245]\ttraining's multi_logloss: 0.188523\tvalid_1's multi_logloss: 0.295037       \n",
      "[246]\ttraining's multi_logloss: 0.187869\tvalid_1's multi_logloss: 0.294809       \n",
      "[247]\ttraining's multi_logloss: 0.187179\tvalid_1's multi_logloss: 0.294556       \n",
      "[248]\ttraining's multi_logloss: 0.186497\tvalid_1's multi_logloss: 0.294341       \n",
      "[249]\ttraining's multi_logloss: 0.185792\tvalid_1's multi_logloss: 0.294121       \n",
      "[250]\ttraining's multi_logloss: 0.185127\tvalid_1's multi_logloss: 0.293899       \n",
      "[251]\ttraining's multi_logloss: 0.184446\tvalid_1's multi_logloss: 0.293676       \n",
      "[252]\ttraining's multi_logloss: 0.183783\tvalid_1's multi_logloss: 0.293488       \n",
      "[253]\ttraining's multi_logloss: 0.183119\tvalid_1's multi_logloss: 0.293278       \n",
      "[254]\ttraining's multi_logloss: 0.182429\tvalid_1's multi_logloss: 0.293085       \n",
      "[255]\ttraining's multi_logloss: 0.181804\tvalid_1's multi_logloss: 0.29292        \n",
      "[256]\ttraining's multi_logloss: 0.181158\tvalid_1's multi_logloss: 0.292759       \n",
      "[257]\ttraining's multi_logloss: 0.180512\tvalid_1's multi_logloss: 0.29266        \n",
      "[258]\ttraining's multi_logloss: 0.179857\tvalid_1's multi_logloss: 0.292463       \n",
      "[259]\ttraining's multi_logloss: 0.179219\tvalid_1's multi_logloss: 0.292307       \n",
      "[260]\ttraining's multi_logloss: 0.178568\tvalid_1's multi_logloss: 0.2921         \n",
      "[261]\ttraining's multi_logloss: 0.177924\tvalid_1's multi_logloss: 0.291922       \n",
      "[262]\ttraining's multi_logloss: 0.177309\tvalid_1's multi_logloss: 0.291825       \n",
      "[263]\ttraining's multi_logloss: 0.176694\tvalid_1's multi_logloss: 0.291663       \n",
      "[264]\ttraining's multi_logloss: 0.176053\tvalid_1's multi_logloss: 0.291421       \n",
      "[265]\ttraining's multi_logloss: 0.175456\tvalid_1's multi_logloss: 0.291327       \n",
      "[266]\ttraining's multi_logloss: 0.174822\tvalid_1's multi_logloss: 0.291141       \n",
      "[267]\ttraining's multi_logloss: 0.174223\tvalid_1's multi_logloss: 0.291038       \n",
      "[268]\ttraining's multi_logloss: 0.173606\tvalid_1's multi_logloss: 0.290859       \n",
      "[269]\ttraining's multi_logloss: 0.173005\tvalid_1's multi_logloss: 0.2907         \n",
      "[270]\ttraining's multi_logloss: 0.17238\tvalid_1's multi_logloss: 0.290505        \n",
      "[271]\ttraining's multi_logloss: 0.171762\tvalid_1's multi_logloss: 0.29034        \n",
      "[272]\ttraining's multi_logloss: 0.171144\tvalid_1's multi_logloss: 0.290183       \n",
      "[273]\ttraining's multi_logloss: 0.17056\tvalid_1's multi_logloss: 0.289976        \n",
      "[274]\ttraining's multi_logloss: 0.169982\tvalid_1's multi_logloss: 0.289809       \n",
      "[275]\ttraining's multi_logloss: 0.16938\tvalid_1's multi_logloss: 0.289617        \n",
      "[276]\ttraining's multi_logloss: 0.168773\tvalid_1's multi_logloss: 0.289471       \n",
      "[277]\ttraining's multi_logloss: 0.168193\tvalid_1's multi_logloss: 0.289274       \n",
      "[278]\ttraining's multi_logloss: 0.1676\tvalid_1's multi_logloss: 0.289093         \n",
      "[279]\ttraining's multi_logloss: 0.167023\tvalid_1's multi_logloss: 0.28893        \n",
      "[280]\ttraining's multi_logloss: 0.166431\tvalid_1's multi_logloss: 0.288746       \n",
      "[281]\ttraining's multi_logloss: 0.165846\tvalid_1's multi_logloss: 0.288574       \n",
      "[282]\ttraining's multi_logloss: 0.165289\tvalid_1's multi_logloss: 0.288401       \n",
      "[283]\ttraining's multi_logloss: 0.164743\tvalid_1's multi_logloss: 0.288277       \n",
      "[284]\ttraining's multi_logloss: 0.164163\tvalid_1's multi_logloss: 0.288044       \n",
      "[285]\ttraining's multi_logloss: 0.16358\tvalid_1's multi_logloss: 0.287912        \n",
      "[286]\ttraining's multi_logloss: 0.162995\tvalid_1's multi_logloss: 0.287746       \n",
      "[287]\ttraining's multi_logloss: 0.16246\tvalid_1's multi_logloss: 0.287629        \n",
      "[288]\ttraining's multi_logloss: 0.161891\tvalid_1's multi_logloss: 0.287475       \n",
      "[289]\ttraining's multi_logloss: 0.161349\tvalid_1's multi_logloss: 0.287325       \n",
      "[290]\ttraining's multi_logloss: 0.160801\tvalid_1's multi_logloss: 0.287082       \n",
      "[291]\ttraining's multi_logloss: 0.160261\tvalid_1's multi_logloss: 0.286948       \n",
      "[292]\ttraining's multi_logloss: 0.159748\tvalid_1's multi_logloss: 0.2868         \n",
      "[293]\ttraining's multi_logloss: 0.159193\tvalid_1's multi_logloss: 0.286655       \n",
      "[294]\ttraining's multi_logloss: 0.158679\tvalid_1's multi_logloss: 0.28653        \n",
      "[295]\ttraining's multi_logloss: 0.15816\tvalid_1's multi_logloss: 0.286389        \n",
      "[296]\ttraining's multi_logloss: 0.157635\tvalid_1's multi_logloss: 0.286159       \n",
      "[297]\ttraining's multi_logloss: 0.157092\tvalid_1's multi_logloss: 0.286007       \n",
      "[298]\ttraining's multi_logloss: 0.156542\tvalid_1's multi_logloss: 0.285875       \n",
      "[299]\ttraining's multi_logloss: 0.155987\tvalid_1's multi_logloss: 0.285757       \n",
      "[300]\ttraining's multi_logloss: 0.155492\tvalid_1's multi_logloss: 0.285698       \n",
      "[301]\ttraining's multi_logloss: 0.15499\tvalid_1's multi_logloss: 0.285523        \n",
      "[302]\ttraining's multi_logloss: 0.154482\tvalid_1's multi_logloss: 0.285425       \n",
      "[303]\ttraining's multi_logloss: 0.153942\tvalid_1's multi_logloss: 0.285319       \n",
      "[304]\ttraining's multi_logloss: 0.153418\tvalid_1's multi_logloss: 0.285209       \n",
      "[305]\ttraining's multi_logloss: 0.15291\tvalid_1's multi_logloss: 0.285165        \n",
      "[306]\ttraining's multi_logloss: 0.152421\tvalid_1's multi_logloss: 0.285003       \n",
      "[307]\ttraining's multi_logloss: 0.151867\tvalid_1's multi_logloss: 0.284925       \n",
      "[308]\ttraining's multi_logloss: 0.151381\tvalid_1's multi_logloss: 0.284803       \n",
      "[309]\ttraining's multi_logloss: 0.150848\tvalid_1's multi_logloss: 0.284777       \n",
      "[310]\ttraining's multi_logloss: 0.150363\tvalid_1's multi_logloss: 0.284696       \n",
      "[311]\ttraining's multi_logloss: 0.149866\tvalid_1's multi_logloss: 0.284611       \n",
      "[312]\ttraining's multi_logloss: 0.149382\tvalid_1's multi_logloss: 0.28454        \n",
      "[313]\ttraining's multi_logloss: 0.1489\tvalid_1's multi_logloss: 0.284413         \n",
      "[314]\ttraining's multi_logloss: 0.148423\tvalid_1's multi_logloss: 0.284388       \n",
      "[315]\ttraining's multi_logloss: 0.147975\tvalid_1's multi_logloss: 0.284339       \n",
      "[316]\ttraining's multi_logloss: 0.147482\tvalid_1's multi_logloss: 0.284181       \n",
      "[317]\ttraining's multi_logloss: 0.14701\tvalid_1's multi_logloss: 0.284084        \n",
      "[318]\ttraining's multi_logloss: 0.146566\tvalid_1's multi_logloss: 0.28398        \n",
      "[319]\ttraining's multi_logloss: 0.146082\tvalid_1's multi_logloss: 0.28388        \n",
      "[320]\ttraining's multi_logloss: 0.145631\tvalid_1's multi_logloss: 0.283758       \n",
      "[321]\ttraining's multi_logloss: 0.145178\tvalid_1's multi_logloss: 0.283705       \n",
      "[322]\ttraining's multi_logloss: 0.144703\tvalid_1's multi_logloss: 0.283621       \n",
      "[323]\ttraining's multi_logloss: 0.144252\tvalid_1's multi_logloss: 0.2835         \n",
      "[324]\ttraining's multi_logloss: 0.143824\tvalid_1's multi_logloss: 0.283428       \n",
      "[325]\ttraining's multi_logloss: 0.143358\tvalid_1's multi_logloss: 0.283348       \n",
      "[326]\ttraining's multi_logloss: 0.142941\tvalid_1's multi_logloss: 0.28325        \n",
      "[327]\ttraining's multi_logloss: 0.142456\tvalid_1's multi_logloss: 0.283203       \n",
      "[328]\ttraining's multi_logloss: 0.142049\tvalid_1's multi_logloss: 0.283078       \n",
      "[329]\ttraining's multi_logloss: 0.141594\tvalid_1's multi_logloss: 0.283062       \n",
      "[330]\ttraining's multi_logloss: 0.141147\tvalid_1's multi_logloss: 0.282994       \n",
      "[331]\ttraining's multi_logloss: 0.140686\tvalid_1's multi_logloss: 0.283016       \n",
      "[332]\ttraining's multi_logloss: 0.140271\tvalid_1's multi_logloss: 0.282914       \n",
      "[333]\ttraining's multi_logloss: 0.139834\tvalid_1's multi_logloss: 0.282805       \n",
      "[334]\ttraining's multi_logloss: 0.139398\tvalid_1's multi_logloss: 0.282764       \n",
      "[335]\ttraining's multi_logloss: 0.138965\tvalid_1's multi_logloss: 0.282733       \n",
      "[336]\ttraining's multi_logloss: 0.138535\tvalid_1's multi_logloss: 0.282741       \n",
      "[337]\ttraining's multi_logloss: 0.138117\tvalid_1's multi_logloss: 0.282713       \n",
      "[338]\ttraining's multi_logloss: 0.137686\tvalid_1's multi_logloss: 0.282663       \n",
      "[339]\ttraining's multi_logloss: 0.137272\tvalid_1's multi_logloss: 0.282629       \n",
      "[340]\ttraining's multi_logloss: 0.136832\tvalid_1's multi_logloss: 0.282616       \n",
      "[341]\ttraining's multi_logloss: 0.136439\tvalid_1's multi_logloss: 0.282596       \n",
      "[342]\ttraining's multi_logloss: 0.136006\tvalid_1's multi_logloss: 0.282642       \n",
      "[343]\ttraining's multi_logloss: 0.135606\tvalid_1's multi_logloss: 0.282599       \n",
      "[344]\ttraining's multi_logloss: 0.13521\tvalid_1's multi_logloss: 0.282584        \n",
      "[345]\ttraining's multi_logloss: 0.134799\tvalid_1's multi_logloss: 0.282575       \n",
      "[346]\ttraining's multi_logloss: 0.134395\tvalid_1's multi_logloss: 0.282522       \n",
      "[347]\ttraining's multi_logloss: 0.133993\tvalid_1's multi_logloss: 0.282538       \n",
      "[348]\ttraining's multi_logloss: 0.133579\tvalid_1's multi_logloss: 0.282539       \n",
      "[349]\ttraining's multi_logloss: 0.13317\tvalid_1's multi_logloss: 0.282487        \n",
      "[350]\ttraining's multi_logloss: 0.132771\tvalid_1's multi_logloss: 0.282499       \n",
      "[351]\ttraining's multi_logloss: 0.132393\tvalid_1's multi_logloss: 0.282503       \n",
      "[352]\ttraining's multi_logloss: 0.131966\tvalid_1's multi_logloss: 0.282484       \n",
      "[353]\ttraining's multi_logloss: 0.131585\tvalid_1's multi_logloss: 0.282499       \n",
      "[354]\ttraining's multi_logloss: 0.131183\tvalid_1's multi_logloss: 0.282459       \n",
      "[355]\ttraining's multi_logloss: 0.130795\tvalid_1's multi_logloss: 0.282435       \n",
      "[356]\ttraining's multi_logloss: 0.130414\tvalid_1's multi_logloss: 0.282385       \n",
      "[357]\ttraining's multi_logloss: 0.130029\tvalid_1's multi_logloss: 0.282325       \n",
      "[358]\ttraining's multi_logloss: 0.129658\tvalid_1's multi_logloss: 0.282301       \n",
      "[359]\ttraining's multi_logloss: 0.129266\tvalid_1's multi_logloss: 0.282269       \n",
      "[360]\ttraining's multi_logloss: 0.128911\tvalid_1's multi_logloss: 0.282221       \n",
      "[361]\ttraining's multi_logloss: 0.128543\tvalid_1's multi_logloss: 0.282172       \n",
      "[362]\ttraining's multi_logloss: 0.12818\tvalid_1's multi_logloss: 0.28213         \n",
      "[363]\ttraining's multi_logloss: 0.127837\tvalid_1's multi_logloss: 0.282143       \n",
      "[364]\ttraining's multi_logloss: 0.127459\tvalid_1's multi_logloss: 0.282075       \n",
      "[365]\ttraining's multi_logloss: 0.127111\tvalid_1's multi_logloss: 0.282051       \n",
      "[366]\ttraining's multi_logloss: 0.126761\tvalid_1's multi_logloss: 0.282051       \n",
      "[367]\ttraining's multi_logloss: 0.12639\tvalid_1's multi_logloss: 0.282041        \n",
      "[368]\ttraining's multi_logloss: 0.12604\tvalid_1's multi_logloss: 0.282059        \n",
      "[369]\ttraining's multi_logloss: 0.125665\tvalid_1's multi_logloss: 0.282034       \n",
      "[370]\ttraining's multi_logloss: 0.125302\tvalid_1's multi_logloss: 0.282014       \n",
      "[371]\ttraining's multi_logloss: 0.124938\tvalid_1's multi_logloss: 0.281972       \n",
      "[372]\ttraining's multi_logloss: 0.124564\tvalid_1's multi_logloss: 0.281966       \n",
      "[373]\ttraining's multi_logloss: 0.124185\tvalid_1's multi_logloss: 0.281958       \n",
      "[374]\ttraining's multi_logloss: 0.123846\tvalid_1's multi_logloss: 0.281915       \n",
      "[375]\ttraining's multi_logloss: 0.123492\tvalid_1's multi_logloss: 0.281906       \n",
      "[376]\ttraining's multi_logloss: 0.123127\tvalid_1's multi_logloss: 0.281879       \n",
      "[377]\ttraining's multi_logloss: 0.122748\tvalid_1's multi_logloss: 0.281868       \n",
      "[378]\ttraining's multi_logloss: 0.122404\tvalid_1's multi_logloss: 0.281876       \n",
      "[379]\ttraining's multi_logloss: 0.12207\tvalid_1's multi_logloss: 0.281863        \n",
      "[380]\ttraining's multi_logloss: 0.121738\tvalid_1's multi_logloss: 0.281864       \n",
      "[381]\ttraining's multi_logloss: 0.121374\tvalid_1's multi_logloss: 0.281849       \n",
      "[382]\ttraining's multi_logloss: 0.121026\tvalid_1's multi_logloss: 0.281844       \n",
      "[383]\ttraining's multi_logloss: 0.120718\tvalid_1's multi_logloss: 0.281861       \n",
      "[384]\ttraining's multi_logloss: 0.120384\tvalid_1's multi_logloss: 0.281869       \n",
      "[385]\ttraining's multi_logloss: 0.120062\tvalid_1's multi_logloss: 0.28188        \n",
      "[386]\ttraining's multi_logloss: 0.119714\tvalid_1's multi_logloss: 0.281874       \n",
      "[387]\ttraining's multi_logloss: 0.119397\tvalid_1's multi_logloss: 0.281837       \n",
      "[388]\ttraining's multi_logloss: 0.11906\tvalid_1's multi_logloss: 0.281861        \n",
      "[389]\ttraining's multi_logloss: 0.118739\tvalid_1's multi_logloss: 0.281886       \n",
      "[390]\ttraining's multi_logloss: 0.118421\tvalid_1's multi_logloss: 0.281896       \n",
      "[391]\ttraining's multi_logloss: 0.118072\tvalid_1's multi_logloss: 0.281897       \n",
      "[392]\ttraining's multi_logloss: 0.117763\tvalid_1's multi_logloss: 0.281941       \n",
      "[393]\ttraining's multi_logloss: 0.117439\tvalid_1's multi_logloss: 0.281898       \n",
      "[394]\ttraining's multi_logloss: 0.117116\tvalid_1's multi_logloss: 0.281903       \n",
      "[395]\ttraining's multi_logloss: 0.116811\tvalid_1's multi_logloss: 0.28192        \n",
      "[396]\ttraining's multi_logloss: 0.116485\tvalid_1's multi_logloss: 0.281946       \n",
      "[397]\ttraining's multi_logloss: 0.116166\tvalid_1's multi_logloss: 0.281954       \n",
      "[398]\ttraining's multi_logloss: 0.115846\tvalid_1's multi_logloss: 0.281901       \n",
      "[399]\ttraining's multi_logloss: 0.11555\tvalid_1's multi_logloss: 0.281921        \n",
      "[400]\ttraining's multi_logloss: 0.115218\tvalid_1's multi_logloss: 0.281936       \n",
      "Did not meet early stopping. Best iteration is:                                  \n",
      "[400]\ttraining's multi_logloss: 0.115218\tvalid_1's multi_logloss: 0.281936\n",
      "[1]\ttraining's multi_logloss: 1.86997\tvalid_1's multi_logloss: 1.87243           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.81417\tvalid_1's multi_logloss: 1.81706           \n",
      "[3]\ttraining's multi_logloss: 1.76207\tvalid_1's multi_logloss: 1.7654            \n",
      "[4]\ttraining's multi_logloss: 1.71333\tvalid_1's multi_logloss: 1.71713           \n",
      "[5]\ttraining's multi_logloss: 1.66739\tvalid_1's multi_logloss: 1.67167           \n",
      "[6]\ttraining's multi_logloss: 1.62394\tvalid_1's multi_logloss: 1.62866           \n",
      "[7]\ttraining's multi_logloss: 1.58274\tvalid_1's multi_logloss: 1.58779           \n",
      "[8]\ttraining's multi_logloss: 1.54378\tvalid_1's multi_logloss: 1.54926           \n",
      "[9]\ttraining's multi_logloss: 1.50638\tvalid_1's multi_logloss: 1.5122            \n",
      "[10]\ttraining's multi_logloss: 1.47075\tvalid_1's multi_logloss: 1.47684          \n",
      "[11]\ttraining's multi_logloss: 1.43663\tvalid_1's multi_logloss: 1.44302          \n",
      "[12]\ttraining's multi_logloss: 1.40413\tvalid_1's multi_logloss: 1.41084          \n",
      "[13]\ttraining's multi_logloss: 1.37292\tvalid_1's multi_logloss: 1.37985          \n",
      "[14]\ttraining's multi_logloss: 1.34287\tvalid_1's multi_logloss: 1.35007          \n",
      "[15]\ttraining's multi_logloss: 1.31406\tvalid_1's multi_logloss: 1.32146          \n",
      "[16]\ttraining's multi_logloss: 1.28634\tvalid_1's multi_logloss: 1.29397          \n",
      "[17]\ttraining's multi_logloss: 1.25975\tvalid_1's multi_logloss: 1.26764          \n",
      "[18]\ttraining's multi_logloss: 1.23417\tvalid_1's multi_logloss: 1.24229          \n",
      "[19]\ttraining's multi_logloss: 1.20958\tvalid_1's multi_logloss: 1.21794          \n",
      "[20]\ttraining's multi_logloss: 1.1857\tvalid_1's multi_logloss: 1.19434           \n",
      "[21]\ttraining's multi_logloss: 1.16276\tvalid_1's multi_logloss: 1.17164          \n",
      "[22]\ttraining's multi_logloss: 1.14044\tvalid_1's multi_logloss: 1.14956          \n",
      "[23]\ttraining's multi_logloss: 1.11873\tvalid_1's multi_logloss: 1.12804          \n",
      "[24]\ttraining's multi_logloss: 1.09783\tvalid_1's multi_logloss: 1.10737          \n",
      "[25]\ttraining's multi_logloss: 1.07775\tvalid_1's multi_logloss: 1.08759          \n",
      "[26]\ttraining's multi_logloss: 1.05827\tvalid_1's multi_logloss: 1.06826          \n",
      "[27]\ttraining's multi_logloss: 1.0393\tvalid_1's multi_logloss: 1.0495            \n",
      "[28]\ttraining's multi_logloss: 1.02094\tvalid_1's multi_logloss: 1.03139          \n",
      "[29]\ttraining's multi_logloss: 1.00316\tvalid_1's multi_logloss: 1.01378          \n",
      "[30]\ttraining's multi_logloss: 0.985781\tvalid_1's multi_logloss: 0.996597        \n",
      "[31]\ttraining's multi_logloss: 0.968967\tvalid_1's multi_logloss: 0.980051        \n",
      "[32]\ttraining's multi_logloss: 0.95256\tvalid_1's multi_logloss: 0.963759         \n",
      "[33]\ttraining's multi_logloss: 0.936733\tvalid_1's multi_logloss: 0.948118        \n",
      "[34]\ttraining's multi_logloss: 0.92125\tvalid_1's multi_logloss: 0.932868         \n",
      "[35]\ttraining's multi_logloss: 0.906222\tvalid_1's multi_logloss: 0.918114        \n",
      "[36]\ttraining's multi_logloss: 0.891485\tvalid_1's multi_logloss: 0.903717        \n",
      "[37]\ttraining's multi_logloss: 0.877219\tvalid_1's multi_logloss: 0.889651        \n",
      "[38]\ttraining's multi_logloss: 0.863282\tvalid_1's multi_logloss: 0.875986        \n",
      "[39]\ttraining's multi_logloss: 0.849771\tvalid_1's multi_logloss: 0.862678        \n",
      "[40]\ttraining's multi_logloss: 0.836594\tvalid_1's multi_logloss: 0.84978         \n",
      "[41]\ttraining's multi_logloss: 0.823793\tvalid_1's multi_logloss: 0.837202        \n",
      "[42]\ttraining's multi_logloss: 0.811261\tvalid_1's multi_logloss: 0.824898        \n",
      "[43]\ttraining's multi_logloss: 0.799074\tvalid_1's multi_logloss: 0.812961        \n",
      "[44]\ttraining's multi_logloss: 0.787211\tvalid_1's multi_logloss: 0.80137         \n",
      "[45]\ttraining's multi_logloss: 0.775596\tvalid_1's multi_logloss: 0.790093        \n",
      "[46]\ttraining's multi_logloss: 0.764372\tvalid_1's multi_logloss: 0.779097        \n",
      "[47]\ttraining's multi_logloss: 0.753473\tvalid_1's multi_logloss: 0.768473        \n",
      "[48]\ttraining's multi_logloss: 0.742837\tvalid_1's multi_logloss: 0.758112        \n",
      "[49]\ttraining's multi_logloss: 0.732359\tvalid_1's multi_logloss: 0.747896        \n",
      "[50]\ttraining's multi_logloss: 0.722075\tvalid_1's multi_logloss: 0.73787         \n",
      "[51]\ttraining's multi_logloss: 0.71217\tvalid_1's multi_logloss: 0.728184         \n",
      "[52]\ttraining's multi_logloss: 0.702538\tvalid_1's multi_logloss: 0.718875        \n",
      "[53]\ttraining's multi_logloss: 0.692894\tvalid_1's multi_logloss: 0.709514        \n",
      "[54]\ttraining's multi_logloss: 0.683605\tvalid_1's multi_logloss: 0.700543        \n",
      "[55]\ttraining's multi_logloss: 0.674549\tvalid_1's multi_logloss: 0.691785        \n",
      "[56]\ttraining's multi_logloss: 0.665685\tvalid_1's multi_logloss: 0.683249        \n",
      "[57]\ttraining's multi_logloss: 0.656993\tvalid_1's multi_logloss: 0.674802        \n",
      "[58]\ttraining's multi_logloss: 0.648541\tvalid_1's multi_logloss: 0.666599        \n",
      "[59]\ttraining's multi_logloss: 0.640236\tvalid_1's multi_logloss: 0.658554        \n",
      "[60]\ttraining's multi_logloss: 0.632142\tvalid_1's multi_logloss: 0.650745        \n",
      "[61]\ttraining's multi_logloss: 0.624223\tvalid_1's multi_logloss: 0.643129        \n",
      "[62]\ttraining's multi_logloss: 0.616511\tvalid_1's multi_logloss: 0.635825        \n",
      "[63]\ttraining's multi_logloss: 0.608907\tvalid_1's multi_logloss: 0.628512        \n",
      "[64]\ttraining's multi_logloss: 0.601549\tvalid_1's multi_logloss: 0.621448        \n",
      "[65]\ttraining's multi_logloss: 0.594299\tvalid_1's multi_logloss: 0.614516        \n",
      "[66]\ttraining's multi_logloss: 0.587299\tvalid_1's multi_logloss: 0.6079          \n",
      "[67]\ttraining's multi_logloss: 0.580333\tvalid_1's multi_logloss: 0.601226        \n",
      "[68]\ttraining's multi_logloss: 0.573595\tvalid_1's multi_logloss: 0.594886        \n",
      "[69]\ttraining's multi_logloss: 0.567053\tvalid_1's multi_logloss: 0.588741        \n",
      "[70]\ttraining's multi_logloss: 0.560565\tvalid_1's multi_logloss: 0.582552        \n",
      "[71]\ttraining's multi_logloss: 0.554305\tvalid_1's multi_logloss: 0.576625        \n",
      "[72]\ttraining's multi_logloss: 0.548101\tvalid_1's multi_logloss: 0.570761        \n",
      "[73]\ttraining's multi_logloss: 0.542074\tvalid_1's multi_logloss: 0.565114        \n",
      "[74]\ttraining's multi_logloss: 0.53615\tvalid_1's multi_logloss: 0.559543         \n",
      "[75]\ttraining's multi_logloss: 0.53032\tvalid_1's multi_logloss: 0.554059         \n",
      "[76]\ttraining's multi_logloss: 0.524633\tvalid_1's multi_logloss: 0.548694        \n",
      "[77]\ttraining's multi_logloss: 0.519078\tvalid_1's multi_logloss: 0.543548        \n",
      "[78]\ttraining's multi_logloss: 0.513651\tvalid_1's multi_logloss: 0.538437        \n",
      "[79]\ttraining's multi_logloss: 0.508297\tvalid_1's multi_logloss: 0.533396        \n",
      "[80]\ttraining's multi_logloss: 0.502964\tvalid_1's multi_logloss: 0.528372        \n",
      "[81]\ttraining's multi_logloss: 0.497828\tvalid_1's multi_logloss: 0.523604        \n",
      "[82]\ttraining's multi_logloss: 0.492688\tvalid_1's multi_logloss: 0.518804        \n",
      "[83]\ttraining's multi_logloss: 0.487679\tvalid_1's multi_logloss: 0.51409         \n",
      "[84]\ttraining's multi_logloss: 0.48282\tvalid_1's multi_logloss: 0.50959          \n",
      "[85]\ttraining's multi_logloss: 0.478083\tvalid_1's multi_logloss: 0.505148        \n",
      "[86]\ttraining's multi_logloss: 0.473382\tvalid_1's multi_logloss: 0.500786        \n",
      "[87]\ttraining's multi_logloss: 0.468817\tvalid_1's multi_logloss: 0.496558        \n",
      "[88]\ttraining's multi_logloss: 0.464367\tvalid_1's multi_logloss: 0.49243         \n",
      "[89]\ttraining's multi_logloss: 0.459962\tvalid_1's multi_logloss: 0.4883          \n",
      "[90]\ttraining's multi_logloss: 0.455653\tvalid_1's multi_logloss: 0.484301        \n",
      "[91]\ttraining's multi_logloss: 0.451454\tvalid_1's multi_logloss: 0.480385        \n",
      "[92]\ttraining's multi_logloss: 0.447323\tvalid_1's multi_logloss: 0.476587        \n",
      "[93]\ttraining's multi_logloss: 0.443223\tvalid_1's multi_logloss: 0.472813        \n",
      "[94]\ttraining's multi_logloss: 0.43921\tvalid_1's multi_logloss: 0.469124         \n",
      "[95]\ttraining's multi_logloss: 0.435257\tvalid_1's multi_logloss: 0.465483        \n",
      "[96]\ttraining's multi_logloss: 0.431386\tvalid_1's multi_logloss: 0.461875        \n",
      "[97]\ttraining's multi_logloss: 0.427625\tvalid_1's multi_logloss: 0.458448        \n",
      "[98]\ttraining's multi_logloss: 0.423896\tvalid_1's multi_logloss: 0.455041        \n",
      "[99]\ttraining's multi_logloss: 0.420174\tvalid_1's multi_logloss: 0.451638        \n",
      "[100]\ttraining's multi_logloss: 0.41653\tvalid_1's multi_logloss: 0.448313        \n",
      "[101]\ttraining's multi_logloss: 0.413025\tvalid_1's multi_logloss: 0.445121       \n",
      "[102]\ttraining's multi_logloss: 0.409509\tvalid_1's multi_logloss: 0.441908       \n",
      "[103]\ttraining's multi_logloss: 0.406058\tvalid_1's multi_logloss: 0.438736       \n",
      "[104]\ttraining's multi_logloss: 0.402668\tvalid_1's multi_logloss: 0.435642       \n",
      "[105]\ttraining's multi_logloss: 0.399286\tvalid_1's multi_logloss: 0.432546       \n",
      "[106]\ttraining's multi_logloss: 0.395991\tvalid_1's multi_logloss: 0.42959        \n",
      "[107]\ttraining's multi_logloss: 0.392671\tvalid_1's multi_logloss: 0.42659        \n",
      "[108]\ttraining's multi_logloss: 0.389551\tvalid_1's multi_logloss: 0.423756       \n",
      "[109]\ttraining's multi_logloss: 0.386477\tvalid_1's multi_logloss: 0.421008       \n",
      "[110]\ttraining's multi_logloss: 0.383263\tvalid_1's multi_logloss: 0.418033       \n",
      "[111]\ttraining's multi_logloss: 0.380302\tvalid_1's multi_logloss: 0.415423       \n",
      "[112]\ttraining's multi_logloss: 0.377244\tvalid_1's multi_logloss: 0.412648       \n",
      "[113]\ttraining's multi_logloss: 0.374386\tvalid_1's multi_logloss: 0.410115       \n",
      "[114]\ttraining's multi_logloss: 0.371573\tvalid_1's multi_logloss: 0.407662       \n",
      "[115]\ttraining's multi_logloss: 0.368731\tvalid_1's multi_logloss: 0.405153       \n",
      "[116]\ttraining's multi_logloss: 0.365892\tvalid_1's multi_logloss: 0.402575       \n",
      "[117]\ttraining's multi_logloss: 0.363081\tvalid_1's multi_logloss: 0.400137       \n",
      "[118]\ttraining's multi_logloss: 0.360388\tvalid_1's multi_logloss: 0.397752       \n",
      "[119]\ttraining's multi_logloss: 0.357733\tvalid_1's multi_logloss: 0.395496       \n",
      "[120]\ttraining's multi_logloss: 0.355105\tvalid_1's multi_logloss: 0.393226       \n",
      "[121]\ttraining's multi_logloss: 0.352572\tvalid_1's multi_logloss: 0.39102        \n",
      "[122]\ttraining's multi_logloss: 0.350059\tvalid_1's multi_logloss: 0.388827       \n",
      "[123]\ttraining's multi_logloss: 0.347612\tvalid_1's multi_logloss: 0.386681       \n",
      "[124]\ttraining's multi_logloss: 0.345154\tvalid_1's multi_logloss: 0.384546       \n",
      "[125]\ttraining's multi_logloss: 0.342743\tvalid_1's multi_logloss: 0.382396       \n",
      "[126]\ttraining's multi_logloss: 0.340394\tvalid_1's multi_logloss: 0.380302       \n",
      "[127]\ttraining's multi_logloss: 0.338112\tvalid_1's multi_logloss: 0.378342       \n",
      "[128]\ttraining's multi_logloss: 0.335843\tvalid_1's multi_logloss: 0.376356       \n",
      "[129]\ttraining's multi_logloss: 0.333616\tvalid_1's multi_logloss: 0.37442        \n",
      "[130]\ttraining's multi_logloss: 0.331394\tvalid_1's multi_logloss: 0.372504       \n",
      "[131]\ttraining's multi_logloss: 0.329228\tvalid_1's multi_logloss: 0.370634       \n",
      "[132]\ttraining's multi_logloss: 0.327108\tvalid_1's multi_logloss: 0.368862       \n",
      "[133]\ttraining's multi_logloss: 0.325028\tvalid_1's multi_logloss: 0.367121       \n",
      "[134]\ttraining's multi_logloss: 0.322941\tvalid_1's multi_logloss: 0.365396       \n",
      "[135]\ttraining's multi_logloss: 0.320876\tvalid_1's multi_logloss: 0.363688       \n",
      "[136]\ttraining's multi_logloss: 0.318842\tvalid_1's multi_logloss: 0.362001       \n",
      "[137]\ttraining's multi_logloss: 0.316867\tvalid_1's multi_logloss: 0.360419       \n",
      "[138]\ttraining's multi_logloss: 0.314929\tvalid_1's multi_logloss: 0.358814       \n",
      "[139]\ttraining's multi_logloss: 0.312977\tvalid_1's multi_logloss: 0.357263       \n",
      "[140]\ttraining's multi_logloss: 0.311015\tvalid_1's multi_logloss: 0.355609       \n",
      "[141]\ttraining's multi_logloss: 0.309104\tvalid_1's multi_logloss: 0.353981       \n",
      "[142]\ttraining's multi_logloss: 0.307206\tvalid_1's multi_logloss: 0.352479       \n",
      "[143]\ttraining's multi_logloss: 0.305346\tvalid_1's multi_logloss: 0.351          \n",
      "[144]\ttraining's multi_logloss: 0.303525\tvalid_1's multi_logloss: 0.349562       \n",
      "[145]\ttraining's multi_logloss: 0.301758\tvalid_1's multi_logloss: 0.348156       \n",
      "[146]\ttraining's multi_logloss: 0.300015\tvalid_1's multi_logloss: 0.346722       \n",
      "[147]\ttraining's multi_logloss: 0.298272\tvalid_1's multi_logloss: 0.345425       \n",
      "[148]\ttraining's multi_logloss: 0.296546\tvalid_1's multi_logloss: 0.344091       \n",
      "[149]\ttraining's multi_logloss: 0.29488\tvalid_1's multi_logloss: 0.342832        \n",
      "[150]\ttraining's multi_logloss: 0.293229\tvalid_1's multi_logloss: 0.341578       \n",
      "[151]\ttraining's multi_logloss: 0.291518\tvalid_1's multi_logloss: 0.340301       \n",
      "[152]\ttraining's multi_logloss: 0.289937\tvalid_1's multi_logloss: 0.339039       \n",
      "[153]\ttraining's multi_logloss: 0.288264\tvalid_1's multi_logloss: 0.337809       \n",
      "[154]\ttraining's multi_logloss: 0.286708\tvalid_1's multi_logloss: 0.336611       \n",
      "[155]\ttraining's multi_logloss: 0.285164\tvalid_1's multi_logloss: 0.335468       \n",
      "[156]\ttraining's multi_logloss: 0.283607\tvalid_1's multi_logloss: 0.334279       \n",
      "[157]\ttraining's multi_logloss: 0.282096\tvalid_1's multi_logloss: 0.333112       \n",
      "[158]\ttraining's multi_logloss: 0.280626\tvalid_1's multi_logloss: 0.332041       \n",
      "[159]\ttraining's multi_logloss: 0.27915\tvalid_1's multi_logloss: 0.33094         \n",
      "[160]\ttraining's multi_logloss: 0.277674\tvalid_1's multi_logloss: 0.329894       \n",
      "[161]\ttraining's multi_logloss: 0.276229\tvalid_1's multi_logloss: 0.328809       \n",
      "[162]\ttraining's multi_logloss: 0.274832\tvalid_1's multi_logloss: 0.327817       \n",
      "[163]\ttraining's multi_logloss: 0.273414\tvalid_1's multi_logloss: 0.326819       \n",
      "[164]\ttraining's multi_logloss: 0.272005\tvalid_1's multi_logloss: 0.325806       \n",
      "[165]\ttraining's multi_logloss: 0.270606\tvalid_1's multi_logloss: 0.324795       \n",
      "[166]\ttraining's multi_logloss: 0.269268\tvalid_1's multi_logloss: 0.323887       \n",
      "[167]\ttraining's multi_logloss: 0.267884\tvalid_1's multi_logloss: 0.32292        \n",
      "[168]\ttraining's multi_logloss: 0.266597\tvalid_1's multi_logloss: 0.321989       \n",
      "[169]\ttraining's multi_logloss: 0.265289\tvalid_1's multi_logloss: 0.321104       \n",
      "[170]\ttraining's multi_logloss: 0.263993\tvalid_1's multi_logloss: 0.320166       \n",
      "[171]\ttraining's multi_logloss: 0.262682\tvalid_1's multi_logloss: 0.319317       \n",
      "[172]\ttraining's multi_logloss: 0.261466\tvalid_1's multi_logloss: 0.318515       \n",
      "[173]\ttraining's multi_logloss: 0.260232\tvalid_1's multi_logloss: 0.317768       \n",
      "[174]\ttraining's multi_logloss: 0.259007\tvalid_1's multi_logloss: 0.317006       \n",
      "[175]\ttraining's multi_logloss: 0.257806\tvalid_1's multi_logloss: 0.316247       \n",
      "[176]\ttraining's multi_logloss: 0.256597\tvalid_1's multi_logloss: 0.315503       \n",
      "[177]\ttraining's multi_logloss: 0.255443\tvalid_1's multi_logloss: 0.314802       \n",
      "[178]\ttraining's multi_logloss: 0.254288\tvalid_1's multi_logloss: 0.314101       \n",
      "[179]\ttraining's multi_logloss: 0.253132\tvalid_1's multi_logloss: 0.313382       \n",
      "[180]\ttraining's multi_logloss: 0.251977\tvalid_1's multi_logloss: 0.3126         \n",
      "[181]\ttraining's multi_logloss: 0.250842\tvalid_1's multi_logloss: 0.311918       \n",
      "[182]\ttraining's multi_logloss: 0.249681\tvalid_1's multi_logloss: 0.311094       \n",
      "[183]\ttraining's multi_logloss: 0.248535\tvalid_1's multi_logloss: 0.310357       \n",
      "[184]\ttraining's multi_logloss: 0.247421\tvalid_1's multi_logloss: 0.309603       \n",
      "[185]\ttraining's multi_logloss: 0.246297\tvalid_1's multi_logloss: 0.308904       \n",
      "[186]\ttraining's multi_logloss: 0.245224\tvalid_1's multi_logloss: 0.308235       \n",
      "[187]\ttraining's multi_logloss: 0.244154\tvalid_1's multi_logloss: 0.307541       \n",
      "[188]\ttraining's multi_logloss: 0.243092\tvalid_1's multi_logloss: 0.306902       \n",
      "[189]\ttraining's multi_logloss: 0.242015\tvalid_1's multi_logloss: 0.306258       \n",
      "[190]\ttraining's multi_logloss: 0.240952\tvalid_1's multi_logloss: 0.305622       \n",
      "[191]\ttraining's multi_logloss: 0.239853\tvalid_1's multi_logloss: 0.304939       \n",
      "[192]\ttraining's multi_logloss: 0.238839\tvalid_1's multi_logloss: 0.304315       \n",
      "[193]\ttraining's multi_logloss: 0.2378\tvalid_1's multi_logloss: 0.303701         \n",
      "[194]\ttraining's multi_logloss: 0.236773\tvalid_1's multi_logloss: 0.303069       \n",
      "[195]\ttraining's multi_logloss: 0.235727\tvalid_1's multi_logloss: 0.302419       \n",
      "[196]\ttraining's multi_logloss: 0.234731\tvalid_1's multi_logloss: 0.30181        \n",
      "[197]\ttraining's multi_logloss: 0.233723\tvalid_1's multi_logloss: 0.301239       \n",
      "[198]\ttraining's multi_logloss: 0.232764\tvalid_1's multi_logloss: 0.30071        \n",
      "[199]\ttraining's multi_logloss: 0.231821\tvalid_1's multi_logloss: 0.300099       \n",
      "[200]\ttraining's multi_logloss: 0.230904\tvalid_1's multi_logloss: 0.29962        \n",
      "[201]\ttraining's multi_logloss: 0.229944\tvalid_1's multi_logloss: 0.2991         \n",
      "[202]\ttraining's multi_logloss: 0.229043\tvalid_1's multi_logloss: 0.2986         \n",
      "[203]\ttraining's multi_logloss: 0.228099\tvalid_1's multi_logloss: 0.298092       \n",
      "[204]\ttraining's multi_logloss: 0.227177\tvalid_1's multi_logloss: 0.297614       \n",
      "[205]\ttraining's multi_logloss: 0.226258\tvalid_1's multi_logloss: 0.297092       \n",
      "[206]\ttraining's multi_logloss: 0.225361\tvalid_1's multi_logloss: 0.296622       \n",
      "[207]\ttraining's multi_logloss: 0.22447\tvalid_1's multi_logloss: 0.296156        \n",
      "[208]\ttraining's multi_logloss: 0.223591\tvalid_1's multi_logloss: 0.295691       \n",
      "[209]\ttraining's multi_logloss: 0.222701\tvalid_1's multi_logloss: 0.295235       \n",
      "[210]\ttraining's multi_logloss: 0.221781\tvalid_1's multi_logloss: 0.294766       \n",
      "[211]\ttraining's multi_logloss: 0.220932\tvalid_1's multi_logloss: 0.29437        \n",
      "[212]\ttraining's multi_logloss: 0.220062\tvalid_1's multi_logloss: 0.293887       \n",
      "[213]\ttraining's multi_logloss: 0.219219\tvalid_1's multi_logloss: 0.293535       \n",
      "[214]\ttraining's multi_logloss: 0.218334\tvalid_1's multi_logloss: 0.293127       \n",
      "[215]\ttraining's multi_logloss: 0.217468\tvalid_1's multi_logloss: 0.29274        \n",
      "[216]\ttraining's multi_logloss: 0.21661\tvalid_1's multi_logloss: 0.292308        \n",
      "[217]\ttraining's multi_logloss: 0.21578\tvalid_1's multi_logloss: 0.291828        \n",
      "[218]\ttraining's multi_logloss: 0.214961\tvalid_1's multi_logloss: 0.291457       \n",
      "[219]\ttraining's multi_logloss: 0.214162\tvalid_1's multi_logloss: 0.291123       \n",
      "[220]\ttraining's multi_logloss: 0.213318\tvalid_1's multi_logloss: 0.290643       \n",
      "[221]\ttraining's multi_logloss: 0.21253\tvalid_1's multi_logloss: 0.290263        \n",
      "[222]\ttraining's multi_logloss: 0.21173\tvalid_1's multi_logloss: 0.289888        \n",
      "[223]\ttraining's multi_logloss: 0.210925\tvalid_1's multi_logloss: 0.28946        \n",
      "[224]\ttraining's multi_logloss: 0.210176\tvalid_1's multi_logloss: 0.289082       \n",
      "[225]\ttraining's multi_logloss: 0.209367\tvalid_1's multi_logloss: 0.288619       \n",
      "[226]\ttraining's multi_logloss: 0.208608\tvalid_1's multi_logloss: 0.288245       \n",
      "[227]\ttraining's multi_logloss: 0.207826\tvalid_1's multi_logloss: 0.287908       \n",
      "[228]\ttraining's multi_logloss: 0.207057\tvalid_1's multi_logloss: 0.287582       \n",
      "[229]\ttraining's multi_logloss: 0.206291\tvalid_1's multi_logloss: 0.287217       \n",
      "[230]\ttraining's multi_logloss: 0.205554\tvalid_1's multi_logloss: 0.286922       \n",
      "[231]\ttraining's multi_logloss: 0.204788\tvalid_1's multi_logloss: 0.286472       \n",
      "[232]\ttraining's multi_logloss: 0.204031\tvalid_1's multi_logloss: 0.286121       \n",
      "[233]\ttraining's multi_logloss: 0.203304\tvalid_1's multi_logloss: 0.285834       \n",
      "[234]\ttraining's multi_logloss: 0.202577\tvalid_1's multi_logloss: 0.285589       \n",
      "[235]\ttraining's multi_logloss: 0.201861\tvalid_1's multi_logloss: 0.285285       \n",
      "[236]\ttraining's multi_logloss: 0.201156\tvalid_1's multi_logloss: 0.28499        \n",
      "[237]\ttraining's multi_logloss: 0.200412\tvalid_1's multi_logloss: 0.284671       \n",
      "[238]\ttraining's multi_logloss: 0.199728\tvalid_1's multi_logloss: 0.284349       \n",
      "[239]\ttraining's multi_logloss: 0.199018\tvalid_1's multi_logloss: 0.284121       \n",
      "[240]\ttraining's multi_logloss: 0.198308\tvalid_1's multi_logloss: 0.283817       \n",
      "[241]\ttraining's multi_logloss: 0.197616\tvalid_1's multi_logloss: 0.283526       \n",
      "[242]\ttraining's multi_logloss: 0.196933\tvalid_1's multi_logloss: 0.283235       \n",
      "[243]\ttraining's multi_logloss: 0.196235\tvalid_1's multi_logloss: 0.282857       \n",
      "[244]\ttraining's multi_logloss: 0.195594\tvalid_1's multi_logloss: 0.282612       \n",
      "[245]\ttraining's multi_logloss: 0.194902\tvalid_1's multi_logloss: 0.282341       \n",
      "[246]\ttraining's multi_logloss: 0.194228\tvalid_1's multi_logloss: 0.282071       \n",
      "[247]\ttraining's multi_logloss: 0.193567\tvalid_1's multi_logloss: 0.281837       \n",
      "[248]\ttraining's multi_logloss: 0.19288\tvalid_1's multi_logloss: 0.281593        \n",
      "[249]\ttraining's multi_logloss: 0.192178\tvalid_1's multi_logloss: 0.281304       \n",
      "[250]\ttraining's multi_logloss: 0.191461\tvalid_1's multi_logloss: 0.281047       \n",
      "[251]\ttraining's multi_logloss: 0.190809\tvalid_1's multi_logloss: 0.280847       \n",
      "[252]\ttraining's multi_logloss: 0.190105\tvalid_1's multi_logloss: 0.280585       \n",
      "[253]\ttraining's multi_logloss: 0.189429\tvalid_1's multi_logloss: 0.280399       \n",
      "[254]\ttraining's multi_logloss: 0.188735\tvalid_1's multi_logloss: 0.280214       \n",
      "[255]\ttraining's multi_logloss: 0.188081\tvalid_1's multi_logloss: 0.280013       \n",
      "[256]\ttraining's multi_logloss: 0.187441\tvalid_1's multi_logloss: 0.279813       \n",
      "[257]\ttraining's multi_logloss: 0.186796\tvalid_1's multi_logloss: 0.279647       \n",
      "[258]\ttraining's multi_logloss: 0.186157\tvalid_1's multi_logloss: 0.279453       \n",
      "[259]\ttraining's multi_logloss: 0.185531\tvalid_1's multi_logloss: 0.279252       \n",
      "[260]\ttraining's multi_logloss: 0.184917\tvalid_1's multi_logloss: 0.279047       \n",
      "[261]\ttraining's multi_logloss: 0.184274\tvalid_1's multi_logloss: 0.278898       \n",
      "[262]\ttraining's multi_logloss: 0.183602\tvalid_1's multi_logloss: 0.278673       \n",
      "[263]\ttraining's multi_logloss: 0.182969\tvalid_1's multi_logloss: 0.278512       \n",
      "[264]\ttraining's multi_logloss: 0.18232\tvalid_1's multi_logloss: 0.278359        \n",
      "[265]\ttraining's multi_logloss: 0.181701\tvalid_1's multi_logloss: 0.278179       \n",
      "[266]\ttraining's multi_logloss: 0.181078\tvalid_1's multi_logloss: 0.278009       \n",
      "[267]\ttraining's multi_logloss: 0.180471\tvalid_1's multi_logloss: 0.27784        \n",
      "[268]\ttraining's multi_logloss: 0.179847\tvalid_1's multi_logloss: 0.277699       \n",
      "[269]\ttraining's multi_logloss: 0.179253\tvalid_1's multi_logloss: 0.277494       \n",
      "[270]\ttraining's multi_logloss: 0.178662\tvalid_1's multi_logloss: 0.27731        \n",
      "[271]\ttraining's multi_logloss: 0.178048\tvalid_1's multi_logloss: 0.277171       \n",
      "[272]\ttraining's multi_logloss: 0.177466\tvalid_1's multi_logloss: 0.277033       \n",
      "[273]\ttraining's multi_logloss: 0.176888\tvalid_1's multi_logloss: 0.276841       \n",
      "[274]\ttraining's multi_logloss: 0.176294\tvalid_1's multi_logloss: 0.276687       \n",
      "[275]\ttraining's multi_logloss: 0.175694\tvalid_1's multi_logloss: 0.276597       \n",
      "[276]\ttraining's multi_logloss: 0.175095\tvalid_1's multi_logloss: 0.276439       \n",
      "[277]\ttraining's multi_logloss: 0.174532\tvalid_1's multi_logloss: 0.276282       \n",
      "[278]\ttraining's multi_logloss: 0.173935\tvalid_1's multi_logloss: 0.276106       \n",
      "[279]\ttraining's multi_logloss: 0.173361\tvalid_1's multi_logloss: 0.27595        \n",
      "[280]\ttraining's multi_logloss: 0.172798\tvalid_1's multi_logloss: 0.275806       \n",
      "[281]\ttraining's multi_logloss: 0.172235\tvalid_1's multi_logloss: 0.275685       \n",
      "[282]\ttraining's multi_logloss: 0.171667\tvalid_1's multi_logloss: 0.275534       \n",
      "[283]\ttraining's multi_logloss: 0.171108\tvalid_1's multi_logloss: 0.27544        \n",
      "[284]\ttraining's multi_logloss: 0.170548\tvalid_1's multi_logloss: 0.275267       \n",
      "[285]\ttraining's multi_logloss: 0.169991\tvalid_1's multi_logloss: 0.275147       \n",
      "[286]\ttraining's multi_logloss: 0.169451\tvalid_1's multi_logloss: 0.275003       \n",
      "[287]\ttraining's multi_logloss: 0.1689\tvalid_1's multi_logloss: 0.274867         \n",
      "[288]\ttraining's multi_logloss: 0.168374\tvalid_1's multi_logloss: 0.274764       \n",
      "[289]\ttraining's multi_logloss: 0.167862\tvalid_1's multi_logloss: 0.274598       \n",
      "[290]\ttraining's multi_logloss: 0.167322\tvalid_1's multi_logloss: 0.274561       \n",
      "[291]\ttraining's multi_logloss: 0.166771\tvalid_1's multi_logloss: 0.274412       \n",
      "[292]\ttraining's multi_logloss: 0.166221\tvalid_1's multi_logloss: 0.274227       \n",
      "[293]\ttraining's multi_logloss: 0.16573\tvalid_1's multi_logloss: 0.274127        \n",
      "[294]\ttraining's multi_logloss: 0.165185\tvalid_1's multi_logloss: 0.274001       \n",
      "[295]\ttraining's multi_logloss: 0.164645\tvalid_1's multi_logloss: 0.273886       \n",
      "[296]\ttraining's multi_logloss: 0.164109\tvalid_1's multi_logloss: 0.273801       \n",
      "[297]\ttraining's multi_logloss: 0.163592\tvalid_1's multi_logloss: 0.273674       \n",
      "[298]\ttraining's multi_logloss: 0.163049\tvalid_1's multi_logloss: 0.273636       \n",
      "[299]\ttraining's multi_logloss: 0.162519\tvalid_1's multi_logloss: 0.273537       \n",
      "[300]\ttraining's multi_logloss: 0.161989\tvalid_1's multi_logloss: 0.273422       \n",
      "[301]\ttraining's multi_logloss: 0.161453\tvalid_1's multi_logloss: 0.273278       \n",
      "[302]\ttraining's multi_logloss: 0.160937\tvalid_1's multi_logloss: 0.273149       \n",
      "[303]\ttraining's multi_logloss: 0.160428\tvalid_1's multi_logloss: 0.2731         \n",
      "[304]\ttraining's multi_logloss: 0.15993\tvalid_1's multi_logloss: 0.273002        \n",
      "[305]\ttraining's multi_logloss: 0.159412\tvalid_1's multi_logloss: 0.272881       \n",
      "[306]\ttraining's multi_logloss: 0.158918\tvalid_1's multi_logloss: 0.272794       \n",
      "[307]\ttraining's multi_logloss: 0.158415\tvalid_1's multi_logloss: 0.272655       \n",
      "[308]\ttraining's multi_logloss: 0.157918\tvalid_1's multi_logloss: 0.272582       \n",
      "[309]\ttraining's multi_logloss: 0.157413\tvalid_1's multi_logloss: 0.272425       \n",
      "[310]\ttraining's multi_logloss: 0.156916\tvalid_1's multi_logloss: 0.272365       \n",
      "[311]\ttraining's multi_logloss: 0.156433\tvalid_1's multi_logloss: 0.272332       \n",
      "[312]\ttraining's multi_logloss: 0.155951\tvalid_1's multi_logloss: 0.272276       \n",
      "[313]\ttraining's multi_logloss: 0.155485\tvalid_1's multi_logloss: 0.272206       \n",
      "[314]\ttraining's multi_logloss: 0.154991\tvalid_1's multi_logloss: 0.272057       \n",
      "[315]\ttraining's multi_logloss: 0.15453\tvalid_1's multi_logloss: 0.271969        \n",
      "[316]\ttraining's multi_logloss: 0.154062\tvalid_1's multi_logloss: 0.271911       \n",
      "[317]\ttraining's multi_logloss: 0.153582\tvalid_1's multi_logloss: 0.271837       \n",
      "[318]\ttraining's multi_logloss: 0.153114\tvalid_1's multi_logloss: 0.2718         \n",
      "[319]\ttraining's multi_logloss: 0.152658\tvalid_1's multi_logloss: 0.271782       \n",
      "[320]\ttraining's multi_logloss: 0.1522\tvalid_1's multi_logloss: 0.271715         \n",
      "[321]\ttraining's multi_logloss: 0.15175\tvalid_1's multi_logloss: 0.271661        \n",
      "[322]\ttraining's multi_logloss: 0.151254\tvalid_1's multi_logloss: 0.271558       \n",
      "[323]\ttraining's multi_logloss: 0.150793\tvalid_1's multi_logloss: 0.271453       \n",
      "[324]\ttraining's multi_logloss: 0.150285\tvalid_1's multi_logloss: 0.27143        \n",
      "[325]\ttraining's multi_logloss: 0.149825\tvalid_1's multi_logloss: 0.271382       \n",
      "[326]\ttraining's multi_logloss: 0.149341\tvalid_1's multi_logloss: 0.271299       \n",
      "[327]\ttraining's multi_logloss: 0.14887\tvalid_1's multi_logloss: 0.271248        \n",
      "[328]\ttraining's multi_logloss: 0.148381\tvalid_1's multi_logloss: 0.271174       \n",
      "[329]\ttraining's multi_logloss: 0.147916\tvalid_1's multi_logloss: 0.271092       \n",
      "[330]\ttraining's multi_logloss: 0.147449\tvalid_1's multi_logloss: 0.271021       \n",
      "[331]\ttraining's multi_logloss: 0.146985\tvalid_1's multi_logloss: 0.270927       \n",
      "[332]\ttraining's multi_logloss: 0.146542\tvalid_1's multi_logloss: 0.270839       \n",
      "[333]\ttraining's multi_logloss: 0.146109\tvalid_1's multi_logloss: 0.27081        \n",
      "[334]\ttraining's multi_logloss: 0.145659\tvalid_1's multi_logloss: 0.270706       \n",
      "[335]\ttraining's multi_logloss: 0.145217\tvalid_1's multi_logloss: 0.270645       \n",
      "[336]\ttraining's multi_logloss: 0.144793\tvalid_1's multi_logloss: 0.270617       \n",
      "[337]\ttraining's multi_logloss: 0.144353\tvalid_1's multi_logloss: 0.270503       \n",
      "[338]\ttraining's multi_logloss: 0.143919\tvalid_1's multi_logloss: 0.270388       \n",
      "[339]\ttraining's multi_logloss: 0.143502\tvalid_1's multi_logloss: 0.270339       \n",
      "[340]\ttraining's multi_logloss: 0.143092\tvalid_1's multi_logloss: 0.270228       \n",
      "[341]\ttraining's multi_logloss: 0.142654\tvalid_1's multi_logloss: 0.270175       \n",
      "[342]\ttraining's multi_logloss: 0.14223\tvalid_1's multi_logloss: 0.270096        \n",
      "[343]\ttraining's multi_logloss: 0.141813\tvalid_1's multi_logloss: 0.269991       \n",
      "[344]\ttraining's multi_logloss: 0.141399\tvalid_1's multi_logloss: 0.269885       \n",
      "[345]\ttraining's multi_logloss: 0.140998\tvalid_1's multi_logloss: 0.269811       \n",
      "[346]\ttraining's multi_logloss: 0.14058\tvalid_1's multi_logloss: 0.269761        \n",
      "[347]\ttraining's multi_logloss: 0.140189\tvalid_1's multi_logloss: 0.269698       \n",
      "[348]\ttraining's multi_logloss: 0.13977\tvalid_1's multi_logloss: 0.269608        \n",
      "[349]\ttraining's multi_logloss: 0.139338\tvalid_1's multi_logloss: 0.269528       \n",
      "[350]\ttraining's multi_logloss: 0.138925\tvalid_1's multi_logloss: 0.269481       \n",
      "[351]\ttraining's multi_logloss: 0.138526\tvalid_1's multi_logloss: 0.269445       \n",
      "[352]\ttraining's multi_logloss: 0.13812\tvalid_1's multi_logloss: 0.269362        \n",
      "[353]\ttraining's multi_logloss: 0.137692\tvalid_1's multi_logloss: 0.269315       \n",
      "[354]\ttraining's multi_logloss: 0.137286\tvalid_1's multi_logloss: 0.269287       \n",
      "[355]\ttraining's multi_logloss: 0.13686\tvalid_1's multi_logloss: 0.269214        \n",
      "[356]\ttraining's multi_logloss: 0.13646\tvalid_1's multi_logloss: 0.269212        \n",
      "[357]\ttraining's multi_logloss: 0.136054\tvalid_1's multi_logloss: 0.269179       \n",
      "[358]\ttraining's multi_logloss: 0.135641\tvalid_1's multi_logloss: 0.269179       \n",
      "[359]\ttraining's multi_logloss: 0.135277\tvalid_1's multi_logloss: 0.269101       \n",
      "[360]\ttraining's multi_logloss: 0.134863\tvalid_1's multi_logloss: 0.269057       \n",
      "[361]\ttraining's multi_logloss: 0.13448\tvalid_1's multi_logloss: 0.269004        \n",
      "[362]\ttraining's multi_logloss: 0.134092\tvalid_1's multi_logloss: 0.26899        \n",
      "[363]\ttraining's multi_logloss: 0.133708\tvalid_1's multi_logloss: 0.268934       \n",
      "[364]\ttraining's multi_logloss: 0.133299\tvalid_1's multi_logloss: 0.268903       \n",
      "[365]\ttraining's multi_logloss: 0.132922\tvalid_1's multi_logloss: 0.268825       \n",
      "[366]\ttraining's multi_logloss: 0.132543\tvalid_1's multi_logloss: 0.268797       \n",
      "[367]\ttraining's multi_logloss: 0.132172\tvalid_1's multi_logloss: 0.268755       \n",
      "[368]\ttraining's multi_logloss: 0.131818\tvalid_1's multi_logloss: 0.268737       \n",
      "[369]\ttraining's multi_logloss: 0.131436\tvalid_1's multi_logloss: 0.268691       \n",
      "[370]\ttraining's multi_logloss: 0.131076\tvalid_1's multi_logloss: 0.268674       \n",
      "[371]\ttraining's multi_logloss: 0.130697\tvalid_1's multi_logloss: 0.268689       \n",
      "[372]\ttraining's multi_logloss: 0.130344\tvalid_1's multi_logloss: 0.268639       \n",
      "[373]\ttraining's multi_logloss: 0.129975\tvalid_1's multi_logloss: 0.268596       \n",
      "[374]\ttraining's multi_logloss: 0.12961\tvalid_1's multi_logloss: 0.268569        \n",
      "[375]\ttraining's multi_logloss: 0.129265\tvalid_1's multi_logloss: 0.268558       \n",
      "[376]\ttraining's multi_logloss: 0.128901\tvalid_1's multi_logloss: 0.26856        \n",
      "[377]\ttraining's multi_logloss: 0.128562\tvalid_1's multi_logloss: 0.268546       \n",
      "[378]\ttraining's multi_logloss: 0.128214\tvalid_1's multi_logloss: 0.268569       \n",
      "[379]\ttraining's multi_logloss: 0.127871\tvalid_1's multi_logloss: 0.268602       \n",
      "[380]\ttraining's multi_logloss: 0.127512\tvalid_1's multi_logloss: 0.26857        \n",
      "[381]\ttraining's multi_logloss: 0.127149\tvalid_1's multi_logloss: 0.268633       \n",
      "[382]\ttraining's multi_logloss: 0.126809\tvalid_1's multi_logloss: 0.268639       \n",
      "[383]\ttraining's multi_logloss: 0.12645\tvalid_1's multi_logloss: 0.268714        \n",
      "[384]\ttraining's multi_logloss: 0.126096\tvalid_1's multi_logloss: 0.268719       \n",
      "[385]\ttraining's multi_logloss: 0.125745\tvalid_1's multi_logloss: 0.2687         \n",
      "[386]\ttraining's multi_logloss: 0.125365\tvalid_1's multi_logloss: 0.268653       \n",
      "[387]\ttraining's multi_logloss: 0.125049\tvalid_1's multi_logloss: 0.268645       \n",
      "[388]\ttraining's multi_logloss: 0.124692\tvalid_1's multi_logloss: 0.268691       \n",
      "[389]\ttraining's multi_logloss: 0.124347\tvalid_1's multi_logloss: 0.268664       \n",
      "[390]\ttraining's multi_logloss: 0.123991\tvalid_1's multi_logloss: 0.268605       \n",
      "[391]\ttraining's multi_logloss: 0.123661\tvalid_1's multi_logloss: 0.268651       \n",
      "[392]\ttraining's multi_logloss: 0.123294\tvalid_1's multi_logloss: 0.268581       \n",
      "[393]\ttraining's multi_logloss: 0.122953\tvalid_1's multi_logloss: 0.268548       \n",
      "[394]\ttraining's multi_logloss: 0.122634\tvalid_1's multi_logloss: 0.268545       \n",
      "[395]\ttraining's multi_logloss: 0.122317\tvalid_1's multi_logloss: 0.26857        \n",
      "[396]\ttraining's multi_logloss: 0.122003\tvalid_1's multi_logloss: 0.268605       \n",
      "[397]\ttraining's multi_logloss: 0.121682\tvalid_1's multi_logloss: 0.268598       \n",
      "[398]\ttraining's multi_logloss: 0.12137\tvalid_1's multi_logloss: 0.268581        \n",
      "[399]\ttraining's multi_logloss: 0.121048\tvalid_1's multi_logloss: 0.268624       \n",
      "[400]\ttraining's multi_logloss: 0.120723\tvalid_1's multi_logloss: 0.268621       \n",
      "Did not meet early stopping. Best iteration is:                                  \n",
      "[400]\ttraining's multi_logloss: 0.120723\tvalid_1's multi_logloss: 0.268621\n",
      "[1]\ttraining's multi_logloss: 1.56001\tvalid_1's multi_logloss: 1.56584           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.32293\tvalid_1's multi_logloss: 1.3342            \n",
      "[3]\ttraining's multi_logloss: 1.14814\tvalid_1's multi_logloss: 1.16492           \n",
      "[4]\ttraining's multi_logloss: 1.01208\tvalid_1's multi_logloss: 1.03345           \n",
      "[5]\ttraining's multi_logloss: 0.903513\tvalid_1's multi_logloss: 0.928675         \n",
      "[6]\ttraining's multi_logloss: 0.814567\tvalid_1's multi_logloss: 0.842774         \n",
      "[7]\ttraining's multi_logloss: 0.739769\tvalid_1's multi_logloss: 0.770754         \n",
      "[8]\ttraining's multi_logloss: 0.675964\tvalid_1's multi_logloss: 0.709716         \n",
      "[9]\ttraining's multi_logloss: 0.620531\tvalid_1's multi_logloss: 0.656879         \n",
      "[10]\ttraining's multi_logloss: 0.573184\tvalid_1's multi_logloss: 0.61219         \n",
      "[11]\ttraining's multi_logloss: 0.532622\tvalid_1's multi_logloss: 0.573845        \n",
      "[12]\ttraining's multi_logloss: 0.49691\tvalid_1's multi_logloss: 0.540325         \n",
      "[13]\ttraining's multi_logloss: 0.465466\tvalid_1's multi_logloss: 0.510831        \n",
      "[14]\ttraining's multi_logloss: 0.437427\tvalid_1's multi_logloss: 0.485449        \n",
      "[15]\ttraining's multi_logloss: 0.412741\tvalid_1's multi_logloss: 0.46325         \n",
      "[16]\ttraining's multi_logloss: 0.390311\tvalid_1's multi_logloss: 0.443201        \n",
      "[17]\ttraining's multi_logloss: 0.371213\tvalid_1's multi_logloss: 0.426138        \n",
      "[18]\ttraining's multi_logloss: 0.353885\tvalid_1's multi_logloss: 0.410691        \n",
      "[19]\ttraining's multi_logloss: 0.338363\tvalid_1's multi_logloss: 0.397274        \n",
      "[20]\ttraining's multi_logloss: 0.324658\tvalid_1's multi_logloss: 0.385948        \n",
      "[21]\ttraining's multi_logloss: 0.31225\tvalid_1's multi_logloss: 0.376026         \n",
      "[22]\ttraining's multi_logloss: 0.300758\tvalid_1's multi_logloss: 0.367041        \n",
      "[23]\ttraining's multi_logloss: 0.290281\tvalid_1's multi_logloss: 0.359021        \n",
      "[24]\ttraining's multi_logloss: 0.280138\tvalid_1's multi_logloss: 0.351692        \n",
      "[25]\ttraining's multi_logloss: 0.270872\tvalid_1's multi_logloss: 0.345167        \n",
      "[26]\ttraining's multi_logloss: 0.262563\tvalid_1's multi_logloss: 0.339211        \n",
      "[27]\ttraining's multi_logloss: 0.25476\tvalid_1's multi_logloss: 0.334353         \n",
      "[28]\ttraining's multi_logloss: 0.247429\tvalid_1's multi_logloss: 0.329777        \n",
      "[29]\ttraining's multi_logloss: 0.240649\tvalid_1's multi_logloss: 0.32561         \n",
      "[30]\ttraining's multi_logloss: 0.233966\tvalid_1's multi_logloss: 0.321899        \n",
      "[31]\ttraining's multi_logloss: 0.227798\tvalid_1's multi_logloss: 0.3185          \n",
      "[32]\ttraining's multi_logloss: 0.221961\tvalid_1's multi_logloss: 0.315514        \n",
      "[33]\ttraining's multi_logloss: 0.216649\tvalid_1's multi_logloss: 0.312568        \n",
      "[34]\ttraining's multi_logloss: 0.211716\tvalid_1's multi_logloss: 0.310738        \n",
      "[35]\ttraining's multi_logloss: 0.206859\tvalid_1's multi_logloss: 0.308715        \n",
      "[36]\ttraining's multi_logloss: 0.202295\tvalid_1's multi_logloss: 0.306527        \n",
      "[37]\ttraining's multi_logloss: 0.197951\tvalid_1's multi_logloss: 0.304639        \n",
      "[38]\ttraining's multi_logloss: 0.193736\tvalid_1's multi_logloss: 0.302701        \n",
      "[39]\ttraining's multi_logloss: 0.189768\tvalid_1's multi_logloss: 0.301356        \n",
      "[40]\ttraining's multi_logloss: 0.185961\tvalid_1's multi_logloss: 0.299902        \n",
      "[41]\ttraining's multi_logloss: 0.182036\tvalid_1's multi_logloss: 0.298828        \n",
      "[42]\ttraining's multi_logloss: 0.178267\tvalid_1's multi_logloss: 0.297648        \n",
      "[43]\ttraining's multi_logloss: 0.174439\tvalid_1's multi_logloss: 0.296565        \n",
      "[44]\ttraining's multi_logloss: 0.170977\tvalid_1's multi_logloss: 0.296172        \n",
      "[45]\ttraining's multi_logloss: 0.167507\tvalid_1's multi_logloss: 0.295308        \n",
      "[46]\ttraining's multi_logloss: 0.164161\tvalid_1's multi_logloss: 0.294792        \n",
      "[47]\ttraining's multi_logloss: 0.161\tvalid_1's multi_logloss: 0.293922           \n",
      "[48]\ttraining's multi_logloss: 0.157754\tvalid_1's multi_logloss: 0.293521        \n",
      "[49]\ttraining's multi_logloss: 0.154586\tvalid_1's multi_logloss: 0.292904        \n",
      "[50]\ttraining's multi_logloss: 0.151666\tvalid_1's multi_logloss: 0.292637        \n",
      "[51]\ttraining's multi_logloss: 0.148952\tvalid_1's multi_logloss: 0.292201        \n",
      "[52]\ttraining's multi_logloss: 0.146049\tvalid_1's multi_logloss: 0.291779        \n",
      "[53]\ttraining's multi_logloss: 0.143378\tvalid_1's multi_logloss: 0.291735        \n",
      "[54]\ttraining's multi_logloss: 0.140907\tvalid_1's multi_logloss: 0.291463        \n",
      "[55]\ttraining's multi_logloss: 0.138268\tvalid_1's multi_logloss: 0.290975        \n",
      "[56]\ttraining's multi_logloss: 0.135714\tvalid_1's multi_logloss: 0.29042         \n",
      "[57]\ttraining's multi_logloss: 0.13336\tvalid_1's multi_logloss: 0.290338         \n",
      "[58]\ttraining's multi_logloss: 0.130829\tvalid_1's multi_logloss: 0.289917        \n",
      "[59]\ttraining's multi_logloss: 0.128557\tvalid_1's multi_logloss: 0.289831        \n",
      "[60]\ttraining's multi_logloss: 0.126374\tvalid_1's multi_logloss: 0.289868        \n",
      "[61]\ttraining's multi_logloss: 0.124227\tvalid_1's multi_logloss: 0.289952        \n",
      "[62]\ttraining's multi_logloss: 0.122171\tvalid_1's multi_logloss: 0.290147        \n",
      "[63]\ttraining's multi_logloss: 0.119999\tvalid_1's multi_logloss: 0.290116        \n",
      "[64]\ttraining's multi_logloss: 0.118003\tvalid_1's multi_logloss: 0.289967        \n",
      "[65]\ttraining's multi_logloss: 0.115994\tvalid_1's multi_logloss: 0.289802        \n",
      "[66]\ttraining's multi_logloss: 0.113997\tvalid_1's multi_logloss: 0.289647        \n",
      "[67]\ttraining's multi_logloss: 0.112313\tvalid_1's multi_logloss: 0.289648        \n",
      "[68]\ttraining's multi_logloss: 0.110393\tvalid_1's multi_logloss: 0.289738        \n",
      "[69]\ttraining's multi_logloss: 0.108746\tvalid_1's multi_logloss: 0.290434        \n",
      "[70]\ttraining's multi_logloss: 0.107142\tvalid_1's multi_logloss: 0.291317        \n",
      "[71]\ttraining's multi_logloss: 0.105545\tvalid_1's multi_logloss: 0.291632        \n",
      "[72]\ttraining's multi_logloss: 0.103862\tvalid_1's multi_logloss: 0.291996        \n",
      "[73]\ttraining's multi_logloss: 0.102088\tvalid_1's multi_logloss: 0.292609        \n",
      "[74]\ttraining's multi_logloss: 0.10065\tvalid_1's multi_logloss: 0.293187         \n",
      "[75]\ttraining's multi_logloss: 0.0992584\tvalid_1's multi_logloss: 0.293335       \n",
      "[76]\ttraining's multi_logloss: 0.097846\tvalid_1's multi_logloss: 0.293693        \n",
      "[77]\ttraining's multi_logloss: 0.0962833\tvalid_1's multi_logloss: 0.293918       \n",
      "[78]\ttraining's multi_logloss: 0.0947581\tvalid_1's multi_logloss: 0.294419       \n",
      "[79]\ttraining's multi_logloss: 0.0934232\tvalid_1's multi_logloss: 0.294509       \n",
      "[80]\ttraining's multi_logloss: 0.0919266\tvalid_1's multi_logloss: 0.294663       \n",
      "[81]\ttraining's multi_logloss: 0.0906269\tvalid_1's multi_logloss: 0.294802       \n",
      "[82]\ttraining's multi_logloss: 0.0891679\tvalid_1's multi_logloss: 0.295285       \n",
      "[83]\ttraining's multi_logloss: 0.0876269\tvalid_1's multi_logloss: 0.295408       \n",
      "[84]\ttraining's multi_logloss: 0.0861373\tvalid_1's multi_logloss: 0.295561       \n",
      "[85]\ttraining's multi_logloss: 0.0849781\tvalid_1's multi_logloss: 0.295788       \n",
      "[86]\ttraining's multi_logloss: 0.0837015\tvalid_1's multi_logloss: 0.296015       \n",
      "[87]\ttraining's multi_logloss: 0.0824493\tvalid_1's multi_logloss: 0.296644       \n",
      "[88]\ttraining's multi_logloss: 0.0812002\tvalid_1's multi_logloss: 0.297048       \n",
      "[89]\ttraining's multi_logloss: 0.0801577\tvalid_1's multi_logloss: 0.297608       \n",
      "[90]\ttraining's multi_logloss: 0.0790054\tvalid_1's multi_logloss: 0.298054       \n",
      "[91]\ttraining's multi_logloss: 0.0778927\tvalid_1's multi_logloss: 0.298274       \n",
      "[92]\ttraining's multi_logloss: 0.0769261\tvalid_1's multi_logloss: 0.299193       \n",
      "[93]\ttraining's multi_logloss: 0.0759272\tvalid_1's multi_logloss: 0.299639       \n",
      "[94]\ttraining's multi_logloss: 0.0747536\tvalid_1's multi_logloss: 0.299889       \n",
      "[95]\ttraining's multi_logloss: 0.0737075\tvalid_1's multi_logloss: 0.300227       \n",
      "[96]\ttraining's multi_logloss: 0.0726623\tvalid_1's multi_logloss: 0.300786       \n",
      "Early stopping, best iteration is:                                               \n",
      "[66]\ttraining's multi_logloss: 0.113997\tvalid_1's multi_logloss: 0.289647\n",
      "[1]\ttraining's multi_logloss: 1.55779\tvalid_1's multi_logloss: 1.56204           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.32268\tvalid_1's multi_logloss: 1.32868           \n",
      "[3]\ttraining's multi_logloss: 1.15078\tvalid_1's multi_logloss: 1.15949           \n",
      "[4]\ttraining's multi_logloss: 1.01739\tvalid_1's multi_logloss: 1.02899           \n",
      "[5]\ttraining's multi_logloss: 0.909958\tvalid_1's multi_logloss: 0.92301          \n",
      "[6]\ttraining's multi_logloss: 0.820464\tvalid_1's multi_logloss: 0.836328         \n",
      "[7]\ttraining's multi_logloss: 0.743898\tvalid_1's multi_logloss: 0.762916         \n",
      "[8]\ttraining's multi_logloss: 0.680067\tvalid_1's multi_logloss: 0.701375         \n",
      "[9]\ttraining's multi_logloss: 0.625694\tvalid_1's multi_logloss: 0.649374         \n",
      "[10]\ttraining's multi_logloss: 0.578852\tvalid_1's multi_logloss: 0.604306        \n",
      "[11]\ttraining's multi_logloss: 0.538056\tvalid_1's multi_logloss: 0.56535         \n",
      "[12]\ttraining's multi_logloss: 0.501931\tvalid_1's multi_logloss: 0.531868        \n",
      "[13]\ttraining's multi_logloss: 0.470697\tvalid_1's multi_logloss: 0.502834        \n",
      "[14]\ttraining's multi_logloss: 0.442446\tvalid_1's multi_logloss: 0.476904        \n",
      "[15]\ttraining's multi_logloss: 0.418074\tvalid_1's multi_logloss: 0.455307        \n",
      "[16]\ttraining's multi_logloss: 0.396199\tvalid_1's multi_logloss: 0.435881        \n",
      "[17]\ttraining's multi_logloss: 0.376817\tvalid_1's multi_logloss: 0.419254        \n",
      "[18]\ttraining's multi_logloss: 0.359297\tvalid_1's multi_logloss: 0.404239        \n",
      "[19]\ttraining's multi_logloss: 0.343587\tvalid_1's multi_logloss: 0.391081        \n",
      "[20]\ttraining's multi_logloss: 0.329358\tvalid_1's multi_logloss: 0.378507        \n",
      "[21]\ttraining's multi_logloss: 0.316511\tvalid_1's multi_logloss: 0.367987        \n",
      "[22]\ttraining's multi_logloss: 0.3042\tvalid_1's multi_logloss: 0.357924          \n",
      "[23]\ttraining's multi_logloss: 0.293218\tvalid_1's multi_logloss: 0.349226        \n",
      "[24]\ttraining's multi_logloss: 0.282837\tvalid_1's multi_logloss: 0.341233        \n",
      "[25]\ttraining's multi_logloss: 0.273615\tvalid_1's multi_logloss: 0.33512         \n",
      "[26]\ttraining's multi_logloss: 0.264762\tvalid_1's multi_logloss: 0.32914         \n",
      "[27]\ttraining's multi_logloss: 0.256927\tvalid_1's multi_logloss: 0.323892        \n",
      "[28]\ttraining's multi_logloss: 0.249675\tvalid_1's multi_logloss: 0.319719        \n",
      "[29]\ttraining's multi_logloss: 0.242678\tvalid_1's multi_logloss: 0.315858        \n",
      "[30]\ttraining's multi_logloss: 0.235919\tvalid_1's multi_logloss: 0.312153        \n",
      "[31]\ttraining's multi_logloss: 0.229726\tvalid_1's multi_logloss: 0.309184        \n",
      "[32]\ttraining's multi_logloss: 0.223785\tvalid_1's multi_logloss: 0.306207        \n",
      "[33]\ttraining's multi_logloss: 0.218339\tvalid_1's multi_logloss: 0.303561        \n",
      "[34]\ttraining's multi_logloss: 0.213038\tvalid_1's multi_logloss: 0.301381        \n",
      "[35]\ttraining's multi_logloss: 0.207953\tvalid_1's multi_logloss: 0.299259        \n",
      "[36]\ttraining's multi_logloss: 0.203165\tvalid_1's multi_logloss: 0.297355        \n",
      "[37]\ttraining's multi_logloss: 0.198716\tvalid_1's multi_logloss: 0.295714        \n",
      "[38]\ttraining's multi_logloss: 0.194198\tvalid_1's multi_logloss: 0.294497        \n",
      "[39]\ttraining's multi_logloss: 0.189999\tvalid_1's multi_logloss: 0.292962        \n",
      "[40]\ttraining's multi_logloss: 0.185773\tvalid_1's multi_logloss: 0.292032        \n",
      "[41]\ttraining's multi_logloss: 0.181835\tvalid_1's multi_logloss: 0.290303        \n",
      "[42]\ttraining's multi_logloss: 0.177985\tvalid_1's multi_logloss: 0.289446        \n",
      "[43]\ttraining's multi_logloss: 0.17428\tvalid_1's multi_logloss: 0.287762         \n",
      "[44]\ttraining's multi_logloss: 0.170684\tvalid_1's multi_logloss: 0.28688         \n",
      "[45]\ttraining's multi_logloss: 0.167126\tvalid_1's multi_logloss: 0.286734        \n",
      "[46]\ttraining's multi_logloss: 0.163499\tvalid_1's multi_logloss: 0.285963        \n",
      "[47]\ttraining's multi_logloss: 0.159876\tvalid_1's multi_logloss: 0.285233        \n",
      "[48]\ttraining's multi_logloss: 0.156864\tvalid_1's multi_logloss: 0.285072        \n",
      "[49]\ttraining's multi_logloss: 0.153716\tvalid_1's multi_logloss: 0.284835        \n",
      "[50]\ttraining's multi_logloss: 0.150708\tvalid_1's multi_logloss: 0.284652        \n",
      "[51]\ttraining's multi_logloss: 0.147705\tvalid_1's multi_logloss: 0.284126        \n",
      "[52]\ttraining's multi_logloss: 0.144892\tvalid_1's multi_logloss: 0.284292        \n",
      "[53]\ttraining's multi_logloss: 0.142169\tvalid_1's multi_logloss: 0.284349        \n",
      "[54]\ttraining's multi_logloss: 0.139612\tvalid_1's multi_logloss: 0.284184        \n",
      "[55]\ttraining's multi_logloss: 0.136927\tvalid_1's multi_logloss: 0.28356         \n",
      "[56]\ttraining's multi_logloss: 0.134633\tvalid_1's multi_logloss: 0.283279        \n",
      "[57]\ttraining's multi_logloss: 0.132289\tvalid_1's multi_logloss: 0.283025        \n",
      "[58]\ttraining's multi_logloss: 0.129955\tvalid_1's multi_logloss: 0.282712        \n",
      "[59]\ttraining's multi_logloss: 0.127488\tvalid_1's multi_logloss: 0.282809        \n",
      "[60]\ttraining's multi_logloss: 0.125244\tvalid_1's multi_logloss: 0.282824        \n",
      "[61]\ttraining's multi_logloss: 0.122995\tvalid_1's multi_logloss: 0.282586        \n",
      "[62]\ttraining's multi_logloss: 0.120733\tvalid_1's multi_logloss: 0.282466        \n",
      "[63]\ttraining's multi_logloss: 0.118738\tvalid_1's multi_logloss: 0.282592        \n",
      "[64]\ttraining's multi_logloss: 0.116706\tvalid_1's multi_logloss: 0.28296         \n",
      "[65]\ttraining's multi_logloss: 0.114505\tvalid_1's multi_logloss: 0.283429        \n",
      "[66]\ttraining's multi_logloss: 0.112401\tvalid_1's multi_logloss: 0.283721        \n",
      "[67]\ttraining's multi_logloss: 0.110463\tvalid_1's multi_logloss: 0.283991        \n",
      "[68]\ttraining's multi_logloss: 0.108627\tvalid_1's multi_logloss: 0.284106        \n",
      "[69]\ttraining's multi_logloss: 0.106818\tvalid_1's multi_logloss: 0.284187        \n",
      "[70]\ttraining's multi_logloss: 0.105211\tvalid_1's multi_logloss: 0.28407         \n",
      "[71]\ttraining's multi_logloss: 0.103392\tvalid_1's multi_logloss: 0.284461        \n",
      "[72]\ttraining's multi_logloss: 0.101762\tvalid_1's multi_logloss: 0.284616        \n",
      "[73]\ttraining's multi_logloss: 0.10013\tvalid_1's multi_logloss: 0.284682         \n",
      "[74]\ttraining's multi_logloss: 0.0985982\tvalid_1's multi_logloss: 0.284923       \n",
      "[75]\ttraining's multi_logloss: 0.0969326\tvalid_1's multi_logloss: 0.285222       \n",
      "[76]\ttraining's multi_logloss: 0.0954623\tvalid_1's multi_logloss: 0.285566       \n",
      "[77]\ttraining's multi_logloss: 0.0940348\tvalid_1's multi_logloss: 0.285906       \n",
      "[78]\ttraining's multi_logloss: 0.0926032\tvalid_1's multi_logloss: 0.285973       \n",
      "[79]\ttraining's multi_logloss: 0.0912703\tvalid_1's multi_logloss: 0.286071       \n",
      "[80]\ttraining's multi_logloss: 0.089821\tvalid_1's multi_logloss: 0.286238        \n",
      "[81]\ttraining's multi_logloss: 0.0885253\tvalid_1's multi_logloss: 0.286707       \n",
      "[82]\ttraining's multi_logloss: 0.0871779\tvalid_1's multi_logloss: 0.286958       \n",
      "[83]\ttraining's multi_logloss: 0.0858111\tvalid_1's multi_logloss: 0.287426       \n",
      "[84]\ttraining's multi_logloss: 0.0843687\tvalid_1's multi_logloss: 0.288083       \n",
      "[85]\ttraining's multi_logloss: 0.0829221\tvalid_1's multi_logloss: 0.288552       \n",
      "[86]\ttraining's multi_logloss: 0.0817602\tvalid_1's multi_logloss: 0.289261       \n",
      "[87]\ttraining's multi_logloss: 0.0805768\tvalid_1's multi_logloss: 0.289682       \n",
      "[88]\ttraining's multi_logloss: 0.0792967\tvalid_1's multi_logloss: 0.290071       \n",
      "[89]\ttraining's multi_logloss: 0.0781501\tvalid_1's multi_logloss: 0.290591       \n",
      "[90]\ttraining's multi_logloss: 0.0769843\tvalid_1's multi_logloss: 0.291077       \n",
      "[91]\ttraining's multi_logloss: 0.0757689\tvalid_1's multi_logloss: 0.291487       \n",
      "[92]\ttraining's multi_logloss: 0.0746353\tvalid_1's multi_logloss: 0.292023       \n",
      "Early stopping, best iteration is:                                               \n",
      "[62]\ttraining's multi_logloss: 0.120733\tvalid_1's multi_logloss: 0.282466\n",
      "[1]\ttraining's multi_logloss: 1.56068\tvalid_1's multi_logloss: 1.56477           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.32423\tvalid_1's multi_logloss: 1.32986           \n",
      "[3]\ttraining's multi_logloss: 1.1525\tvalid_1's multi_logloss: 1.1596             \n",
      "[4]\ttraining's multi_logloss: 1.01822\tvalid_1's multi_logloss: 1.02667           \n",
      "[5]\ttraining's multi_logloss: 0.910242\tvalid_1's multi_logloss: 0.919765         \n",
      "[6]\ttraining's multi_logloss: 0.820666\tvalid_1's multi_logloss: 0.832171         \n",
      "[7]\ttraining's multi_logloss: 0.744895\tvalid_1's multi_logloss: 0.757976         \n",
      "[8]\ttraining's multi_logloss: 0.681422\tvalid_1's multi_logloss: 0.696128         \n",
      "[9]\ttraining's multi_logloss: 0.627442\tvalid_1's multi_logloss: 0.644042         \n",
      "[10]\ttraining's multi_logloss: 0.580327\tvalid_1's multi_logloss: 0.598638        \n",
      "[11]\ttraining's multi_logloss: 0.539791\tvalid_1's multi_logloss: 0.560055        \n",
      "[12]\ttraining's multi_logloss: 0.504464\tvalid_1's multi_logloss: 0.526433        \n",
      "[13]\ttraining's multi_logloss: 0.473389\tvalid_1's multi_logloss: 0.49745         \n",
      "[14]\ttraining's multi_logloss: 0.446488\tvalid_1's multi_logloss: 0.472487        \n",
      "[15]\ttraining's multi_logloss: 0.421986\tvalid_1's multi_logloss: 0.450018        \n",
      "[16]\ttraining's multi_logloss: 0.400601\tvalid_1's multi_logloss: 0.430309        \n",
      "[17]\ttraining's multi_logloss: 0.380638\tvalid_1's multi_logloss: 0.412133        \n",
      "[18]\ttraining's multi_logloss: 0.362974\tvalid_1's multi_logloss: 0.39644         \n",
      "[19]\ttraining's multi_logloss: 0.347343\tvalid_1's multi_logloss: 0.382797        \n",
      "[20]\ttraining's multi_logloss: 0.333042\tvalid_1's multi_logloss: 0.370521        \n",
      "[21]\ttraining's multi_logloss: 0.320453\tvalid_1's multi_logloss: 0.359985        \n",
      "[22]\ttraining's multi_logloss: 0.308667\tvalid_1's multi_logloss: 0.350383        \n",
      "[23]\ttraining's multi_logloss: 0.297868\tvalid_1's multi_logloss: 0.341616        \n",
      "[24]\ttraining's multi_logloss: 0.287952\tvalid_1's multi_logloss: 0.334529        \n",
      "[25]\ttraining's multi_logloss: 0.278823\tvalid_1's multi_logloss: 0.328039        \n",
      "[26]\ttraining's multi_logloss: 0.27025\tvalid_1's multi_logloss: 0.321736         \n",
      "[27]\ttraining's multi_logloss: 0.261967\tvalid_1's multi_logloss: 0.316487        \n",
      "[28]\ttraining's multi_logloss: 0.254919\tvalid_1's multi_logloss: 0.311655        \n",
      "[29]\ttraining's multi_logloss: 0.248144\tvalid_1's multi_logloss: 0.307588        \n",
      "[30]\ttraining's multi_logloss: 0.241886\tvalid_1's multi_logloss: 0.303891        \n",
      "[31]\ttraining's multi_logloss: 0.235996\tvalid_1's multi_logloss: 0.300383        \n",
      "[32]\ttraining's multi_logloss: 0.230136\tvalid_1's multi_logloss: 0.297139        \n",
      "[33]\ttraining's multi_logloss: 0.224931\tvalid_1's multi_logloss: 0.294354        \n",
      "[34]\ttraining's multi_logloss: 0.219603\tvalid_1's multi_logloss: 0.291607        \n",
      "[35]\ttraining's multi_logloss: 0.214586\tvalid_1's multi_logloss: 0.288996        \n",
      "[36]\ttraining's multi_logloss: 0.20983\tvalid_1's multi_logloss: 0.286721         \n",
      "[37]\ttraining's multi_logloss: 0.205329\tvalid_1's multi_logloss: 0.284885        \n",
      "[38]\ttraining's multi_logloss: 0.200911\tvalid_1's multi_logloss: 0.283318        \n",
      "[39]\ttraining's multi_logloss: 0.196448\tvalid_1's multi_logloss: 0.281942        \n",
      "[40]\ttraining's multi_logloss: 0.192436\tvalid_1's multi_logloss: 0.280734        \n",
      "[41]\ttraining's multi_logloss: 0.188512\tvalid_1's multi_logloss: 0.279759        \n",
      "[42]\ttraining's multi_logloss: 0.18474\tvalid_1's multi_logloss: 0.278936         \n",
      "[43]\ttraining's multi_logloss: 0.181066\tvalid_1's multi_logloss: 0.277902        \n",
      "[44]\ttraining's multi_logloss: 0.177447\tvalid_1's multi_logloss: 0.276628        \n",
      "[45]\ttraining's multi_logloss: 0.174276\tvalid_1's multi_logloss: 0.27584         \n",
      "[46]\ttraining's multi_logloss: 0.17067\tvalid_1's multi_logloss: 0.274996         \n",
      "[47]\ttraining's multi_logloss: 0.167384\tvalid_1's multi_logloss: 0.274473        \n",
      "[48]\ttraining's multi_logloss: 0.164089\tvalid_1's multi_logloss: 0.274014        \n",
      "[49]\ttraining's multi_logloss: 0.161001\tvalid_1's multi_logloss: 0.273433        \n",
      "[50]\ttraining's multi_logloss: 0.158091\tvalid_1's multi_logloss: 0.272609        \n",
      "[51]\ttraining's multi_logloss: 0.155184\tvalid_1's multi_logloss: 0.272129        \n",
      "[52]\ttraining's multi_logloss: 0.152128\tvalid_1's multi_logloss: 0.272141        \n",
      "[53]\ttraining's multi_logloss: 0.149337\tvalid_1's multi_logloss: 0.27198         \n",
      "[54]\ttraining's multi_logloss: 0.146406\tvalid_1's multi_logloss: 0.271816        \n",
      "[55]\ttraining's multi_logloss: 0.143599\tvalid_1's multi_logloss: 0.271543        \n",
      "[56]\ttraining's multi_logloss: 0.141006\tvalid_1's multi_logloss: 0.270889        \n",
      "[57]\ttraining's multi_logloss: 0.138427\tvalid_1's multi_logloss: 0.270285        \n",
      "[58]\ttraining's multi_logloss: 0.135978\tvalid_1's multi_logloss: 0.269918        \n",
      "[59]\ttraining's multi_logloss: 0.133502\tvalid_1's multi_logloss: 0.269752        \n",
      "[60]\ttraining's multi_logloss: 0.131305\tvalid_1's multi_logloss: 0.269618        \n",
      "[61]\ttraining's multi_logloss: 0.129096\tvalid_1's multi_logloss: 0.269302        \n",
      "[62]\ttraining's multi_logloss: 0.126927\tvalid_1's multi_logloss: 0.269126        \n",
      "[63]\ttraining's multi_logloss: 0.124804\tvalid_1's multi_logloss: 0.26901         \n",
      "[64]\ttraining's multi_logloss: 0.122689\tvalid_1's multi_logloss: 0.268889        \n",
      "[65]\ttraining's multi_logloss: 0.12057\tvalid_1's multi_logloss: 0.26875          \n",
      "[66]\ttraining's multi_logloss: 0.118756\tvalid_1's multi_logloss: 0.268558        \n",
      "[67]\ttraining's multi_logloss: 0.116806\tvalid_1's multi_logloss: 0.268288        \n",
      "[68]\ttraining's multi_logloss: 0.114858\tvalid_1's multi_logloss: 0.268302        \n",
      "[69]\ttraining's multi_logloss: 0.113117\tvalid_1's multi_logloss: 0.268311        \n",
      "[70]\ttraining's multi_logloss: 0.111361\tvalid_1's multi_logloss: 0.26876         \n",
      "[71]\ttraining's multi_logloss: 0.109636\tvalid_1's multi_logloss: 0.269003        \n",
      "[72]\ttraining's multi_logloss: 0.107888\tvalid_1's multi_logloss: 0.269069        \n",
      "[73]\ttraining's multi_logloss: 0.106057\tvalid_1's multi_logloss: 0.26887         \n",
      "[74]\ttraining's multi_logloss: 0.104229\tvalid_1's multi_logloss: 0.269023        \n",
      "[75]\ttraining's multi_logloss: 0.102758\tvalid_1's multi_logloss: 0.269328        \n",
      "[76]\ttraining's multi_logloss: 0.101155\tvalid_1's multi_logloss: 0.269481        \n",
      "[77]\ttraining's multi_logloss: 0.0996573\tvalid_1's multi_logloss: 0.269331       \n",
      "[78]\ttraining's multi_logloss: 0.0982098\tvalid_1's multi_logloss: 0.269653       \n",
      "[79]\ttraining's multi_logloss: 0.0965738\tvalid_1's multi_logloss: 0.26962        \n",
      "[80]\ttraining's multi_logloss: 0.0952048\tvalid_1's multi_logloss: 0.26983        \n",
      "[81]\ttraining's multi_logloss: 0.0938239\tvalid_1's multi_logloss: 0.270158       \n",
      "[82]\ttraining's multi_logloss: 0.0921945\tvalid_1's multi_logloss: 0.270393       \n",
      "[83]\ttraining's multi_logloss: 0.090799\tvalid_1's multi_logloss: 0.270553        \n",
      "[84]\ttraining's multi_logloss: 0.0893615\tvalid_1's multi_logloss: 0.270849       \n",
      "[85]\ttraining's multi_logloss: 0.0881671\tvalid_1's multi_logloss: 0.270865       \n",
      "[86]\ttraining's multi_logloss: 0.0868545\tvalid_1's multi_logloss: 0.271229       \n",
      "[87]\ttraining's multi_logloss: 0.0855327\tvalid_1's multi_logloss: 0.27163        \n",
      "[88]\ttraining's multi_logloss: 0.0843237\tvalid_1's multi_logloss: 0.272074       \n",
      "[89]\ttraining's multi_logloss: 0.0831913\tvalid_1's multi_logloss: 0.272277       \n",
      "[90]\ttraining's multi_logloss: 0.081956\tvalid_1's multi_logloss: 0.272742        \n",
      "[91]\ttraining's multi_logloss: 0.080817\tvalid_1's multi_logloss: 0.272779        \n",
      "[92]\ttraining's multi_logloss: 0.079629\tvalid_1's multi_logloss: 0.272781        \n",
      "[93]\ttraining's multi_logloss: 0.078307\tvalid_1's multi_logloss: 0.273088        \n",
      "[94]\ttraining's multi_logloss: 0.0772201\tvalid_1's multi_logloss: 0.273518       \n",
      "[95]\ttraining's multi_logloss: 0.0762176\tvalid_1's multi_logloss: 0.274051       \n",
      "[96]\ttraining's multi_logloss: 0.0750277\tvalid_1's multi_logloss: 0.274531       \n",
      "[97]\ttraining's multi_logloss: 0.0738911\tvalid_1's multi_logloss: 0.27455        \n",
      "Early stopping, best iteration is:                                               \n",
      "[67]\ttraining's multi_logloss: 0.116806\tvalid_1's multi_logloss: 0.268288\n",
      "[1]\ttraining's multi_logloss: 1.74689\tvalid_1's multi_logloss: 1.74846           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.59864\tvalid_1's multi_logloss: 1.6031            \n",
      "[3]\ttraining's multi_logloss: 1.47528\tvalid_1's multi_logloss: 1.48321           \n",
      "[4]\ttraining's multi_logloss: 1.36961\tvalid_1's multi_logloss: 1.38074           \n",
      "[5]\ttraining's multi_logloss: 1.27762\tvalid_1's multi_logloss: 1.29123           \n",
      "[6]\ttraining's multi_logloss: 1.197\tvalid_1's multi_logloss: 1.2128              \n",
      "[7]\ttraining's multi_logloss: 1.12522\tvalid_1's multi_logloss: 1.14314           \n",
      "[8]\ttraining's multi_logloss: 1.06062\tvalid_1's multi_logloss: 1.08044           \n",
      "[9]\ttraining's multi_logloss: 1.00239\tvalid_1's multi_logloss: 1.02414           \n",
      "[10]\ttraining's multi_logloss: 0.949371\tvalid_1's multi_logloss: 0.972815        \n",
      "[11]\ttraining's multi_logloss: 0.90073\tvalid_1's multi_logloss: 0.925483         \n",
      "[12]\ttraining's multi_logloss: 0.856614\tvalid_1's multi_logloss: 0.882903        \n",
      "[13]\ttraining's multi_logloss: 0.815885\tvalid_1's multi_logloss: 0.843913        \n",
      "[14]\ttraining's multi_logloss: 0.778465\tvalid_1's multi_logloss: 0.807587        \n",
      "[15]\ttraining's multi_logloss: 0.743842\tvalid_1's multi_logloss: 0.774202        \n",
      "[16]\ttraining's multi_logloss: 0.712308\tvalid_1's multi_logloss: 0.743668        \n",
      "[17]\ttraining's multi_logloss: 0.682552\tvalid_1's multi_logloss: 0.715212        \n",
      "[18]\ttraining's multi_logloss: 0.65509\tvalid_1's multi_logloss: 0.688658         \n",
      "[19]\ttraining's multi_logloss: 0.629641\tvalid_1's multi_logloss: 0.664231        \n",
      "[20]\ttraining's multi_logloss: 0.605603\tvalid_1's multi_logloss: 0.641152        \n",
      "[21]\ttraining's multi_logloss: 0.583193\tvalid_1's multi_logloss: 0.619727        \n",
      "[22]\ttraining's multi_logloss: 0.562331\tvalid_1's multi_logloss: 0.599904        \n",
      "[23]\ttraining's multi_logloss: 0.542836\tvalid_1's multi_logloss: 0.581588        \n",
      "[24]\ttraining's multi_logloss: 0.524646\tvalid_1's multi_logloss: 0.564418        \n",
      "[25]\ttraining's multi_logloss: 0.507262\tvalid_1's multi_logloss: 0.548168        \n",
      "[26]\ttraining's multi_logloss: 0.491457\tvalid_1's multi_logloss: 0.533494        \n",
      "[27]\ttraining's multi_logloss: 0.476474\tvalid_1's multi_logloss: 0.519457        \n",
      "[28]\ttraining's multi_logloss: 0.46233\tvalid_1's multi_logloss: 0.506329         \n",
      "[29]\ttraining's multi_logloss: 0.448903\tvalid_1's multi_logloss: 0.494004        \n",
      "[30]\ttraining's multi_logloss: 0.436422\tvalid_1's multi_logloss: 0.48244         \n",
      "[31]\ttraining's multi_logloss: 0.42447\tvalid_1's multi_logloss: 0.47157          \n",
      "[32]\ttraining's multi_logloss: 0.41324\tvalid_1's multi_logloss: 0.461526         \n",
      "[33]\ttraining's multi_logloss: 0.402695\tvalid_1's multi_logloss: 0.452059        \n",
      "[34]\ttraining's multi_logloss: 0.39274\tvalid_1's multi_logloss: 0.44317          \n",
      "[35]\ttraining's multi_logloss: 0.383348\tvalid_1's multi_logloss: 0.434938        \n",
      "[36]\ttraining's multi_logloss: 0.374416\tvalid_1's multi_logloss: 0.427174        \n",
      "[37]\ttraining's multi_logloss: 0.365912\tvalid_1's multi_logloss: 0.419795        \n",
      "[38]\ttraining's multi_logloss: 0.357842\tvalid_1's multi_logloss: 0.41297         \n",
      "[39]\ttraining's multi_logloss: 0.350376\tvalid_1's multi_logloss: 0.406846        \n",
      "[40]\ttraining's multi_logloss: 0.343204\tvalid_1's multi_logloss: 0.400837        \n",
      "[41]\ttraining's multi_logloss: 0.336171\tvalid_1's multi_logloss: 0.394958        \n",
      "[42]\ttraining's multi_logloss: 0.32939\tvalid_1's multi_logloss: 0.389439         \n",
      "[43]\ttraining's multi_logloss: 0.323001\tvalid_1's multi_logloss: 0.384082        \n",
      "[44]\ttraining's multi_logloss: 0.316883\tvalid_1's multi_logloss: 0.378967        \n",
      "[45]\ttraining's multi_logloss: 0.311095\tvalid_1's multi_logloss: 0.374356        \n",
      "[46]\ttraining's multi_logloss: 0.305677\tvalid_1's multi_logloss: 0.369946        \n",
      "[47]\ttraining's multi_logloss: 0.300217\tvalid_1's multi_logloss: 0.365843        \n",
      "[48]\ttraining's multi_logloss: 0.295344\tvalid_1's multi_logloss: 0.36207         \n",
      "[49]\ttraining's multi_logloss: 0.290406\tvalid_1's multi_logloss: 0.358301        \n",
      "[50]\ttraining's multi_logloss: 0.285918\tvalid_1's multi_logloss: 0.354778        \n",
      "[51]\ttraining's multi_logloss: 0.281436\tvalid_1's multi_logloss: 0.351477        \n",
      "[52]\ttraining's multi_logloss: 0.2773\tvalid_1's multi_logloss: 0.348501          \n",
      "[53]\ttraining's multi_logloss: 0.273092\tvalid_1's multi_logloss: 0.34531         \n",
      "[54]\ttraining's multi_logloss: 0.269052\tvalid_1's multi_logloss: 0.342474        \n",
      "[55]\ttraining's multi_logloss: 0.265299\tvalid_1's multi_logloss: 0.339985        \n",
      "[56]\ttraining's multi_logloss: 0.261545\tvalid_1's multi_logloss: 0.337456        \n",
      "[57]\ttraining's multi_logloss: 0.257782\tvalid_1's multi_logloss: 0.334904        \n",
      "[58]\ttraining's multi_logloss: 0.254301\tvalid_1's multi_logloss: 0.332758        \n",
      "[59]\ttraining's multi_logloss: 0.25093\tvalid_1's multi_logloss: 0.330696         \n",
      "[60]\ttraining's multi_logloss: 0.247601\tvalid_1's multi_logloss: 0.328476        \n",
      "[61]\ttraining's multi_logloss: 0.244368\tvalid_1's multi_logloss: 0.326488        \n",
      "[62]\ttraining's multi_logloss: 0.241207\tvalid_1's multi_logloss: 0.324494        \n",
      "[63]\ttraining's multi_logloss: 0.238244\tvalid_1's multi_logloss: 0.322851        \n",
      "[64]\ttraining's multi_logloss: 0.235342\tvalid_1's multi_logloss: 0.321193        \n",
      "[65]\ttraining's multi_logloss: 0.232543\tvalid_1's multi_logloss: 0.319676        \n",
      "[66]\ttraining's multi_logloss: 0.229782\tvalid_1's multi_logloss: 0.318087        \n",
      "[67]\ttraining's multi_logloss: 0.227074\tvalid_1's multi_logloss: 0.31652         \n",
      "[68]\ttraining's multi_logloss: 0.224497\tvalid_1's multi_logloss: 0.31487         \n",
      "[69]\ttraining's multi_logloss: 0.221968\tvalid_1's multi_logloss: 0.313454        \n",
      "[70]\ttraining's multi_logloss: 0.219514\tvalid_1's multi_logloss: 0.312398        \n",
      "[71]\ttraining's multi_logloss: 0.217092\tvalid_1's multi_logloss: 0.311167        \n",
      "[72]\ttraining's multi_logloss: 0.214668\tvalid_1's multi_logloss: 0.310058        \n",
      "[73]\ttraining's multi_logloss: 0.212256\tvalid_1's multi_logloss: 0.309029        \n",
      "[74]\ttraining's multi_logloss: 0.209901\tvalid_1's multi_logloss: 0.308074        \n",
      "[75]\ttraining's multi_logloss: 0.207708\tvalid_1's multi_logloss: 0.307006        \n",
      "[76]\ttraining's multi_logloss: 0.205483\tvalid_1's multi_logloss: 0.306078        \n",
      "[77]\ttraining's multi_logloss: 0.203356\tvalid_1's multi_logloss: 0.305283        \n",
      "[78]\ttraining's multi_logloss: 0.201311\tvalid_1's multi_logloss: 0.304408        \n",
      "[79]\ttraining's multi_logloss: 0.199315\tvalid_1's multi_logloss: 0.303627        \n",
      "[80]\ttraining's multi_logloss: 0.197406\tvalid_1's multi_logloss: 0.302885        \n",
      "[81]\ttraining's multi_logloss: 0.195469\tvalid_1's multi_logloss: 0.302015        \n",
      "[82]\ttraining's multi_logloss: 0.193557\tvalid_1's multi_logloss: 0.30154         \n",
      "[83]\ttraining's multi_logloss: 0.191613\tvalid_1's multi_logloss: 0.300983        \n",
      "[84]\ttraining's multi_logloss: 0.189653\tvalid_1's multi_logloss: 0.300191        \n",
      "[85]\ttraining's multi_logloss: 0.187716\tvalid_1's multi_logloss: 0.299709        \n",
      "[86]\ttraining's multi_logloss: 0.185961\tvalid_1's multi_logloss: 0.299054        \n",
      "[87]\ttraining's multi_logloss: 0.184073\tvalid_1's multi_logloss: 0.298456        \n",
      "[88]\ttraining's multi_logloss: 0.182397\tvalid_1's multi_logloss: 0.298024        \n",
      "[89]\ttraining's multi_logloss: 0.180612\tvalid_1's multi_logloss: 0.297383        \n",
      "[90]\ttraining's multi_logloss: 0.178827\tvalid_1's multi_logloss: 0.296917        \n",
      "[91]\ttraining's multi_logloss: 0.177057\tvalid_1's multi_logloss: 0.296316        \n",
      "[92]\ttraining's multi_logloss: 0.175326\tvalid_1's multi_logloss: 0.295866        \n",
      "[93]\ttraining's multi_logloss: 0.173629\tvalid_1's multi_logloss: 0.295427        \n",
      "[94]\ttraining's multi_logloss: 0.172015\tvalid_1's multi_logloss: 0.29493         \n",
      "[95]\ttraining's multi_logloss: 0.170401\tvalid_1's multi_logloss: 0.294463        \n",
      "[96]\ttraining's multi_logloss: 0.168758\tvalid_1's multi_logloss: 0.294002        \n",
      "[97]\ttraining's multi_logloss: 0.167206\tvalid_1's multi_logloss: 0.293586        \n",
      "[98]\ttraining's multi_logloss: 0.165649\tvalid_1's multi_logloss: 0.293199        \n",
      "[99]\ttraining's multi_logloss: 0.164083\tvalid_1's multi_logloss: 0.292842        \n",
      "[100]\ttraining's multi_logloss: 0.16255\tvalid_1's multi_logloss: 0.292492        \n",
      "[101]\ttraining's multi_logloss: 0.160969\tvalid_1's multi_logloss: 0.292216       \n",
      "[102]\ttraining's multi_logloss: 0.159436\tvalid_1's multi_logloss: 0.291925       \n",
      "[103]\ttraining's multi_logloss: 0.157918\tvalid_1's multi_logloss: 0.291792       \n",
      "[104]\ttraining's multi_logloss: 0.156452\tvalid_1's multi_logloss: 0.291682       \n",
      "[105]\ttraining's multi_logloss: 0.155085\tvalid_1's multi_logloss: 0.291256       \n",
      "[106]\ttraining's multi_logloss: 0.153697\tvalid_1's multi_logloss: 0.291155       \n",
      "[107]\ttraining's multi_logloss: 0.15228\tvalid_1's multi_logloss: 0.290937        \n",
      "[108]\ttraining's multi_logloss: 0.150843\tvalid_1's multi_logloss: 0.290788       \n",
      "[109]\ttraining's multi_logloss: 0.149412\tvalid_1's multi_logloss: 0.290465       \n",
      "[110]\ttraining's multi_logloss: 0.148086\tvalid_1's multi_logloss: 0.290473       \n",
      "[111]\ttraining's multi_logloss: 0.146826\tvalid_1's multi_logloss: 0.290445       \n",
      "[112]\ttraining's multi_logloss: 0.145509\tvalid_1's multi_logloss: 0.290267       \n",
      "[113]\ttraining's multi_logloss: 0.14426\tvalid_1's multi_logloss: 0.290185        \n",
      "[114]\ttraining's multi_logloss: 0.14303\tvalid_1's multi_logloss: 0.29015         \n",
      "[115]\ttraining's multi_logloss: 0.141766\tvalid_1's multi_logloss: 0.290113       \n",
      "[116]\ttraining's multi_logloss: 0.140532\tvalid_1's multi_logloss: 0.290044       \n",
      "[117]\ttraining's multi_logloss: 0.139282\tvalid_1's multi_logloss: 0.29007        \n",
      "[118]\ttraining's multi_logloss: 0.138004\tvalid_1's multi_logloss: 0.289922       \n",
      "[119]\ttraining's multi_logloss: 0.136663\tvalid_1's multi_logloss: 0.289841       \n",
      "[120]\ttraining's multi_logloss: 0.135447\tvalid_1's multi_logloss: 0.289763       \n",
      "[121]\ttraining's multi_logloss: 0.134248\tvalid_1's multi_logloss: 0.289694       \n",
      "[122]\ttraining's multi_logloss: 0.133145\tvalid_1's multi_logloss: 0.289673       \n",
      "[123]\ttraining's multi_logloss: 0.131987\tvalid_1's multi_logloss: 0.28952        \n",
      "[124]\ttraining's multi_logloss: 0.130787\tvalid_1's multi_logloss: 0.289425       \n",
      "[125]\ttraining's multi_logloss: 0.129617\tvalid_1's multi_logloss: 0.289445       \n",
      "[126]\ttraining's multi_logloss: 0.128476\tvalid_1's multi_logloss: 0.289367       \n",
      "[127]\ttraining's multi_logloss: 0.127403\tvalid_1's multi_logloss: 0.289245       \n",
      "[128]\ttraining's multi_logloss: 0.126298\tvalid_1's multi_logloss: 0.289059       \n",
      "[129]\ttraining's multi_logloss: 0.125213\tvalid_1's multi_logloss: 0.288989       \n",
      "[130]\ttraining's multi_logloss: 0.124132\tvalid_1's multi_logloss: 0.288904       \n",
      "[131]\ttraining's multi_logloss: 0.123149\tvalid_1's multi_logloss: 0.288851       \n",
      "[132]\ttraining's multi_logloss: 0.122099\tvalid_1's multi_logloss: 0.288914       \n",
      "[133]\ttraining's multi_logloss: 0.121147\tvalid_1's multi_logloss: 0.288872       \n",
      "[134]\ttraining's multi_logloss: 0.120058\tvalid_1's multi_logloss: 0.288981       \n",
      "[135]\ttraining's multi_logloss: 0.119078\tvalid_1's multi_logloss: 0.289102       \n",
      "[136]\ttraining's multi_logloss: 0.118129\tvalid_1's multi_logloss: 0.289167       \n",
      "[137]\ttraining's multi_logloss: 0.117201\tvalid_1's multi_logloss: 0.289236       \n",
      "[138]\ttraining's multi_logloss: 0.116249\tvalid_1's multi_logloss: 0.289342       \n",
      "[139]\ttraining's multi_logloss: 0.115324\tvalid_1's multi_logloss: 0.289347       \n",
      "[140]\ttraining's multi_logloss: 0.114466\tvalid_1's multi_logloss: 0.289238       \n",
      "[141]\ttraining's multi_logloss: 0.113522\tvalid_1's multi_logloss: 0.289153       \n",
      "[142]\ttraining's multi_logloss: 0.112621\tvalid_1's multi_logloss: 0.289125       \n",
      "[143]\ttraining's multi_logloss: 0.111761\tvalid_1's multi_logloss: 0.289204       \n",
      "[144]\ttraining's multi_logloss: 0.110986\tvalid_1's multi_logloss: 0.289216       \n",
      "[145]\ttraining's multi_logloss: 0.110143\tvalid_1's multi_logloss: 0.289155       \n",
      "[146]\ttraining's multi_logloss: 0.109357\tvalid_1's multi_logloss: 0.289263       \n",
      "[147]\ttraining's multi_logloss: 0.10859\tvalid_1's multi_logloss: 0.289281        \n",
      "[148]\ttraining's multi_logloss: 0.107802\tvalid_1's multi_logloss: 0.289307       \n",
      "[149]\ttraining's multi_logloss: 0.106984\tvalid_1's multi_logloss: 0.289528       \n",
      "[150]\ttraining's multi_logloss: 0.106198\tvalid_1's multi_logloss: 0.289561       \n",
      "[151]\ttraining's multi_logloss: 0.10541\tvalid_1's multi_logloss: 0.289694        \n",
      "[152]\ttraining's multi_logloss: 0.104614\tvalid_1's multi_logloss: 0.289804       \n",
      "[153]\ttraining's multi_logloss: 0.103811\tvalid_1's multi_logloss: 0.289778       \n",
      "[154]\ttraining's multi_logloss: 0.103015\tvalid_1's multi_logloss: 0.289769       \n",
      "[155]\ttraining's multi_logloss: 0.102235\tvalid_1's multi_logloss: 0.289831       \n",
      "[156]\ttraining's multi_logloss: 0.101509\tvalid_1's multi_logloss: 0.289935       \n",
      "[157]\ttraining's multi_logloss: 0.100702\tvalid_1's multi_logloss: 0.289957       \n",
      "[158]\ttraining's multi_logloss: 0.0998682\tvalid_1's multi_logloss: 0.290029      \n",
      "[159]\ttraining's multi_logloss: 0.099107\tvalid_1's multi_logloss: 0.290103       \n",
      "[160]\ttraining's multi_logloss: 0.0984011\tvalid_1's multi_logloss: 0.290138      \n",
      "[161]\ttraining's multi_logloss: 0.0976223\tvalid_1's multi_logloss: 0.29022       \n",
      "Early stopping, best iteration is:                                               \n",
      "[131]\ttraining's multi_logloss: 0.123149\tvalid_1's multi_logloss: 0.288851\n",
      "[1]\ttraining's multi_logloss: 1.74555\tvalid_1's multi_logloss: 1.74821           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.59801\tvalid_1's multi_logloss: 1.60163           \n",
      "[3]\ttraining's multi_logloss: 1.47595\tvalid_1's multi_logloss: 1.48055           \n",
      "[4]\ttraining's multi_logloss: 1.37159\tvalid_1's multi_logloss: 1.37748           \n",
      "[5]\ttraining's multi_logloss: 1.28089\tvalid_1's multi_logloss: 1.28776           \n",
      "[6]\ttraining's multi_logloss: 1.20098\tvalid_1's multi_logloss: 1.20896           \n",
      "[7]\ttraining's multi_logloss: 1.12994\tvalid_1's multi_logloss: 1.13882           \n",
      "[8]\ttraining's multi_logloss: 1.06617\tvalid_1's multi_logloss: 1.07604           \n",
      "[9]\ttraining's multi_logloss: 1.00832\tvalid_1's multi_logloss: 1.01929           \n",
      "[10]\ttraining's multi_logloss: 0.955822\tvalid_1's multi_logloss: 0.967483        \n",
      "[11]\ttraining's multi_logloss: 0.907977\tvalid_1's multi_logloss: 0.920344        \n",
      "[12]\ttraining's multi_logloss: 0.864257\tvalid_1's multi_logloss: 0.877774        \n",
      "[13]\ttraining's multi_logloss: 0.823782\tvalid_1's multi_logloss: 0.838194        \n",
      "[14]\ttraining's multi_logloss: 0.786411\tvalid_1's multi_logloss: 0.801975        \n",
      "[15]\ttraining's multi_logloss: 0.751764\tvalid_1's multi_logloss: 0.768594        \n",
      "[16]\ttraining's multi_logloss: 0.720099\tvalid_1's multi_logloss: 0.738233        \n",
      "[17]\ttraining's multi_logloss: 0.690204\tvalid_1's multi_logloss: 0.709602        \n",
      "[18]\ttraining's multi_logloss: 0.662377\tvalid_1's multi_logloss: 0.682911        \n",
      "[19]\ttraining's multi_logloss: 0.636471\tvalid_1's multi_logloss: 0.658012        \n",
      "[20]\ttraining's multi_logloss: 0.61246\tvalid_1's multi_logloss: 0.63509          \n",
      "[21]\ttraining's multi_logloss: 0.590073\tvalid_1's multi_logloss: 0.613659        \n",
      "[22]\ttraining's multi_logloss: 0.569411\tvalid_1's multi_logloss: 0.594216        \n",
      "[23]\ttraining's multi_logloss: 0.550042\tvalid_1's multi_logloss: 0.575807        \n",
      "[24]\ttraining's multi_logloss: 0.531823\tvalid_1's multi_logloss: 0.558761        \n",
      "[25]\ttraining's multi_logloss: 0.514876\tvalid_1's multi_logloss: 0.543043        \n",
      "[26]\ttraining's multi_logloss: 0.498647\tvalid_1's multi_logloss: 0.527754        \n",
      "[27]\ttraining's multi_logloss: 0.483429\tvalid_1's multi_logloss: 0.51352         \n",
      "[28]\ttraining's multi_logloss: 0.468878\tvalid_1's multi_logloss: 0.500019        \n",
      "[29]\ttraining's multi_logloss: 0.455364\tvalid_1's multi_logloss: 0.487595        \n",
      "[30]\ttraining's multi_logloss: 0.442484\tvalid_1's multi_logloss: 0.4758          \n",
      "[31]\ttraining's multi_logloss: 0.430395\tvalid_1's multi_logloss: 0.464767        \n",
      "[32]\ttraining's multi_logloss: 0.419008\tvalid_1's multi_logloss: 0.454404        \n",
      "[33]\ttraining's multi_logloss: 0.408096\tvalid_1's multi_logloss: 0.44464         \n",
      "[34]\ttraining's multi_logloss: 0.397875\tvalid_1's multi_logloss: 0.435492        \n",
      "[35]\ttraining's multi_logloss: 0.388599\tvalid_1's multi_logloss: 0.427356        \n",
      "[36]\ttraining's multi_logloss: 0.379772\tvalid_1's multi_logloss: 0.419636        \n",
      "[37]\ttraining's multi_logloss: 0.371353\tvalid_1's multi_logloss: 0.41238         \n",
      "[38]\ttraining's multi_logloss: 0.36314\tvalid_1's multi_logloss: 0.405196         \n",
      "[39]\ttraining's multi_logloss: 0.355396\tvalid_1's multi_logloss: 0.398626        \n",
      "[40]\ttraining's multi_logloss: 0.34791\tvalid_1's multi_logloss: 0.392177         \n",
      "[41]\ttraining's multi_logloss: 0.340901\tvalid_1's multi_logloss: 0.386096        \n",
      "[42]\ttraining's multi_logloss: 0.334055\tvalid_1's multi_logloss: 0.380301        \n",
      "[43]\ttraining's multi_logloss: 0.327485\tvalid_1's multi_logloss: 0.374898        \n",
      "[44]\ttraining's multi_logloss: 0.321275\tvalid_1's multi_logloss: 0.369956        \n",
      "[45]\ttraining's multi_logloss: 0.315251\tvalid_1's multi_logloss: 0.36504         \n",
      "[46]\ttraining's multi_logloss: 0.309602\tvalid_1's multi_logloss: 0.360446        \n",
      "[47]\ttraining's multi_logloss: 0.304184\tvalid_1's multi_logloss: 0.356149        \n",
      "[48]\ttraining's multi_logloss: 0.298964\tvalid_1's multi_logloss: 0.352115        \n",
      "[49]\ttraining's multi_logloss: 0.29381\tvalid_1's multi_logloss: 0.348122         \n",
      "[50]\ttraining's multi_logloss: 0.288949\tvalid_1's multi_logloss: 0.344325        \n",
      "[51]\ttraining's multi_logloss: 0.284429\tvalid_1's multi_logloss: 0.340898        \n",
      "[52]\ttraining's multi_logloss: 0.279973\tvalid_1's multi_logloss: 0.337709        \n",
      "[53]\ttraining's multi_logloss: 0.275634\tvalid_1's multi_logloss: 0.334361        \n",
      "[54]\ttraining's multi_logloss: 0.271627\tvalid_1's multi_logloss: 0.331661        \n",
      "[55]\ttraining's multi_logloss: 0.267584\tvalid_1's multi_logloss: 0.328778        \n",
      "[56]\ttraining's multi_logloss: 0.26385\tvalid_1's multi_logloss: 0.326326         \n",
      "[57]\ttraining's multi_logloss: 0.260166\tvalid_1's multi_logloss: 0.323896        \n",
      "[58]\ttraining's multi_logloss: 0.256588\tvalid_1's multi_logloss: 0.321699        \n",
      "[59]\ttraining's multi_logloss: 0.252984\tvalid_1's multi_logloss: 0.319404        \n",
      "[60]\ttraining's multi_logloss: 0.249731\tvalid_1's multi_logloss: 0.317534        \n",
      "[61]\ttraining's multi_logloss: 0.246455\tvalid_1's multi_logloss: 0.315468        \n",
      "[62]\ttraining's multi_logloss: 0.243121\tvalid_1's multi_logloss: 0.313764        \n",
      "[63]\ttraining's multi_logloss: 0.239945\tvalid_1's multi_logloss: 0.312092        \n",
      "[64]\ttraining's multi_logloss: 0.236836\tvalid_1's multi_logloss: 0.310378        \n",
      "[65]\ttraining's multi_logloss: 0.233838\tvalid_1's multi_logloss: 0.308926        \n",
      "[66]\ttraining's multi_logloss: 0.23101\tvalid_1's multi_logloss: 0.307601         \n",
      "[67]\ttraining's multi_logloss: 0.228254\tvalid_1's multi_logloss: 0.306077        \n",
      "[68]\ttraining's multi_logloss: 0.225558\tvalid_1's multi_logloss: 0.304869        \n",
      "[69]\ttraining's multi_logloss: 0.222884\tvalid_1's multi_logloss: 0.303649        \n",
      "[70]\ttraining's multi_logloss: 0.220291\tvalid_1's multi_logloss: 0.302305        \n",
      "[71]\ttraining's multi_logloss: 0.217839\tvalid_1's multi_logloss: 0.301207        \n",
      "[72]\ttraining's multi_logloss: 0.215398\tvalid_1's multi_logloss: 0.3             \n",
      "[73]\ttraining's multi_logloss: 0.212863\tvalid_1's multi_logloss: 0.298887        \n",
      "[74]\ttraining's multi_logloss: 0.210514\tvalid_1's multi_logloss: 0.297953        \n",
      "[75]\ttraining's multi_logloss: 0.208189\tvalid_1's multi_logloss: 0.29708         \n",
      "[76]\ttraining's multi_logloss: 0.20587\tvalid_1's multi_logloss: 0.296232         \n",
      "[77]\ttraining's multi_logloss: 0.203545\tvalid_1's multi_logloss: 0.295412        \n",
      "[78]\ttraining's multi_logloss: 0.201317\tvalid_1's multi_logloss: 0.294565        \n",
      "[79]\ttraining's multi_logloss: 0.199147\tvalid_1's multi_logloss: 0.293884        \n",
      "[80]\ttraining's multi_logloss: 0.196974\tvalid_1's multi_logloss: 0.293391        \n",
      "[81]\ttraining's multi_logloss: 0.194936\tvalid_1's multi_logloss: 0.292572        \n",
      "[82]\ttraining's multi_logloss: 0.192947\tvalid_1's multi_logloss: 0.291985        \n",
      "[83]\ttraining's multi_logloss: 0.190888\tvalid_1's multi_logloss: 0.291431        \n",
      "[84]\ttraining's multi_logloss: 0.188881\tvalid_1's multi_logloss: 0.290888        \n",
      "[85]\ttraining's multi_logloss: 0.186947\tvalid_1's multi_logloss: 0.290258        \n",
      "[86]\ttraining's multi_logloss: 0.185198\tvalid_1's multi_logloss: 0.28983         \n",
      "[87]\ttraining's multi_logloss: 0.18334\tvalid_1's multi_logloss: 0.289458         \n",
      "[88]\ttraining's multi_logloss: 0.181467\tvalid_1's multi_logloss: 0.288864        \n",
      "[89]\ttraining's multi_logloss: 0.179704\tvalid_1's multi_logloss: 0.288376        \n",
      "[90]\ttraining's multi_logloss: 0.177927\tvalid_1's multi_logloss: 0.287959        \n",
      "[91]\ttraining's multi_logloss: 0.176037\tvalid_1's multi_logloss: 0.287395        \n",
      "[92]\ttraining's multi_logloss: 0.174217\tvalid_1's multi_logloss: 0.287141        \n",
      "[93]\ttraining's multi_logloss: 0.172459\tvalid_1's multi_logloss: 0.286695        \n",
      "[94]\ttraining's multi_logloss: 0.170734\tvalid_1's multi_logloss: 0.286463        \n",
      "[95]\ttraining's multi_logloss: 0.168971\tvalid_1's multi_logloss: 0.286161        \n",
      "[96]\ttraining's multi_logloss: 0.167264\tvalid_1's multi_logloss: 0.285899        \n",
      "[97]\ttraining's multi_logloss: 0.165678\tvalid_1's multi_logloss: 0.285859        \n",
      "[98]\ttraining's multi_logloss: 0.164101\tvalid_1's multi_logloss: 0.285648        \n",
      "[99]\ttraining's multi_logloss: 0.162469\tvalid_1's multi_logloss: 0.285498        \n",
      "[100]\ttraining's multi_logloss: 0.160973\tvalid_1's multi_logloss: 0.285234       \n",
      "[101]\ttraining's multi_logloss: 0.159441\tvalid_1's multi_logloss: 0.284813       \n",
      "[102]\ttraining's multi_logloss: 0.157949\tvalid_1's multi_logloss: 0.284736       \n",
      "[103]\ttraining's multi_logloss: 0.156504\tvalid_1's multi_logloss: 0.284629       \n",
      "[104]\ttraining's multi_logloss: 0.155126\tvalid_1's multi_logloss: 0.284502       \n",
      "[105]\ttraining's multi_logloss: 0.153645\tvalid_1's multi_logloss: 0.284328       \n",
      "[106]\ttraining's multi_logloss: 0.152274\tvalid_1's multi_logloss: 0.284113       \n",
      "[107]\ttraining's multi_logloss: 0.150935\tvalid_1's multi_logloss: 0.283874       \n",
      "[108]\ttraining's multi_logloss: 0.149547\tvalid_1's multi_logloss: 0.283772       \n",
      "[109]\ttraining's multi_logloss: 0.148272\tvalid_1's multi_logloss: 0.283762       \n",
      "[110]\ttraining's multi_logloss: 0.146921\tvalid_1's multi_logloss: 0.283554       \n",
      "[111]\ttraining's multi_logloss: 0.145668\tvalid_1's multi_logloss: 0.283426       \n",
      "[112]\ttraining's multi_logloss: 0.144366\tvalid_1's multi_logloss: 0.283315       \n",
      "[113]\ttraining's multi_logloss: 0.143125\tvalid_1's multi_logloss: 0.283044       \n",
      "[114]\ttraining's multi_logloss: 0.141921\tvalid_1's multi_logloss: 0.28306        \n",
      "[115]\ttraining's multi_logloss: 0.14068\tvalid_1's multi_logloss: 0.282992        \n",
      "[116]\ttraining's multi_logloss: 0.139535\tvalid_1's multi_logloss: 0.282848       \n",
      "[117]\ttraining's multi_logloss: 0.138248\tvalid_1's multi_logloss: 0.282661       \n",
      "[118]\ttraining's multi_logloss: 0.137051\tvalid_1's multi_logloss: 0.282682       \n",
      "[119]\ttraining's multi_logloss: 0.135842\tvalid_1's multi_logloss: 0.282537       \n",
      "[120]\ttraining's multi_logloss: 0.134584\tvalid_1's multi_logloss: 0.282678       \n",
      "[121]\ttraining's multi_logloss: 0.133488\tvalid_1's multi_logloss: 0.282569       \n",
      "[122]\ttraining's multi_logloss: 0.132346\tvalid_1's multi_logloss: 0.282425       \n",
      "[123]\ttraining's multi_logloss: 0.131264\tvalid_1's multi_logloss: 0.282466       \n",
      "[124]\ttraining's multi_logloss: 0.13015\tvalid_1's multi_logloss: 0.282147        \n",
      "[125]\ttraining's multi_logloss: 0.129004\tvalid_1's multi_logloss: 0.282141       \n",
      "[126]\ttraining's multi_logloss: 0.127905\tvalid_1's multi_logloss: 0.282159       \n",
      "[127]\ttraining's multi_logloss: 0.126829\tvalid_1's multi_logloss: 0.282078       \n",
      "[128]\ttraining's multi_logloss: 0.125787\tvalid_1's multi_logloss: 0.282073       \n",
      "[129]\ttraining's multi_logloss: 0.124727\tvalid_1's multi_logloss: 0.282071       \n",
      "[130]\ttraining's multi_logloss: 0.12367\tvalid_1's multi_logloss: 0.281942        \n",
      "[131]\ttraining's multi_logloss: 0.122569\tvalid_1's multi_logloss: 0.281918       \n",
      "[132]\ttraining's multi_logloss: 0.12155\tvalid_1's multi_logloss: 0.281692        \n",
      "[133]\ttraining's multi_logloss: 0.120434\tvalid_1's multi_logloss: 0.281593       \n",
      "[134]\ttraining's multi_logloss: 0.119402\tvalid_1's multi_logloss: 0.281593       \n",
      "[135]\ttraining's multi_logloss: 0.118359\tvalid_1's multi_logloss: 0.281693       \n",
      "[136]\ttraining's multi_logloss: 0.117325\tvalid_1's multi_logloss: 0.281721       \n",
      "[137]\ttraining's multi_logloss: 0.11627\tvalid_1's multi_logloss: 0.281698        \n",
      "[138]\ttraining's multi_logloss: 0.115239\tvalid_1's multi_logloss: 0.281609       \n",
      "[139]\ttraining's multi_logloss: 0.114202\tvalid_1's multi_logloss: 0.281586       \n",
      "[140]\ttraining's multi_logloss: 0.113209\tvalid_1's multi_logloss: 0.281527       \n",
      "[141]\ttraining's multi_logloss: 0.112255\tvalid_1's multi_logloss: 0.281585       \n",
      "[142]\ttraining's multi_logloss: 0.111353\tvalid_1's multi_logloss: 0.281601       \n",
      "[143]\ttraining's multi_logloss: 0.110364\tvalid_1's multi_logloss: 0.28165        \n",
      "[144]\ttraining's multi_logloss: 0.109529\tvalid_1's multi_logloss: 0.281669       \n",
      "[145]\ttraining's multi_logloss: 0.108624\tvalid_1's multi_logloss: 0.281731       \n",
      "[146]\ttraining's multi_logloss: 0.107703\tvalid_1's multi_logloss: 0.281752       \n",
      "[147]\ttraining's multi_logloss: 0.106847\tvalid_1's multi_logloss: 0.282038       \n",
      "[148]\ttraining's multi_logloss: 0.106044\tvalid_1's multi_logloss: 0.282019       \n",
      "[149]\ttraining's multi_logloss: 0.105247\tvalid_1's multi_logloss: 0.282127       \n",
      "[150]\ttraining's multi_logloss: 0.104449\tvalid_1's multi_logloss: 0.282221       \n",
      "[151]\ttraining's multi_logloss: 0.103673\tvalid_1's multi_logloss: 0.282411       \n",
      "[152]\ttraining's multi_logloss: 0.102821\tvalid_1's multi_logloss: 0.282622       \n",
      "[153]\ttraining's multi_logloss: 0.102034\tvalid_1's multi_logloss: 0.282734       \n",
      "[154]\ttraining's multi_logloss: 0.101273\tvalid_1's multi_logloss: 0.28279        \n",
      "[155]\ttraining's multi_logloss: 0.100457\tvalid_1's multi_logloss: 0.282937       \n",
      "[156]\ttraining's multi_logloss: 0.0997026\tvalid_1's multi_logloss: 0.283119      \n",
      "[157]\ttraining's multi_logloss: 0.0988838\tvalid_1's multi_logloss: 0.283379      \n",
      "[158]\ttraining's multi_logloss: 0.098037\tvalid_1's multi_logloss: 0.283538       \n",
      "[159]\ttraining's multi_logloss: 0.0971898\tvalid_1's multi_logloss: 0.283507      \n",
      "[160]\ttraining's multi_logloss: 0.0965056\tvalid_1's multi_logloss: 0.283601      \n",
      "[161]\ttraining's multi_logloss: 0.0958076\tvalid_1's multi_logloss: 0.283888      \n",
      "[162]\ttraining's multi_logloss: 0.0950336\tvalid_1's multi_logloss: 0.284003      \n",
      "[163]\ttraining's multi_logloss: 0.0943296\tvalid_1's multi_logloss: 0.284236      \n",
      "[164]\ttraining's multi_logloss: 0.0936793\tvalid_1's multi_logloss: 0.284284      \n",
      "[165]\ttraining's multi_logloss: 0.0929174\tvalid_1's multi_logloss: 0.2846        \n",
      "[166]\ttraining's multi_logloss: 0.0922417\tvalid_1's multi_logloss: 0.284751      \n",
      "[167]\ttraining's multi_logloss: 0.0915105\tvalid_1's multi_logloss: 0.284852      \n",
      "[168]\ttraining's multi_logloss: 0.0906829\tvalid_1's multi_logloss: 0.284968      \n",
      "[169]\ttraining's multi_logloss: 0.089913\tvalid_1's multi_logloss: 0.285184       \n",
      "[170]\ttraining's multi_logloss: 0.0891679\tvalid_1's multi_logloss: 0.285272      \n",
      "Early stopping, best iteration is:                                               \n",
      "[140]\ttraining's multi_logloss: 0.113209\tvalid_1's multi_logloss: 0.281527\n",
      "[1]\ttraining's multi_logloss: 1.74639\tvalid_1's multi_logloss: 1.74915           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.60031\tvalid_1's multi_logloss: 1.60443           \n",
      "[3]\ttraining's multi_logloss: 1.47754\tvalid_1's multi_logloss: 1.48263           \n",
      "[4]\ttraining's multi_logloss: 1.37307\tvalid_1's multi_logloss: 1.37873           \n",
      "[5]\ttraining's multi_logloss: 1.28211\tvalid_1's multi_logloss: 1.28872           \n",
      "[6]\ttraining's multi_logloss: 1.2018\tvalid_1's multi_logloss: 1.20882            \n",
      "[7]\ttraining's multi_logloss: 1.13134\tvalid_1's multi_logloss: 1.13935           \n",
      "[8]\ttraining's multi_logloss: 1.06725\tvalid_1's multi_logloss: 1.07579           \n",
      "[9]\ttraining's multi_logloss: 1.00904\tvalid_1's multi_logloss: 1.01822           \n",
      "[10]\ttraining's multi_logloss: 0.956389\tvalid_1's multi_logloss: 0.96621         \n",
      "[11]\ttraining's multi_logloss: 0.908811\tvalid_1's multi_logloss: 0.91889         \n",
      "[12]\ttraining's multi_logloss: 0.864462\tvalid_1's multi_logloss: 0.875249        \n",
      "[13]\ttraining's multi_logloss: 0.823429\tvalid_1's multi_logloss: 0.834989        \n",
      "[14]\ttraining's multi_logloss: 0.785911\tvalid_1's multi_logloss: 0.798135        \n",
      "[15]\ttraining's multi_logloss: 0.751609\tvalid_1's multi_logloss: 0.764812        \n",
      "[16]\ttraining's multi_logloss: 0.719908\tvalid_1's multi_logloss: 0.734064        \n",
      "[17]\ttraining's multi_logloss: 0.690331\tvalid_1's multi_logloss: 0.705397        \n",
      "[18]\ttraining's multi_logloss: 0.662494\tvalid_1's multi_logloss: 0.678271        \n",
      "[19]\ttraining's multi_logloss: 0.63653\tvalid_1's multi_logloss: 0.653002         \n",
      "[20]\ttraining's multi_logloss: 0.61288\tvalid_1's multi_logloss: 0.630164         \n",
      "[21]\ttraining's multi_logloss: 0.591121\tvalid_1's multi_logloss: 0.609368        \n",
      "[22]\ttraining's multi_logloss: 0.570125\tvalid_1's multi_logloss: 0.589152        \n",
      "[23]\ttraining's multi_logloss: 0.550946\tvalid_1's multi_logloss: 0.570838        \n",
      "[24]\ttraining's multi_logloss: 0.532718\tvalid_1's multi_logloss: 0.553477        \n",
      "[25]\ttraining's multi_logloss: 0.51575\tvalid_1's multi_logloss: 0.537166         \n",
      "[26]\ttraining's multi_logloss: 0.499992\tvalid_1's multi_logloss: 0.522199        \n",
      "[27]\ttraining's multi_logloss: 0.484957\tvalid_1's multi_logloss: 0.507908        \n",
      "[28]\ttraining's multi_logloss: 0.470869\tvalid_1's multi_logloss: 0.494707        \n",
      "[29]\ttraining's multi_logloss: 0.457712\tvalid_1's multi_logloss: 0.482342        \n",
      "[30]\ttraining's multi_logloss: 0.445249\tvalid_1's multi_logloss: 0.470641        \n",
      "[31]\ttraining's multi_logloss: 0.433342\tvalid_1's multi_logloss: 0.459698        \n",
      "[32]\ttraining's multi_logloss: 0.421993\tvalid_1's multi_logloss: 0.449062        \n",
      "[33]\ttraining's multi_logloss: 0.41135\tvalid_1's multi_logloss: 0.439259         \n",
      "[34]\ttraining's multi_logloss: 0.401315\tvalid_1's multi_logloss: 0.429993        \n",
      "[35]\ttraining's multi_logloss: 0.391785\tvalid_1's multi_logloss: 0.421238        \n",
      "[36]\ttraining's multi_logloss: 0.382748\tvalid_1's multi_logloss: 0.412939        \n",
      "[37]\ttraining's multi_logloss: 0.374342\tvalid_1's multi_logloss: 0.405276        \n",
      "[38]\ttraining's multi_logloss: 0.366139\tvalid_1's multi_logloss: 0.397972        \n",
      "[39]\ttraining's multi_logloss: 0.358605\tvalid_1's multi_logloss: 0.391125        \n",
      "[40]\ttraining's multi_logloss: 0.351358\tvalid_1's multi_logloss: 0.38477         \n",
      "[41]\ttraining's multi_logloss: 0.344415\tvalid_1's multi_logloss: 0.37875         \n",
      "[42]\ttraining's multi_logloss: 0.337953\tvalid_1's multi_logloss: 0.373042        \n",
      "[43]\ttraining's multi_logloss: 0.331515\tvalid_1's multi_logloss: 0.367608        \n",
      "[44]\ttraining's multi_logloss: 0.325499\tvalid_1's multi_logloss: 0.362474        \n",
      "[45]\ttraining's multi_logloss: 0.31973\tvalid_1's multi_logloss: 0.357692         \n",
      "[46]\ttraining's multi_logloss: 0.314298\tvalid_1's multi_logloss: 0.353073        \n",
      "[47]\ttraining's multi_logloss: 0.308976\tvalid_1's multi_logloss: 0.348568        \n",
      "[48]\ttraining's multi_logloss: 0.303794\tvalid_1's multi_logloss: 0.344169        \n",
      "[49]\ttraining's multi_logloss: 0.298842\tvalid_1's multi_logloss: 0.340375        \n",
      "[50]\ttraining's multi_logloss: 0.293971\tvalid_1's multi_logloss: 0.336583        \n",
      "[51]\ttraining's multi_logloss: 0.289242\tvalid_1's multi_logloss: 0.332574        \n",
      "[52]\ttraining's multi_logloss: 0.284952\tvalid_1's multi_logloss: 0.329461        \n",
      "[53]\ttraining's multi_logloss: 0.28068\tvalid_1's multi_logloss: 0.326179         \n",
      "[54]\ttraining's multi_logloss: 0.276613\tvalid_1's multi_logloss: 0.323079        \n",
      "[55]\ttraining's multi_logloss: 0.272704\tvalid_1's multi_logloss: 0.320286        \n",
      "[56]\ttraining's multi_logloss: 0.268739\tvalid_1's multi_logloss: 0.317762        \n",
      "[57]\ttraining's multi_logloss: 0.265068\tvalid_1's multi_logloss: 0.315493        \n",
      "[58]\ttraining's multi_logloss: 0.261411\tvalid_1's multi_logloss: 0.313084        \n",
      "[59]\ttraining's multi_logloss: 0.257961\tvalid_1's multi_logloss: 0.310742        \n",
      "[60]\ttraining's multi_logloss: 0.254552\tvalid_1's multi_logloss: 0.308697        \n",
      "[61]\ttraining's multi_logloss: 0.251282\tvalid_1's multi_logloss: 0.306546        \n",
      "[62]\ttraining's multi_logloss: 0.248165\tvalid_1's multi_logloss: 0.304816        \n",
      "[63]\ttraining's multi_logloss: 0.245164\tvalid_1's multi_logloss: 0.302905        \n",
      "[64]\ttraining's multi_logloss: 0.242271\tvalid_1's multi_logloss: 0.301153        \n",
      "[65]\ttraining's multi_logloss: 0.239352\tvalid_1's multi_logloss: 0.2991          \n",
      "[66]\ttraining's multi_logloss: 0.236468\tvalid_1's multi_logloss: 0.297412        \n",
      "[67]\ttraining's multi_logloss: 0.233794\tvalid_1's multi_logloss: 0.295946        \n",
      "[68]\ttraining's multi_logloss: 0.231115\tvalid_1's multi_logloss: 0.294419        \n",
      "[69]\ttraining's multi_logloss: 0.228587\tvalid_1's multi_logloss: 0.293014        \n",
      "[70]\ttraining's multi_logloss: 0.226084\tvalid_1's multi_logloss: 0.2918          \n",
      "[71]\ttraining's multi_logloss: 0.223699\tvalid_1's multi_logloss: 0.290639        \n",
      "[72]\ttraining's multi_logloss: 0.221339\tvalid_1's multi_logloss: 0.289355        \n",
      "[73]\ttraining's multi_logloss: 0.218969\tvalid_1's multi_logloss: 0.288146        \n",
      "[74]\ttraining's multi_logloss: 0.216601\tvalid_1's multi_logloss: 0.28694         \n",
      "[75]\ttraining's multi_logloss: 0.214426\tvalid_1's multi_logloss: 0.28608         \n",
      "[76]\ttraining's multi_logloss: 0.212152\tvalid_1's multi_logloss: 0.285082        \n",
      "[77]\ttraining's multi_logloss: 0.209849\tvalid_1's multi_logloss: 0.284145        \n",
      "[78]\ttraining's multi_logloss: 0.20765\tvalid_1's multi_logloss: 0.283482         \n",
      "[79]\ttraining's multi_logloss: 0.20557\tvalid_1's multi_logloss: 0.282683         \n",
      "[80]\ttraining's multi_logloss: 0.203463\tvalid_1's multi_logloss: 0.282049        \n",
      "[81]\ttraining's multi_logloss: 0.201299\tvalid_1's multi_logloss: 0.281211        \n",
      "[82]\ttraining's multi_logloss: 0.199351\tvalid_1's multi_logloss: 0.280632        \n",
      "[83]\ttraining's multi_logloss: 0.197382\tvalid_1's multi_logloss: 0.279826        \n",
      "[84]\ttraining's multi_logloss: 0.195454\tvalid_1's multi_logloss: 0.279101        \n",
      "[85]\ttraining's multi_logloss: 0.193611\tvalid_1's multi_logloss: 0.27845         \n",
      "[86]\ttraining's multi_logloss: 0.191743\tvalid_1's multi_logloss: 0.277874        \n",
      "[87]\ttraining's multi_logloss: 0.189873\tvalid_1's multi_logloss: 0.27709         \n",
      "[88]\ttraining's multi_logloss: 0.188049\tvalid_1's multi_logloss: 0.276575        \n",
      "[89]\ttraining's multi_logloss: 0.186213\tvalid_1's multi_logloss: 0.2761          \n",
      "[90]\ttraining's multi_logloss: 0.184474\tvalid_1's multi_logloss: 0.275417        \n",
      "[91]\ttraining's multi_logloss: 0.182697\tvalid_1's multi_logloss: 0.274984        \n",
      "[92]\ttraining's multi_logloss: 0.181009\tvalid_1's multi_logloss: 0.274711        \n",
      "[93]\ttraining's multi_logloss: 0.179292\tvalid_1's multi_logloss: 0.274181        \n",
      "[94]\ttraining's multi_logloss: 0.177614\tvalid_1's multi_logloss: 0.273734        \n",
      "[95]\ttraining's multi_logloss: 0.1759\tvalid_1's multi_logloss: 0.273366          \n",
      "[96]\ttraining's multi_logloss: 0.174221\tvalid_1's multi_logloss: 0.273071        \n",
      "[97]\ttraining's multi_logloss: 0.172715\tvalid_1's multi_logloss: 0.272682        \n",
      "[98]\ttraining's multi_logloss: 0.171012\tvalid_1's multi_logloss: 0.272368        \n",
      "[99]\ttraining's multi_logloss: 0.169462\tvalid_1's multi_logloss: 0.27212         \n",
      "[100]\ttraining's multi_logloss: 0.167872\tvalid_1's multi_logloss: 0.27196        \n",
      "[101]\ttraining's multi_logloss: 0.166207\tvalid_1's multi_logloss: 0.271755       \n",
      "[102]\ttraining's multi_logloss: 0.164509\tvalid_1's multi_logloss: 0.271471       \n",
      "[103]\ttraining's multi_logloss: 0.162946\tvalid_1's multi_logloss: 0.271045       \n",
      "[104]\ttraining's multi_logloss: 0.161477\tvalid_1's multi_logloss: 0.270792       \n",
      "[105]\ttraining's multi_logloss: 0.159881\tvalid_1's multi_logloss: 0.270454       \n",
      "[106]\ttraining's multi_logloss: 0.15833\tvalid_1's multi_logloss: 0.270145        \n",
      "[107]\ttraining's multi_logloss: 0.15691\tvalid_1's multi_logloss: 0.269954        \n",
      "[108]\ttraining's multi_logloss: 0.155485\tvalid_1's multi_logloss: 0.269786       \n",
      "[109]\ttraining's multi_logloss: 0.154115\tvalid_1's multi_logloss: 0.26964        \n",
      "[110]\ttraining's multi_logloss: 0.152694\tvalid_1's multi_logloss: 0.269527       \n",
      "[111]\ttraining's multi_logloss: 0.151326\tvalid_1's multi_logloss: 0.269389       \n",
      "[112]\ttraining's multi_logloss: 0.149979\tvalid_1's multi_logloss: 0.269198       \n",
      "[113]\ttraining's multi_logloss: 0.148572\tvalid_1's multi_logloss: 0.268903       \n",
      "[114]\ttraining's multi_logloss: 0.147238\tvalid_1's multi_logloss: 0.268625       \n",
      "[115]\ttraining's multi_logloss: 0.145984\tvalid_1's multi_logloss: 0.268412       \n",
      "[116]\ttraining's multi_logloss: 0.144706\tvalid_1's multi_logloss: 0.268377       \n",
      "[117]\ttraining's multi_logloss: 0.143389\tvalid_1's multi_logloss: 0.26808        \n",
      "[118]\ttraining's multi_logloss: 0.142188\tvalid_1's multi_logloss: 0.267883       \n",
      "[119]\ttraining's multi_logloss: 0.140986\tvalid_1's multi_logloss: 0.26793        \n",
      "[120]\ttraining's multi_logloss: 0.139779\tvalid_1's multi_logloss: 0.267588       \n",
      "[121]\ttraining's multi_logloss: 0.138545\tvalid_1's multi_logloss: 0.267565       \n",
      "[122]\ttraining's multi_logloss: 0.137378\tvalid_1's multi_logloss: 0.267572       \n",
      "[123]\ttraining's multi_logloss: 0.13624\tvalid_1's multi_logloss: 0.267483        \n",
      "[124]\ttraining's multi_logloss: 0.13508\tvalid_1's multi_logloss: 0.267373        \n",
      "[125]\ttraining's multi_logloss: 0.134025\tvalid_1's multi_logloss: 0.267219       \n",
      "[126]\ttraining's multi_logloss: 0.133054\tvalid_1's multi_logloss: 0.267226       \n",
      "[127]\ttraining's multi_logloss: 0.131991\tvalid_1's multi_logloss: 0.267286       \n",
      "[128]\ttraining's multi_logloss: 0.130937\tvalid_1's multi_logloss: 0.267329       \n",
      "[129]\ttraining's multi_logloss: 0.129844\tvalid_1's multi_logloss: 0.267251       \n",
      "[130]\ttraining's multi_logloss: 0.128806\tvalid_1's multi_logloss: 0.267371       \n",
      "[131]\ttraining's multi_logloss: 0.127645\tvalid_1's multi_logloss: 0.267339       \n",
      "[132]\ttraining's multi_logloss: 0.126671\tvalid_1's multi_logloss: 0.267444       \n",
      "[133]\ttraining's multi_logloss: 0.125627\tvalid_1's multi_logloss: 0.267475       \n",
      "[134]\ttraining's multi_logloss: 0.124676\tvalid_1's multi_logloss: 0.267409       \n",
      "[135]\ttraining's multi_logloss: 0.123672\tvalid_1's multi_logloss: 0.267274       \n",
      "[136]\ttraining's multi_logloss: 0.122746\tvalid_1's multi_logloss: 0.267377       \n",
      "[137]\ttraining's multi_logloss: 0.121755\tvalid_1's multi_logloss: 0.267265       \n",
      "[138]\ttraining's multi_logloss: 0.120832\tvalid_1's multi_logloss: 0.267267       \n",
      "[139]\ttraining's multi_logloss: 0.11995\tvalid_1's multi_logloss: 0.267172        \n",
      "[140]\ttraining's multi_logloss: 0.118911\tvalid_1's multi_logloss: 0.267127       \n",
      "[141]\ttraining's multi_logloss: 0.117995\tvalid_1's multi_logloss: 0.267154       \n",
      "[142]\ttraining's multi_logloss: 0.117034\tvalid_1's multi_logloss: 0.267083       \n",
      "[143]\ttraining's multi_logloss: 0.116167\tvalid_1's multi_logloss: 0.267233       \n",
      "[144]\ttraining's multi_logloss: 0.115219\tvalid_1's multi_logloss: 0.267273       \n",
      "[145]\ttraining's multi_logloss: 0.114329\tvalid_1's multi_logloss: 0.267437       \n",
      "[146]\ttraining's multi_logloss: 0.113515\tvalid_1's multi_logloss: 0.267565       \n",
      "[147]\ttraining's multi_logloss: 0.112605\tvalid_1's multi_logloss: 0.267598       \n",
      "[148]\ttraining's multi_logloss: 0.111813\tvalid_1's multi_logloss: 0.267605       \n",
      "[149]\ttraining's multi_logloss: 0.110882\tvalid_1's multi_logloss: 0.267501       \n",
      "[150]\ttraining's multi_logloss: 0.110082\tvalid_1's multi_logloss: 0.267498       \n",
      "[151]\ttraining's multi_logloss: 0.109317\tvalid_1's multi_logloss: 0.26759        \n",
      "[152]\ttraining's multi_logloss: 0.108483\tvalid_1's multi_logloss: 0.26774        \n",
      "[153]\ttraining's multi_logloss: 0.107712\tvalid_1's multi_logloss: 0.267803       \n",
      "[154]\ttraining's multi_logloss: 0.106993\tvalid_1's multi_logloss: 0.267876       \n",
      "[155]\ttraining's multi_logloss: 0.106221\tvalid_1's multi_logloss: 0.267962       \n",
      "[156]\ttraining's multi_logloss: 0.105457\tvalid_1's multi_logloss: 0.268207       \n",
      "[157]\ttraining's multi_logloss: 0.104753\tvalid_1's multi_logloss: 0.268156       \n",
      "[158]\ttraining's multi_logloss: 0.103999\tvalid_1's multi_logloss: 0.268254       \n",
      "[159]\ttraining's multi_logloss: 0.103252\tvalid_1's multi_logloss: 0.268245       \n",
      "[160]\ttraining's multi_logloss: 0.102494\tvalid_1's multi_logloss: 0.268267       \n",
      "[161]\ttraining's multi_logloss: 0.10178\tvalid_1's multi_logloss: 0.268271        \n",
      "[162]\ttraining's multi_logloss: 0.101026\tvalid_1's multi_logloss: 0.268343       \n",
      "[163]\ttraining's multi_logloss: 0.100309\tvalid_1's multi_logloss: 0.268524       \n",
      "[164]\ttraining's multi_logloss: 0.0996024\tvalid_1's multi_logloss: 0.268488      \n",
      "[165]\ttraining's multi_logloss: 0.0988956\tvalid_1's multi_logloss: 0.268486      \n",
      "[166]\ttraining's multi_logloss: 0.0982349\tvalid_1's multi_logloss: 0.268805      \n",
      "[167]\ttraining's multi_logloss: 0.0974908\tvalid_1's multi_logloss: 0.268787      \n",
      "[168]\ttraining's multi_logloss: 0.0967883\tvalid_1's multi_logloss: 0.268934      \n",
      "[169]\ttraining's multi_logloss: 0.0961011\tvalid_1's multi_logloss: 0.269142      \n",
      "[170]\ttraining's multi_logloss: 0.0954851\tvalid_1's multi_logloss: 0.269265      \n",
      "[171]\ttraining's multi_logloss: 0.0947531\tvalid_1's multi_logloss: 0.269356      \n",
      "[172]\ttraining's multi_logloss: 0.0940778\tvalid_1's multi_logloss: 0.269493      \n",
      "Early stopping, best iteration is:                                               \n",
      "[142]\ttraining's multi_logloss: 0.117034\tvalid_1's multi_logloss: 0.267083\n",
      "[1]\ttraining's multi_logloss: 1.69614\tvalid_1's multi_logloss: 1.69886           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.51704\tvalid_1's multi_logloss: 1.52406           \n",
      "[3]\ttraining's multi_logloss: 1.37402\tvalid_1's multi_logloss: 1.38514           \n",
      "[4]\ttraining's multi_logloss: 1.2551\tvalid_1's multi_logloss: 1.26937            \n",
      "[5]\ttraining's multi_logloss: 1.15408\tvalid_1's multi_logloss: 1.17158           \n",
      "[6]\ttraining's multi_logloss: 1.06731\tvalid_1's multi_logloss: 1.08761           \n",
      "[7]\ttraining's multi_logloss: 0.991748\tvalid_1's multi_logloss: 1.01449          \n",
      "[8]\ttraining's multi_logloss: 0.92436\tvalid_1's multi_logloss: 0.949622          \n",
      "[9]\ttraining's multi_logloss: 0.864672\tvalid_1's multi_logloss: 0.891879         \n",
      "[10]\ttraining's multi_logloss: 0.811057\tvalid_1's multi_logloss: 0.840346        \n",
      "[11]\ttraining's multi_logloss: 0.763136\tvalid_1's multi_logloss: 0.794338        \n",
      "[12]\ttraining's multi_logloss: 0.72\tvalid_1's multi_logloss: 0.753025            \n",
      "[13]\ttraining's multi_logloss: 0.68055\tvalid_1's multi_logloss: 0.715376         \n",
      "[14]\ttraining's multi_logloss: 0.644599\tvalid_1's multi_logloss: 0.681126        \n",
      "[15]\ttraining's multi_logloss: 0.611848\tvalid_1's multi_logloss: 0.65013         \n",
      "[16]\ttraining's multi_logloss: 0.581813\tvalid_1's multi_logloss: 0.621891        \n",
      "[17]\ttraining's multi_logloss: 0.554667\tvalid_1's multi_logloss: 0.596359        \n",
      "[18]\ttraining's multi_logloss: 0.529734\tvalid_1's multi_logloss: 0.572839        \n",
      "[19]\ttraining's multi_logloss: 0.506791\tvalid_1's multi_logloss: 0.551456        \n",
      "[20]\ttraining's multi_logloss: 0.485366\tvalid_1's multi_logloss: 0.531434        \n",
      "[21]\ttraining's multi_logloss: 0.46621\tvalid_1's multi_logloss: 0.513959         \n",
      "[22]\ttraining's multi_logloss: 0.447812\tvalid_1's multi_logloss: 0.497041        \n",
      "[23]\ttraining's multi_logloss: 0.431176\tvalid_1's multi_logloss: 0.481697        \n",
      "[24]\ttraining's multi_logloss: 0.415626\tvalid_1's multi_logloss: 0.467839        \n",
      "[25]\ttraining's multi_logloss: 0.40102\tvalid_1's multi_logloss: 0.454575         \n",
      "[26]\ttraining's multi_logloss: 0.387574\tvalid_1's multi_logloss: 0.442522        \n",
      "[27]\ttraining's multi_logloss: 0.375044\tvalid_1's multi_logloss: 0.431285        \n",
      "[28]\ttraining's multi_logloss: 0.363479\tvalid_1's multi_logloss: 0.42116         \n",
      "[29]\ttraining's multi_logloss: 0.352846\tvalid_1's multi_logloss: 0.411804        \n",
      "[30]\ttraining's multi_logloss: 0.342924\tvalid_1's multi_logloss: 0.403568        \n",
      "[31]\ttraining's multi_logloss: 0.333175\tvalid_1's multi_logloss: 0.39548         \n",
      "[32]\ttraining's multi_logloss: 0.324337\tvalid_1's multi_logloss: 0.388143        \n",
      "[33]\ttraining's multi_logloss: 0.315922\tvalid_1's multi_logloss: 0.381078        \n",
      "[34]\ttraining's multi_logloss: 0.308044\tvalid_1's multi_logloss: 0.375139        \n",
      "[35]\ttraining's multi_logloss: 0.300626\tvalid_1's multi_logloss: 0.369409        \n",
      "[36]\ttraining's multi_logloss: 0.293572\tvalid_1's multi_logloss: 0.363921        \n",
      "[37]\ttraining's multi_logloss: 0.28682\tvalid_1's multi_logloss: 0.358646         \n",
      "[38]\ttraining's multi_logloss: 0.280579\tvalid_1's multi_logloss: 0.353908        \n",
      "[39]\ttraining's multi_logloss: 0.274391\tvalid_1's multi_logloss: 0.349455        \n",
      "[40]\ttraining's multi_logloss: 0.268743\tvalid_1's multi_logloss: 0.345508        \n",
      "[41]\ttraining's multi_logloss: 0.263222\tvalid_1's multi_logloss: 0.341625        \n",
      "[42]\ttraining's multi_logloss: 0.258032\tvalid_1's multi_logloss: 0.338006        \n",
      "[43]\ttraining's multi_logloss: 0.253113\tvalid_1's multi_logloss: 0.334735        \n",
      "[44]\ttraining's multi_logloss: 0.248371\tvalid_1's multi_logloss: 0.331888        \n",
      "[45]\ttraining's multi_logloss: 0.243643\tvalid_1's multi_logloss: 0.328923        \n",
      "[46]\ttraining's multi_logloss: 0.239287\tvalid_1's multi_logloss: 0.32635         \n",
      "[47]\ttraining's multi_logloss: 0.235111\tvalid_1's multi_logloss: 0.324009        \n",
      "[48]\ttraining's multi_logloss: 0.23085\tvalid_1's multi_logloss: 0.321516         \n",
      "[49]\ttraining's multi_logloss: 0.226922\tvalid_1's multi_logloss: 0.319109        \n",
      "[50]\ttraining's multi_logloss: 0.222935\tvalid_1's multi_logloss: 0.316879        \n",
      "[51]\ttraining's multi_logloss: 0.219186\tvalid_1's multi_logloss: 0.314942        \n",
      "[52]\ttraining's multi_logloss: 0.215844\tvalid_1's multi_logloss: 0.313253        \n",
      "[53]\ttraining's multi_logloss: 0.212342\tvalid_1's multi_logloss: 0.311259        \n",
      "[54]\ttraining's multi_logloss: 0.208906\tvalid_1's multi_logloss: 0.309614        \n",
      "[55]\ttraining's multi_logloss: 0.20572\tvalid_1's multi_logloss: 0.308089         \n",
      "[56]\ttraining's multi_logloss: 0.202687\tvalid_1's multi_logloss: 0.306909        \n",
      "[57]\ttraining's multi_logloss: 0.199676\tvalid_1's multi_logloss: 0.305652        \n",
      "[58]\ttraining's multi_logloss: 0.196693\tvalid_1's multi_logloss: 0.304475        \n",
      "[59]\ttraining's multi_logloss: 0.193756\tvalid_1's multi_logloss: 0.303307        \n",
      "[60]\ttraining's multi_logloss: 0.190972\tvalid_1's multi_logloss: 0.302191        \n",
      "[61]\ttraining's multi_logloss: 0.188269\tvalid_1's multi_logloss: 0.301223        \n",
      "[62]\ttraining's multi_logloss: 0.185458\tvalid_1's multi_logloss: 0.300373        \n",
      "[63]\ttraining's multi_logloss: 0.182981\tvalid_1's multi_logloss: 0.299683        \n",
      "[64]\ttraining's multi_logloss: 0.180351\tvalid_1's multi_logloss: 0.298813        \n",
      "[65]\ttraining's multi_logloss: 0.177914\tvalid_1's multi_logloss: 0.297841        \n",
      "[66]\ttraining's multi_logloss: 0.175507\tvalid_1's multi_logloss: 0.29708         \n",
      "[67]\ttraining's multi_logloss: 0.17307\tvalid_1's multi_logloss: 0.296332         \n",
      "[68]\ttraining's multi_logloss: 0.170689\tvalid_1's multi_logloss: 0.295572        \n",
      "[69]\ttraining's multi_logloss: 0.168409\tvalid_1's multi_logloss: 0.294834        \n",
      "[70]\ttraining's multi_logloss: 0.166051\tvalid_1's multi_logloss: 0.294061        \n",
      "[71]\ttraining's multi_logloss: 0.163833\tvalid_1's multi_logloss: 0.293487        \n",
      "[72]\ttraining's multi_logloss: 0.161489\tvalid_1's multi_logloss: 0.29308         \n",
      "[73]\ttraining's multi_logloss: 0.159345\tvalid_1's multi_logloss: 0.292842        \n",
      "[74]\ttraining's multi_logloss: 0.157179\tvalid_1's multi_logloss: 0.292349        \n",
      "[75]\ttraining's multi_logloss: 0.15517\tvalid_1's multi_logloss: 0.292131         \n",
      "[76]\ttraining's multi_logloss: 0.153149\tvalid_1's multi_logloss: 0.291756        \n",
      "[77]\ttraining's multi_logloss: 0.151212\tvalid_1's multi_logloss: 0.291415        \n",
      "[78]\ttraining's multi_logloss: 0.149241\tvalid_1's multi_logloss: 0.291088        \n",
      "[79]\ttraining's multi_logloss: 0.147324\tvalid_1's multi_logloss: 0.290766        \n",
      "[80]\ttraining's multi_logloss: 0.145355\tvalid_1's multi_logloss: 0.29043         \n",
      "[81]\ttraining's multi_logloss: 0.14351\tvalid_1's multi_logloss: 0.290092         \n",
      "[82]\ttraining's multi_logloss: 0.141614\tvalid_1's multi_logloss: 0.289703        \n",
      "[83]\ttraining's multi_logloss: 0.139902\tvalid_1's multi_logloss: 0.289755        \n",
      "[84]\ttraining's multi_logloss: 0.138195\tvalid_1's multi_logloss: 0.289562        \n",
      "[85]\ttraining's multi_logloss: 0.136575\tvalid_1's multi_logloss: 0.289447        \n",
      "[86]\ttraining's multi_logloss: 0.134929\tvalid_1's multi_logloss: 0.289272        \n",
      "[87]\ttraining's multi_logloss: 0.133282\tvalid_1's multi_logloss: 0.28924         \n",
      "[88]\ttraining's multi_logloss: 0.131692\tvalid_1's multi_logloss: 0.289167        \n",
      "[89]\ttraining's multi_logloss: 0.130045\tvalid_1's multi_logloss: 0.288871        \n",
      "[90]\ttraining's multi_logloss: 0.128399\tvalid_1's multi_logloss: 0.288758        \n",
      "[91]\ttraining's multi_logloss: 0.126791\tvalid_1's multi_logloss: 0.288509        \n",
      "[92]\ttraining's multi_logloss: 0.125324\tvalid_1's multi_logloss: 0.288426        \n",
      "[93]\ttraining's multi_logloss: 0.123809\tvalid_1's multi_logloss: 0.28846         \n",
      "[94]\ttraining's multi_logloss: 0.122396\tvalid_1's multi_logloss: 0.288284        \n",
      "[95]\ttraining's multi_logloss: 0.121037\tvalid_1's multi_logloss: 0.288233        \n",
      "[96]\ttraining's multi_logloss: 0.11958\tvalid_1's multi_logloss: 0.288053         \n",
      "[97]\ttraining's multi_logloss: 0.118176\tvalid_1's multi_logloss: 0.287836        \n",
      "[98]\ttraining's multi_logloss: 0.116826\tvalid_1's multi_logloss: 0.287826        \n",
      "[99]\ttraining's multi_logloss: 0.115528\tvalid_1's multi_logloss: 0.287998        \n",
      "[100]\ttraining's multi_logloss: 0.114193\tvalid_1's multi_logloss: 0.287723       \n",
      "[101]\ttraining's multi_logloss: 0.112825\tvalid_1's multi_logloss: 0.287794       \n",
      "[102]\ttraining's multi_logloss: 0.111509\tvalid_1's multi_logloss: 0.287924       \n",
      "[103]\ttraining's multi_logloss: 0.110271\tvalid_1's multi_logloss: 0.287948       \n",
      "[104]\ttraining's multi_logloss: 0.109024\tvalid_1's multi_logloss: 0.287945       \n",
      "[105]\ttraining's multi_logloss: 0.107813\tvalid_1's multi_logloss: 0.288402       \n",
      "[106]\ttraining's multi_logloss: 0.106668\tvalid_1's multi_logloss: 0.288421       \n",
      "[107]\ttraining's multi_logloss: 0.105494\tvalid_1's multi_logloss: 0.28864        \n",
      "[108]\ttraining's multi_logloss: 0.104337\tvalid_1's multi_logloss: 0.288792       \n",
      "[109]\ttraining's multi_logloss: 0.10316\tvalid_1's multi_logloss: 0.288811        \n",
      "[110]\ttraining's multi_logloss: 0.101948\tvalid_1's multi_logloss: 0.288907       \n",
      "[111]\ttraining's multi_logloss: 0.100785\tvalid_1's multi_logloss: 0.28903        \n",
      "[112]\ttraining's multi_logloss: 0.0996851\tvalid_1's multi_logloss: 0.289089      \n",
      "[113]\ttraining's multi_logloss: 0.0987103\tvalid_1's multi_logloss: 0.28912       \n",
      "[114]\ttraining's multi_logloss: 0.0976599\tvalid_1's multi_logloss: 0.289253      \n",
      "[115]\ttraining's multi_logloss: 0.0966357\tvalid_1's multi_logloss: 0.289307      \n",
      "[116]\ttraining's multi_logloss: 0.095647\tvalid_1's multi_logloss: 0.289384       \n",
      "[117]\ttraining's multi_logloss: 0.0947132\tvalid_1's multi_logloss: 0.289552      \n",
      "[118]\ttraining's multi_logloss: 0.0936449\tvalid_1's multi_logloss: 0.289597      \n",
      "[119]\ttraining's multi_logloss: 0.0926672\tvalid_1's multi_logloss: 0.289754      \n",
      "[120]\ttraining's multi_logloss: 0.0917283\tvalid_1's multi_logloss: 0.290025      \n",
      "[121]\ttraining's multi_logloss: 0.0907095\tvalid_1's multi_logloss: 0.290315      \n",
      "[122]\ttraining's multi_logloss: 0.0897051\tvalid_1's multi_logloss: 0.29028       \n",
      "[123]\ttraining's multi_logloss: 0.0888489\tvalid_1's multi_logloss: 0.290451      \n",
      "[124]\ttraining's multi_logloss: 0.0879101\tvalid_1's multi_logloss: 0.290805      \n",
      "[125]\ttraining's multi_logloss: 0.0870566\tvalid_1's multi_logloss: 0.290857      \n",
      "[126]\ttraining's multi_logloss: 0.0861745\tvalid_1's multi_logloss: 0.291125      \n",
      "[127]\ttraining's multi_logloss: 0.0852354\tvalid_1's multi_logloss: 0.291452      \n",
      "[128]\ttraining's multi_logloss: 0.0844315\tvalid_1's multi_logloss: 0.291411      \n",
      "[129]\ttraining's multi_logloss: 0.0835784\tvalid_1's multi_logloss: 0.291812      \n",
      "[130]\ttraining's multi_logloss: 0.0827872\tvalid_1's multi_logloss: 0.29217       \n",
      "Early stopping, best iteration is:                                               \n",
      "[100]\ttraining's multi_logloss: 0.114193\tvalid_1's multi_logloss: 0.287723\n",
      "[1]\ttraining's multi_logloss: 1.69469\tvalid_1's multi_logloss: 1.69814           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.51785\tvalid_1's multi_logloss: 1.523             \n",
      "[3]\ttraining's multi_logloss: 1.37673\tvalid_1's multi_logloss: 1.38389           \n",
      "[4]\ttraining's multi_logloss: 1.25944\tvalid_1's multi_logloss: 1.26801           \n",
      "[5]\ttraining's multi_logloss: 1.1591\tvalid_1's multi_logloss: 1.16951            \n",
      "[6]\ttraining's multi_logloss: 1.07244\tvalid_1's multi_logloss: 1.0844            \n",
      "[7]\ttraining's multi_logloss: 0.996903\tvalid_1's multi_logloss: 1.01065          \n",
      "[8]\ttraining's multi_logloss: 0.930753\tvalid_1's multi_logloss: 0.945987         \n",
      "[9]\ttraining's multi_logloss: 0.871519\tvalid_1's multi_logloss: 0.888069         \n",
      "[10]\ttraining's multi_logloss: 0.818843\tvalid_1's multi_logloss: 0.836913        \n",
      "[11]\ttraining's multi_logloss: 0.770524\tvalid_1's multi_logloss: 0.790656        \n",
      "[12]\ttraining's multi_logloss: 0.726529\tvalid_1's multi_logloss: 0.748348        \n",
      "[13]\ttraining's multi_logloss: 0.687377\tvalid_1's multi_logloss: 0.710707        \n",
      "[14]\ttraining's multi_logloss: 0.651585\tvalid_1's multi_logloss: 0.676421        \n",
      "[15]\ttraining's multi_logloss: 0.618576\tvalid_1's multi_logloss: 0.644963        \n",
      "[16]\ttraining's multi_logloss: 0.588707\tvalid_1's multi_logloss: 0.616317        \n",
      "[17]\ttraining's multi_logloss: 0.561517\tvalid_1's multi_logloss: 0.590708        \n",
      "[18]\ttraining's multi_logloss: 0.536327\tvalid_1's multi_logloss: 0.566817        \n",
      "[19]\ttraining's multi_logloss: 0.513296\tvalid_1's multi_logloss: 0.545294        \n",
      "[20]\ttraining's multi_logloss: 0.492169\tvalid_1's multi_logloss: 0.525526        \n",
      "[21]\ttraining's multi_logloss: 0.472684\tvalid_1's multi_logloss: 0.507538        \n",
      "[22]\ttraining's multi_logloss: 0.454627\tvalid_1's multi_logloss: 0.491176        \n",
      "[23]\ttraining's multi_logloss: 0.438021\tvalid_1's multi_logloss: 0.476457        \n",
      "[24]\ttraining's multi_logloss: 0.422367\tvalid_1's multi_logloss: 0.462415        \n",
      "[25]\ttraining's multi_logloss: 0.407809\tvalid_1's multi_logloss: 0.449495        \n",
      "[26]\ttraining's multi_logloss: 0.394269\tvalid_1's multi_logloss: 0.437724        \n",
      "[27]\ttraining's multi_logloss: 0.381668\tvalid_1's multi_logloss: 0.42689         \n",
      "[28]\ttraining's multi_logloss: 0.370107\tvalid_1's multi_logloss: 0.416968        \n",
      "[29]\ttraining's multi_logloss: 0.359304\tvalid_1's multi_logloss: 0.407816        \n",
      "[30]\ttraining's multi_logloss: 0.348853\tvalid_1's multi_logloss: 0.399143        \n",
      "[31]\ttraining's multi_logloss: 0.339281\tvalid_1's multi_logloss: 0.391108        \n",
      "[32]\ttraining's multi_logloss: 0.330047\tvalid_1's multi_logloss: 0.383378        \n",
      "[33]\ttraining's multi_logloss: 0.321392\tvalid_1's multi_logloss: 0.376207        \n",
      "[34]\ttraining's multi_logloss: 0.31333\tvalid_1's multi_logloss: 0.369882         \n",
      "[35]\ttraining's multi_logloss: 0.30538\tvalid_1's multi_logloss: 0.363826         \n",
      "[36]\ttraining's multi_logloss: 0.297884\tvalid_1's multi_logloss: 0.358112        \n",
      "[37]\ttraining's multi_logloss: 0.290529\tvalid_1's multi_logloss: 0.352448        \n",
      "[38]\ttraining's multi_logloss: 0.28391\tvalid_1's multi_logloss: 0.347732         \n",
      "[39]\ttraining's multi_logloss: 0.277539\tvalid_1's multi_logloss: 0.342939        \n",
      "[40]\ttraining's multi_logloss: 0.271613\tvalid_1's multi_logloss: 0.338679        \n",
      "[41]\ttraining's multi_logloss: 0.265823\tvalid_1's multi_logloss: 0.334831        \n",
      "[42]\ttraining's multi_logloss: 0.260458\tvalid_1's multi_logloss: 0.331261        \n",
      "[43]\ttraining's multi_logloss: 0.255295\tvalid_1's multi_logloss: 0.32791         \n",
      "[44]\ttraining's multi_logloss: 0.250232\tvalid_1's multi_logloss: 0.324785        \n",
      "[45]\ttraining's multi_logloss: 0.245505\tvalid_1's multi_logloss: 0.321942        \n",
      "[46]\ttraining's multi_logloss: 0.240936\tvalid_1's multi_logloss: 0.319332        \n",
      "[47]\ttraining's multi_logloss: 0.236772\tvalid_1's multi_logloss: 0.317218        \n",
      "[48]\ttraining's multi_logloss: 0.232398\tvalid_1's multi_logloss: 0.314995        \n",
      "[49]\ttraining's multi_logloss: 0.228446\tvalid_1's multi_logloss: 0.312791        \n",
      "[50]\ttraining's multi_logloss: 0.224307\tvalid_1's multi_logloss: 0.310543        \n",
      "[51]\ttraining's multi_logloss: 0.220618\tvalid_1's multi_logloss: 0.308864        \n",
      "[52]\ttraining's multi_logloss: 0.216784\tvalid_1's multi_logloss: 0.307055        \n",
      "[53]\ttraining's multi_logloss: 0.213108\tvalid_1's multi_logloss: 0.305284        \n",
      "[54]\ttraining's multi_logloss: 0.209842\tvalid_1's multi_logloss: 0.303844        \n",
      "[55]\ttraining's multi_logloss: 0.206543\tvalid_1's multi_logloss: 0.302417        \n",
      "[56]\ttraining's multi_logloss: 0.203373\tvalid_1's multi_logloss: 0.301265        \n",
      "[57]\ttraining's multi_logloss: 0.200283\tvalid_1's multi_logloss: 0.29988         \n",
      "[58]\ttraining's multi_logloss: 0.197215\tvalid_1's multi_logloss: 0.298843        \n",
      "[59]\ttraining's multi_logloss: 0.194386\tvalid_1's multi_logloss: 0.297535        \n",
      "[60]\ttraining's multi_logloss: 0.191567\tvalid_1's multi_logloss: 0.29658         \n",
      "[61]\ttraining's multi_logloss: 0.188779\tvalid_1's multi_logloss: 0.295351        \n",
      "[62]\ttraining's multi_logloss: 0.186082\tvalid_1's multi_logloss: 0.294651        \n",
      "[63]\ttraining's multi_logloss: 0.183368\tvalid_1's multi_logloss: 0.293715        \n",
      "[64]\ttraining's multi_logloss: 0.180782\tvalid_1's multi_logloss: 0.293132        \n",
      "[65]\ttraining's multi_logloss: 0.178292\tvalid_1's multi_logloss: 0.292181        \n",
      "[66]\ttraining's multi_logloss: 0.175695\tvalid_1's multi_logloss: 0.291432        \n",
      "[67]\ttraining's multi_logloss: 0.173144\tvalid_1's multi_logloss: 0.290733        \n",
      "[68]\ttraining's multi_logloss: 0.170754\tvalid_1's multi_logloss: 0.290376        \n",
      "[69]\ttraining's multi_logloss: 0.168431\tvalid_1's multi_logloss: 0.289878        \n",
      "[70]\ttraining's multi_logloss: 0.16615\tvalid_1's multi_logloss: 0.289398         \n",
      "[71]\ttraining's multi_logloss: 0.163831\tvalid_1's multi_logloss: 0.288843        \n",
      "[72]\ttraining's multi_logloss: 0.16155\tvalid_1's multi_logloss: 0.288379         \n",
      "[73]\ttraining's multi_logloss: 0.159338\tvalid_1's multi_logloss: 0.288001        \n",
      "[74]\ttraining's multi_logloss: 0.156993\tvalid_1's multi_logloss: 0.287551        \n",
      "[75]\ttraining's multi_logloss: 0.154956\tvalid_1's multi_logloss: 0.28731         \n",
      "[76]\ttraining's multi_logloss: 0.152727\tvalid_1's multi_logloss: 0.287116        \n",
      "[77]\ttraining's multi_logloss: 0.150619\tvalid_1's multi_logloss: 0.286695        \n",
      "[78]\ttraining's multi_logloss: 0.148513\tvalid_1's multi_logloss: 0.286379        \n",
      "[79]\ttraining's multi_logloss: 0.146606\tvalid_1's multi_logloss: 0.285903        \n",
      "[80]\ttraining's multi_logloss: 0.144671\tvalid_1's multi_logloss: 0.285751        \n",
      "[81]\ttraining's multi_logloss: 0.142899\tvalid_1's multi_logloss: 0.285607        \n",
      "[82]\ttraining's multi_logloss: 0.141249\tvalid_1's multi_logloss: 0.285469        \n",
      "[83]\ttraining's multi_logloss: 0.139439\tvalid_1's multi_logloss: 0.285168        \n",
      "[84]\ttraining's multi_logloss: 0.137697\tvalid_1's multi_logloss: 0.285211        \n",
      "[85]\ttraining's multi_logloss: 0.136041\tvalid_1's multi_logloss: 0.285026        \n",
      "[86]\ttraining's multi_logloss: 0.13429\tvalid_1's multi_logloss: 0.284818         \n",
      "[87]\ttraining's multi_logloss: 0.132649\tvalid_1's multi_logloss: 0.284533        \n",
      "[88]\ttraining's multi_logloss: 0.130956\tvalid_1's multi_logloss: 0.284421        \n",
      "[89]\ttraining's multi_logloss: 0.129341\tvalid_1's multi_logloss: 0.28436         \n",
      "[90]\ttraining's multi_logloss: 0.12781\tvalid_1's multi_logloss: 0.284271         \n",
      "[91]\ttraining's multi_logloss: 0.126301\tvalid_1's multi_logloss: 0.284321        \n",
      "[92]\ttraining's multi_logloss: 0.124818\tvalid_1's multi_logloss: 0.284255        \n",
      "[93]\ttraining's multi_logloss: 0.123343\tvalid_1's multi_logloss: 0.28422         \n",
      "[94]\ttraining's multi_logloss: 0.121917\tvalid_1's multi_logloss: 0.284284        \n",
      "[95]\ttraining's multi_logloss: 0.120517\tvalid_1's multi_logloss: 0.284223        \n",
      "[96]\ttraining's multi_logloss: 0.119071\tvalid_1's multi_logloss: 0.284241        \n",
      "[97]\ttraining's multi_logloss: 0.117662\tvalid_1's multi_logloss: 0.284052        \n",
      "[98]\ttraining's multi_logloss: 0.116213\tvalid_1's multi_logloss: 0.2842          \n",
      "[99]\ttraining's multi_logloss: 0.114906\tvalid_1's multi_logloss: 0.284507        \n",
      "[100]\ttraining's multi_logloss: 0.113487\tvalid_1's multi_logloss: 0.284635       \n",
      "[101]\ttraining's multi_logloss: 0.112158\tvalid_1's multi_logloss: 0.284687       \n",
      "[102]\ttraining's multi_logloss: 0.110794\tvalid_1's multi_logloss: 0.28473        \n",
      "[103]\ttraining's multi_logloss: 0.109483\tvalid_1's multi_logloss: 0.285018       \n",
      "[104]\ttraining's multi_logloss: 0.108243\tvalid_1's multi_logloss: 0.285276       \n",
      "[105]\ttraining's multi_logloss: 0.107025\tvalid_1's multi_logloss: 0.285264       \n",
      "[106]\ttraining's multi_logloss: 0.105813\tvalid_1's multi_logloss: 0.285354       \n",
      "[107]\ttraining's multi_logloss: 0.104493\tvalid_1's multi_logloss: 0.285232       \n",
      "[108]\ttraining's multi_logloss: 0.103264\tvalid_1's multi_logloss: 0.285692       \n",
      "[109]\ttraining's multi_logloss: 0.102185\tvalid_1's multi_logloss: 0.285951       \n",
      "[110]\ttraining's multi_logloss: 0.100994\tvalid_1's multi_logloss: 0.286032       \n",
      "[111]\ttraining's multi_logloss: 0.0997646\tvalid_1's multi_logloss: 0.286301      \n",
      "[112]\ttraining's multi_logloss: 0.0985595\tvalid_1's multi_logloss: 0.28645       \n",
      "[113]\ttraining's multi_logloss: 0.097529\tvalid_1's multi_logloss: 0.286546       \n",
      "[114]\ttraining's multi_logloss: 0.0963729\tvalid_1's multi_logloss: 0.286732      \n",
      "[115]\ttraining's multi_logloss: 0.0952985\tvalid_1's multi_logloss: 0.286879      \n",
      "[116]\ttraining's multi_logloss: 0.0942515\tvalid_1's multi_logloss: 0.286863      \n",
      "[117]\ttraining's multi_logloss: 0.0932783\tvalid_1's multi_logloss: 0.287038      \n",
      "[118]\ttraining's multi_logloss: 0.0922572\tvalid_1's multi_logloss: 0.287032      \n",
      "[119]\ttraining's multi_logloss: 0.0911543\tvalid_1's multi_logloss: 0.287267      \n",
      "[120]\ttraining's multi_logloss: 0.0901328\tvalid_1's multi_logloss: 0.28754       \n",
      "[121]\ttraining's multi_logloss: 0.0891115\tvalid_1's multi_logloss: 0.287813      \n",
      "[122]\ttraining's multi_logloss: 0.0881959\tvalid_1's multi_logloss: 0.288088      \n",
      "[123]\ttraining's multi_logloss: 0.0872787\tvalid_1's multi_logloss: 0.288225      \n",
      "[124]\ttraining's multi_logloss: 0.0863534\tvalid_1's multi_logloss: 0.288414      \n",
      "[125]\ttraining's multi_logloss: 0.0854593\tvalid_1's multi_logloss: 0.288748      \n",
      "[126]\ttraining's multi_logloss: 0.0845888\tvalid_1's multi_logloss: 0.288901      \n",
      "[127]\ttraining's multi_logloss: 0.0836291\tvalid_1's multi_logloss: 0.288881      \n",
      "Early stopping, best iteration is:                                               \n",
      "[97]\ttraining's multi_logloss: 0.117662\tvalid_1's multi_logloss: 0.284052\n",
      "[1]\ttraining's multi_logloss: 1.69629\tvalid_1's multi_logloss: 1.69999           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.52002\tvalid_1's multi_logloss: 1.52537           \n",
      "[3]\ttraining's multi_logloss: 1.37816\tvalid_1's multi_logloss: 1.38419           \n",
      "[4]\ttraining's multi_logloss: 1.26038\tvalid_1's multi_logloss: 1.26761           \n",
      "[5]\ttraining's multi_logloss: 1.16022\tvalid_1's multi_logloss: 1.16859           \n",
      "[6]\ttraining's multi_logloss: 1.07433\tvalid_1's multi_logloss: 1.08361           \n",
      "[7]\ttraining's multi_logloss: 0.998635\tvalid_1's multi_logloss: 1.00905          \n",
      "[8]\ttraining's multi_logloss: 0.932042\tvalid_1's multi_logloss: 0.942886         \n",
      "[9]\ttraining's multi_logloss: 0.872372\tvalid_1's multi_logloss: 0.884198         \n",
      "[10]\ttraining's multi_logloss: 0.819444\tvalid_1's multi_logloss: 0.832236        \n",
      "[11]\ttraining's multi_logloss: 0.771356\tvalid_1's multi_logloss: 0.785142        \n",
      "[12]\ttraining's multi_logloss: 0.728211\tvalid_1's multi_logloss: 0.743007        \n",
      "[13]\ttraining's multi_logloss: 0.688986\tvalid_1's multi_logloss: 0.705097        \n",
      "[14]\ttraining's multi_logloss: 0.652773\tvalid_1's multi_logloss: 0.669775        \n",
      "[15]\ttraining's multi_logloss: 0.620483\tvalid_1's multi_logloss: 0.638539        \n",
      "[16]\ttraining's multi_logloss: 0.590877\tvalid_1's multi_logloss: 0.610738        \n",
      "[17]\ttraining's multi_logloss: 0.563811\tvalid_1's multi_logloss: 0.585105        \n",
      "[18]\ttraining's multi_logloss: 0.539245\tvalid_1's multi_logloss: 0.561888        \n",
      "[19]\ttraining's multi_logloss: 0.516587\tvalid_1's multi_logloss: 0.540644        \n",
      "[20]\ttraining's multi_logloss: 0.495598\tvalid_1's multi_logloss: 0.520853        \n",
      "[21]\ttraining's multi_logloss: 0.476226\tvalid_1's multi_logloss: 0.502637        \n",
      "[22]\ttraining's multi_logloss: 0.458318\tvalid_1's multi_logloss: 0.48592         \n",
      "[23]\ttraining's multi_logloss: 0.441807\tvalid_1's multi_logloss: 0.470845        \n",
      "[24]\ttraining's multi_logloss: 0.426207\tvalid_1's multi_logloss: 0.45663         \n",
      "[25]\ttraining's multi_logloss: 0.411647\tvalid_1's multi_logloss: 0.443338        \n",
      "[26]\ttraining's multi_logloss: 0.398108\tvalid_1's multi_logloss: 0.431027        \n",
      "[27]\ttraining's multi_logloss: 0.385419\tvalid_1's multi_logloss: 0.419508        \n",
      "[28]\ttraining's multi_logloss: 0.373584\tvalid_1's multi_logloss: 0.408889        \n",
      "[29]\ttraining's multi_logloss: 0.36237\tvalid_1's multi_logloss: 0.399108         \n",
      "[30]\ttraining's multi_logloss: 0.352108\tvalid_1's multi_logloss: 0.390354        \n",
      "[31]\ttraining's multi_logloss: 0.342634\tvalid_1's multi_logloss: 0.382243        \n",
      "[32]\ttraining's multi_logloss: 0.333568\tvalid_1's multi_logloss: 0.37437         \n",
      "[33]\ttraining's multi_logloss: 0.32507\tvalid_1's multi_logloss: 0.367299         \n",
      "[34]\ttraining's multi_logloss: 0.317092\tvalid_1's multi_logloss: 0.360638        \n",
      "[35]\ttraining's multi_logloss: 0.309402\tvalid_1's multi_logloss: 0.354528        \n",
      "[36]\ttraining's multi_logloss: 0.301905\tvalid_1's multi_logloss: 0.348713        \n",
      "[37]\ttraining's multi_logloss: 0.294959\tvalid_1's multi_logloss: 0.343335        \n",
      "[38]\ttraining's multi_logloss: 0.288461\tvalid_1's multi_logloss: 0.338484        \n",
      "[39]\ttraining's multi_logloss: 0.282461\tvalid_1's multi_logloss: 0.333877        \n",
      "[40]\ttraining's multi_logloss: 0.276708\tvalid_1's multi_logloss: 0.32967         \n",
      "[41]\ttraining's multi_logloss: 0.270856\tvalid_1's multi_logloss: 0.325449        \n",
      "[42]\ttraining's multi_logloss: 0.265322\tvalid_1's multi_logloss: 0.321575        \n",
      "[43]\ttraining's multi_logloss: 0.26024\tvalid_1's multi_logloss: 0.318301         \n",
      "[44]\ttraining's multi_logloss: 0.255426\tvalid_1's multi_logloss: 0.314949        \n",
      "[45]\ttraining's multi_logloss: 0.250773\tvalid_1's multi_logloss: 0.311946        \n",
      "[46]\ttraining's multi_logloss: 0.246373\tvalid_1's multi_logloss: 0.30928         \n",
      "[47]\ttraining's multi_logloss: 0.242091\tvalid_1's multi_logloss: 0.306541        \n",
      "[48]\ttraining's multi_logloss: 0.237699\tvalid_1's multi_logloss: 0.304018        \n",
      "[49]\ttraining's multi_logloss: 0.233677\tvalid_1's multi_logloss: 0.30164         \n",
      "[50]\ttraining's multi_logloss: 0.230027\tvalid_1's multi_logloss: 0.299646        \n",
      "[51]\ttraining's multi_logloss: 0.226244\tvalid_1's multi_logloss: 0.297487        \n",
      "[52]\ttraining's multi_logloss: 0.222575\tvalid_1's multi_logloss: 0.295355        \n",
      "[53]\ttraining's multi_logloss: 0.219166\tvalid_1's multi_logloss: 0.293696        \n",
      "[54]\ttraining's multi_logloss: 0.215897\tvalid_1's multi_logloss: 0.292483        \n",
      "[55]\ttraining's multi_logloss: 0.212613\tvalid_1's multi_logloss: 0.291177        \n",
      "[56]\ttraining's multi_logloss: 0.209537\tvalid_1's multi_logloss: 0.28962         \n",
      "[57]\ttraining's multi_logloss: 0.206316\tvalid_1's multi_logloss: 0.288284        \n",
      "[58]\ttraining's multi_logloss: 0.203168\tvalid_1's multi_logloss: 0.286913        \n",
      "[59]\ttraining's multi_logloss: 0.200293\tvalid_1's multi_logloss: 0.285309        \n",
      "[60]\ttraining's multi_logloss: 0.197461\tvalid_1's multi_logloss: 0.284358        \n",
      "[61]\ttraining's multi_logloss: 0.194659\tvalid_1's multi_logloss: 0.283217        \n",
      "[62]\ttraining's multi_logloss: 0.191955\tvalid_1's multi_logloss: 0.282292        \n",
      "[63]\ttraining's multi_logloss: 0.189114\tvalid_1's multi_logloss: 0.281238        \n",
      "[64]\ttraining's multi_logloss: 0.186399\tvalid_1's multi_logloss: 0.280394        \n",
      "[65]\ttraining's multi_logloss: 0.183784\tvalid_1's multi_logloss: 0.279673        \n",
      "[66]\ttraining's multi_logloss: 0.181239\tvalid_1's multi_logloss: 0.27888         \n",
      "[67]\ttraining's multi_logloss: 0.178753\tvalid_1's multi_logloss: 0.278177        \n",
      "[68]\ttraining's multi_logloss: 0.176345\tvalid_1's multi_logloss: 0.277628        \n",
      "[69]\ttraining's multi_logloss: 0.17395\tvalid_1's multi_logloss: 0.277184         \n",
      "[70]\ttraining's multi_logloss: 0.17165\tvalid_1's multi_logloss: 0.276862         \n",
      "[71]\ttraining's multi_logloss: 0.169298\tvalid_1's multi_logloss: 0.276077        \n",
      "[72]\ttraining's multi_logloss: 0.167112\tvalid_1's multi_logloss: 0.275625        \n",
      "[73]\ttraining's multi_logloss: 0.164894\tvalid_1's multi_logloss: 0.275021        \n",
      "[74]\ttraining's multi_logloss: 0.162777\tvalid_1's multi_logloss: 0.274785        \n",
      "[75]\ttraining's multi_logloss: 0.160717\tvalid_1's multi_logloss: 0.274315        \n",
      "[76]\ttraining's multi_logloss: 0.158635\tvalid_1's multi_logloss: 0.273854        \n",
      "[77]\ttraining's multi_logloss: 0.156774\tvalid_1's multi_logloss: 0.273484        \n",
      "[78]\ttraining's multi_logloss: 0.154879\tvalid_1's multi_logloss: 0.273333        \n",
      "[79]\ttraining's multi_logloss: 0.152933\tvalid_1's multi_logloss: 0.273081        \n",
      "[80]\ttraining's multi_logloss: 0.151019\tvalid_1's multi_logloss: 0.272846        \n",
      "[81]\ttraining's multi_logloss: 0.149123\tvalid_1's multi_logloss: 0.272624        \n",
      "[82]\ttraining's multi_logloss: 0.147177\tvalid_1's multi_logloss: 0.272219        \n",
      "[83]\ttraining's multi_logloss: 0.145387\tvalid_1's multi_logloss: 0.272264        \n",
      "[84]\ttraining's multi_logloss: 0.143568\tvalid_1's multi_logloss: 0.271666        \n",
      "[85]\ttraining's multi_logloss: 0.141771\tvalid_1's multi_logloss: 0.27136         \n",
      "[86]\ttraining's multi_logloss: 0.140054\tvalid_1's multi_logloss: 0.271008        \n",
      "[87]\ttraining's multi_logloss: 0.138317\tvalid_1's multi_logloss: 0.2709          \n",
      "[88]\ttraining's multi_logloss: 0.136532\tvalid_1's multi_logloss: 0.270875        \n",
      "[89]\ttraining's multi_logloss: 0.134836\tvalid_1's multi_logloss: 0.270919        \n",
      "[90]\ttraining's multi_logloss: 0.133141\tvalid_1's multi_logloss: 0.270793        \n",
      "[91]\ttraining's multi_logloss: 0.131442\tvalid_1's multi_logloss: 0.270508        \n",
      "[92]\ttraining's multi_logloss: 0.129882\tvalid_1's multi_logloss: 0.270476        \n",
      "[93]\ttraining's multi_logloss: 0.128369\tvalid_1's multi_logloss: 0.270266        \n",
      "[94]\ttraining's multi_logloss: 0.126874\tvalid_1's multi_logloss: 0.270154        \n",
      "[95]\ttraining's multi_logloss: 0.125427\tvalid_1's multi_logloss: 0.270053        \n",
      "[96]\ttraining's multi_logloss: 0.123971\tvalid_1's multi_logloss: 0.269994        \n",
      "[97]\ttraining's multi_logloss: 0.122593\tvalid_1's multi_logloss: 0.26996         \n",
      "[98]\ttraining's multi_logloss: 0.121202\tvalid_1's multi_logloss: 0.269687        \n",
      "[99]\ttraining's multi_logloss: 0.119841\tvalid_1's multi_logloss: 0.269428        \n",
      "[100]\ttraining's multi_logloss: 0.118584\tvalid_1's multi_logloss: 0.269135       \n",
      "[101]\ttraining's multi_logloss: 0.117243\tvalid_1's multi_logloss: 0.269288       \n",
      "[102]\ttraining's multi_logloss: 0.115945\tvalid_1's multi_logloss: 0.269067       \n",
      "[103]\ttraining's multi_logloss: 0.11474\tvalid_1's multi_logloss: 0.2692          \n",
      "[104]\ttraining's multi_logloss: 0.113475\tvalid_1's multi_logloss: 0.26921        \n",
      "[105]\ttraining's multi_logloss: 0.112204\tvalid_1's multi_logloss: 0.269259       \n",
      "[106]\ttraining's multi_logloss: 0.11091\tvalid_1's multi_logloss: 0.269514        \n",
      "[107]\ttraining's multi_logloss: 0.109757\tvalid_1's multi_logloss: 0.269581       \n",
      "[108]\ttraining's multi_logloss: 0.108555\tvalid_1's multi_logloss: 0.26963        \n",
      "[109]\ttraining's multi_logloss: 0.107282\tvalid_1's multi_logloss: 0.26974        \n",
      "[110]\ttraining's multi_logloss: 0.106042\tvalid_1's multi_logloss: 0.269793       \n",
      "[111]\ttraining's multi_logloss: 0.104871\tvalid_1's multi_logloss: 0.270126       \n",
      "[112]\ttraining's multi_logloss: 0.103708\tvalid_1's multi_logloss: 0.27022        \n",
      "[113]\ttraining's multi_logloss: 0.102667\tvalid_1's multi_logloss: 0.270524       \n",
      "[114]\ttraining's multi_logloss: 0.101644\tvalid_1's multi_logloss: 0.270714       \n",
      "[115]\ttraining's multi_logloss: 0.10056\tvalid_1's multi_logloss: 0.270744        \n",
      "[116]\ttraining's multi_logloss: 0.0995779\tvalid_1's multi_logloss: 0.270907      \n",
      "[117]\ttraining's multi_logloss: 0.0985009\tvalid_1's multi_logloss: 0.27121       \n",
      "[118]\ttraining's multi_logloss: 0.0974444\tvalid_1's multi_logloss: 0.27129       \n",
      "[119]\ttraining's multi_logloss: 0.096452\tvalid_1's multi_logloss: 0.27163        \n",
      "[120]\ttraining's multi_logloss: 0.0955108\tvalid_1's multi_logloss: 0.271813      \n",
      "[121]\ttraining's multi_logloss: 0.0945026\tvalid_1's multi_logloss: 0.271964      \n",
      "[122]\ttraining's multi_logloss: 0.0935957\tvalid_1's multi_logloss: 0.272074      \n",
      "[123]\ttraining's multi_logloss: 0.0926362\tvalid_1's multi_logloss: 0.272188      \n",
      "[124]\ttraining's multi_logloss: 0.0917047\tvalid_1's multi_logloss: 0.272228      \n",
      "[125]\ttraining's multi_logloss: 0.0907773\tvalid_1's multi_logloss: 0.272345      \n",
      "[126]\ttraining's multi_logloss: 0.0898712\tvalid_1's multi_logloss: 0.27258       \n",
      "[127]\ttraining's multi_logloss: 0.0889686\tvalid_1's multi_logloss: 0.272818      \n",
      "[128]\ttraining's multi_logloss: 0.0880078\tvalid_1's multi_logloss: 0.272877      \n",
      "[129]\ttraining's multi_logloss: 0.0870953\tvalid_1's multi_logloss: 0.27302       \n",
      "[130]\ttraining's multi_logloss: 0.086232\tvalid_1's multi_logloss: 0.273132       \n",
      "[131]\ttraining's multi_logloss: 0.0853211\tvalid_1's multi_logloss: 0.27346       \n",
      "[132]\ttraining's multi_logloss: 0.0844646\tvalid_1's multi_logloss: 0.273822      \n",
      "Early stopping, best iteration is:                                               \n",
      "[102]\ttraining's multi_logloss: 0.115945\tvalid_1's multi_logloss: 0.269067\n",
      "[1]\ttraining's multi_logloss: 1.55427\tvalid_1's multi_logloss: 1.56055           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.31543\tvalid_1's multi_logloss: 1.32774           \n",
      "[3]\ttraining's multi_logloss: 1.13948\tvalid_1's multi_logloss: 1.15744           \n",
      "[4]\ttraining's multi_logloss: 1.00325\tvalid_1's multi_logloss: 1.02597           \n",
      "[5]\ttraining's multi_logloss: 0.893714\tvalid_1's multi_logloss: 0.920046         \n",
      "[6]\ttraining's multi_logloss: 0.804343\tvalid_1's multi_logloss: 0.833718         \n",
      "[7]\ttraining's multi_logloss: 0.729319\tvalid_1's multi_logloss: 0.761492         \n",
      "[8]\ttraining's multi_logloss: 0.666051\tvalid_1's multi_logloss: 0.700736         \n",
      "[9]\ttraining's multi_logloss: 0.610818\tvalid_1's multi_logloss: 0.648317         \n",
      "[10]\ttraining's multi_logloss: 0.563636\tvalid_1's multi_logloss: 0.603249        \n",
      "[11]\ttraining's multi_logloss: 0.523491\tvalid_1's multi_logloss: 0.565713        \n",
      "[12]\ttraining's multi_logloss: 0.487523\tvalid_1's multi_logloss: 0.532074        \n",
      "[13]\ttraining's multi_logloss: 0.456266\tvalid_1's multi_logloss: 0.502969        \n",
      "[14]\ttraining's multi_logloss: 0.428784\tvalid_1's multi_logloss: 0.477843        \n",
      "[15]\ttraining's multi_logloss: 0.404515\tvalid_1's multi_logloss: 0.456202        \n",
      "[16]\ttraining's multi_logloss: 0.383123\tvalid_1's multi_logloss: 0.437002        \n",
      "[17]\ttraining's multi_logloss: 0.363774\tvalid_1's multi_logloss: 0.419911        \n",
      "[18]\ttraining's multi_logloss: 0.34711\tvalid_1's multi_logloss: 0.405366         \n",
      "[19]\ttraining's multi_logloss: 0.33161\tvalid_1's multi_logloss: 0.39248          \n",
      "[20]\ttraining's multi_logloss: 0.317688\tvalid_1's multi_logloss: 0.381145        \n",
      "[21]\ttraining's multi_logloss: 0.305105\tvalid_1's multi_logloss: 0.371026        \n",
      "[22]\ttraining's multi_logloss: 0.293282\tvalid_1's multi_logloss: 0.36166         \n",
      "[23]\ttraining's multi_logloss: 0.282535\tvalid_1's multi_logloss: 0.353643        \n",
      "[24]\ttraining's multi_logloss: 0.272857\tvalid_1's multi_logloss: 0.34665         \n",
      "[25]\ttraining's multi_logloss: 0.263734\tvalid_1's multi_logloss: 0.340175        \n",
      "[26]\ttraining's multi_logloss: 0.255404\tvalid_1's multi_logloss: 0.334851        \n",
      "[27]\ttraining's multi_logloss: 0.247467\tvalid_1's multi_logloss: 0.329844        \n",
      "[28]\ttraining's multi_logloss: 0.240152\tvalid_1's multi_logloss: 0.32554         \n",
      "[29]\ttraining's multi_logloss: 0.233148\tvalid_1's multi_logloss: 0.321307        \n",
      "[30]\ttraining's multi_logloss: 0.227085\tvalid_1's multi_logloss: 0.318111        \n",
      "[31]\ttraining's multi_logloss: 0.221006\tvalid_1's multi_logloss: 0.315362        \n",
      "[32]\ttraining's multi_logloss: 0.215029\tvalid_1's multi_logloss: 0.312791        \n",
      "[33]\ttraining's multi_logloss: 0.209463\tvalid_1's multi_logloss: 0.310318        \n",
      "[34]\ttraining's multi_logloss: 0.204115\tvalid_1's multi_logloss: 0.307695        \n",
      "[35]\ttraining's multi_logloss: 0.199161\tvalid_1's multi_logloss: 0.305779        \n",
      "[36]\ttraining's multi_logloss: 0.194261\tvalid_1's multi_logloss: 0.303845        \n",
      "[37]\ttraining's multi_logloss: 0.189564\tvalid_1's multi_logloss: 0.302294        \n",
      "[38]\ttraining's multi_logloss: 0.184769\tvalid_1's multi_logloss: 0.300548        \n",
      "[39]\ttraining's multi_logloss: 0.180561\tvalid_1's multi_logloss: 0.299444        \n",
      "[40]\ttraining's multi_logloss: 0.176299\tvalid_1's multi_logloss: 0.298393        \n",
      "[41]\ttraining's multi_logloss: 0.172274\tvalid_1's multi_logloss: 0.297632        \n",
      "[42]\ttraining's multi_logloss: 0.168571\tvalid_1's multi_logloss: 0.296774        \n",
      "[43]\ttraining's multi_logloss: 0.164676\tvalid_1's multi_logloss: 0.296136        \n",
      "[44]\ttraining's multi_logloss: 0.160935\tvalid_1's multi_logloss: 0.295515        \n",
      "[45]\ttraining's multi_logloss: 0.157057\tvalid_1's multi_logloss: 0.295126        \n",
      "[46]\ttraining's multi_logloss: 0.153596\tvalid_1's multi_logloss: 0.294313        \n",
      "[47]\ttraining's multi_logloss: 0.150074\tvalid_1's multi_logloss: 0.293864        \n",
      "[48]\ttraining's multi_logloss: 0.146493\tvalid_1's multi_logloss: 0.293297        \n",
      "[49]\ttraining's multi_logloss: 0.142887\tvalid_1's multi_logloss: 0.292903        \n",
      "[50]\ttraining's multi_logloss: 0.139607\tvalid_1's multi_logloss: 0.292271        \n",
      "[51]\ttraining's multi_logloss: 0.136455\tvalid_1's multi_logloss: 0.292429        \n",
      "[52]\ttraining's multi_logloss: 0.133472\tvalid_1's multi_logloss: 0.29223         \n",
      "[53]\ttraining's multi_logloss: 0.130442\tvalid_1's multi_logloss: 0.291865        \n",
      "[54]\ttraining's multi_logloss: 0.127676\tvalid_1's multi_logloss: 0.291841        \n",
      "[55]\ttraining's multi_logloss: 0.124912\tvalid_1's multi_logloss: 0.291861        \n",
      "[56]\ttraining's multi_logloss: 0.121955\tvalid_1's multi_logloss: 0.292358        \n",
      "[57]\ttraining's multi_logloss: 0.119505\tvalid_1's multi_logloss: 0.292447        \n",
      "[58]\ttraining's multi_logloss: 0.116693\tvalid_1's multi_logloss: 0.292218        \n",
      "[59]\ttraining's multi_logloss: 0.114209\tvalid_1's multi_logloss: 0.292212        \n",
      "[60]\ttraining's multi_logloss: 0.111602\tvalid_1's multi_logloss: 0.292084        \n",
      "[61]\ttraining's multi_logloss: 0.109028\tvalid_1's multi_logloss: 0.292602        \n",
      "[62]\ttraining's multi_logloss: 0.106646\tvalid_1's multi_logloss: 0.292935        \n",
      "[63]\ttraining's multi_logloss: 0.104513\tvalid_1's multi_logloss: 0.293025        \n",
      "[64]\ttraining's multi_logloss: 0.102238\tvalid_1's multi_logloss: 0.293312        \n",
      "[65]\ttraining's multi_logloss: 0.0999214\tvalid_1's multi_logloss: 0.293382       \n",
      "[66]\ttraining's multi_logloss: 0.0978064\tvalid_1's multi_logloss: 0.293561       \n",
      "[67]\ttraining's multi_logloss: 0.0959393\tvalid_1's multi_logloss: 0.29392        \n",
      "[68]\ttraining's multi_logloss: 0.0937157\tvalid_1's multi_logloss: 0.294433       \n",
      "[69]\ttraining's multi_logloss: 0.0916621\tvalid_1's multi_logloss: 0.294964       \n",
      "[70]\ttraining's multi_logloss: 0.0897718\tvalid_1's multi_logloss: 0.295565       \n",
      "[71]\ttraining's multi_logloss: 0.0880296\tvalid_1's multi_logloss: 0.296025       \n",
      "[72]\ttraining's multi_logloss: 0.0861292\tvalid_1's multi_logloss: 0.296214       \n",
      "[73]\ttraining's multi_logloss: 0.0844603\tvalid_1's multi_logloss: 0.296632       \n",
      "[74]\ttraining's multi_logloss: 0.0828445\tvalid_1's multi_logloss: 0.297289       \n",
      "[75]\ttraining's multi_logloss: 0.0812973\tvalid_1's multi_logloss: 0.2978         \n",
      "[76]\ttraining's multi_logloss: 0.0797461\tvalid_1's multi_logloss: 0.298342       \n",
      "[77]\ttraining's multi_logloss: 0.0778805\tvalid_1's multi_logloss: 0.298731       \n",
      "[78]\ttraining's multi_logloss: 0.0764341\tvalid_1's multi_logloss: 0.299699       \n",
      "[79]\ttraining's multi_logloss: 0.0751034\tvalid_1's multi_logloss: 0.30014        \n",
      "[80]\ttraining's multi_logloss: 0.0735942\tvalid_1's multi_logloss: 0.300632       \n",
      "[81]\ttraining's multi_logloss: 0.0721168\tvalid_1's multi_logloss: 0.301316       \n",
      "[82]\ttraining's multi_logloss: 0.0706545\tvalid_1's multi_logloss: 0.301896       \n",
      "[83]\ttraining's multi_logloss: 0.0693061\tvalid_1's multi_logloss: 0.302108       \n",
      "[84]\ttraining's multi_logloss: 0.0678108\tvalid_1's multi_logloss: 0.302676       \n",
      "Early stopping, best iteration is:                                               \n",
      "[54]\ttraining's multi_logloss: 0.127676\tvalid_1's multi_logloss: 0.291841\n",
      "[1]\ttraining's multi_logloss: 1.55219\tvalid_1's multi_logloss: 1.55658           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.31511\tvalid_1's multi_logloss: 1.32128           \n",
      "[3]\ttraining's multi_logloss: 1.14242\tvalid_1's multi_logloss: 1.15146           \n",
      "[4]\ttraining's multi_logloss: 1.00856\tvalid_1's multi_logloss: 1.01986           \n",
      "[5]\ttraining's multi_logloss: 0.90094\tvalid_1's multi_logloss: 0.914297          \n",
      "[6]\ttraining's multi_logloss: 0.811849\tvalid_1's multi_logloss: 0.827651         \n",
      "[7]\ttraining's multi_logloss: 0.736411\tvalid_1's multi_logloss: 0.754946         \n",
      "[8]\ttraining's multi_logloss: 0.671981\tvalid_1's multi_logloss: 0.693572         \n",
      "[9]\ttraining's multi_logloss: 0.617802\tvalid_1's multi_logloss: 0.641888         \n",
      "[10]\ttraining's multi_logloss: 0.570866\tvalid_1's multi_logloss: 0.596688        \n",
      "[11]\ttraining's multi_logloss: 0.529982\tvalid_1's multi_logloss: 0.558319        \n",
      "[12]\ttraining's multi_logloss: 0.494813\tvalid_1's multi_logloss: 0.525734        \n",
      "[13]\ttraining's multi_logloss: 0.462805\tvalid_1's multi_logloss: 0.496018        \n",
      "[14]\ttraining's multi_logloss: 0.435356\tvalid_1's multi_logloss: 0.47128         \n",
      "[15]\ttraining's multi_logloss: 0.411119\tvalid_1's multi_logloss: 0.44989         \n",
      "[16]\ttraining's multi_logloss: 0.389317\tvalid_1's multi_logloss: 0.430723        \n",
      "[17]\ttraining's multi_logloss: 0.369977\tvalid_1's multi_logloss: 0.414378        \n",
      "[18]\ttraining's multi_logloss: 0.352816\tvalid_1's multi_logloss: 0.399447        \n",
      "[19]\ttraining's multi_logloss: 0.337046\tvalid_1's multi_logloss: 0.385908        \n",
      "[20]\ttraining's multi_logloss: 0.323041\tvalid_1's multi_logloss: 0.374408        \n",
      "[21]\ttraining's multi_logloss: 0.310138\tvalid_1's multi_logloss: 0.36385         \n",
      "[22]\ttraining's multi_logloss: 0.29801\tvalid_1's multi_logloss: 0.354548         \n",
      "[23]\ttraining's multi_logloss: 0.28719\tvalid_1's multi_logloss: 0.346519         \n",
      "[24]\ttraining's multi_logloss: 0.277132\tvalid_1's multi_logloss: 0.339165        \n",
      "[25]\ttraining's multi_logloss: 0.267627\tvalid_1's multi_logloss: 0.332476        \n",
      "[26]\ttraining's multi_logloss: 0.258724\tvalid_1's multi_logloss: 0.326569        \n",
      "[27]\ttraining's multi_logloss: 0.250657\tvalid_1's multi_logloss: 0.321378        \n",
      "[28]\ttraining's multi_logloss: 0.243162\tvalid_1's multi_logloss: 0.317523        \n",
      "[29]\ttraining's multi_logloss: 0.235746\tvalid_1's multi_logloss: 0.313647        \n",
      "[30]\ttraining's multi_logloss: 0.229123\tvalid_1's multi_logloss: 0.310919        \n",
      "[31]\ttraining's multi_logloss: 0.222737\tvalid_1's multi_logloss: 0.307644        \n",
      "[32]\ttraining's multi_logloss: 0.216488\tvalid_1's multi_logloss: 0.305108        \n",
      "[33]\ttraining's multi_logloss: 0.210951\tvalid_1's multi_logloss: 0.302791        \n",
      "[34]\ttraining's multi_logloss: 0.20522\tvalid_1's multi_logloss: 0.301116         \n",
      "[35]\ttraining's multi_logloss: 0.199943\tvalid_1's multi_logloss: 0.299499        \n",
      "[36]\ttraining's multi_logloss: 0.194887\tvalid_1's multi_logloss: 0.297773        \n",
      "[37]\ttraining's multi_logloss: 0.189868\tvalid_1's multi_logloss: 0.295595        \n",
      "[38]\ttraining's multi_logloss: 0.18527\tvalid_1's multi_logloss: 0.294126         \n",
      "[39]\ttraining's multi_logloss: 0.181053\tvalid_1's multi_logloss: 0.293002        \n",
      "[40]\ttraining's multi_logloss: 0.176928\tvalid_1's multi_logloss: 0.292198        \n",
      "[41]\ttraining's multi_logloss: 0.172756\tvalid_1's multi_logloss: 0.291314        \n",
      "[42]\ttraining's multi_logloss: 0.168896\tvalid_1's multi_logloss: 0.290386        \n",
      "[43]\ttraining's multi_logloss: 0.164763\tvalid_1's multi_logloss: 0.289463        \n",
      "[44]\ttraining's multi_logloss: 0.161045\tvalid_1's multi_logloss: 0.288744        \n",
      "[45]\ttraining's multi_logloss: 0.157165\tvalid_1's multi_logloss: 0.287693        \n",
      "[46]\ttraining's multi_logloss: 0.153439\tvalid_1's multi_logloss: 0.287343        \n",
      "[47]\ttraining's multi_logloss: 0.149485\tvalid_1's multi_logloss: 0.286928        \n",
      "[48]\ttraining's multi_logloss: 0.14597\tvalid_1's multi_logloss: 0.286422         \n",
      "[49]\ttraining's multi_logloss: 0.142656\tvalid_1's multi_logloss: 0.286175        \n",
      "[50]\ttraining's multi_logloss: 0.139537\tvalid_1's multi_logloss: 0.285786        \n",
      "[51]\ttraining's multi_logloss: 0.136319\tvalid_1's multi_logloss: 0.285635        \n",
      "[52]\ttraining's multi_logloss: 0.13334\tvalid_1's multi_logloss: 0.285229         \n",
      "[53]\ttraining's multi_logloss: 0.1304\tvalid_1's multi_logloss: 0.285333          \n",
      "[54]\ttraining's multi_logloss: 0.12759\tvalid_1's multi_logloss: 0.285415         \n",
      "[55]\ttraining's multi_logloss: 0.124714\tvalid_1's multi_logloss: 0.285207        \n",
      "[56]\ttraining's multi_logloss: 0.121898\tvalid_1's multi_logloss: 0.285309        \n",
      "[57]\ttraining's multi_logloss: 0.119093\tvalid_1's multi_logloss: 0.285056        \n",
      "[58]\ttraining's multi_logloss: 0.116391\tvalid_1's multi_logloss: 0.285074        \n",
      "[59]\ttraining's multi_logloss: 0.113731\tvalid_1's multi_logloss: 0.284876        \n",
      "[60]\ttraining's multi_logloss: 0.110946\tvalid_1's multi_logloss: 0.285113        \n",
      "[61]\ttraining's multi_logloss: 0.108496\tvalid_1's multi_logloss: 0.28557         \n",
      "[62]\ttraining's multi_logloss: 0.106052\tvalid_1's multi_logloss: 0.285818        \n",
      "[63]\ttraining's multi_logloss: 0.103631\tvalid_1's multi_logloss: 0.286291        \n",
      "[64]\ttraining's multi_logloss: 0.101268\tvalid_1's multi_logloss: 0.286991        \n",
      "[65]\ttraining's multi_logloss: 0.0989204\tvalid_1's multi_logloss: 0.287671       \n",
      "[66]\ttraining's multi_logloss: 0.0965534\tvalid_1's multi_logloss: 0.288168       \n",
      "[67]\ttraining's multi_logloss: 0.0944882\tvalid_1's multi_logloss: 0.288661       \n",
      "[68]\ttraining's multi_logloss: 0.092429\tvalid_1's multi_logloss: 0.28915         \n",
      "[69]\ttraining's multi_logloss: 0.0904637\tvalid_1's multi_logloss: 0.289231       \n",
      "[70]\ttraining's multi_logloss: 0.0884508\tvalid_1's multi_logloss: 0.289959       \n",
      "[71]\ttraining's multi_logloss: 0.0865562\tvalid_1's multi_logloss: 0.290292       \n",
      "[72]\ttraining's multi_logloss: 0.0845412\tvalid_1's multi_logloss: 0.290656       \n",
      "[73]\ttraining's multi_logloss: 0.0829866\tvalid_1's multi_logloss: 0.290922       \n",
      "[74]\ttraining's multi_logloss: 0.0813962\tvalid_1's multi_logloss: 0.291216       \n",
      "[75]\ttraining's multi_logloss: 0.0795961\tvalid_1's multi_logloss: 0.291573       \n",
      "[76]\ttraining's multi_logloss: 0.077858\tvalid_1's multi_logloss: 0.29179         \n",
      "[77]\ttraining's multi_logloss: 0.0762674\tvalid_1's multi_logloss: 0.292509       \n",
      "[78]\ttraining's multi_logloss: 0.0748817\tvalid_1's multi_logloss: 0.292883       \n",
      "[79]\ttraining's multi_logloss: 0.073296\tvalid_1's multi_logloss: 0.2933          \n",
      "[80]\ttraining's multi_logloss: 0.0717085\tvalid_1's multi_logloss: 0.293952       \n",
      "[81]\ttraining's multi_logloss: 0.0703137\tvalid_1's multi_logloss: 0.29472        \n",
      "[82]\ttraining's multi_logloss: 0.0689502\tvalid_1's multi_logloss: 0.294939       \n",
      "[83]\ttraining's multi_logloss: 0.0674025\tvalid_1's multi_logloss: 0.295593       \n",
      "[84]\ttraining's multi_logloss: 0.0659618\tvalid_1's multi_logloss: 0.296618       \n",
      "[85]\ttraining's multi_logloss: 0.0647145\tvalid_1's multi_logloss: 0.297235       \n",
      "[86]\ttraining's multi_logloss: 0.063527\tvalid_1's multi_logloss: 0.298067        \n",
      "[87]\ttraining's multi_logloss: 0.0622536\tvalid_1's multi_logloss: 0.298737       \n",
      "[88]\ttraining's multi_logloss: 0.060976\tvalid_1's multi_logloss: 0.299377        \n",
      "[89]\ttraining's multi_logloss: 0.0598718\tvalid_1's multi_logloss: 0.300109       \n",
      "Early stopping, best iteration is:                                               \n",
      "[59]\ttraining's multi_logloss: 0.113731\tvalid_1's multi_logloss: 0.284876\n",
      "[1]\ttraining's multi_logloss: 1.55517\tvalid_1's multi_logloss: 1.55941           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.31688\tvalid_1's multi_logloss: 1.32267           \n",
      "[3]\ttraining's multi_logloss: 1.1442\tvalid_1's multi_logloss: 1.15162            \n",
      "[4]\ttraining's multi_logloss: 1.00972\tvalid_1's multi_logloss: 1.01812           \n",
      "[5]\ttraining's multi_logloss: 0.90131\tvalid_1's multi_logloss: 0.911541          \n",
      "[6]\ttraining's multi_logloss: 0.810421\tvalid_1's multi_logloss: 0.822005         \n",
      "[7]\ttraining's multi_logloss: 0.735118\tvalid_1's multi_logloss: 0.748252         \n",
      "[8]\ttraining's multi_logloss: 0.67169\tvalid_1's multi_logloss: 0.686576          \n",
      "[9]\ttraining's multi_logloss: 0.618368\tvalid_1's multi_logloss: 0.635142         \n",
      "[10]\ttraining's multi_logloss: 0.57223\tvalid_1's multi_logloss: 0.591746         \n",
      "[11]\ttraining's multi_logloss: 0.531328\tvalid_1's multi_logloss: 0.552623        \n",
      "[12]\ttraining's multi_logloss: 0.496118\tvalid_1's multi_logloss: 0.519401        \n",
      "[13]\ttraining's multi_logloss: 0.465049\tvalid_1's multi_logloss: 0.490625        \n",
      "[14]\ttraining's multi_logloss: 0.438299\tvalid_1's multi_logloss: 0.465878        \n",
      "[15]\ttraining's multi_logloss: 0.413856\tvalid_1's multi_logloss: 0.443581        \n",
      "[16]\ttraining's multi_logloss: 0.391533\tvalid_1's multi_logloss: 0.423064        \n",
      "[17]\ttraining's multi_logloss: 0.37239\tvalid_1's multi_logloss: 0.40603          \n",
      "[18]\ttraining's multi_logloss: 0.354891\tvalid_1's multi_logloss: 0.390691        \n",
      "[19]\ttraining's multi_logloss: 0.339317\tvalid_1's multi_logloss: 0.3773          \n",
      "[20]\ttraining's multi_logloss: 0.325462\tvalid_1's multi_logloss: 0.365455        \n",
      "[21]\ttraining's multi_logloss: 0.313161\tvalid_1's multi_logloss: 0.355684        \n",
      "[22]\ttraining's multi_logloss: 0.301123\tvalid_1's multi_logloss: 0.346269        \n",
      "[23]\ttraining's multi_logloss: 0.290296\tvalid_1's multi_logloss: 0.337808        \n",
      "[24]\ttraining's multi_logloss: 0.280792\tvalid_1's multi_logloss: 0.330682        \n",
      "[25]\ttraining's multi_logloss: 0.271909\tvalid_1's multi_logloss: 0.32416         \n",
      "[26]\ttraining's multi_logloss: 0.263523\tvalid_1's multi_logloss: 0.318593        \n",
      "[27]\ttraining's multi_logloss: 0.255314\tvalid_1's multi_logloss: 0.313313        \n",
      "[28]\ttraining's multi_logloss: 0.247794\tvalid_1's multi_logloss: 0.30852         \n",
      "[29]\ttraining's multi_logloss: 0.240565\tvalid_1's multi_logloss: 0.304529        \n",
      "[30]\ttraining's multi_logloss: 0.234111\tvalid_1's multi_logloss: 0.301404        \n",
      "[31]\ttraining's multi_logloss: 0.227893\tvalid_1's multi_logloss: 0.298009        \n",
      "[32]\ttraining's multi_logloss: 0.221874\tvalid_1's multi_logloss: 0.295134        \n",
      "[33]\ttraining's multi_logloss: 0.216416\tvalid_1's multi_logloss: 0.292348        \n",
      "[34]\ttraining's multi_logloss: 0.211132\tvalid_1's multi_logloss: 0.290374        \n",
      "[35]\ttraining's multi_logloss: 0.206053\tvalid_1's multi_logloss: 0.288           \n",
      "[36]\ttraining's multi_logloss: 0.200988\tvalid_1's multi_logloss: 0.285586        \n",
      "[37]\ttraining's multi_logloss: 0.195988\tvalid_1's multi_logloss: 0.28344         \n",
      "[38]\ttraining's multi_logloss: 0.191265\tvalid_1's multi_logloss: 0.281786        \n",
      "[39]\ttraining's multi_logloss: 0.186836\tvalid_1's multi_logloss: 0.280433        \n",
      "[40]\ttraining's multi_logloss: 0.182314\tvalid_1's multi_logloss: 0.279174        \n",
      "[41]\ttraining's multi_logloss: 0.177851\tvalid_1's multi_logloss: 0.277953        \n",
      "[42]\ttraining's multi_logloss: 0.173545\tvalid_1's multi_logloss: 0.276696        \n",
      "[43]\ttraining's multi_logloss: 0.169685\tvalid_1's multi_logloss: 0.275824        \n",
      "[44]\ttraining's multi_logloss: 0.165645\tvalid_1's multi_logloss: 0.275102        \n",
      "[45]\ttraining's multi_logloss: 0.162069\tvalid_1's multi_logloss: 0.274467        \n",
      "[46]\ttraining's multi_logloss: 0.158433\tvalid_1's multi_logloss: 0.27432         \n",
      "[47]\ttraining's multi_logloss: 0.154726\tvalid_1's multi_logloss: 0.274011        \n",
      "[48]\ttraining's multi_logloss: 0.151053\tvalid_1's multi_logloss: 0.273687        \n",
      "[49]\ttraining's multi_logloss: 0.147582\tvalid_1's multi_logloss: 0.273407        \n",
      "[50]\ttraining's multi_logloss: 0.144583\tvalid_1's multi_logloss: 0.273052        \n",
      "[51]\ttraining's multi_logloss: 0.141454\tvalid_1's multi_logloss: 0.272503        \n",
      "[52]\ttraining's multi_logloss: 0.138128\tvalid_1's multi_logloss: 0.272402        \n",
      "[53]\ttraining's multi_logloss: 0.134941\tvalid_1's multi_logloss: 0.272218        \n",
      "[54]\ttraining's multi_logloss: 0.132244\tvalid_1's multi_logloss: 0.271865        \n",
      "[55]\ttraining's multi_logloss: 0.129359\tvalid_1's multi_logloss: 0.271496        \n",
      "[56]\ttraining's multi_logloss: 0.126473\tvalid_1's multi_logloss: 0.271688        \n",
      "[57]\ttraining's multi_logloss: 0.123697\tvalid_1's multi_logloss: 0.271391        \n",
      "[58]\ttraining's multi_logloss: 0.121137\tvalid_1's multi_logloss: 0.271219        \n",
      "[59]\ttraining's multi_logloss: 0.118662\tvalid_1's multi_logloss: 0.271445        \n",
      "[60]\ttraining's multi_logloss: 0.116202\tvalid_1's multi_logloss: 0.271616        \n",
      "[61]\ttraining's multi_logloss: 0.11374\tvalid_1's multi_logloss: 0.272025         \n",
      "[62]\ttraining's multi_logloss: 0.111444\tvalid_1's multi_logloss: 0.272039        \n",
      "[63]\ttraining's multi_logloss: 0.109014\tvalid_1's multi_logloss: 0.271851        \n",
      "[64]\ttraining's multi_logloss: 0.106484\tvalid_1's multi_logloss: 0.272053        \n",
      "[65]\ttraining's multi_logloss: 0.104177\tvalid_1's multi_logloss: 0.272132        \n",
      "[66]\ttraining's multi_logloss: 0.102025\tvalid_1's multi_logloss: 0.272131        \n",
      "[67]\ttraining's multi_logloss: 0.099859\tvalid_1's multi_logloss: 0.272108        \n",
      "[68]\ttraining's multi_logloss: 0.0978112\tvalid_1's multi_logloss: 0.272482       \n",
      "[69]\ttraining's multi_logloss: 0.0955963\tvalid_1's multi_logloss: 0.272596       \n",
      "[70]\ttraining's multi_logloss: 0.0935937\tvalid_1's multi_logloss: 0.273142       \n",
      "[71]\ttraining's multi_logloss: 0.0917393\tvalid_1's multi_logloss: 0.273335       \n",
      "[72]\ttraining's multi_logloss: 0.0897789\tvalid_1's multi_logloss: 0.273773       \n",
      "[73]\ttraining's multi_logloss: 0.0878102\tvalid_1's multi_logloss: 0.274219       \n",
      "[74]\ttraining's multi_logloss: 0.0861156\tvalid_1's multi_logloss: 0.274207       \n",
      "[75]\ttraining's multi_logloss: 0.0844792\tvalid_1's multi_logloss: 0.274628       \n",
      "[76]\ttraining's multi_logloss: 0.0827253\tvalid_1's multi_logloss: 0.274732       \n",
      "[77]\ttraining's multi_logloss: 0.0809734\tvalid_1's multi_logloss: 0.275169       \n",
      "[78]\ttraining's multi_logloss: 0.0792463\tvalid_1's multi_logloss: 0.275479       \n",
      "[79]\ttraining's multi_logloss: 0.0776541\tvalid_1's multi_logloss: 0.275802       \n",
      "[80]\ttraining's multi_logloss: 0.0762269\tvalid_1's multi_logloss: 0.275975       \n",
      "[81]\ttraining's multi_logloss: 0.0745803\tvalid_1's multi_logloss: 0.276472       \n",
      "[82]\ttraining's multi_logloss: 0.0730571\tvalid_1's multi_logloss: 0.276615       \n",
      "[83]\ttraining's multi_logloss: 0.0715963\tvalid_1's multi_logloss: 0.277032       \n",
      "[84]\ttraining's multi_logloss: 0.0700272\tvalid_1's multi_logloss: 0.277408       \n",
      "[85]\ttraining's multi_logloss: 0.0685887\tvalid_1's multi_logloss: 0.277987       \n",
      "[86]\ttraining's multi_logloss: 0.0672748\tvalid_1's multi_logloss: 0.278397       \n",
      "[87]\ttraining's multi_logloss: 0.0658417\tvalid_1's multi_logloss: 0.27909        \n",
      "[88]\ttraining's multi_logloss: 0.0645321\tvalid_1's multi_logloss: 0.279637       \n",
      "Early stopping, best iteration is:                                               \n",
      "[58]\ttraining's multi_logloss: 0.121137\tvalid_1's multi_logloss: 0.271219\n",
      "[1]\ttraining's multi_logloss: 1.73117\tvalid_1's multi_logloss: 1.73338           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.57129\tvalid_1's multi_logloss: 1.57747           \n",
      "[3]\ttraining's multi_logloss: 1.4406\tvalid_1's multi_logloss: 1.45033            \n",
      "[4]\ttraining's multi_logloss: 1.32927\tvalid_1's multi_logloss: 1.3428            \n",
      "[5]\ttraining's multi_logloss: 1.23375\tvalid_1's multi_logloss: 1.24959           \n",
      "[6]\ttraining's multi_logloss: 1.15003\tvalid_1's multi_logloss: 1.16876           \n",
      "[7]\ttraining's multi_logloss: 1.07617\tvalid_1's multi_logloss: 1.0972            \n",
      "[8]\ttraining's multi_logloss: 1.01059\tvalid_1's multi_logloss: 1.0339            \n",
      "[9]\ttraining's multi_logloss: 0.95128\tvalid_1's multi_logloss: 0.976696          \n",
      "[10]\ttraining's multi_logloss: 0.89798\tvalid_1's multi_logloss: 0.925588         \n",
      "[11]\ttraining's multi_logloss: 0.849262\tvalid_1's multi_logloss: 0.878792        \n",
      "[12]\ttraining's multi_logloss: 0.804906\tvalid_1's multi_logloss: 0.83592         \n",
      "[13]\ttraining's multi_logloss: 0.76409\tvalid_1's multi_logloss: 0.796702         \n",
      "[14]\ttraining's multi_logloss: 0.726834\tvalid_1's multi_logloss: 0.761097        \n",
      "[15]\ttraining's multi_logloss: 0.69249\tvalid_1's multi_logloss: 0.728185         \n",
      "[16]\ttraining's multi_logloss: 0.660946\tvalid_1's multi_logloss: 0.698174        \n",
      "[17]\ttraining's multi_logloss: 0.631731\tvalid_1's multi_logloss: 0.670514        \n",
      "[18]\ttraining's multi_logloss: 0.604704\tvalid_1's multi_logloss: 0.644949        \n",
      "[19]\ttraining's multi_logloss: 0.579344\tvalid_1's multi_logloss: 0.621172        \n",
      "[20]\ttraining's multi_logloss: 0.556179\tvalid_1's multi_logloss: 0.59953         \n",
      "[21]\ttraining's multi_logloss: 0.534511\tvalid_1's multi_logloss: 0.57906         \n",
      "[22]\ttraining's multi_logloss: 0.514261\tvalid_1's multi_logloss: 0.560351        \n",
      "[23]\ttraining's multi_logloss: 0.495461\tvalid_1's multi_logloss: 0.542815        \n",
      "[24]\ttraining's multi_logloss: 0.477953\tvalid_1's multi_logloss: 0.526537        \n",
      "[25]\ttraining's multi_logloss: 0.461495\tvalid_1's multi_logloss: 0.511228        \n",
      "[26]\ttraining's multi_logloss: 0.446157\tvalid_1's multi_logloss: 0.497373        \n",
      "[27]\ttraining's multi_logloss: 0.431456\tvalid_1's multi_logloss: 0.484048        \n",
      "[28]\ttraining's multi_logloss: 0.417934\tvalid_1's multi_logloss: 0.471704        \n",
      "[29]\ttraining's multi_logloss: 0.405283\tvalid_1's multi_logloss: 0.46041         \n",
      "[30]\ttraining's multi_logloss: 0.393281\tvalid_1's multi_logloss: 0.449735        \n",
      "[31]\ttraining's multi_logloss: 0.381997\tvalid_1's multi_logloss: 0.439457        \n",
      "[32]\ttraining's multi_logloss: 0.371512\tvalid_1's multi_logloss: 0.430225        \n",
      "[33]\ttraining's multi_logloss: 0.361602\tvalid_1's multi_logloss: 0.421456        \n",
      "[34]\ttraining's multi_logloss: 0.35226\tvalid_1's multi_logloss: 0.413291         \n",
      "[35]\ttraining's multi_logloss: 0.343481\tvalid_1's multi_logloss: 0.405984        \n",
      "[36]\ttraining's multi_logloss: 0.335015\tvalid_1's multi_logloss: 0.399025        \n",
      "[37]\ttraining's multi_logloss: 0.327243\tvalid_1's multi_logloss: 0.392924        \n",
      "[38]\ttraining's multi_logloss: 0.319698\tvalid_1's multi_logloss: 0.386653        \n",
      "[39]\ttraining's multi_logloss: 0.312571\tvalid_1's multi_logloss: 0.381028        \n",
      "[40]\ttraining's multi_logloss: 0.305766\tvalid_1's multi_logloss: 0.375616        \n",
      "[41]\ttraining's multi_logloss: 0.299369\tvalid_1's multi_logloss: 0.370643        \n",
      "[42]\ttraining's multi_logloss: 0.293218\tvalid_1's multi_logloss: 0.365673        \n",
      "[43]\ttraining's multi_logloss: 0.287453\tvalid_1's multi_logloss: 0.361305        \n",
      "[44]\ttraining's multi_logloss: 0.281749\tvalid_1's multi_logloss: 0.357218        \n",
      "[45]\ttraining's multi_logloss: 0.276228\tvalid_1's multi_logloss: 0.35316         \n",
      "[46]\ttraining's multi_logloss: 0.27112\tvalid_1's multi_logloss: 0.349601         \n",
      "[47]\ttraining's multi_logloss: 0.266215\tvalid_1's multi_logloss: 0.346059        \n",
      "[48]\ttraining's multi_logloss: 0.261517\tvalid_1's multi_logloss: 0.342832        \n",
      "[49]\ttraining's multi_logloss: 0.257133\tvalid_1's multi_logloss: 0.339726        \n",
      "[50]\ttraining's multi_logloss: 0.252756\tvalid_1's multi_logloss: 0.336856        \n",
      "[51]\ttraining's multi_logloss: 0.24856\tvalid_1's multi_logloss: 0.333925         \n",
      "[52]\ttraining's multi_logloss: 0.244451\tvalid_1's multi_logloss: 0.331329        \n",
      "[53]\ttraining's multi_logloss: 0.240531\tvalid_1's multi_logloss: 0.328863        \n",
      "[54]\ttraining's multi_logloss: 0.236725\tvalid_1's multi_logloss: 0.326637        \n",
      "[55]\ttraining's multi_logloss: 0.233081\tvalid_1's multi_logloss: 0.324392        \n",
      "[56]\ttraining's multi_logloss: 0.229576\tvalid_1's multi_logloss: 0.322483        \n",
      "[57]\ttraining's multi_logloss: 0.226102\tvalid_1's multi_logloss: 0.320496        \n",
      "[58]\ttraining's multi_logloss: 0.222805\tvalid_1's multi_logloss: 0.318668        \n",
      "[59]\ttraining's multi_logloss: 0.219614\tvalid_1's multi_logloss: 0.316981        \n",
      "[60]\ttraining's multi_logloss: 0.216439\tvalid_1's multi_logloss: 0.315473        \n",
      "[61]\ttraining's multi_logloss: 0.213446\tvalid_1's multi_logloss: 0.314107        \n",
      "[62]\ttraining's multi_logloss: 0.210554\tvalid_1's multi_logloss: 0.31261         \n",
      "[63]\ttraining's multi_logloss: 0.207634\tvalid_1's multi_logloss: 0.311237        \n",
      "[64]\ttraining's multi_logloss: 0.204986\tvalid_1's multi_logloss: 0.310061        \n",
      "[65]\ttraining's multi_logloss: 0.202219\tvalid_1's multi_logloss: 0.30891         \n",
      "[66]\ttraining's multi_logloss: 0.199454\tvalid_1's multi_logloss: 0.307873        \n",
      "[67]\ttraining's multi_logloss: 0.196892\tvalid_1's multi_logloss: 0.306938        \n",
      "[68]\ttraining's multi_logloss: 0.194257\tvalid_1's multi_logloss: 0.305983        \n",
      "[69]\ttraining's multi_logloss: 0.19178\tvalid_1's multi_logloss: 0.305035         \n",
      "[70]\ttraining's multi_logloss: 0.189401\tvalid_1's multi_logloss: 0.304224        \n",
      "[71]\ttraining's multi_logloss: 0.186958\tvalid_1's multi_logloss: 0.303149        \n",
      "[72]\ttraining's multi_logloss: 0.184624\tvalid_1's multi_logloss: 0.302265        \n",
      "[73]\ttraining's multi_logloss: 0.182383\tvalid_1's multi_logloss: 0.301515        \n",
      "[74]\ttraining's multi_logloss: 0.18009\tvalid_1's multi_logloss: 0.300719         \n",
      "[75]\ttraining's multi_logloss: 0.177802\tvalid_1's multi_logloss: 0.299936        \n",
      "[76]\ttraining's multi_logloss: 0.175579\tvalid_1's multi_logloss: 0.299161        \n",
      "[77]\ttraining's multi_logloss: 0.173379\tvalid_1's multi_logloss: 0.298699        \n",
      "[78]\ttraining's multi_logloss: 0.171358\tvalid_1's multi_logloss: 0.297912        \n",
      "[79]\ttraining's multi_logloss: 0.169334\tvalid_1's multi_logloss: 0.297559        \n",
      "[80]\ttraining's multi_logloss: 0.167363\tvalid_1's multi_logloss: 0.297108        \n",
      "[81]\ttraining's multi_logloss: 0.165376\tvalid_1's multi_logloss: 0.296562        \n",
      "[82]\ttraining's multi_logloss: 0.163432\tvalid_1's multi_logloss: 0.295975        \n",
      "[83]\ttraining's multi_logloss: 0.161558\tvalid_1's multi_logloss: 0.295622        \n",
      "[84]\ttraining's multi_logloss: 0.159639\tvalid_1's multi_logloss: 0.295409        \n",
      "[85]\ttraining's multi_logloss: 0.15786\tvalid_1's multi_logloss: 0.295049         \n",
      "[86]\ttraining's multi_logloss: 0.156033\tvalid_1's multi_logloss: 0.294645        \n",
      "[87]\ttraining's multi_logloss: 0.154123\tvalid_1's multi_logloss: 0.29412         \n",
      "[88]\ttraining's multi_logloss: 0.152338\tvalid_1's multi_logloss: 0.293707        \n",
      "[89]\ttraining's multi_logloss: 0.150554\tvalid_1's multi_logloss: 0.293366        \n",
      "[90]\ttraining's multi_logloss: 0.148778\tvalid_1's multi_logloss: 0.293006        \n",
      "[91]\ttraining's multi_logloss: 0.147118\tvalid_1's multi_logloss: 0.292635        \n",
      "[92]\ttraining's multi_logloss: 0.145483\tvalid_1's multi_logloss: 0.292272        \n",
      "[93]\ttraining's multi_logloss: 0.143886\tvalid_1's multi_logloss: 0.292003        \n",
      "[94]\ttraining's multi_logloss: 0.14235\tvalid_1's multi_logloss: 0.29177          \n",
      "[95]\ttraining's multi_logloss: 0.140771\tvalid_1's multi_logloss: 0.291457        \n",
      "[96]\ttraining's multi_logloss: 0.139338\tvalid_1's multi_logloss: 0.291213        \n",
      "[97]\ttraining's multi_logloss: 0.1379\tvalid_1's multi_logloss: 0.290808          \n",
      "[98]\ttraining's multi_logloss: 0.136463\tvalid_1's multi_logloss: 0.290755        \n",
      "[99]\ttraining's multi_logloss: 0.134975\tvalid_1's multi_logloss: 0.290499        \n",
      "[100]\ttraining's multi_logloss: 0.13357\tvalid_1's multi_logloss: 0.290324        \n",
      "[101]\ttraining's multi_logloss: 0.132203\tvalid_1's multi_logloss: 0.289964       \n",
      "[102]\ttraining's multi_logloss: 0.130873\tvalid_1's multi_logloss: 0.28993        \n",
      "[103]\ttraining's multi_logloss: 0.129535\tvalid_1's multi_logloss: 0.289796       \n",
      "[104]\ttraining's multi_logloss: 0.128156\tvalid_1's multi_logloss: 0.289732       \n",
      "[105]\ttraining's multi_logloss: 0.126794\tvalid_1's multi_logloss: 0.289681       \n",
      "[106]\ttraining's multi_logloss: 0.125561\tvalid_1's multi_logloss: 0.289597       \n",
      "[107]\ttraining's multi_logloss: 0.124234\tvalid_1's multi_logloss: 0.289445       \n",
      "[108]\ttraining's multi_logloss: 0.122917\tvalid_1's multi_logloss: 0.289567       \n",
      "[109]\ttraining's multi_logloss: 0.12171\tvalid_1's multi_logloss: 0.289495        \n",
      "[110]\ttraining's multi_logloss: 0.120513\tvalid_1's multi_logloss: 0.289454       \n",
      "[111]\ttraining's multi_logloss: 0.119375\tvalid_1's multi_logloss: 0.289303       \n",
      "[112]\ttraining's multi_logloss: 0.118175\tvalid_1's multi_logloss: 0.289319       \n",
      "[113]\ttraining's multi_logloss: 0.116969\tvalid_1's multi_logloss: 0.289324       \n",
      "[114]\ttraining's multi_logloss: 0.115785\tvalid_1's multi_logloss: 0.289271       \n",
      "[115]\ttraining's multi_logloss: 0.114613\tvalid_1's multi_logloss: 0.28931        \n",
      "[116]\ttraining's multi_logloss: 0.11349\tvalid_1's multi_logloss: 0.289352        \n",
      "[117]\ttraining's multi_logloss: 0.112396\tvalid_1's multi_logloss: 0.289603       \n",
      "[118]\ttraining's multi_logloss: 0.111383\tvalid_1's multi_logloss: 0.289792       \n",
      "[119]\ttraining's multi_logloss: 0.110344\tvalid_1's multi_logloss: 0.289736       \n",
      "[120]\ttraining's multi_logloss: 0.109272\tvalid_1's multi_logloss: 0.289817       \n",
      "[121]\ttraining's multi_logloss: 0.10819\tvalid_1's multi_logloss: 0.289691        \n",
      "[122]\ttraining's multi_logloss: 0.107161\tvalid_1's multi_logloss: 0.289845       \n",
      "[123]\ttraining's multi_logloss: 0.106179\tvalid_1's multi_logloss: 0.29006        \n",
      "[124]\ttraining's multi_logloss: 0.105223\tvalid_1's multi_logloss: 0.290219       \n",
      "[125]\ttraining's multi_logloss: 0.104255\tvalid_1's multi_logloss: 0.290387       \n",
      "[126]\ttraining's multi_logloss: 0.103248\tvalid_1's multi_logloss: 0.290628       \n",
      "[127]\ttraining's multi_logloss: 0.102294\tvalid_1's multi_logloss: 0.290742       \n",
      "[128]\ttraining's multi_logloss: 0.101322\tvalid_1's multi_logloss: 0.291011       \n",
      "[129]\ttraining's multi_logloss: 0.100378\tvalid_1's multi_logloss: 0.291116       \n",
      "[130]\ttraining's multi_logloss: 0.0994464\tvalid_1's multi_logloss: 0.291425      \n",
      "[131]\ttraining's multi_logloss: 0.098593\tvalid_1's multi_logloss: 0.291564       \n",
      "[132]\ttraining's multi_logloss: 0.0977116\tvalid_1's multi_logloss: 0.291597      \n",
      "[133]\ttraining's multi_logloss: 0.096874\tvalid_1's multi_logloss: 0.291579       \n",
      "[134]\ttraining's multi_logloss: 0.0959194\tvalid_1's multi_logloss: 0.291856      \n",
      "[135]\ttraining's multi_logloss: 0.0951029\tvalid_1's multi_logloss: 0.291908      \n",
      "[136]\ttraining's multi_logloss: 0.0942903\tvalid_1's multi_logloss: 0.292054      \n",
      "[137]\ttraining's multi_logloss: 0.0934462\tvalid_1's multi_logloss: 0.292148      \n",
      "[138]\ttraining's multi_logloss: 0.0926431\tvalid_1's multi_logloss: 0.292347      \n",
      "[139]\ttraining's multi_logloss: 0.0918029\tvalid_1's multi_logloss: 0.292639      \n",
      "[140]\ttraining's multi_logloss: 0.0909769\tvalid_1's multi_logloss: 0.292646      \n",
      "[141]\ttraining's multi_logloss: 0.0901988\tvalid_1's multi_logloss: 0.292902      \n",
      "[142]\ttraining's multi_logloss: 0.0894711\tvalid_1's multi_logloss: 0.292986      \n",
      "[143]\ttraining's multi_logloss: 0.0887062\tvalid_1's multi_logloss: 0.293203      \n",
      "[144]\ttraining's multi_logloss: 0.0879642\tvalid_1's multi_logloss: 0.2933        \n",
      "Early stopping, best iteration is:                                               \n",
      "[114]\ttraining's multi_logloss: 0.115785\tvalid_1's multi_logloss: 0.289271\n",
      "[1]\ttraining's multi_logloss: 1.72917\tvalid_1's multi_logloss: 1.73265           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.57206\tvalid_1's multi_logloss: 1.57665           \n",
      "[3]\ttraining's multi_logloss: 1.44245\tvalid_1's multi_logloss: 1.44809           \n",
      "[4]\ttraining's multi_logloss: 1.33275\tvalid_1's multi_logloss: 1.34007           \n",
      "[5]\ttraining's multi_logloss: 1.23743\tvalid_1's multi_logloss: 1.2467            \n",
      "[6]\ttraining's multi_logloss: 1.1548\tvalid_1's multi_logloss: 1.16529            \n",
      "[7]\ttraining's multi_logloss: 1.0809\tvalid_1's multi_logloss: 1.09284            \n",
      "[8]\ttraining's multi_logloss: 1.01532\tvalid_1's multi_logloss: 1.02853           \n",
      "[9]\ttraining's multi_logloss: 0.956605\tvalid_1's multi_logloss: 0.971268         \n",
      "[10]\ttraining's multi_logloss: 0.903402\tvalid_1's multi_logloss: 0.919634        \n",
      "[11]\ttraining's multi_logloss: 0.854751\tvalid_1's multi_logloss: 0.872691        \n",
      "[12]\ttraining's multi_logloss: 0.810406\tvalid_1's multi_logloss: 0.829708        \n",
      "[13]\ttraining's multi_logloss: 0.769764\tvalid_1's multi_logloss: 0.790321        \n",
      "[14]\ttraining's multi_logloss: 0.732517\tvalid_1's multi_logloss: 0.754576        \n",
      "[15]\ttraining's multi_logloss: 0.697954\tvalid_1's multi_logloss: 0.721517        \n",
      "[16]\ttraining's multi_logloss: 0.666366\tvalid_1's multi_logloss: 0.691509        \n",
      "[17]\ttraining's multi_logloss: 0.636896\tvalid_1's multi_logloss: 0.663624        \n",
      "[18]\ttraining's multi_logloss: 0.609709\tvalid_1's multi_logloss: 0.637813        \n",
      "[19]\ttraining's multi_logloss: 0.584462\tvalid_1's multi_logloss: 0.613767        \n",
      "[20]\ttraining's multi_logloss: 0.561083\tvalid_1's multi_logloss: 0.591575        \n",
      "[21]\ttraining's multi_logloss: 0.539323\tvalid_1's multi_logloss: 0.571024        \n",
      "[22]\ttraining's multi_logloss: 0.519289\tvalid_1's multi_logloss: 0.552273        \n",
      "[23]\ttraining's multi_logloss: 0.500329\tvalid_1's multi_logloss: 0.534719        \n",
      "[24]\ttraining's multi_logloss: 0.483051\tvalid_1's multi_logloss: 0.518855        \n",
      "[25]\ttraining's multi_logloss: 0.466705\tvalid_1's multi_logloss: 0.50394         \n",
      "[26]\ttraining's multi_logloss: 0.451453\tvalid_1's multi_logloss: 0.490044        \n",
      "[27]\ttraining's multi_logloss: 0.437101\tvalid_1's multi_logloss: 0.477279        \n",
      "[28]\ttraining's multi_logloss: 0.423476\tvalid_1's multi_logloss: 0.465157        \n",
      "[29]\ttraining's multi_logloss: 0.410758\tvalid_1's multi_logloss: 0.453763        \n",
      "[30]\ttraining's multi_logloss: 0.398738\tvalid_1's multi_logloss: 0.443152        \n",
      "[31]\ttraining's multi_logloss: 0.387576\tvalid_1's multi_logloss: 0.433563        \n",
      "[32]\ttraining's multi_logloss: 0.37696\tvalid_1's multi_logloss: 0.424492         \n",
      "[33]\ttraining's multi_logloss: 0.366957\tvalid_1's multi_logloss: 0.416199        \n",
      "[34]\ttraining's multi_logloss: 0.357492\tvalid_1's multi_logloss: 0.408429        \n",
      "[35]\ttraining's multi_logloss: 0.348473\tvalid_1's multi_logloss: 0.40111         \n",
      "[36]\ttraining's multi_logloss: 0.340004\tvalid_1's multi_logloss: 0.394326        \n",
      "[37]\ttraining's multi_logloss: 0.33181\tvalid_1's multi_logloss: 0.387374         \n",
      "[38]\ttraining's multi_logloss: 0.324051\tvalid_1's multi_logloss: 0.381196        \n",
      "[39]\ttraining's multi_logloss: 0.316697\tvalid_1's multi_logloss: 0.375262        \n",
      "[40]\ttraining's multi_logloss: 0.309765\tvalid_1's multi_logloss: 0.369689        \n",
      "[41]\ttraining's multi_logloss: 0.303211\tvalid_1's multi_logloss: 0.364646        \n",
      "[42]\ttraining's multi_logloss: 0.29701\tvalid_1's multi_logloss: 0.359949         \n",
      "[43]\ttraining's multi_logloss: 0.290772\tvalid_1's multi_logloss: 0.355031        \n",
      "[44]\ttraining's multi_logloss: 0.28465\tvalid_1's multi_logloss: 0.35043          \n",
      "[45]\ttraining's multi_logloss: 0.279181\tvalid_1's multi_logloss: 0.346359        \n",
      "[46]\ttraining's multi_logloss: 0.273771\tvalid_1's multi_logloss: 0.342575        \n",
      "[47]\ttraining's multi_logloss: 0.268675\tvalid_1's multi_logloss: 0.338994        \n",
      "[48]\ttraining's multi_logloss: 0.263864\tvalid_1's multi_logloss: 0.335792        \n",
      "[49]\ttraining's multi_logloss: 0.259068\tvalid_1's multi_logloss: 0.332466        \n",
      "[50]\ttraining's multi_logloss: 0.254484\tvalid_1's multi_logloss: 0.329468        \n",
      "[51]\ttraining's multi_logloss: 0.250224\tvalid_1's multi_logloss: 0.326749        \n",
      "[52]\ttraining's multi_logloss: 0.24596\tvalid_1's multi_logloss: 0.324279         \n",
      "[53]\ttraining's multi_logloss: 0.241778\tvalid_1's multi_logloss: 0.321976        \n",
      "[54]\ttraining's multi_logloss: 0.237852\tvalid_1's multi_logloss: 0.319844        \n",
      "[55]\ttraining's multi_logloss: 0.23407\tvalid_1's multi_logloss: 0.317925         \n",
      "[56]\ttraining's multi_logloss: 0.230488\tvalid_1's multi_logloss: 0.316079        \n",
      "[57]\ttraining's multi_logloss: 0.226892\tvalid_1's multi_logloss: 0.314095        \n",
      "[58]\ttraining's multi_logloss: 0.223497\tvalid_1's multi_logloss: 0.312403        \n",
      "[59]\ttraining's multi_logloss: 0.220126\tvalid_1's multi_logloss: 0.310867        \n",
      "[60]\ttraining's multi_logloss: 0.21689\tvalid_1's multi_logloss: 0.309466         \n",
      "[61]\ttraining's multi_logloss: 0.213757\tvalid_1's multi_logloss: 0.30798         \n",
      "[62]\ttraining's multi_logloss: 0.210711\tvalid_1's multi_logloss: 0.306729        \n",
      "[63]\ttraining's multi_logloss: 0.207727\tvalid_1's multi_logloss: 0.305406        \n",
      "[64]\ttraining's multi_logloss: 0.204834\tvalid_1's multi_logloss: 0.304159        \n",
      "[65]\ttraining's multi_logloss: 0.202115\tvalid_1's multi_logloss: 0.303183        \n",
      "[66]\ttraining's multi_logloss: 0.199403\tvalid_1's multi_logloss: 0.302243        \n",
      "[67]\ttraining's multi_logloss: 0.196716\tvalid_1's multi_logloss: 0.301319        \n",
      "[68]\ttraining's multi_logloss: 0.194066\tvalid_1's multi_logloss: 0.300422        \n",
      "[69]\ttraining's multi_logloss: 0.191566\tvalid_1's multi_logloss: 0.299486        \n",
      "[70]\ttraining's multi_logloss: 0.189237\tvalid_1's multi_logloss: 0.298811        \n",
      "[71]\ttraining's multi_logloss: 0.186824\tvalid_1's multi_logloss: 0.298022        \n",
      "[72]\ttraining's multi_logloss: 0.184389\tvalid_1's multi_logloss: 0.297105        \n",
      "[73]\ttraining's multi_logloss: 0.182057\tvalid_1's multi_logloss: 0.296472        \n",
      "[74]\ttraining's multi_logloss: 0.179735\tvalid_1's multi_logloss: 0.295737        \n",
      "[75]\ttraining's multi_logloss: 0.17755\tvalid_1's multi_logloss: 0.295168         \n",
      "[76]\ttraining's multi_logloss: 0.175307\tvalid_1's multi_logloss: 0.294624        \n",
      "[77]\ttraining's multi_logloss: 0.173146\tvalid_1's multi_logloss: 0.293905        \n",
      "[78]\ttraining's multi_logloss: 0.171122\tvalid_1's multi_logloss: 0.293421        \n",
      "[79]\ttraining's multi_logloss: 0.169146\tvalid_1's multi_logloss: 0.292887        \n",
      "[80]\ttraining's multi_logloss: 0.167065\tvalid_1's multi_logloss: 0.292386        \n",
      "[81]\ttraining's multi_logloss: 0.165059\tvalid_1's multi_logloss: 0.291847        \n",
      "[82]\ttraining's multi_logloss: 0.163048\tvalid_1's multi_logloss: 0.291319        \n",
      "[83]\ttraining's multi_logloss: 0.161145\tvalid_1's multi_logloss: 0.290813        \n",
      "[84]\ttraining's multi_logloss: 0.159209\tvalid_1's multi_logloss: 0.290241        \n",
      "[85]\ttraining's multi_logloss: 0.157358\tvalid_1's multi_logloss: 0.290013        \n",
      "[86]\ttraining's multi_logloss: 0.15554\tvalid_1's multi_logloss: 0.289602         \n",
      "[87]\ttraining's multi_logloss: 0.153674\tvalid_1's multi_logloss: 0.289166        \n",
      "[88]\ttraining's multi_logloss: 0.151904\tvalid_1's multi_logloss: 0.28896         \n",
      "[89]\ttraining's multi_logloss: 0.150172\tvalid_1's multi_logloss: 0.288698        \n",
      "[90]\ttraining's multi_logloss: 0.148321\tvalid_1's multi_logloss: 0.288319        \n",
      "[91]\ttraining's multi_logloss: 0.146596\tvalid_1's multi_logloss: 0.288158        \n",
      "[92]\ttraining's multi_logloss: 0.145025\tvalid_1's multi_logloss: 0.287778        \n",
      "[93]\ttraining's multi_logloss: 0.14329\tvalid_1's multi_logloss: 0.287398         \n",
      "[94]\ttraining's multi_logloss: 0.141815\tvalid_1's multi_logloss: 0.28727         \n",
      "[95]\ttraining's multi_logloss: 0.14022\tvalid_1's multi_logloss: 0.286976         \n",
      "[96]\ttraining's multi_logloss: 0.13876\tvalid_1's multi_logloss: 0.286828         \n",
      "[97]\ttraining's multi_logloss: 0.137333\tvalid_1's multi_logloss: 0.286679        \n",
      "[98]\ttraining's multi_logloss: 0.135854\tvalid_1's multi_logloss: 0.2866          \n",
      "[99]\ttraining's multi_logloss: 0.134323\tvalid_1's multi_logloss: 0.286383        \n",
      "[100]\ttraining's multi_logloss: 0.13283\tvalid_1's multi_logloss: 0.286126        \n",
      "[101]\ttraining's multi_logloss: 0.131503\tvalid_1's multi_logloss: 0.286066       \n",
      "[102]\ttraining's multi_logloss: 0.130053\tvalid_1's multi_logloss: 0.285886       \n",
      "[103]\ttraining's multi_logloss: 0.128644\tvalid_1's multi_logloss: 0.285565       \n",
      "[104]\ttraining's multi_logloss: 0.127307\tvalid_1's multi_logloss: 0.285552       \n",
      "[105]\ttraining's multi_logloss: 0.126008\tvalid_1's multi_logloss: 0.285505       \n",
      "[106]\ttraining's multi_logloss: 0.12475\tvalid_1's multi_logloss: 0.285444        \n",
      "[107]\ttraining's multi_logloss: 0.123437\tvalid_1's multi_logloss: 0.285529       \n",
      "[108]\ttraining's multi_logloss: 0.122238\tvalid_1's multi_logloss: 0.285547       \n",
      "[109]\ttraining's multi_logloss: 0.121002\tvalid_1's multi_logloss: 0.285475       \n",
      "[110]\ttraining's multi_logloss: 0.119729\tvalid_1's multi_logloss: 0.285507       \n",
      "[111]\ttraining's multi_logloss: 0.118541\tvalid_1's multi_logloss: 0.285437       \n",
      "[112]\ttraining's multi_logloss: 0.117355\tvalid_1's multi_logloss: 0.285406       \n",
      "[113]\ttraining's multi_logloss: 0.116101\tvalid_1's multi_logloss: 0.285257       \n",
      "[114]\ttraining's multi_logloss: 0.114989\tvalid_1's multi_logloss: 0.285279       \n",
      "[115]\ttraining's multi_logloss: 0.113845\tvalid_1's multi_logloss: 0.285319       \n",
      "[116]\ttraining's multi_logloss: 0.112829\tvalid_1's multi_logloss: 0.285401       \n",
      "[117]\ttraining's multi_logloss: 0.11173\tvalid_1's multi_logloss: 0.2856          \n",
      "[118]\ttraining's multi_logloss: 0.110564\tvalid_1's multi_logloss: 0.285869       \n",
      "[119]\ttraining's multi_logloss: 0.109473\tvalid_1's multi_logloss: 0.285832       \n",
      "[120]\ttraining's multi_logloss: 0.108322\tvalid_1's multi_logloss: 0.285916       \n",
      "[121]\ttraining's multi_logloss: 0.107269\tvalid_1's multi_logloss: 0.285994       \n",
      "[122]\ttraining's multi_logloss: 0.106291\tvalid_1's multi_logloss: 0.286189       \n",
      "[123]\ttraining's multi_logloss: 0.105273\tvalid_1's multi_logloss: 0.286341       \n",
      "[124]\ttraining's multi_logloss: 0.104222\tvalid_1's multi_logloss: 0.286481       \n",
      "[125]\ttraining's multi_logloss: 0.103256\tvalid_1's multi_logloss: 0.286518       \n",
      "[126]\ttraining's multi_logloss: 0.102241\tvalid_1's multi_logloss: 0.286643       \n",
      "[127]\ttraining's multi_logloss: 0.101279\tvalid_1's multi_logloss: 0.28683        \n",
      "[128]\ttraining's multi_logloss: 0.100262\tvalid_1's multi_logloss: 0.287131       \n",
      "[129]\ttraining's multi_logloss: 0.0992963\tvalid_1's multi_logloss: 0.287243      \n",
      "[130]\ttraining's multi_logloss: 0.0983275\tvalid_1's multi_logloss: 0.287461      \n",
      "[131]\ttraining's multi_logloss: 0.0974218\tvalid_1's multi_logloss: 0.287577      \n",
      "[132]\ttraining's multi_logloss: 0.0964573\tvalid_1's multi_logloss: 0.287643      \n",
      "[133]\ttraining's multi_logloss: 0.0954544\tvalid_1's multi_logloss: 0.287844      \n",
      "[134]\ttraining's multi_logloss: 0.0945881\tvalid_1's multi_logloss: 0.28815       \n",
      "[135]\ttraining's multi_logloss: 0.0935902\tvalid_1's multi_logloss: 0.288484      \n",
      "[136]\ttraining's multi_logloss: 0.092702\tvalid_1's multi_logloss: 0.288541       \n",
      "[137]\ttraining's multi_logloss: 0.0918582\tvalid_1's multi_logloss: 0.28883       \n",
      "[138]\ttraining's multi_logloss: 0.0910206\tvalid_1's multi_logloss: 0.28896       \n",
      "[139]\ttraining's multi_logloss: 0.090163\tvalid_1's multi_logloss: 0.2889         \n",
      "[140]\ttraining's multi_logloss: 0.0893014\tvalid_1's multi_logloss: 0.289039      \n",
      "[141]\ttraining's multi_logloss: 0.0885108\tvalid_1's multi_logloss: 0.289328      \n",
      "[142]\ttraining's multi_logloss: 0.0876614\tvalid_1's multi_logloss: 0.289389      \n",
      "[143]\ttraining's multi_logloss: 0.0868422\tvalid_1's multi_logloss: 0.289556      \n",
      "Early stopping, best iteration is:                                               \n",
      "[113]\ttraining's multi_logloss: 0.116101\tvalid_1's multi_logloss: 0.285257\n",
      "[1]\ttraining's multi_logloss: 1.73023\tvalid_1's multi_logloss: 1.73381           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.57386\tvalid_1's multi_logloss: 1.57905           \n",
      "[3]\ttraining's multi_logloss: 1.44411\tvalid_1's multi_logloss: 1.45029           \n",
      "[4]\ttraining's multi_logloss: 1.33478\tvalid_1's multi_logloss: 1.342             \n",
      "[5]\ttraining's multi_logloss: 1.2398\tvalid_1's multi_logloss: 1.24789            \n",
      "[6]\ttraining's multi_logloss: 1.15708\tvalid_1's multi_logloss: 1.16594           \n",
      "[7]\ttraining's multi_logloss: 1.08394\tvalid_1's multi_logloss: 1.09364           \n",
      "[8]\ttraining's multi_logloss: 1.01834\tvalid_1's multi_logloss: 1.02893           \n",
      "[9]\ttraining's multi_logloss: 0.958859\tvalid_1's multi_logloss: 0.970154         \n",
      "[10]\ttraining's multi_logloss: 0.905371\tvalid_1's multi_logloss: 0.917516        \n",
      "[11]\ttraining's multi_logloss: 0.856376\tvalid_1's multi_logloss: 0.869367        \n",
      "[12]\ttraining's multi_logloss: 0.812212\tvalid_1's multi_logloss: 0.825578        \n",
      "[13]\ttraining's multi_logloss: 0.771769\tvalid_1's multi_logloss: 0.785898        \n",
      "[14]\ttraining's multi_logloss: 0.734698\tvalid_1's multi_logloss: 0.749814        \n",
      "[15]\ttraining's multi_logloss: 0.700761\tvalid_1's multi_logloss: 0.71691         \n",
      "[16]\ttraining's multi_logloss: 0.669139\tvalid_1's multi_logloss: 0.686465        \n",
      "[17]\ttraining's multi_logloss: 0.639835\tvalid_1's multi_logloss: 0.658057        \n",
      "[18]\ttraining's multi_logloss: 0.61312\tvalid_1's multi_logloss: 0.632634         \n",
      "[19]\ttraining's multi_logloss: 0.588207\tvalid_1's multi_logloss: 0.609048        \n",
      "[20]\ttraining's multi_logloss: 0.564962\tvalid_1's multi_logloss: 0.586916        \n",
      "[21]\ttraining's multi_logloss: 0.543794\tvalid_1's multi_logloss: 0.566923        \n",
      "[22]\ttraining's multi_logloss: 0.524015\tvalid_1's multi_logloss: 0.548391        \n",
      "[23]\ttraining's multi_logloss: 0.505301\tvalid_1's multi_logloss: 0.530843        \n",
      "[24]\ttraining's multi_logloss: 0.488109\tvalid_1's multi_logloss: 0.514725        \n",
      "[25]\ttraining's multi_logloss: 0.471925\tvalid_1's multi_logloss: 0.499705        \n",
      "[26]\ttraining's multi_logloss: 0.456677\tvalid_1's multi_logloss: 0.485641        \n",
      "[27]\ttraining's multi_logloss: 0.442542\tvalid_1's multi_logloss: 0.472653        \n",
      "[28]\ttraining's multi_logloss: 0.428963\tvalid_1's multi_logloss: 0.46021         \n",
      "[29]\ttraining's multi_logloss: 0.416196\tvalid_1's multi_logloss: 0.448789        \n",
      "[30]\ttraining's multi_logloss: 0.404204\tvalid_1's multi_logloss: 0.437959        \n",
      "[31]\ttraining's multi_logloss: 0.392922\tvalid_1's multi_logloss: 0.427931        \n",
      "[32]\ttraining's multi_logloss: 0.381803\tvalid_1's multi_logloss: 0.417738        \n",
      "[33]\ttraining's multi_logloss: 0.37186\tvalid_1's multi_logloss: 0.408808         \n",
      "[34]\ttraining's multi_logloss: 0.362454\tvalid_1's multi_logloss: 0.400516        \n",
      "[35]\ttraining's multi_logloss: 0.353108\tvalid_1's multi_logloss: 0.392115        \n",
      "[36]\ttraining's multi_logloss: 0.344571\tvalid_1's multi_logloss: 0.38476         \n",
      "[37]\ttraining's multi_logloss: 0.336438\tvalid_1's multi_logloss: 0.377624        \n",
      "[38]\ttraining's multi_logloss: 0.32894\tvalid_1's multi_logloss: 0.37139          \n",
      "[39]\ttraining's multi_logloss: 0.321854\tvalid_1's multi_logloss: 0.365497        \n",
      "[40]\ttraining's multi_logloss: 0.314986\tvalid_1's multi_logloss: 0.359833        \n",
      "[41]\ttraining's multi_logloss: 0.308306\tvalid_1's multi_logloss: 0.35436         \n",
      "[42]\ttraining's multi_logloss: 0.301908\tvalid_1's multi_logloss: 0.3493          \n",
      "[43]\ttraining's multi_logloss: 0.295893\tvalid_1's multi_logloss: 0.344707        \n",
      "[44]\ttraining's multi_logloss: 0.29024\tvalid_1's multi_logloss: 0.340229         \n",
      "[45]\ttraining's multi_logloss: 0.284776\tvalid_1's multi_logloss: 0.336194        \n",
      "[46]\ttraining's multi_logloss: 0.279413\tvalid_1's multi_logloss: 0.332246        \n",
      "[47]\ttraining's multi_logloss: 0.274465\tvalid_1's multi_logloss: 0.328745        \n",
      "[48]\ttraining's multi_logloss: 0.269625\tvalid_1's multi_logloss: 0.325178        \n",
      "[49]\ttraining's multi_logloss: 0.265003\tvalid_1's multi_logloss: 0.321978        \n",
      "[50]\ttraining's multi_logloss: 0.260552\tvalid_1's multi_logloss: 0.319089        \n",
      "[51]\ttraining's multi_logloss: 0.256394\tvalid_1's multi_logloss: 0.316121        \n",
      "[52]\ttraining's multi_logloss: 0.252355\tvalid_1's multi_logloss: 0.313644        \n",
      "[53]\ttraining's multi_logloss: 0.248374\tvalid_1's multi_logloss: 0.310966        \n",
      "[54]\ttraining's multi_logloss: 0.244613\tvalid_1's multi_logloss: 0.308697        \n",
      "[55]\ttraining's multi_logloss: 0.240973\tvalid_1's multi_logloss: 0.306318        \n",
      "[56]\ttraining's multi_logloss: 0.237352\tvalid_1's multi_logloss: 0.304308        \n",
      "[57]\ttraining's multi_logloss: 0.233856\tvalid_1's multi_logloss: 0.302303        \n",
      "[58]\ttraining's multi_logloss: 0.230328\tvalid_1's multi_logloss: 0.300166        \n",
      "[59]\ttraining's multi_logloss: 0.226986\tvalid_1's multi_logloss: 0.298355        \n",
      "[60]\ttraining's multi_logloss: 0.223697\tvalid_1's multi_logloss: 0.296869        \n",
      "[61]\ttraining's multi_logloss: 0.220731\tvalid_1's multi_logloss: 0.295422        \n",
      "[62]\ttraining's multi_logloss: 0.217611\tvalid_1's multi_logloss: 0.294005        \n",
      "[63]\ttraining's multi_logloss: 0.214789\tvalid_1's multi_logloss: 0.292685        \n",
      "[64]\ttraining's multi_logloss: 0.211921\tvalid_1's multi_logloss: 0.291328        \n",
      "[65]\ttraining's multi_logloss: 0.209118\tvalid_1's multi_logloss: 0.289948        \n",
      "[66]\ttraining's multi_logloss: 0.206407\tvalid_1's multi_logloss: 0.288699        \n",
      "[67]\ttraining's multi_logloss: 0.203729\tvalid_1's multi_logloss: 0.287619        \n",
      "[68]\ttraining's multi_logloss: 0.201038\tvalid_1's multi_logloss: 0.286327        \n",
      "[69]\ttraining's multi_logloss: 0.198482\tvalid_1's multi_logloss: 0.285361        \n",
      "[70]\ttraining's multi_logloss: 0.196152\tvalid_1's multi_logloss: 0.284656        \n",
      "[71]\ttraining's multi_logloss: 0.19377\tvalid_1's multi_logloss: 0.283781         \n",
      "[72]\ttraining's multi_logloss: 0.191383\tvalid_1's multi_logloss: 0.282909        \n",
      "[73]\ttraining's multi_logloss: 0.189021\tvalid_1's multi_logloss: 0.282104        \n",
      "[74]\ttraining's multi_logloss: 0.186715\tvalid_1's multi_logloss: 0.281064        \n",
      "[75]\ttraining's multi_logloss: 0.184321\tvalid_1's multi_logloss: 0.280385        \n",
      "[76]\ttraining's multi_logloss: 0.182116\tvalid_1's multi_logloss: 0.279651        \n",
      "[77]\ttraining's multi_logloss: 0.17978\tvalid_1's multi_logloss: 0.278794         \n",
      "[78]\ttraining's multi_logloss: 0.177572\tvalid_1's multi_logloss: 0.278265        \n",
      "[79]\ttraining's multi_logloss: 0.175362\tvalid_1's multi_logloss: 0.277747        \n",
      "[80]\ttraining's multi_logloss: 0.173321\tvalid_1's multi_logloss: 0.277047        \n",
      "[81]\ttraining's multi_logloss: 0.171269\tvalid_1's multi_logloss: 0.276404        \n",
      "[82]\ttraining's multi_logloss: 0.169323\tvalid_1's multi_logloss: 0.275817        \n",
      "[83]\ttraining's multi_logloss: 0.167419\tvalid_1's multi_logloss: 0.27543         \n",
      "[84]\ttraining's multi_logloss: 0.165467\tvalid_1's multi_logloss: 0.274687        \n",
      "[85]\ttraining's multi_logloss: 0.163687\tvalid_1's multi_logloss: 0.274205        \n",
      "[86]\ttraining's multi_logloss: 0.161777\tvalid_1's multi_logloss: 0.273594        \n",
      "[87]\ttraining's multi_logloss: 0.160056\tvalid_1's multi_logloss: 0.273367        \n",
      "[88]\ttraining's multi_logloss: 0.158329\tvalid_1's multi_logloss: 0.27298         \n",
      "[89]\ttraining's multi_logloss: 0.156634\tvalid_1's multi_logloss: 0.272757        \n",
      "[90]\ttraining's multi_logloss: 0.154837\tvalid_1's multi_logloss: 0.272434        \n",
      "[91]\ttraining's multi_logloss: 0.15311\tvalid_1's multi_logloss: 0.272181         \n",
      "[92]\ttraining's multi_logloss: 0.151349\tvalid_1's multi_logloss: 0.271719        \n",
      "[93]\ttraining's multi_logloss: 0.149696\tvalid_1's multi_logloss: 0.271569        \n",
      "[94]\ttraining's multi_logloss: 0.148142\tvalid_1's multi_logloss: 0.271476        \n",
      "[95]\ttraining's multi_logloss: 0.146514\tvalid_1's multi_logloss: 0.271212        \n",
      "[96]\ttraining's multi_logloss: 0.14489\tvalid_1's multi_logloss: 0.270888         \n",
      "[97]\ttraining's multi_logloss: 0.143293\tvalid_1's multi_logloss: 0.270584        \n",
      "[98]\ttraining's multi_logloss: 0.141855\tvalid_1's multi_logloss: 0.270356        \n",
      "[99]\ttraining's multi_logloss: 0.140358\tvalid_1's multi_logloss: 0.270185        \n",
      "[100]\ttraining's multi_logloss: 0.138979\tvalid_1's multi_logloss: 0.269834       \n",
      "[101]\ttraining's multi_logloss: 0.137403\tvalid_1's multi_logloss: 0.269347       \n",
      "[102]\ttraining's multi_logloss: 0.135998\tvalid_1's multi_logloss: 0.26924        \n",
      "[103]\ttraining's multi_logloss: 0.134529\tvalid_1's multi_logloss: 0.268869       \n",
      "[104]\ttraining's multi_logloss: 0.133131\tvalid_1's multi_logloss: 0.268559       \n",
      "[105]\ttraining's multi_logloss: 0.131699\tvalid_1's multi_logloss: 0.268394       \n",
      "[106]\ttraining's multi_logloss: 0.130337\tvalid_1's multi_logloss: 0.268393       \n",
      "[107]\ttraining's multi_logloss: 0.128979\tvalid_1's multi_logloss: 0.268372       \n",
      "[108]\ttraining's multi_logloss: 0.127653\tvalid_1's multi_logloss: 0.26833        \n",
      "[109]\ttraining's multi_logloss: 0.126328\tvalid_1's multi_logloss: 0.268279       \n",
      "[110]\ttraining's multi_logloss: 0.125045\tvalid_1's multi_logloss: 0.26826        \n",
      "[111]\ttraining's multi_logloss: 0.123783\tvalid_1's multi_logloss: 0.268263       \n",
      "[112]\ttraining's multi_logloss: 0.122585\tvalid_1's multi_logloss: 0.268129       \n",
      "[113]\ttraining's multi_logloss: 0.121426\tvalid_1's multi_logloss: 0.268096       \n",
      "[114]\ttraining's multi_logloss: 0.120235\tvalid_1's multi_logloss: 0.268098       \n",
      "[115]\ttraining's multi_logloss: 0.118952\tvalid_1's multi_logloss: 0.268133       \n",
      "[116]\ttraining's multi_logloss: 0.117862\tvalid_1's multi_logloss: 0.268025       \n",
      "[117]\ttraining's multi_logloss: 0.116753\tvalid_1's multi_logloss: 0.267894       \n",
      "[118]\ttraining's multi_logloss: 0.115657\tvalid_1's multi_logloss: 0.267937       \n",
      "[119]\ttraining's multi_logloss: 0.114586\tvalid_1's multi_logloss: 0.268146       \n",
      "[120]\ttraining's multi_logloss: 0.113562\tvalid_1's multi_logloss: 0.268106       \n",
      "[121]\ttraining's multi_logloss: 0.112509\tvalid_1's multi_logloss: 0.268051       \n",
      "[122]\ttraining's multi_logloss: 0.111486\tvalid_1's multi_logloss: 0.268142       \n",
      "[123]\ttraining's multi_logloss: 0.110474\tvalid_1's multi_logloss: 0.268139       \n",
      "[124]\ttraining's multi_logloss: 0.109468\tvalid_1's multi_logloss: 0.268141       \n",
      "[125]\ttraining's multi_logloss: 0.10849\tvalid_1's multi_logloss: 0.268318        \n",
      "[126]\ttraining's multi_logloss: 0.107487\tvalid_1's multi_logloss: 0.268355       \n",
      "[127]\ttraining's multi_logloss: 0.106514\tvalid_1's multi_logloss: 0.268262       \n",
      "[128]\ttraining's multi_logloss: 0.105557\tvalid_1's multi_logloss: 0.268339       \n",
      "[129]\ttraining's multi_logloss: 0.104576\tvalid_1's multi_logloss: 0.268401       \n",
      "[130]\ttraining's multi_logloss: 0.103606\tvalid_1's multi_logloss: 0.26841        \n",
      "[131]\ttraining's multi_logloss: 0.102737\tvalid_1's multi_logloss: 0.268489       \n",
      "[132]\ttraining's multi_logloss: 0.101809\tvalid_1's multi_logloss: 0.268271       \n",
      "[133]\ttraining's multi_logloss: 0.100883\tvalid_1's multi_logloss: 0.268163       \n",
      "[134]\ttraining's multi_logloss: 0.0999694\tvalid_1's multi_logloss: 0.268351      \n",
      "[135]\ttraining's multi_logloss: 0.0990503\tvalid_1's multi_logloss: 0.268517      \n",
      "[136]\ttraining's multi_logloss: 0.0981933\tvalid_1's multi_logloss: 0.268622      \n",
      "[137]\ttraining's multi_logloss: 0.0972601\tvalid_1's multi_logloss: 0.26897       \n",
      "[138]\ttraining's multi_logloss: 0.0963818\tvalid_1's multi_logloss: 0.268842      \n",
      "[139]\ttraining's multi_logloss: 0.0954939\tvalid_1's multi_logloss: 0.268873      \n",
      "[140]\ttraining's multi_logloss: 0.0946521\tvalid_1's multi_logloss: 0.268882      \n",
      "[141]\ttraining's multi_logloss: 0.0938518\tvalid_1's multi_logloss: 0.269046      \n",
      "[142]\ttraining's multi_logloss: 0.0929824\tvalid_1's multi_logloss: 0.26902       \n",
      "[143]\ttraining's multi_logloss: 0.0921484\tvalid_1's multi_logloss: 0.269086      \n",
      "[144]\ttraining's multi_logloss: 0.0912174\tvalid_1's multi_logloss: 0.269185      \n",
      "[145]\ttraining's multi_logloss: 0.0904413\tvalid_1's multi_logloss: 0.269337      \n",
      "[146]\ttraining's multi_logloss: 0.0896\tvalid_1's multi_logloss: 0.269534         \n",
      "[147]\ttraining's multi_logloss: 0.0888338\tvalid_1's multi_logloss: 0.269671      \n",
      "Early stopping, best iteration is:                                               \n",
      "[117]\ttraining's multi_logloss: 0.116753\tvalid_1's multi_logloss: 0.267894\n",
      "[1]\ttraining's multi_logloss: 1.58189\tvalid_1's multi_logloss: 1.58729           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.35124\tvalid_1's multi_logloss: 1.36286           \n",
      "[3]\ttraining's multi_logloss: 1.17935\tvalid_1's multi_logloss: 1.19584           \n",
      "[4]\ttraining's multi_logloss: 1.04514\tvalid_1's multi_logloss: 1.06609           \n",
      "[5]\ttraining's multi_logloss: 0.937024\tvalid_1's multi_logloss: 0.961798         \n",
      "[6]\ttraining's multi_logloss: 0.845432\tvalid_1's multi_logloss: 0.873356         \n",
      "[7]\ttraining's multi_logloss: 0.769388\tvalid_1's multi_logloss: 0.800545         \n",
      "[8]\ttraining's multi_logloss: 0.704305\tvalid_1's multi_logloss: 0.738154         \n",
      "[9]\ttraining's multi_logloss: 0.6476\tvalid_1's multi_logloss: 0.68394            \n",
      "[10]\ttraining's multi_logloss: 0.598864\tvalid_1's multi_logloss: 0.637831        \n",
      "[11]\ttraining's multi_logloss: 0.555324\tvalid_1's multi_logloss: 0.596927        \n",
      "[12]\ttraining's multi_logloss: 0.518059\tvalid_1's multi_logloss: 0.561476        \n",
      "[13]\ttraining's multi_logloss: 0.484843\tvalid_1's multi_logloss: 0.530617        \n",
      "[14]\ttraining's multi_logloss: 0.456054\tvalid_1's multi_logloss: 0.504383        \n",
      "[15]\ttraining's multi_logloss: 0.430188\tvalid_1's multi_logloss: 0.481198        \n",
      "[16]\ttraining's multi_logloss: 0.406855\tvalid_1's multi_logloss: 0.460101        \n",
      "[17]\ttraining's multi_logloss: 0.386376\tvalid_1's multi_logloss: 0.441947        \n",
      "[18]\ttraining's multi_logloss: 0.36765\tvalid_1's multi_logloss: 0.425002         \n",
      "[19]\ttraining's multi_logloss: 0.351204\tvalid_1's multi_logloss: 0.410984        \n",
      "[20]\ttraining's multi_logloss: 0.335726\tvalid_1's multi_logloss: 0.39772         \n",
      "[21]\ttraining's multi_logloss: 0.322023\tvalid_1's multi_logloss: 0.386509        \n",
      "[22]\ttraining's multi_logloss: 0.309526\tvalid_1's multi_logloss: 0.376409        \n",
      "[23]\ttraining's multi_logloss: 0.29821\tvalid_1's multi_logloss: 0.367801         \n",
      "[24]\ttraining's multi_logloss: 0.287488\tvalid_1's multi_logloss: 0.359799        \n",
      "[25]\ttraining's multi_logloss: 0.277597\tvalid_1's multi_logloss: 0.352907        \n",
      "[26]\ttraining's multi_logloss: 0.268494\tvalid_1's multi_logloss: 0.346524        \n",
      "[27]\ttraining's multi_logloss: 0.259908\tvalid_1's multi_logloss: 0.340986        \n",
      "[28]\ttraining's multi_logloss: 0.251798\tvalid_1's multi_logloss: 0.335734        \n",
      "[29]\ttraining's multi_logloss: 0.244631\tvalid_1's multi_logloss: 0.330867        \n",
      "[30]\ttraining's multi_logloss: 0.237697\tvalid_1's multi_logloss: 0.326398        \n",
      "[31]\ttraining's multi_logloss: 0.230913\tvalid_1's multi_logloss: 0.322189        \n",
      "[32]\ttraining's multi_logloss: 0.224555\tvalid_1's multi_logloss: 0.318635        \n",
      "[33]\ttraining's multi_logloss: 0.218612\tvalid_1's multi_logloss: 0.315385        \n",
      "[34]\ttraining's multi_logloss: 0.213179\tvalid_1's multi_logloss: 0.312807        \n",
      "[35]\ttraining's multi_logloss: 0.207945\tvalid_1's multi_logloss: 0.310525        \n",
      "[36]\ttraining's multi_logloss: 0.20282\tvalid_1's multi_logloss: 0.308249         \n",
      "[37]\ttraining's multi_logloss: 0.197889\tvalid_1's multi_logloss: 0.305992        \n",
      "[38]\ttraining's multi_logloss: 0.193171\tvalid_1's multi_logloss: 0.303679        \n",
      "[39]\ttraining's multi_logloss: 0.188685\tvalid_1's multi_logloss: 0.302316        \n",
      "[40]\ttraining's multi_logloss: 0.184387\tvalid_1's multi_logloss: 0.300977        \n",
      "[41]\ttraining's multi_logloss: 0.180064\tvalid_1's multi_logloss: 0.299626        \n",
      "[42]\ttraining's multi_logloss: 0.176045\tvalid_1's multi_logloss: 0.298622        \n",
      "[43]\ttraining's multi_logloss: 0.172163\tvalid_1's multi_logloss: 0.297185        \n",
      "[44]\ttraining's multi_logloss: 0.168417\tvalid_1's multi_logloss: 0.2965          \n",
      "[45]\ttraining's multi_logloss: 0.164641\tvalid_1's multi_logloss: 0.295165        \n",
      "[46]\ttraining's multi_logloss: 0.161124\tvalid_1's multi_logloss: 0.294721        \n",
      "[47]\ttraining's multi_logloss: 0.157504\tvalid_1's multi_logloss: 0.294266        \n",
      "[48]\ttraining's multi_logloss: 0.154047\tvalid_1's multi_logloss: 0.293737        \n",
      "[49]\ttraining's multi_logloss: 0.150839\tvalid_1's multi_logloss: 0.29322         \n",
      "[50]\ttraining's multi_logloss: 0.147589\tvalid_1's multi_logloss: 0.292408        \n",
      "[51]\ttraining's multi_logloss: 0.144581\tvalid_1's multi_logloss: 0.291962        \n",
      "[52]\ttraining's multi_logloss: 0.141663\tvalid_1's multi_logloss: 0.291624        \n",
      "[53]\ttraining's multi_logloss: 0.138871\tvalid_1's multi_logloss: 0.291434        \n",
      "[54]\ttraining's multi_logloss: 0.136076\tvalid_1's multi_logloss: 0.290926        \n",
      "[55]\ttraining's multi_logloss: 0.13313\tvalid_1's multi_logloss: 0.290515         \n",
      "[56]\ttraining's multi_logloss: 0.130433\tvalid_1's multi_logloss: 0.290046        \n",
      "[57]\ttraining's multi_logloss: 0.127762\tvalid_1's multi_logloss: 0.28985         \n",
      "[58]\ttraining's multi_logloss: 0.125219\tvalid_1's multi_logloss: 0.289146        \n",
      "[59]\ttraining's multi_logloss: 0.122788\tvalid_1's multi_logloss: 0.288716        \n",
      "[60]\ttraining's multi_logloss: 0.120503\tvalid_1's multi_logloss: 0.28838         \n",
      "[61]\ttraining's multi_logloss: 0.118084\tvalid_1's multi_logloss: 0.288357        \n",
      "[62]\ttraining's multi_logloss: 0.115711\tvalid_1's multi_logloss: 0.288333        \n",
      "[63]\ttraining's multi_logloss: 0.113489\tvalid_1's multi_logloss: 0.288122        \n",
      "[64]\ttraining's multi_logloss: 0.111239\tvalid_1's multi_logloss: 0.288041        \n",
      "[65]\ttraining's multi_logloss: 0.109054\tvalid_1's multi_logloss: 0.287917        \n",
      "[66]\ttraining's multi_logloss: 0.106794\tvalid_1's multi_logloss: 0.288024        \n",
      "[67]\ttraining's multi_logloss: 0.104827\tvalid_1's multi_logloss: 0.288113        \n",
      "[68]\ttraining's multi_logloss: 0.102958\tvalid_1's multi_logloss: 0.288004        \n",
      "[69]\ttraining's multi_logloss: 0.101015\tvalid_1's multi_logloss: 0.288055        \n",
      "[70]\ttraining's multi_logloss: 0.0990379\tvalid_1's multi_logloss: 0.2881         \n",
      "[71]\ttraining's multi_logloss: 0.097356\tvalid_1's multi_logloss: 0.288253        \n",
      "[72]\ttraining's multi_logloss: 0.0955437\tvalid_1's multi_logloss: 0.288716       \n",
      "[73]\ttraining's multi_logloss: 0.0936721\tvalid_1's multi_logloss: 0.288722       \n",
      "[74]\ttraining's multi_logloss: 0.091935\tvalid_1's multi_logloss: 0.289158        \n",
      "[75]\ttraining's multi_logloss: 0.090342\tvalid_1's multi_logloss: 0.289492        \n",
      "[76]\ttraining's multi_logloss: 0.0889067\tvalid_1's multi_logloss: 0.290068       \n",
      "[77]\ttraining's multi_logloss: 0.0874402\tvalid_1's multi_logloss: 0.290137       \n",
      "[78]\ttraining's multi_logloss: 0.0860048\tvalid_1's multi_logloss: 0.290637       \n",
      "[79]\ttraining's multi_logloss: 0.0845059\tvalid_1's multi_logloss: 0.291108       \n",
      "[80]\ttraining's multi_logloss: 0.0830613\tvalid_1's multi_logloss: 0.291528       \n",
      "[81]\ttraining's multi_logloss: 0.0815412\tvalid_1's multi_logloss: 0.292129       \n",
      "[82]\ttraining's multi_logloss: 0.0800944\tvalid_1's multi_logloss: 0.292494       \n",
      "[83]\ttraining's multi_logloss: 0.0788233\tvalid_1's multi_logloss: 0.292872       \n",
      "[84]\ttraining's multi_logloss: 0.0774715\tvalid_1's multi_logloss: 0.293233       \n",
      "[85]\ttraining's multi_logloss: 0.076207\tvalid_1's multi_logloss: 0.293771        \n",
      "[86]\ttraining's multi_logloss: 0.0747286\tvalid_1's multi_logloss: 0.293768       \n",
      "[87]\ttraining's multi_logloss: 0.0734383\tvalid_1's multi_logloss: 0.29424        \n",
      "[88]\ttraining's multi_logloss: 0.0720337\tvalid_1's multi_logloss: 0.294904       \n",
      "[89]\ttraining's multi_logloss: 0.0709662\tvalid_1's multi_logloss: 0.295361       \n",
      "[90]\ttraining's multi_logloss: 0.0697004\tvalid_1's multi_logloss: 0.295743       \n",
      "[91]\ttraining's multi_logloss: 0.0685427\tvalid_1's multi_logloss: 0.296161       \n",
      "[92]\ttraining's multi_logloss: 0.0674577\tvalid_1's multi_logloss: 0.29683        \n",
      "[93]\ttraining's multi_logloss: 0.0660958\tvalid_1's multi_logloss: 0.297493       \n",
      "[94]\ttraining's multi_logloss: 0.0649111\tvalid_1's multi_logloss: 0.297873       \n",
      "[95]\ttraining's multi_logloss: 0.0636258\tvalid_1's multi_logloss: 0.298593       \n",
      "Early stopping, best iteration is:                                               \n",
      "[65]\ttraining's multi_logloss: 0.109054\tvalid_1's multi_logloss: 0.287917\n",
      "[1]\ttraining's multi_logloss: 1.58044\tvalid_1's multi_logloss: 1.58492           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.35164\tvalid_1's multi_logloss: 1.35729           \n",
      "[3]\ttraining's multi_logloss: 1.1827\tvalid_1's multi_logloss: 1.19193            \n",
      "[4]\ttraining's multi_logloss: 1.04912\tvalid_1's multi_logloss: 1.06053           \n",
      "[5]\ttraining's multi_logloss: 0.94184\tvalid_1's multi_logloss: 0.956277          \n",
      "[6]\ttraining's multi_logloss: 0.852044\tvalid_1's multi_logloss: 0.86865          \n",
      "[7]\ttraining's multi_logloss: 0.776006\tvalid_1's multi_logloss: 0.794676         \n",
      "[8]\ttraining's multi_logloss: 0.710182\tvalid_1's multi_logloss: 0.731622         \n",
      "[9]\ttraining's multi_logloss: 0.653597\tvalid_1's multi_logloss: 0.677817         \n",
      "[10]\ttraining's multi_logloss: 0.6047\tvalid_1's multi_logloss: 0.631693          \n",
      "[11]\ttraining's multi_logloss: 0.562022\tvalid_1's multi_logloss: 0.591007        \n",
      "[12]\ttraining's multi_logloss: 0.523938\tvalid_1's multi_logloss: 0.555076        \n",
      "[13]\ttraining's multi_logloss: 0.490988\tvalid_1's multi_logloss: 0.524451        \n",
      "[14]\ttraining's multi_logloss: 0.461494\tvalid_1's multi_logloss: 0.497532        \n",
      "[15]\ttraining's multi_logloss: 0.435482\tvalid_1's multi_logloss: 0.474636        \n",
      "[16]\ttraining's multi_logloss: 0.412373\tvalid_1's multi_logloss: 0.454317        \n",
      "[17]\ttraining's multi_logloss: 0.391782\tvalid_1's multi_logloss: 0.436402        \n",
      "[18]\ttraining's multi_logloss: 0.37324\tvalid_1's multi_logloss: 0.42058          \n",
      "[19]\ttraining's multi_logloss: 0.356295\tvalid_1's multi_logloss: 0.405953        \n",
      "[20]\ttraining's multi_logloss: 0.340497\tvalid_1's multi_logloss: 0.39244         \n",
      "[21]\ttraining's multi_logloss: 0.326632\tvalid_1's multi_logloss: 0.381094        \n",
      "[22]\ttraining's multi_logloss: 0.313449\tvalid_1's multi_logloss: 0.37082         \n",
      "[23]\ttraining's multi_logloss: 0.301794\tvalid_1's multi_logloss: 0.361802        \n",
      "[24]\ttraining's multi_logloss: 0.290735\tvalid_1's multi_logloss: 0.353685        \n",
      "[25]\ttraining's multi_logloss: 0.280335\tvalid_1's multi_logloss: 0.346227        \n",
      "[26]\ttraining's multi_logloss: 0.271164\tvalid_1's multi_logloss: 0.339721        \n",
      "[27]\ttraining's multi_logloss: 0.262032\tvalid_1's multi_logloss: 0.333719        \n",
      "[28]\ttraining's multi_logloss: 0.253692\tvalid_1's multi_logloss: 0.3288          \n",
      "[29]\ttraining's multi_logloss: 0.246256\tvalid_1's multi_logloss: 0.32424         \n",
      "[30]\ttraining's multi_logloss: 0.239145\tvalid_1's multi_logloss: 0.320019        \n",
      "[31]\ttraining's multi_logloss: 0.232352\tvalid_1's multi_logloss: 0.316228        \n",
      "[32]\ttraining's multi_logloss: 0.226155\tvalid_1's multi_logloss: 0.313084        \n",
      "[33]\ttraining's multi_logloss: 0.220001\tvalid_1's multi_logloss: 0.310157        \n",
      "[34]\ttraining's multi_logloss: 0.214271\tvalid_1's multi_logloss: 0.307519        \n",
      "[35]\ttraining's multi_logloss: 0.208668\tvalid_1's multi_logloss: 0.305233        \n",
      "[36]\ttraining's multi_logloss: 0.203552\tvalid_1's multi_logloss: 0.303095        \n",
      "[37]\ttraining's multi_logloss: 0.198584\tvalid_1's multi_logloss: 0.301489        \n",
      "[38]\ttraining's multi_logloss: 0.193771\tvalid_1's multi_logloss: 0.299545        \n",
      "[39]\ttraining's multi_logloss: 0.188969\tvalid_1's multi_logloss: 0.29777         \n",
      "[40]\ttraining's multi_logloss: 0.184648\tvalid_1's multi_logloss: 0.296469        \n",
      "[41]\ttraining's multi_logloss: 0.180297\tvalid_1's multi_logloss: 0.295321        \n",
      "[42]\ttraining's multi_logloss: 0.176006\tvalid_1's multi_logloss: 0.293885        \n",
      "[43]\ttraining's multi_logloss: 0.171913\tvalid_1's multi_logloss: 0.29296         \n",
      "[44]\ttraining's multi_logloss: 0.16818\tvalid_1's multi_logloss: 0.291969         \n",
      "[45]\ttraining's multi_logloss: 0.164357\tvalid_1's multi_logloss: 0.290933        \n",
      "[46]\ttraining's multi_logloss: 0.160656\tvalid_1's multi_logloss: 0.290133        \n",
      "[47]\ttraining's multi_logloss: 0.156954\tvalid_1's multi_logloss: 0.288767        \n",
      "[48]\ttraining's multi_logloss: 0.153615\tvalid_1's multi_logloss: 0.287802        \n",
      "[49]\ttraining's multi_logloss: 0.150138\tvalid_1's multi_logloss: 0.287715        \n",
      "[50]\ttraining's multi_logloss: 0.146816\tvalid_1's multi_logloss: 0.287794        \n",
      "[51]\ttraining's multi_logloss: 0.143497\tvalid_1's multi_logloss: 0.287419        \n",
      "[52]\ttraining's multi_logloss: 0.140292\tvalid_1's multi_logloss: 0.287024        \n",
      "[53]\ttraining's multi_logloss: 0.137289\tvalid_1's multi_logloss: 0.28662         \n",
      "[54]\ttraining's multi_logloss: 0.134478\tvalid_1's multi_logloss: 0.286717        \n",
      "[55]\ttraining's multi_logloss: 0.13163\tvalid_1's multi_logloss: 0.286408         \n",
      "[56]\ttraining's multi_logloss: 0.128877\tvalid_1's multi_logloss: 0.286563        \n",
      "[57]\ttraining's multi_logloss: 0.126246\tvalid_1's multi_logloss: 0.286571        \n",
      "[58]\ttraining's multi_logloss: 0.123536\tvalid_1's multi_logloss: 0.286468        \n",
      "[59]\ttraining's multi_logloss: 0.121062\tvalid_1's multi_logloss: 0.286106        \n",
      "[60]\ttraining's multi_logloss: 0.118699\tvalid_1's multi_logloss: 0.286086        \n",
      "[61]\ttraining's multi_logloss: 0.116224\tvalid_1's multi_logloss: 0.286113        \n",
      "[62]\ttraining's multi_logloss: 0.11391\tvalid_1's multi_logloss: 0.28604          \n",
      "[63]\ttraining's multi_logloss: 0.111915\tvalid_1's multi_logloss: 0.285996        \n",
      "[64]\ttraining's multi_logloss: 0.109709\tvalid_1's multi_logloss: 0.285963        \n",
      "[65]\ttraining's multi_logloss: 0.107603\tvalid_1's multi_logloss: 0.285952        \n",
      "[66]\ttraining's multi_logloss: 0.105574\tvalid_1's multi_logloss: 0.286122        \n",
      "[67]\ttraining's multi_logloss: 0.103603\tvalid_1's multi_logloss: 0.286606        \n",
      "[68]\ttraining's multi_logloss: 0.101767\tvalid_1's multi_logloss: 0.286761        \n",
      "[69]\ttraining's multi_logloss: 0.0996105\tvalid_1's multi_logloss: 0.286741       \n",
      "[70]\ttraining's multi_logloss: 0.097822\tvalid_1's multi_logloss: 0.28733         \n",
      "[71]\ttraining's multi_logloss: 0.0960206\tvalid_1's multi_logloss: 0.287611       \n",
      "[72]\ttraining's multi_logloss: 0.0943457\tvalid_1's multi_logloss: 0.287728       \n",
      "[73]\ttraining's multi_logloss: 0.0925135\tvalid_1's multi_logloss: 0.288205       \n",
      "[74]\ttraining's multi_logloss: 0.0905076\tvalid_1's multi_logloss: 0.288363       \n",
      "[75]\ttraining's multi_logloss: 0.0888452\tvalid_1's multi_logloss: 0.288572       \n",
      "[76]\ttraining's multi_logloss: 0.0868946\tvalid_1's multi_logloss: 0.289211       \n",
      "[77]\ttraining's multi_logloss: 0.0851475\tvalid_1's multi_logloss: 0.289671       \n",
      "[78]\ttraining's multi_logloss: 0.0833637\tvalid_1's multi_logloss: 0.289909       \n",
      "[79]\ttraining's multi_logloss: 0.0819314\tvalid_1's multi_logloss: 0.290013       \n",
      "[80]\ttraining's multi_logloss: 0.080502\tvalid_1's multi_logloss: 0.290197        \n",
      "[81]\ttraining's multi_logloss: 0.0791016\tvalid_1's multi_logloss: 0.290627       \n",
      "[82]\ttraining's multi_logloss: 0.0776943\tvalid_1's multi_logloss: 0.29115        \n",
      "[83]\ttraining's multi_logloss: 0.0762125\tvalid_1's multi_logloss: 0.291364       \n",
      "[84]\ttraining's multi_logloss: 0.0749482\tvalid_1's multi_logloss: 0.291924       \n",
      "[85]\ttraining's multi_logloss: 0.073638\tvalid_1's multi_logloss: 0.29222         \n",
      "[86]\ttraining's multi_logloss: 0.0723403\tvalid_1's multi_logloss: 0.292477       \n",
      "[87]\ttraining's multi_logloss: 0.0710744\tvalid_1's multi_logloss: 0.292727       \n",
      "[88]\ttraining's multi_logloss: 0.0698425\tvalid_1's multi_logloss: 0.293262       \n",
      "[89]\ttraining's multi_logloss: 0.0685796\tvalid_1's multi_logloss: 0.294128       \n",
      "[90]\ttraining's multi_logloss: 0.0674675\tvalid_1's multi_logloss: 0.29449        \n",
      "[91]\ttraining's multi_logloss: 0.0662991\tvalid_1's multi_logloss: 0.294926       \n",
      "[92]\ttraining's multi_logloss: 0.0651366\tvalid_1's multi_logloss: 0.295539       \n",
      "[93]\ttraining's multi_logloss: 0.0641061\tvalid_1's multi_logloss: 0.295787       \n",
      "[94]\ttraining's multi_logloss: 0.0630503\tvalid_1's multi_logloss: 0.296364       \n",
      "[95]\ttraining's multi_logloss: 0.061999\tvalid_1's multi_logloss: 0.297195        \n",
      "Early stopping, best iteration is:                                               \n",
      "[65]\ttraining's multi_logloss: 0.107603\tvalid_1's multi_logloss: 0.285952\n",
      "[1]\ttraining's multi_logloss: 1.58291\tvalid_1's multi_logloss: 1.58746           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.35523\tvalid_1's multi_logloss: 1.36164           \n",
      "[3]\ttraining's multi_logloss: 1.18514\tvalid_1's multi_logloss: 1.19361           \n",
      "[4]\ttraining's multi_logloss: 1.05256\tvalid_1's multi_logloss: 1.06306           \n",
      "[5]\ttraining's multi_logloss: 0.944112\tvalid_1's multi_logloss: 0.955917         \n",
      "[6]\ttraining's multi_logloss: 0.853807\tvalid_1's multi_logloss: 0.8671           \n",
      "[7]\ttraining's multi_logloss: 0.777096\tvalid_1's multi_logloss: 0.791736         \n",
      "[8]\ttraining's multi_logloss: 0.71178\tvalid_1's multi_logloss: 0.727757          \n",
      "[9]\ttraining's multi_logloss: 0.655457\tvalid_1's multi_logloss: 0.67303          \n",
      "[10]\ttraining's multi_logloss: 0.606769\tvalid_1's multi_logloss: 0.626355        \n",
      "[11]\ttraining's multi_logloss: 0.56484\tvalid_1's multi_logloss: 0.586748         \n",
      "[12]\ttraining's multi_logloss: 0.527811\tvalid_1's multi_logloss: 0.552091        \n",
      "[13]\ttraining's multi_logloss: 0.495741\tvalid_1's multi_logloss: 0.522087        \n",
      "[14]\ttraining's multi_logloss: 0.466834\tvalid_1's multi_logloss: 0.494988        \n",
      "[15]\ttraining's multi_logloss: 0.441244\tvalid_1's multi_logloss: 0.471697        \n",
      "[16]\ttraining's multi_logloss: 0.417868\tvalid_1's multi_logloss: 0.450213        \n",
      "[17]\ttraining's multi_logloss: 0.397042\tvalid_1's multi_logloss: 0.431331        \n",
      "[18]\ttraining's multi_logloss: 0.377989\tvalid_1's multi_logloss: 0.414096        \n",
      "[19]\ttraining's multi_logloss: 0.360713\tvalid_1's multi_logloss: 0.39894         \n",
      "[20]\ttraining's multi_logloss: 0.345435\tvalid_1's multi_logloss: 0.385514        \n",
      "[21]\ttraining's multi_logloss: 0.331594\tvalid_1's multi_logloss: 0.373697        \n",
      "[22]\ttraining's multi_logloss: 0.319\tvalid_1's multi_logloss: 0.363262           \n",
      "[23]\ttraining's multi_logloss: 0.306956\tvalid_1's multi_logloss: 0.353598        \n",
      "[24]\ttraining's multi_logloss: 0.296347\tvalid_1's multi_logloss: 0.345385        \n",
      "[25]\ttraining's multi_logloss: 0.286282\tvalid_1's multi_logloss: 0.338109        \n",
      "[26]\ttraining's multi_logloss: 0.276902\tvalid_1's multi_logloss: 0.330814        \n",
      "[27]\ttraining's multi_logloss: 0.268424\tvalid_1's multi_logloss: 0.325097        \n",
      "[28]\ttraining's multi_logloss: 0.260454\tvalid_1's multi_logloss: 0.319562        \n",
      "[29]\ttraining's multi_logloss: 0.252737\tvalid_1's multi_logloss: 0.314278        \n",
      "[30]\ttraining's multi_logloss: 0.245491\tvalid_1's multi_logloss: 0.309983        \n",
      "[31]\ttraining's multi_logloss: 0.238705\tvalid_1's multi_logloss: 0.305679        \n",
      "[32]\ttraining's multi_logloss: 0.232177\tvalid_1's multi_logloss: 0.302431        \n",
      "[33]\ttraining's multi_logloss: 0.226461\tvalid_1's multi_logloss: 0.299536        \n",
      "[34]\ttraining's multi_logloss: 0.220746\tvalid_1's multi_logloss: 0.296206        \n",
      "[35]\ttraining's multi_logloss: 0.215102\tvalid_1's multi_logloss: 0.293696        \n",
      "[36]\ttraining's multi_logloss: 0.209853\tvalid_1's multi_logloss: 0.291346        \n",
      "[37]\ttraining's multi_logloss: 0.205007\tvalid_1's multi_logloss: 0.289397        \n",
      "[38]\ttraining's multi_logloss: 0.200238\tvalid_1's multi_logloss: 0.287492        \n",
      "[39]\ttraining's multi_logloss: 0.195606\tvalid_1's multi_logloss: 0.285817        \n",
      "[40]\ttraining's multi_logloss: 0.191206\tvalid_1's multi_logloss: 0.284608        \n",
      "[41]\ttraining's multi_logloss: 0.18691\tvalid_1's multi_logloss: 0.283348         \n",
      "[42]\ttraining's multi_logloss: 0.182642\tvalid_1's multi_logloss: 0.281685        \n",
      "[43]\ttraining's multi_logloss: 0.17832\tvalid_1's multi_logloss: 0.280567         \n",
      "[44]\ttraining's multi_logloss: 0.174469\tvalid_1's multi_logloss: 0.279083        \n",
      "[45]\ttraining's multi_logloss: 0.170892\tvalid_1's multi_logloss: 0.278083        \n",
      "[46]\ttraining's multi_logloss: 0.167178\tvalid_1's multi_logloss: 0.277055        \n",
      "[47]\ttraining's multi_logloss: 0.163666\tvalid_1's multi_logloss: 0.27642         \n",
      "[48]\ttraining's multi_logloss: 0.160202\tvalid_1's multi_logloss: 0.275504        \n",
      "[49]\ttraining's multi_logloss: 0.156715\tvalid_1's multi_logloss: 0.275521        \n",
      "[50]\ttraining's multi_logloss: 0.1533\tvalid_1's multi_logloss: 0.275287          \n",
      "[51]\ttraining's multi_logloss: 0.150159\tvalid_1's multi_logloss: 0.274874        \n",
      "[52]\ttraining's multi_logloss: 0.147145\tvalid_1's multi_logloss: 0.274617        \n",
      "[53]\ttraining's multi_logloss: 0.143926\tvalid_1's multi_logloss: 0.274394        \n",
      "[54]\ttraining's multi_logloss: 0.140989\tvalid_1's multi_logloss: 0.273733        \n",
      "[55]\ttraining's multi_logloss: 0.138153\tvalid_1's multi_logloss: 0.273307        \n",
      "[56]\ttraining's multi_logloss: 0.135402\tvalid_1's multi_logloss: 0.272798        \n",
      "[57]\ttraining's multi_logloss: 0.132544\tvalid_1's multi_logloss: 0.272577        \n",
      "[58]\ttraining's multi_logloss: 0.129738\tvalid_1's multi_logloss: 0.271839        \n",
      "[59]\ttraining's multi_logloss: 0.127133\tvalid_1's multi_logloss: 0.271631        \n",
      "[60]\ttraining's multi_logloss: 0.124718\tvalid_1's multi_logloss: 0.271429        \n",
      "[61]\ttraining's multi_logloss: 0.122212\tvalid_1's multi_logloss: 0.271381        \n",
      "[62]\ttraining's multi_logloss: 0.119841\tvalid_1's multi_logloss: 0.271309        \n",
      "[63]\ttraining's multi_logloss: 0.117482\tvalid_1's multi_logloss: 0.271793        \n",
      "[64]\ttraining's multi_logloss: 0.115205\tvalid_1's multi_logloss: 0.271887        \n",
      "[65]\ttraining's multi_logloss: 0.112934\tvalid_1's multi_logloss: 0.271723        \n",
      "[66]\ttraining's multi_logloss: 0.110633\tvalid_1's multi_logloss: 0.271518        \n",
      "[67]\ttraining's multi_logloss: 0.10849\tvalid_1's multi_logloss: 0.271867         \n",
      "[68]\ttraining's multi_logloss: 0.106512\tvalid_1's multi_logloss: 0.271993        \n",
      "[69]\ttraining's multi_logloss: 0.10454\tvalid_1's multi_logloss: 0.271798         \n",
      "[70]\ttraining's multi_logloss: 0.102585\tvalid_1's multi_logloss: 0.271908        \n",
      "[71]\ttraining's multi_logloss: 0.100712\tvalid_1's multi_logloss: 0.271909        \n",
      "[72]\ttraining's multi_logloss: 0.0987269\tvalid_1's multi_logloss: 0.272242       \n",
      "[73]\ttraining's multi_logloss: 0.0968366\tvalid_1's multi_logloss: 0.272446       \n",
      "[74]\ttraining's multi_logloss: 0.094982\tvalid_1's multi_logloss: 0.272506        \n",
      "[75]\ttraining's multi_logloss: 0.093352\tvalid_1's multi_logloss: 0.27276         \n",
      "[76]\ttraining's multi_logloss: 0.0917267\tvalid_1's multi_logloss: 0.273349       \n",
      "[77]\ttraining's multi_logloss: 0.0900412\tvalid_1's multi_logloss: 0.273307       \n",
      "[78]\ttraining's multi_logloss: 0.0884044\tvalid_1's multi_logloss: 0.273606       \n",
      "[79]\ttraining's multi_logloss: 0.0868038\tvalid_1's multi_logloss: 0.274094       \n",
      "[80]\ttraining's multi_logloss: 0.0852305\tvalid_1's multi_logloss: 0.27464        \n",
      "[81]\ttraining's multi_logloss: 0.0836806\tvalid_1's multi_logloss: 0.274824       \n",
      "[82]\ttraining's multi_logloss: 0.0822156\tvalid_1's multi_logloss: 0.274925       \n",
      "[83]\ttraining's multi_logloss: 0.0807707\tvalid_1's multi_logloss: 0.275218       \n",
      "[84]\ttraining's multi_logloss: 0.0793143\tvalid_1's multi_logloss: 0.27577        \n",
      "[85]\ttraining's multi_logloss: 0.0777705\tvalid_1's multi_logloss: 0.276099       \n",
      "[86]\ttraining's multi_logloss: 0.076317\tvalid_1's multi_logloss: 0.27635         \n",
      "[87]\ttraining's multi_logloss: 0.0749148\tvalid_1's multi_logloss: 0.276314       \n",
      "[88]\ttraining's multi_logloss: 0.0736982\tvalid_1's multi_logloss: 0.276407       \n",
      "[89]\ttraining's multi_logloss: 0.072427\tvalid_1's multi_logloss: 0.276794        \n",
      "[90]\ttraining's multi_logloss: 0.0711215\tvalid_1's multi_logloss: 0.277033       \n",
      "[91]\ttraining's multi_logloss: 0.0698459\tvalid_1's multi_logloss: 0.277006       \n",
      "[92]\ttraining's multi_logloss: 0.0686587\tvalid_1's multi_logloss: 0.277209       \n",
      "Early stopping, best iteration is:                                               \n",
      "[62]\ttraining's multi_logloss: 0.119841\tvalid_1's multi_logloss: 0.271309\n",
      "[1]\ttraining's multi_logloss: 1.87351\tvalid_1's multi_logloss: 1.87238           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.81916\tvalid_1's multi_logloss: 1.81954           \n",
      "[3]\ttraining's multi_logloss: 1.76806\tvalid_1's multi_logloss: 1.76982           \n",
      "[4]\ttraining's multi_logloss: 1.71996\tvalid_1's multi_logloss: 1.72298           \n",
      "[5]\ttraining's multi_logloss: 1.67458\tvalid_1's multi_logloss: 1.6788            \n",
      "[6]\ttraining's multi_logloss: 1.6317\tvalid_1's multi_logloss: 1.63716            \n",
      "[7]\ttraining's multi_logloss: 1.59102\tvalid_1's multi_logloss: 1.59761           \n",
      "[8]\ttraining's multi_logloss: 1.55238\tvalid_1's multi_logloss: 1.56025           \n",
      "[9]\ttraining's multi_logloss: 1.51537\tvalid_1's multi_logloss: 1.52428           \n",
      "[10]\ttraining's multi_logloss: 1.48021\tvalid_1's multi_logloss: 1.4902           \n",
      "[11]\ttraining's multi_logloss: 1.44654\tvalid_1's multi_logloss: 1.45748          \n",
      "[12]\ttraining's multi_logloss: 1.41435\tvalid_1's multi_logloss: 1.42612          \n",
      "[13]\ttraining's multi_logloss: 1.38336\tvalid_1's multi_logloss: 1.396            \n",
      "[14]\ttraining's multi_logloss: 1.35355\tvalid_1's multi_logloss: 1.36702          \n",
      "[15]\ttraining's multi_logloss: 1.32487\tvalid_1's multi_logloss: 1.33916          \n",
      "[16]\ttraining's multi_logloss: 1.29735\tvalid_1's multi_logloss: 1.31243          \n",
      "[17]\ttraining's multi_logloss: 1.27085\tvalid_1's multi_logloss: 1.28666          \n",
      "[18]\ttraining's multi_logloss: 1.24537\tvalid_1's multi_logloss: 1.26198          \n",
      "[19]\ttraining's multi_logloss: 1.22074\tvalid_1's multi_logloss: 1.2382           \n",
      "[20]\ttraining's multi_logloss: 1.19692\tvalid_1's multi_logloss: 1.21522          \n",
      "[21]\ttraining's multi_logloss: 1.17395\tvalid_1's multi_logloss: 1.19297          \n",
      "[22]\ttraining's multi_logloss: 1.15184\tvalid_1's multi_logloss: 1.17166          \n",
      "[23]\ttraining's multi_logloss: 1.13046\tvalid_1's multi_logloss: 1.15104          \n",
      "[24]\ttraining's multi_logloss: 1.10978\tvalid_1's multi_logloss: 1.13106          \n",
      "[25]\ttraining's multi_logloss: 1.08968\tvalid_1's multi_logloss: 1.11172          \n",
      "[26]\ttraining's multi_logloss: 1.07028\tvalid_1's multi_logloss: 1.09298          \n",
      "[27]\ttraining's multi_logloss: 1.05134\tvalid_1's multi_logloss: 1.07475          \n",
      "[28]\ttraining's multi_logloss: 1.03304\tvalid_1's multi_logloss: 1.05715          \n",
      "[29]\ttraining's multi_logloss: 1.01528\tvalid_1's multi_logloss: 1.04008          \n",
      "[30]\ttraining's multi_logloss: 0.998011\tvalid_1's multi_logloss: 1.02345         \n",
      "[31]\ttraining's multi_logloss: 0.981273\tvalid_1's multi_logloss: 1.00735         \n",
      "[32]\ttraining's multi_logloss: 0.964973\tvalid_1's multi_logloss: 0.991605        \n",
      "[33]\ttraining's multi_logloss: 0.949063\tvalid_1's multi_logloss: 0.9763          \n",
      "[34]\ttraining's multi_logloss: 0.933584\tvalid_1's multi_logloss: 0.961387        \n",
      "[35]\ttraining's multi_logloss: 0.918602\tvalid_1's multi_logloss: 0.947006        \n",
      "[36]\ttraining's multi_logloss: 0.903868\tvalid_1's multi_logloss: 0.932874        \n",
      "[37]\ttraining's multi_logloss: 0.889635\tvalid_1's multi_logloss: 0.91916         \n",
      "[38]\ttraining's multi_logloss: 0.875675\tvalid_1's multi_logloss: 0.905681        \n",
      "[39]\ttraining's multi_logloss: 0.861976\tvalid_1's multi_logloss: 0.892547        \n",
      "[40]\ttraining's multi_logloss: 0.848646\tvalid_1's multi_logloss: 0.879737        \n",
      "[41]\ttraining's multi_logloss: 0.835622\tvalid_1's multi_logloss: 0.867208        \n",
      "[42]\ttraining's multi_logloss: 0.822975\tvalid_1's multi_logloss: 0.855056        \n",
      "[43]\ttraining's multi_logloss: 0.810692\tvalid_1's multi_logloss: 0.843194        \n",
      "[44]\ttraining's multi_logloss: 0.798597\tvalid_1's multi_logloss: 0.831554        \n",
      "[45]\ttraining's multi_logloss: 0.786885\tvalid_1's multi_logloss: 0.820294        \n",
      "[46]\ttraining's multi_logloss: 0.775432\tvalid_1's multi_logloss: 0.809244        \n",
      "[47]\ttraining's multi_logloss: 0.76432\tvalid_1's multi_logloss: 0.798526         \n",
      "[48]\ttraining's multi_logloss: 0.753393\tvalid_1's multi_logloss: 0.788006        \n",
      "[49]\ttraining's multi_logloss: 0.742741\tvalid_1's multi_logloss: 0.77777         \n",
      "[50]\ttraining's multi_logloss: 0.73235\tvalid_1's multi_logloss: 0.767798         \n",
      "[51]\ttraining's multi_logloss: 0.7222\tvalid_1's multi_logloss: 0.758079          \n",
      "[52]\ttraining's multi_logloss: 0.71232\tvalid_1's multi_logloss: 0.748606         \n",
      "[53]\ttraining's multi_logloss: 0.702662\tvalid_1's multi_logloss: 0.739336        \n",
      "[54]\ttraining's multi_logloss: 0.69326\tvalid_1's multi_logloss: 0.730365         \n",
      "[55]\ttraining's multi_logloss: 0.684048\tvalid_1's multi_logloss: 0.721542        \n",
      "[56]\ttraining's multi_logloss: 0.674979\tvalid_1's multi_logloss: 0.712925        \n",
      "[57]\ttraining's multi_logloss: 0.666184\tvalid_1's multi_logloss: 0.704553        \n",
      "[58]\ttraining's multi_logloss: 0.657519\tvalid_1's multi_logloss: 0.696334        \n",
      "[59]\ttraining's multi_logloss: 0.649079\tvalid_1's multi_logloss: 0.688351        \n",
      "[60]\ttraining's multi_logloss: 0.640847\tvalid_1's multi_logloss: 0.680539        \n",
      "[61]\ttraining's multi_logloss: 0.63273\tvalid_1's multi_logloss: 0.672847         \n",
      "[62]\ttraining's multi_logloss: 0.624779\tvalid_1's multi_logloss: 0.665374        \n",
      "[63]\ttraining's multi_logloss: 0.617043\tvalid_1's multi_logloss: 0.658061        \n",
      "[64]\ttraining's multi_logloss: 0.609473\tvalid_1's multi_logloss: 0.650918        \n",
      "[65]\ttraining's multi_logloss: 0.602036\tvalid_1's multi_logloss: 0.643973        \n",
      "[66]\ttraining's multi_logloss: 0.594723\tvalid_1's multi_logloss: 0.637094        \n",
      "[67]\ttraining's multi_logloss: 0.587554\tvalid_1's multi_logloss: 0.6304          \n",
      "[68]\ttraining's multi_logloss: 0.580523\tvalid_1's multi_logloss: 0.623851        \n",
      "[69]\ttraining's multi_logloss: 0.573635\tvalid_1's multi_logloss: 0.617458        \n",
      "[70]\ttraining's multi_logloss: 0.566946\tvalid_1's multi_logloss: 0.611231        \n",
      "[71]\ttraining's multi_logloss: 0.56032\tvalid_1's multi_logloss: 0.605044         \n",
      "[72]\ttraining's multi_logloss: 0.553857\tvalid_1's multi_logloss: 0.598985        \n",
      "[73]\ttraining's multi_logloss: 0.547587\tvalid_1's multi_logloss: 0.593126        \n",
      "[74]\ttraining's multi_logloss: 0.541383\tvalid_1's multi_logloss: 0.587354        \n",
      "[75]\ttraining's multi_logloss: 0.535275\tvalid_1's multi_logloss: 0.581659        \n",
      "[76]\ttraining's multi_logloss: 0.529312\tvalid_1's multi_logloss: 0.576119        \n",
      "[77]\ttraining's multi_logloss: 0.523517\tvalid_1's multi_logloss: 0.570749        \n",
      "[78]\ttraining's multi_logloss: 0.517802\tvalid_1's multi_logloss: 0.565416        \n",
      "[79]\ttraining's multi_logloss: 0.512241\tvalid_1's multi_logloss: 0.560284        \n",
      "[80]\ttraining's multi_logloss: 0.506793\tvalid_1's multi_logloss: 0.555292        \n",
      "[81]\ttraining's multi_logloss: 0.501409\tvalid_1's multi_logloss: 0.550386        \n",
      "[82]\ttraining's multi_logloss: 0.496062\tvalid_1's multi_logloss: 0.54541         \n",
      "[83]\ttraining's multi_logloss: 0.490826\tvalid_1's multi_logloss: 0.540535        \n",
      "[84]\ttraining's multi_logloss: 0.485772\tvalid_1's multi_logloss: 0.535949        \n",
      "[85]\ttraining's multi_logloss: 0.480791\tvalid_1's multi_logloss: 0.531445        \n",
      "[86]\ttraining's multi_logloss: 0.475924\tvalid_1's multi_logloss: 0.527037        \n",
      "[87]\ttraining's multi_logloss: 0.471119\tvalid_1's multi_logloss: 0.522749        \n",
      "[88]\ttraining's multi_logloss: 0.466417\tvalid_1's multi_logloss: 0.518479        \n",
      "[89]\ttraining's multi_logloss: 0.461807\tvalid_1's multi_logloss: 0.51427         \n",
      "[90]\ttraining's multi_logloss: 0.457263\tvalid_1's multi_logloss: 0.510174        \n",
      "[91]\ttraining's multi_logloss: 0.452811\tvalid_1's multi_logloss: 0.506197        \n",
      "[92]\ttraining's multi_logloss: 0.448483\tvalid_1's multi_logloss: 0.502256        \n",
      "[93]\ttraining's multi_logloss: 0.444126\tvalid_1's multi_logloss: 0.498308        \n",
      "[94]\ttraining's multi_logloss: 0.439946\tvalid_1's multi_logloss: 0.494589        \n",
      "[95]\ttraining's multi_logloss: 0.435726\tvalid_1's multi_logloss: 0.490808        \n",
      "[96]\ttraining's multi_logloss: 0.431587\tvalid_1's multi_logloss: 0.48708         \n",
      "[97]\ttraining's multi_logloss: 0.427536\tvalid_1's multi_logloss: 0.48345         \n",
      "[98]\ttraining's multi_logloss: 0.423596\tvalid_1's multi_logloss: 0.479897        \n",
      "[99]\ttraining's multi_logloss: 0.419774\tvalid_1's multi_logloss: 0.476473        \n",
      "[100]\ttraining's multi_logloss: 0.415942\tvalid_1's multi_logloss: 0.473087       \n",
      "[101]\ttraining's multi_logloss: 0.412231\tvalid_1's multi_logloss: 0.469817       \n",
      "[102]\ttraining's multi_logloss: 0.408565\tvalid_1's multi_logloss: 0.466534       \n",
      "[103]\ttraining's multi_logloss: 0.404973\tvalid_1's multi_logloss: 0.463313       \n",
      "[104]\ttraining's multi_logloss: 0.401405\tvalid_1's multi_logloss: 0.460163       \n",
      "[105]\ttraining's multi_logloss: 0.397956\tvalid_1's multi_logloss: 0.457129       \n",
      "[106]\ttraining's multi_logloss: 0.394592\tvalid_1's multi_logloss: 0.454163       \n",
      "[107]\ttraining's multi_logloss: 0.391267\tvalid_1's multi_logloss: 0.451199       \n",
      "[108]\ttraining's multi_logloss: 0.388014\tvalid_1's multi_logloss: 0.448319       \n",
      "[109]\ttraining's multi_logloss: 0.384823\tvalid_1's multi_logloss: 0.44554        \n",
      "[110]\ttraining's multi_logloss: 0.3817\tvalid_1's multi_logloss: 0.442833         \n",
      "[111]\ttraining's multi_logloss: 0.378623\tvalid_1's multi_logloss: 0.440136       \n",
      "[112]\ttraining's multi_logloss: 0.375563\tvalid_1's multi_logloss: 0.43743        \n",
      "[113]\ttraining's multi_logloss: 0.372546\tvalid_1's multi_logloss: 0.43475        \n",
      "[114]\ttraining's multi_logloss: 0.369563\tvalid_1's multi_logloss: 0.432141       \n",
      "[115]\ttraining's multi_logloss: 0.366622\tvalid_1's multi_logloss: 0.429553       \n",
      "[116]\ttraining's multi_logloss: 0.36374\tvalid_1's multi_logloss: 0.427057        \n",
      "[117]\ttraining's multi_logloss: 0.360905\tvalid_1's multi_logloss: 0.424665       \n",
      "[118]\ttraining's multi_logloss: 0.358099\tvalid_1's multi_logloss: 0.422185       \n",
      "[119]\ttraining's multi_logloss: 0.355338\tvalid_1's multi_logloss: 0.41985        \n",
      "[120]\ttraining's multi_logloss: 0.352643\tvalid_1's multi_logloss: 0.417587       \n",
      "[121]\ttraining's multi_logloss: 0.350051\tvalid_1's multi_logloss: 0.415386       \n",
      "[122]\ttraining's multi_logloss: 0.347513\tvalid_1's multi_logloss: 0.413243       \n",
      "[123]\ttraining's multi_logloss: 0.34495\tvalid_1's multi_logloss: 0.41107         \n",
      "[124]\ttraining's multi_logloss: 0.342433\tvalid_1's multi_logloss: 0.408952       \n",
      "[125]\ttraining's multi_logloss: 0.340005\tvalid_1's multi_logloss: 0.40696        \n",
      "[126]\ttraining's multi_logloss: 0.337581\tvalid_1's multi_logloss: 0.405014       \n",
      "[127]\ttraining's multi_logloss: 0.335177\tvalid_1's multi_logloss: 0.403051       \n",
      "[128]\ttraining's multi_logloss: 0.332772\tvalid_1's multi_logloss: 0.401044       \n",
      "[129]\ttraining's multi_logloss: 0.330414\tvalid_1's multi_logloss: 0.39914        \n",
      "[130]\ttraining's multi_logloss: 0.328133\tvalid_1's multi_logloss: 0.397255       \n",
      "[131]\ttraining's multi_logloss: 0.325895\tvalid_1's multi_logloss: 0.395455       \n",
      "[132]\ttraining's multi_logloss: 0.323661\tvalid_1's multi_logloss: 0.393659       \n",
      "[133]\ttraining's multi_logloss: 0.32147\tvalid_1's multi_logloss: 0.39188         \n",
      "[134]\ttraining's multi_logloss: 0.319352\tvalid_1's multi_logloss: 0.390159       \n",
      "[135]\ttraining's multi_logloss: 0.317238\tvalid_1's multi_logloss: 0.388501       \n",
      "[136]\ttraining's multi_logloss: 0.315108\tvalid_1's multi_logloss: 0.386797       \n",
      "[137]\ttraining's multi_logloss: 0.313052\tvalid_1's multi_logloss: 0.385165       \n",
      "[138]\ttraining's multi_logloss: 0.310985\tvalid_1's multi_logloss: 0.383529       \n",
      "[139]\ttraining's multi_logloss: 0.308944\tvalid_1's multi_logloss: 0.381921       \n",
      "[140]\ttraining's multi_logloss: 0.306948\tvalid_1's multi_logloss: 0.38033        \n",
      "[141]\ttraining's multi_logloss: 0.304943\tvalid_1's multi_logloss: 0.378767       \n",
      "[142]\ttraining's multi_logloss: 0.303042\tvalid_1's multi_logloss: 0.377299       \n",
      "[143]\ttraining's multi_logloss: 0.301101\tvalid_1's multi_logloss: 0.375821       \n",
      "[144]\ttraining's multi_logloss: 0.299268\tvalid_1's multi_logloss: 0.374391       \n",
      "[145]\ttraining's multi_logloss: 0.297374\tvalid_1's multi_logloss: 0.372902       \n",
      "[146]\ttraining's multi_logloss: 0.295578\tvalid_1's multi_logloss: 0.371522       \n",
      "[147]\ttraining's multi_logloss: 0.293746\tvalid_1's multi_logloss: 0.3701         \n",
      "[148]\ttraining's multi_logloss: 0.292\tvalid_1's multi_logloss: 0.368809          \n",
      "[149]\ttraining's multi_logloss: 0.290261\tvalid_1's multi_logloss: 0.367525       \n",
      "[150]\ttraining's multi_logloss: 0.288556\tvalid_1's multi_logloss: 0.366218       \n",
      "[151]\ttraining's multi_logloss: 0.28684\tvalid_1's multi_logloss: 0.364889        \n",
      "[152]\ttraining's multi_logloss: 0.285118\tvalid_1's multi_logloss: 0.363595       \n",
      "[153]\ttraining's multi_logloss: 0.28346\tvalid_1's multi_logloss: 0.362359        \n",
      "[154]\ttraining's multi_logloss: 0.281789\tvalid_1's multi_logloss: 0.361161       \n",
      "[155]\ttraining's multi_logloss: 0.280138\tvalid_1's multi_logloss: 0.359946       \n",
      "[156]\ttraining's multi_logloss: 0.278538\tvalid_1's multi_logloss: 0.358759       \n",
      "[157]\ttraining's multi_logloss: 0.276933\tvalid_1's multi_logloss: 0.357593       \n",
      "[158]\ttraining's multi_logloss: 0.275382\tvalid_1's multi_logloss: 0.356466       \n",
      "[159]\ttraining's multi_logloss: 0.273878\tvalid_1's multi_logloss: 0.355377       \n",
      "[160]\ttraining's multi_logloss: 0.272354\tvalid_1's multi_logloss: 0.354294       \n",
      "[161]\ttraining's multi_logloss: 0.270845\tvalid_1's multi_logloss: 0.35322        \n",
      "[162]\ttraining's multi_logloss: 0.269355\tvalid_1's multi_logloss: 0.352106       \n",
      "[163]\ttraining's multi_logloss: 0.267904\tvalid_1's multi_logloss: 0.351042       \n",
      "[164]\ttraining's multi_logloss: 0.266444\tvalid_1's multi_logloss: 0.350058       \n",
      "[165]\ttraining's multi_logloss: 0.264964\tvalid_1's multi_logloss: 0.348987       \n",
      "[166]\ttraining's multi_logloss: 0.263538\tvalid_1's multi_logloss: 0.347989       \n",
      "[167]\ttraining's multi_logloss: 0.262135\tvalid_1's multi_logloss: 0.347035       \n",
      "[168]\ttraining's multi_logloss: 0.260762\tvalid_1's multi_logloss: 0.346093       \n",
      "[169]\ttraining's multi_logloss: 0.259403\tvalid_1's multi_logloss: 0.34517        \n",
      "[170]\ttraining's multi_logloss: 0.258063\tvalid_1's multi_logloss: 0.344237       \n",
      "[171]\ttraining's multi_logloss: 0.256732\tvalid_1's multi_logloss: 0.343361       \n",
      "[172]\ttraining's multi_logloss: 0.255384\tvalid_1's multi_logloss: 0.342423       \n",
      "[173]\ttraining's multi_logloss: 0.254074\tvalid_1's multi_logloss: 0.341598       \n",
      "[174]\ttraining's multi_logloss: 0.252776\tvalid_1's multi_logloss: 0.34072        \n",
      "[175]\ttraining's multi_logloss: 0.251496\tvalid_1's multi_logloss: 0.33986        \n",
      "[176]\ttraining's multi_logloss: 0.250232\tvalid_1's multi_logloss: 0.339053       \n",
      "[177]\ttraining's multi_logloss: 0.248956\tvalid_1's multi_logloss: 0.338249       \n",
      "[178]\ttraining's multi_logloss: 0.247702\tvalid_1's multi_logloss: 0.337463       \n",
      "[179]\ttraining's multi_logloss: 0.246483\tvalid_1's multi_logloss: 0.336676       \n",
      "[180]\ttraining's multi_logloss: 0.245277\tvalid_1's multi_logloss: 0.335944       \n",
      "[181]\ttraining's multi_logloss: 0.244075\tvalid_1's multi_logloss: 0.33521        \n",
      "[182]\ttraining's multi_logloss: 0.242895\tvalid_1's multi_logloss: 0.3345         \n",
      "[183]\ttraining's multi_logloss: 0.241698\tvalid_1's multi_logloss: 0.333732       \n",
      "[184]\ttraining's multi_logloss: 0.240519\tvalid_1's multi_logloss: 0.333009       \n",
      "[185]\ttraining's multi_logloss: 0.239338\tvalid_1's multi_logloss: 0.332246       \n",
      "[186]\ttraining's multi_logloss: 0.238137\tvalid_1's multi_logloss: 0.331514       \n",
      "[187]\ttraining's multi_logloss: 0.237023\tvalid_1's multi_logloss: 0.330839       \n",
      "[188]\ttraining's multi_logloss: 0.235899\tvalid_1's multi_logloss: 0.330158       \n",
      "[189]\ttraining's multi_logloss: 0.234761\tvalid_1's multi_logloss: 0.329458       \n",
      "[190]\ttraining's multi_logloss: 0.233663\tvalid_1's multi_logloss: 0.32877        \n",
      "[191]\ttraining's multi_logloss: 0.232527\tvalid_1's multi_logloss: 0.328053       \n",
      "[192]\ttraining's multi_logloss: 0.231497\tvalid_1's multi_logloss: 0.32744        \n",
      "[193]\ttraining's multi_logloss: 0.230412\tvalid_1's multi_logloss: 0.326777       \n",
      "[194]\ttraining's multi_logloss: 0.22931\tvalid_1's multi_logloss: 0.326145        \n",
      "[195]\ttraining's multi_logloss: 0.228247\tvalid_1's multi_logloss: 0.325525       \n",
      "[196]\ttraining's multi_logloss: 0.227209\tvalid_1's multi_logloss: 0.324942       \n",
      "[197]\ttraining's multi_logloss: 0.226176\tvalid_1's multi_logloss: 0.324352       \n",
      "[198]\ttraining's multi_logloss: 0.22512\tvalid_1's multi_logloss: 0.323792        \n",
      "[199]\ttraining's multi_logloss: 0.224116\tvalid_1's multi_logloss: 0.323275       \n",
      "[200]\ttraining's multi_logloss: 0.223125\tvalid_1's multi_logloss: 0.322713       \n",
      "[201]\ttraining's multi_logloss: 0.222125\tvalid_1's multi_logloss: 0.322228       \n",
      "[202]\ttraining's multi_logloss: 0.221147\tvalid_1's multi_logloss: 0.321765       \n",
      "[203]\ttraining's multi_logloss: 0.220161\tvalid_1's multi_logloss: 0.321251       \n",
      "[204]\ttraining's multi_logloss: 0.219147\tvalid_1's multi_logloss: 0.320765       \n",
      "[205]\ttraining's multi_logloss: 0.218158\tvalid_1's multi_logloss: 0.320307       \n",
      "[206]\ttraining's multi_logloss: 0.217215\tvalid_1's multi_logloss: 0.31989        \n",
      "[207]\ttraining's multi_logloss: 0.216245\tvalid_1's multi_logloss: 0.319429       \n",
      "[208]\ttraining's multi_logloss: 0.215317\tvalid_1's multi_logloss: 0.318926       \n",
      "[209]\ttraining's multi_logloss: 0.214357\tvalid_1's multi_logloss: 0.318453       \n",
      "[210]\ttraining's multi_logloss: 0.213397\tvalid_1's multi_logloss: 0.317987       \n",
      "[211]\ttraining's multi_logloss: 0.212473\tvalid_1's multi_logloss: 0.317526       \n",
      "[212]\ttraining's multi_logloss: 0.211557\tvalid_1's multi_logloss: 0.317077       \n",
      "[213]\ttraining's multi_logloss: 0.210656\tvalid_1's multi_logloss: 0.316632       \n",
      "[214]\ttraining's multi_logloss: 0.209699\tvalid_1's multi_logloss: 0.316195       \n",
      "[215]\ttraining's multi_logloss: 0.208865\tvalid_1's multi_logloss: 0.315856       \n",
      "[216]\ttraining's multi_logloss: 0.208004\tvalid_1's multi_logloss: 0.315456       \n",
      "[217]\ttraining's multi_logloss: 0.207097\tvalid_1's multi_logloss: 0.315051       \n",
      "[218]\ttraining's multi_logloss: 0.206253\tvalid_1's multi_logloss: 0.314697       \n",
      "[219]\ttraining's multi_logloss: 0.205361\tvalid_1's multi_logloss: 0.3143         \n",
      "[220]\ttraining's multi_logloss: 0.204496\tvalid_1's multi_logloss: 0.313929       \n",
      "[221]\ttraining's multi_logloss: 0.203606\tvalid_1's multi_logloss: 0.313573       \n",
      "[222]\ttraining's multi_logloss: 0.202749\tvalid_1's multi_logloss: 0.313225       \n",
      "[223]\ttraining's multi_logloss: 0.201916\tvalid_1's multi_logloss: 0.312901       \n",
      "[224]\ttraining's multi_logloss: 0.201086\tvalid_1's multi_logloss: 0.312499       \n",
      "[225]\ttraining's multi_logloss: 0.200277\tvalid_1's multi_logloss: 0.312218       \n",
      "[226]\ttraining's multi_logloss: 0.199455\tvalid_1's multi_logloss: 0.311845       \n",
      "[227]\ttraining's multi_logloss: 0.198665\tvalid_1's multi_logloss: 0.311551       \n",
      "[228]\ttraining's multi_logloss: 0.19788\tvalid_1's multi_logloss: 0.311209        \n",
      "[229]\ttraining's multi_logloss: 0.19706\tvalid_1's multi_logloss: 0.31085         \n",
      "[230]\ttraining's multi_logloss: 0.196283\tvalid_1's multi_logloss: 0.310514       \n",
      "[231]\ttraining's multi_logloss: 0.195479\tvalid_1's multi_logloss: 0.31018        \n",
      "[232]\ttraining's multi_logloss: 0.194683\tvalid_1's multi_logloss: 0.309866       \n",
      "[233]\ttraining's multi_logloss: 0.193897\tvalid_1's multi_logloss: 0.309519       \n",
      "[234]\ttraining's multi_logloss: 0.193144\tvalid_1's multi_logloss: 0.309271       \n",
      "[235]\ttraining's multi_logloss: 0.192379\tvalid_1's multi_logloss: 0.30901        \n",
      "[236]\ttraining's multi_logloss: 0.191594\tvalid_1's multi_logloss: 0.308663       \n",
      "[237]\ttraining's multi_logloss: 0.190834\tvalid_1's multi_logloss: 0.308335       \n",
      "[238]\ttraining's multi_logloss: 0.190103\tvalid_1's multi_logloss: 0.308022       \n",
      "[239]\ttraining's multi_logloss: 0.189378\tvalid_1's multi_logloss: 0.307727       \n",
      "[240]\ttraining's multi_logloss: 0.188641\tvalid_1's multi_logloss: 0.307458       \n",
      "[241]\ttraining's multi_logloss: 0.187904\tvalid_1's multi_logloss: 0.307202       \n",
      "[242]\ttraining's multi_logloss: 0.187176\tvalid_1's multi_logloss: 0.307024       \n",
      "[243]\ttraining's multi_logloss: 0.186468\tvalid_1's multi_logloss: 0.306782       \n",
      "[244]\ttraining's multi_logloss: 0.18575\tvalid_1's multi_logloss: 0.306528        \n",
      "[245]\ttraining's multi_logloss: 0.184995\tvalid_1's multi_logloss: 0.30625        \n",
      "[246]\ttraining's multi_logloss: 0.184234\tvalid_1's multi_logloss: 0.305935       \n",
      "[247]\ttraining's multi_logloss: 0.183524\tvalid_1's multi_logloss: 0.305664       \n",
      "[248]\ttraining's multi_logloss: 0.182763\tvalid_1's multi_logloss: 0.305335       \n",
      "[249]\ttraining's multi_logloss: 0.182024\tvalid_1's multi_logloss: 0.305026       \n",
      "[250]\ttraining's multi_logloss: 0.181316\tvalid_1's multi_logloss: 0.30477        \n",
      "[251]\ttraining's multi_logloss: 0.180609\tvalid_1's multi_logloss: 0.304521       \n",
      "[252]\ttraining's multi_logloss: 0.179911\tvalid_1's multi_logloss: 0.304298       \n",
      "[253]\ttraining's multi_logloss: 0.179217\tvalid_1's multi_logloss: 0.304036       \n",
      "[254]\ttraining's multi_logloss: 0.178513\tvalid_1's multi_logloss: 0.30375        \n",
      "[255]\ttraining's multi_logloss: 0.177839\tvalid_1's multi_logloss: 0.303466       \n",
      "[256]\ttraining's multi_logloss: 0.177158\tvalid_1's multi_logloss: 0.303186       \n",
      "[257]\ttraining's multi_logloss: 0.176477\tvalid_1's multi_logloss: 0.302952       \n",
      "[258]\ttraining's multi_logloss: 0.175806\tvalid_1's multi_logloss: 0.302706       \n",
      "[259]\ttraining's multi_logloss: 0.175184\tvalid_1's multi_logloss: 0.302523       \n",
      "[260]\ttraining's multi_logloss: 0.174528\tvalid_1's multi_logloss: 0.302309       \n",
      "[261]\ttraining's multi_logloss: 0.173866\tvalid_1's multi_logloss: 0.302071       \n",
      "[262]\ttraining's multi_logloss: 0.173256\tvalid_1's multi_logloss: 0.301861       \n",
      "[263]\ttraining's multi_logloss: 0.172623\tvalid_1's multi_logloss: 0.301643       \n",
      "[264]\ttraining's multi_logloss: 0.172\tvalid_1's multi_logloss: 0.301439          \n",
      "[265]\ttraining's multi_logloss: 0.171356\tvalid_1's multi_logloss: 0.301214       \n",
      "[266]\ttraining's multi_logloss: 0.170714\tvalid_1's multi_logloss: 0.301026       \n",
      "[267]\ttraining's multi_logloss: 0.170098\tvalid_1's multi_logloss: 0.300791       \n",
      "[268]\ttraining's multi_logloss: 0.169473\tvalid_1's multi_logloss: 0.300637       \n",
      "[269]\ttraining's multi_logloss: 0.168863\tvalid_1's multi_logloss: 0.300429       \n",
      "[270]\ttraining's multi_logloss: 0.168263\tvalid_1's multi_logloss: 0.300285       \n",
      "[271]\ttraining's multi_logloss: 0.167639\tvalid_1's multi_logloss: 0.300092       \n",
      "[272]\ttraining's multi_logloss: 0.167038\tvalid_1's multi_logloss: 0.299891       \n",
      "[273]\ttraining's multi_logloss: 0.166436\tvalid_1's multi_logloss: 0.299674       \n",
      "[274]\ttraining's multi_logloss: 0.165825\tvalid_1's multi_logloss: 0.299563       \n",
      "[275]\ttraining's multi_logloss: 0.165229\tvalid_1's multi_logloss: 0.299333       \n",
      "[276]\ttraining's multi_logloss: 0.164626\tvalid_1's multi_logloss: 0.299155       \n",
      "[277]\ttraining's multi_logloss: 0.164019\tvalid_1's multi_logloss: 0.298912       \n",
      "[278]\ttraining's multi_logloss: 0.163416\tvalid_1's multi_logloss: 0.298795       \n",
      "[279]\ttraining's multi_logloss: 0.162842\tvalid_1's multi_logloss: 0.298581       \n",
      "[280]\ttraining's multi_logloss: 0.162251\tvalid_1's multi_logloss: 0.298458       \n",
      "[281]\ttraining's multi_logloss: 0.161658\tvalid_1's multi_logloss: 0.298227       \n",
      "[282]\ttraining's multi_logloss: 0.161073\tvalid_1's multi_logloss: 0.298026       \n",
      "[283]\ttraining's multi_logloss: 0.160482\tvalid_1's multi_logloss: 0.297883       \n",
      "[284]\ttraining's multi_logloss: 0.159914\tvalid_1's multi_logloss: 0.297716       \n",
      "[285]\ttraining's multi_logloss: 0.159354\tvalid_1's multi_logloss: 0.297587       \n",
      "[286]\ttraining's multi_logloss: 0.158796\tvalid_1's multi_logloss: 0.297444       \n",
      "[287]\ttraining's multi_logloss: 0.158236\tvalid_1's multi_logloss: 0.29729        \n",
      "[288]\ttraining's multi_logloss: 0.157664\tvalid_1's multi_logloss: 0.297165       \n",
      "[289]\ttraining's multi_logloss: 0.157121\tvalid_1's multi_logloss: 0.297061       \n",
      "[290]\ttraining's multi_logloss: 0.156577\tvalid_1's multi_logloss: 0.296962       \n",
      "[291]\ttraining's multi_logloss: 0.15602\tvalid_1's multi_logloss: 0.296835        \n",
      "[292]\ttraining's multi_logloss: 0.155452\tvalid_1's multi_logloss: 0.296719       \n",
      "[293]\ttraining's multi_logloss: 0.154915\tvalid_1's multi_logloss: 0.296602       \n",
      "[294]\ttraining's multi_logloss: 0.154394\tvalid_1's multi_logloss: 0.296514       \n",
      "[295]\ttraining's multi_logloss: 0.15386\tvalid_1's multi_logloss: 0.296403        \n",
      "[296]\ttraining's multi_logloss: 0.153337\tvalid_1's multi_logloss: 0.296292       \n",
      "[297]\ttraining's multi_logloss: 0.152821\tvalid_1's multi_logloss: 0.296179       \n",
      "[298]\ttraining's multi_logloss: 0.152317\tvalid_1's multi_logloss: 0.296128       \n",
      "[299]\ttraining's multi_logloss: 0.151795\tvalid_1's multi_logloss: 0.296004       \n",
      "[300]\ttraining's multi_logloss: 0.151285\tvalid_1's multi_logloss: 0.295899       \n",
      "[301]\ttraining's multi_logloss: 0.150784\tvalid_1's multi_logloss: 0.295792       \n",
      "[302]\ttraining's multi_logloss: 0.150299\tvalid_1's multi_logloss: 0.295703       \n",
      "[303]\ttraining's multi_logloss: 0.149778\tvalid_1's multi_logloss: 0.295558       \n",
      "[304]\ttraining's multi_logloss: 0.149246\tvalid_1's multi_logloss: 0.295414       \n",
      "[305]\ttraining's multi_logloss: 0.148747\tvalid_1's multi_logloss: 0.29528        \n",
      "[306]\ttraining's multi_logloss: 0.148249\tvalid_1's multi_logloss: 0.295213       \n",
      "[307]\ttraining's multi_logloss: 0.147757\tvalid_1's multi_logloss: 0.295136       \n",
      "[308]\ttraining's multi_logloss: 0.147265\tvalid_1's multi_logloss: 0.295072       \n",
      "[309]\ttraining's multi_logloss: 0.146761\tvalid_1's multi_logloss: 0.294976       \n",
      "[310]\ttraining's multi_logloss: 0.146279\tvalid_1's multi_logloss: 0.294862       \n",
      "[311]\ttraining's multi_logloss: 0.145786\tvalid_1's multi_logloss: 0.294799       \n",
      "[312]\ttraining's multi_logloss: 0.145289\tvalid_1's multi_logloss: 0.294727       \n",
      "[313]\ttraining's multi_logloss: 0.14481\tvalid_1's multi_logloss: 0.294676        \n",
      "[314]\ttraining's multi_logloss: 0.144329\tvalid_1's multi_logloss: 0.294612       \n",
      "[315]\ttraining's multi_logloss: 0.143864\tvalid_1's multi_logloss: 0.294564       \n",
      "[316]\ttraining's multi_logloss: 0.143391\tvalid_1's multi_logloss: 0.2945         \n",
      "[317]\ttraining's multi_logloss: 0.142902\tvalid_1's multi_logloss: 0.294466       \n",
      "[318]\ttraining's multi_logloss: 0.142423\tvalid_1's multi_logloss: 0.294368       \n",
      "[319]\ttraining's multi_logloss: 0.141959\tvalid_1's multi_logloss: 0.294324       \n",
      "[320]\ttraining's multi_logloss: 0.141455\tvalid_1's multi_logloss: 0.294243       \n",
      "[321]\ttraining's multi_logloss: 0.140979\tvalid_1's multi_logloss: 0.294163       \n",
      "[322]\ttraining's multi_logloss: 0.140524\tvalid_1's multi_logloss: 0.294032       \n",
      "[323]\ttraining's multi_logloss: 0.140079\tvalid_1's multi_logloss: 0.293914       \n",
      "[324]\ttraining's multi_logloss: 0.139622\tvalid_1's multi_logloss: 0.293822       \n",
      "[325]\ttraining's multi_logloss: 0.139166\tvalid_1's multi_logloss: 0.293805       \n",
      "[326]\ttraining's multi_logloss: 0.138732\tvalid_1's multi_logloss: 0.29374        \n",
      "[327]\ttraining's multi_logloss: 0.138278\tvalid_1's multi_logloss: 0.293595       \n",
      "[328]\ttraining's multi_logloss: 0.137832\tvalid_1's multi_logloss: 0.293567       \n",
      "[329]\ttraining's multi_logloss: 0.137382\tvalid_1's multi_logloss: 0.293458       \n",
      "[330]\ttraining's multi_logloss: 0.136934\tvalid_1's multi_logloss: 0.293383       \n",
      "[331]\ttraining's multi_logloss: 0.136476\tvalid_1's multi_logloss: 0.293257       \n",
      "[332]\ttraining's multi_logloss: 0.136054\tvalid_1's multi_logloss: 0.293239       \n",
      "[333]\ttraining's multi_logloss: 0.135609\tvalid_1's multi_logloss: 0.293182       \n",
      "[334]\ttraining's multi_logloss: 0.135171\tvalid_1's multi_logloss: 0.293092       \n",
      "[335]\ttraining's multi_logloss: 0.134738\tvalid_1's multi_logloss: 0.293034       \n",
      "[336]\ttraining's multi_logloss: 0.13431\tvalid_1's multi_logloss: 0.29302         \n",
      "[337]\ttraining's multi_logloss: 0.133881\tvalid_1's multi_logloss: 0.293006       \n",
      "[338]\ttraining's multi_logloss: 0.133457\tvalid_1's multi_logloss: 0.292931       \n",
      "[339]\ttraining's multi_logloss: 0.133023\tvalid_1's multi_logloss: 0.292895       \n",
      "[340]\ttraining's multi_logloss: 0.132613\tvalid_1's multi_logloss: 0.292835       \n",
      "[341]\ttraining's multi_logloss: 0.132178\tvalid_1's multi_logloss: 0.292765       \n",
      "[342]\ttraining's multi_logloss: 0.131763\tvalid_1's multi_logloss: 0.292724       \n",
      "[343]\ttraining's multi_logloss: 0.131325\tvalid_1's multi_logloss: 0.292695       \n",
      "[344]\ttraining's multi_logloss: 0.130936\tvalid_1's multi_logloss: 0.292656       \n",
      "[345]\ttraining's multi_logloss: 0.130496\tvalid_1's multi_logloss: 0.292534       \n",
      "[346]\ttraining's multi_logloss: 0.130078\tvalid_1's multi_logloss: 0.292505       \n",
      "[347]\ttraining's multi_logloss: 0.129666\tvalid_1's multi_logloss: 0.292469       \n",
      "[348]\ttraining's multi_logloss: 0.129244\tvalid_1's multi_logloss: 0.29242        \n",
      "[349]\ttraining's multi_logloss: 0.128837\tvalid_1's multi_logloss: 0.292427       \n",
      "[350]\ttraining's multi_logloss: 0.128427\tvalid_1's multi_logloss: 0.292344       \n",
      "[351]\ttraining's multi_logloss: 0.128002\tvalid_1's multi_logloss: 0.2923         \n",
      "[352]\ttraining's multi_logloss: 0.127587\tvalid_1's multi_logloss: 0.292264       \n",
      "[353]\ttraining's multi_logloss: 0.127174\tvalid_1's multi_logloss: 0.292222       \n",
      "[354]\ttraining's multi_logloss: 0.126762\tvalid_1's multi_logloss: 0.292164       \n",
      "[355]\ttraining's multi_logloss: 0.126375\tvalid_1's multi_logloss: 0.292148       \n",
      "[356]\ttraining's multi_logloss: 0.125963\tvalid_1's multi_logloss: 0.292102       \n",
      "[357]\ttraining's multi_logloss: 0.125566\tvalid_1's multi_logloss: 0.292124       \n",
      "[358]\ttraining's multi_logloss: 0.125161\tvalid_1's multi_logloss: 0.292116       \n",
      "[359]\ttraining's multi_logloss: 0.124776\tvalid_1's multi_logloss: 0.292133       \n",
      "[360]\ttraining's multi_logloss: 0.124392\tvalid_1's multi_logloss: 0.292154       \n",
      "[361]\ttraining's multi_logloss: 0.124012\tvalid_1's multi_logloss: 0.292126       \n",
      "[362]\ttraining's multi_logloss: 0.123632\tvalid_1's multi_logloss: 0.292037       \n",
      "[363]\ttraining's multi_logloss: 0.123245\tvalid_1's multi_logloss: 0.292025       \n",
      "[364]\ttraining's multi_logloss: 0.122845\tvalid_1's multi_logloss: 0.292016       \n",
      "[365]\ttraining's multi_logloss: 0.122485\tvalid_1's multi_logloss: 0.29199        \n",
      "[366]\ttraining's multi_logloss: 0.12209\tvalid_1's multi_logloss: 0.291964        \n",
      "[367]\ttraining's multi_logloss: 0.121715\tvalid_1's multi_logloss: 0.291951       \n",
      "[368]\ttraining's multi_logloss: 0.121341\tvalid_1's multi_logloss: 0.29193        \n",
      "[369]\ttraining's multi_logloss: 0.120993\tvalid_1's multi_logloss: 0.2919         \n",
      "[370]\ttraining's multi_logloss: 0.120629\tvalid_1's multi_logloss: 0.291861       \n",
      "[371]\ttraining's multi_logloss: 0.120263\tvalid_1's multi_logloss: 0.291833       \n",
      "[372]\ttraining's multi_logloss: 0.119899\tvalid_1's multi_logloss: 0.291773       \n",
      "[373]\ttraining's multi_logloss: 0.119532\tvalid_1's multi_logloss: 0.291758       \n",
      "[374]\ttraining's multi_logloss: 0.119164\tvalid_1's multi_logloss: 0.291754       \n",
      "[375]\ttraining's multi_logloss: 0.118775\tvalid_1's multi_logloss: 0.291732       \n",
      "[376]\ttraining's multi_logloss: 0.118387\tvalid_1's multi_logloss: 0.291681       \n",
      "[377]\ttraining's multi_logloss: 0.118012\tvalid_1's multi_logloss: 0.29163        \n",
      "[378]\ttraining's multi_logloss: 0.117668\tvalid_1's multi_logloss: 0.291683       \n",
      "[379]\ttraining's multi_logloss: 0.11732\tvalid_1's multi_logloss: 0.291705        \n",
      "[380]\ttraining's multi_logloss: 0.11695\tvalid_1's multi_logloss: 0.291692        \n",
      "[381]\ttraining's multi_logloss: 0.116597\tvalid_1's multi_logloss: 0.291704       \n",
      "[382]\ttraining's multi_logloss: 0.116236\tvalid_1's multi_logloss: 0.291696       \n",
      "[383]\ttraining's multi_logloss: 0.115877\tvalid_1's multi_logloss: 0.291673       \n",
      "[384]\ttraining's multi_logloss: 0.115523\tvalid_1's multi_logloss: 0.291644       \n",
      "[385]\ttraining's multi_logloss: 0.115168\tvalid_1's multi_logloss: 0.291635       \n",
      "[386]\ttraining's multi_logloss: 0.114816\tvalid_1's multi_logloss: 0.291595       \n",
      "[387]\ttraining's multi_logloss: 0.114451\tvalid_1's multi_logloss: 0.291563       \n",
      "[388]\ttraining's multi_logloss: 0.114093\tvalid_1's multi_logloss: 0.291608       \n",
      "[389]\ttraining's multi_logloss: 0.113739\tvalid_1's multi_logloss: 0.291618       \n",
      "[390]\ttraining's multi_logloss: 0.113391\tvalid_1's multi_logloss: 0.29161        \n",
      "[391]\ttraining's multi_logloss: 0.113046\tvalid_1's multi_logloss: 0.291599       \n",
      "[392]\ttraining's multi_logloss: 0.112694\tvalid_1's multi_logloss: 0.291634       \n",
      "[393]\ttraining's multi_logloss: 0.112343\tvalid_1's multi_logloss: 0.291652       \n",
      "[394]\ttraining's multi_logloss: 0.112011\tvalid_1's multi_logloss: 0.291615       \n",
      "[395]\ttraining's multi_logloss: 0.111682\tvalid_1's multi_logloss: 0.291666       \n",
      "[396]\ttraining's multi_logloss: 0.111341\tvalid_1's multi_logloss: 0.291708       \n",
      "[397]\ttraining's multi_logloss: 0.110994\tvalid_1's multi_logloss: 0.291708       \n",
      "[398]\ttraining's multi_logloss: 0.110667\tvalid_1's multi_logloss: 0.291729       \n",
      "[399]\ttraining's multi_logloss: 0.110342\tvalid_1's multi_logloss: 0.291712       \n",
      "[400]\ttraining's multi_logloss: 0.109987\tvalid_1's multi_logloss: 0.29176        \n",
      "Did not meet early stopping. Best iteration is:                                  \n",
      "[400]\ttraining's multi_logloss: 0.109987\tvalid_1's multi_logloss: 0.29176\n",
      "[1]\ttraining's multi_logloss: 1.87199\tvalid_1's multi_logloss: 1.87407           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.81792\tvalid_1's multi_logloss: 1.82039           \n",
      "[3]\ttraining's multi_logloss: 1.76723\tvalid_1's multi_logloss: 1.77003           \n",
      "[4]\ttraining's multi_logloss: 1.71972\tvalid_1's multi_logloss: 1.72291           \n",
      "[5]\ttraining's multi_logloss: 1.67471\tvalid_1's multi_logloss: 1.67825           \n",
      "[6]\ttraining's multi_logloss: 1.63217\tvalid_1's multi_logloss: 1.63607           \n",
      "[7]\ttraining's multi_logloss: 1.59171\tvalid_1's multi_logloss: 1.59582           \n",
      "[8]\ttraining's multi_logloss: 1.5532\tvalid_1's multi_logloss: 1.55759            \n",
      "[9]\ttraining's multi_logloss: 1.51671\tvalid_1's multi_logloss: 1.52156           \n",
      "[10]\ttraining's multi_logloss: 1.48174\tvalid_1's multi_logloss: 1.48703          \n",
      "[11]\ttraining's multi_logloss: 1.44815\tvalid_1's multi_logloss: 1.45406          \n",
      "[12]\ttraining's multi_logloss: 1.41618\tvalid_1's multi_logloss: 1.42258          \n",
      "[13]\ttraining's multi_logloss: 1.38564\tvalid_1's multi_logloss: 1.39255          \n",
      "[14]\ttraining's multi_logloss: 1.35617\tvalid_1's multi_logloss: 1.36346          \n",
      "[15]\ttraining's multi_logloss: 1.32797\tvalid_1's multi_logloss: 1.33575          \n",
      "[16]\ttraining's multi_logloss: 1.30083\tvalid_1's multi_logloss: 1.30892          \n",
      "[17]\ttraining's multi_logloss: 1.27463\tvalid_1's multi_logloss: 1.28325          \n",
      "[18]\ttraining's multi_logloss: 1.2494\tvalid_1's multi_logloss: 1.2585            \n",
      "[19]\ttraining's multi_logloss: 1.22482\tvalid_1's multi_logloss: 1.23433          \n",
      "[20]\ttraining's multi_logloss: 1.20128\tvalid_1's multi_logloss: 1.21119          \n",
      "[21]\ttraining's multi_logloss: 1.17851\tvalid_1's multi_logloss: 1.18881          \n",
      "[22]\ttraining's multi_logloss: 1.15641\tvalid_1's multi_logloss: 1.16724          \n",
      "[23]\ttraining's multi_logloss: 1.13512\tvalid_1's multi_logloss: 1.14629          \n",
      "[24]\ttraining's multi_logloss: 1.11438\tvalid_1's multi_logloss: 1.126            \n",
      "[25]\ttraining's multi_logloss: 1.09433\tvalid_1's multi_logloss: 1.10633          \n",
      "[26]\ttraining's multi_logloss: 1.07492\tvalid_1's multi_logloss: 1.08732          \n",
      "[27]\ttraining's multi_logloss: 1.05595\tvalid_1's multi_logloss: 1.06875          \n",
      "[28]\ttraining's multi_logloss: 1.0376\tvalid_1's multi_logloss: 1.05088           \n",
      "[29]\ttraining's multi_logloss: 1.01974\tvalid_1's multi_logloss: 1.03351          \n",
      "[30]\ttraining's multi_logloss: 1.00246\tvalid_1's multi_logloss: 1.01659          \n",
      "[31]\ttraining's multi_logloss: 0.985681\tvalid_1's multi_logloss: 1.00026         \n",
      "[32]\ttraining's multi_logloss: 0.969273\tvalid_1's multi_logloss: 0.984258        \n",
      "[33]\ttraining's multi_logloss: 0.953337\tvalid_1's multi_logloss: 0.968786        \n",
      "[34]\ttraining's multi_logloss: 0.937889\tvalid_1's multi_logloss: 0.95373         \n",
      "[35]\ttraining's multi_logloss: 0.922772\tvalid_1's multi_logloss: 0.939041        \n",
      "[36]\ttraining's multi_logloss: 0.90811\tvalid_1's multi_logloss: 0.924747         \n",
      "[37]\ttraining's multi_logloss: 0.893804\tvalid_1's multi_logloss: 0.910872        \n",
      "[38]\ttraining's multi_logloss: 0.879917\tvalid_1's multi_logloss: 0.897364        \n",
      "[39]\ttraining's multi_logloss: 0.866365\tvalid_1's multi_logloss: 0.884272        \n",
      "[40]\ttraining's multi_logloss: 0.853163\tvalid_1's multi_logloss: 0.871463        \n",
      "[41]\ttraining's multi_logloss: 0.840255\tvalid_1's multi_logloss: 0.85898         \n",
      "[42]\ttraining's multi_logloss: 0.827702\tvalid_1's multi_logloss: 0.846834        \n",
      "[43]\ttraining's multi_logloss: 0.815503\tvalid_1's multi_logloss: 0.835062        \n",
      "[44]\ttraining's multi_logloss: 0.803606\tvalid_1's multi_logloss: 0.823553        \n",
      "[45]\ttraining's multi_logloss: 0.792005\tvalid_1's multi_logloss: 0.812409        \n",
      "[46]\ttraining's multi_logloss: 0.780619\tvalid_1's multi_logloss: 0.801493        \n",
      "[47]\ttraining's multi_logloss: 0.769457\tvalid_1's multi_logloss: 0.790799        \n",
      "[48]\ttraining's multi_logloss: 0.758618\tvalid_1's multi_logloss: 0.780351        \n",
      "[49]\ttraining's multi_logloss: 0.748032\tvalid_1's multi_logloss: 0.770202        \n",
      "[50]\ttraining's multi_logloss: 0.737666\tvalid_1's multi_logloss: 0.760272        \n",
      "[51]\ttraining's multi_logloss: 0.727548\tvalid_1's multi_logloss: 0.750532        \n",
      "[52]\ttraining's multi_logloss: 0.717714\tvalid_1's multi_logloss: 0.741095        \n",
      "[53]\ttraining's multi_logloss: 0.708111\tvalid_1's multi_logloss: 0.731984        \n",
      "[54]\ttraining's multi_logloss: 0.698649\tvalid_1's multi_logloss: 0.722956        \n",
      "[55]\ttraining's multi_logloss: 0.689401\tvalid_1's multi_logloss: 0.714184        \n",
      "[56]\ttraining's multi_logloss: 0.680285\tvalid_1's multi_logloss: 0.705502        \n",
      "[57]\ttraining's multi_logloss: 0.671357\tvalid_1's multi_logloss: 0.697038        \n",
      "[58]\ttraining's multi_logloss: 0.662723\tvalid_1's multi_logloss: 0.688911        \n",
      "[59]\ttraining's multi_logloss: 0.654074\tvalid_1's multi_logloss: 0.680745        \n",
      "[60]\ttraining's multi_logloss: 0.64578\tvalid_1's multi_logloss: 0.672881         \n",
      "[61]\ttraining's multi_logloss: 0.637579\tvalid_1's multi_logloss: 0.665163        \n",
      "[62]\ttraining's multi_logloss: 0.62955\tvalid_1's multi_logloss: 0.657579         \n",
      "[63]\ttraining's multi_logloss: 0.62171\tvalid_1's multi_logloss: 0.650177         \n",
      "[64]\ttraining's multi_logloss: 0.613992\tvalid_1's multi_logloss: 0.642869        \n",
      "[65]\ttraining's multi_logloss: 0.606509\tvalid_1's multi_logloss: 0.635817        \n",
      "[66]\ttraining's multi_logloss: 0.599154\tvalid_1's multi_logloss: 0.628876        \n",
      "[67]\ttraining's multi_logloss: 0.591936\tvalid_1's multi_logloss: 0.621972        \n",
      "[68]\ttraining's multi_logloss: 0.584884\tvalid_1's multi_logloss: 0.615288        \n",
      "[69]\ttraining's multi_logloss: 0.577971\tvalid_1's multi_logloss: 0.608701        \n",
      "[70]\ttraining's multi_logloss: 0.571261\tvalid_1's multi_logloss: 0.602336        \n",
      "[71]\ttraining's multi_logloss: 0.564671\tvalid_1's multi_logloss: 0.59614         \n",
      "[72]\ttraining's multi_logloss: 0.558269\tvalid_1's multi_logloss: 0.590114        \n",
      "[73]\ttraining's multi_logloss: 0.55196\tvalid_1's multi_logloss: 0.5842           \n",
      "[74]\ttraining's multi_logloss: 0.545779\tvalid_1's multi_logloss: 0.57834         \n",
      "[75]\ttraining's multi_logloss: 0.539722\tvalid_1's multi_logloss: 0.572668        \n",
      "[76]\ttraining's multi_logloss: 0.533746\tvalid_1's multi_logloss: 0.567109        \n",
      "[77]\ttraining's multi_logloss: 0.527933\tvalid_1's multi_logloss: 0.561615        \n",
      "[78]\ttraining's multi_logloss: 0.52218\tvalid_1's multi_logloss: 0.556267         \n",
      "[79]\ttraining's multi_logloss: 0.516647\tvalid_1's multi_logloss: 0.551088        \n",
      "[80]\ttraining's multi_logloss: 0.51112\tvalid_1's multi_logloss: 0.545999         \n",
      "[81]\ttraining's multi_logloss: 0.505786\tvalid_1's multi_logloss: 0.540965        \n",
      "[82]\ttraining's multi_logloss: 0.500553\tvalid_1's multi_logloss: 0.536158        \n",
      "[83]\ttraining's multi_logloss: 0.49543\tvalid_1's multi_logloss: 0.531415         \n",
      "[84]\ttraining's multi_logloss: 0.490414\tvalid_1's multi_logloss: 0.526811        \n",
      "[85]\ttraining's multi_logloss: 0.485481\tvalid_1's multi_logloss: 0.522287        \n",
      "[86]\ttraining's multi_logloss: 0.480646\tvalid_1's multi_logloss: 0.517869        \n",
      "[87]\ttraining's multi_logloss: 0.475933\tvalid_1's multi_logloss: 0.513541        \n",
      "[88]\ttraining's multi_logloss: 0.471234\tvalid_1's multi_logloss: 0.509228        \n",
      "[89]\ttraining's multi_logloss: 0.466673\tvalid_1's multi_logloss: 0.505076        \n",
      "[90]\ttraining's multi_logloss: 0.462161\tvalid_1's multi_logloss: 0.500939        \n",
      "[91]\ttraining's multi_logloss: 0.457711\tvalid_1's multi_logloss: 0.496819        \n",
      "[92]\ttraining's multi_logloss: 0.453361\tvalid_1's multi_logloss: 0.492898        \n",
      "[93]\ttraining's multi_logloss: 0.449089\tvalid_1's multi_logloss: 0.489036        \n",
      "[94]\ttraining's multi_logloss: 0.444862\tvalid_1's multi_logloss: 0.485217        \n",
      "[95]\ttraining's multi_logloss: 0.440751\tvalid_1's multi_logloss: 0.481523        \n",
      "[96]\ttraining's multi_logloss: 0.436708\tvalid_1's multi_logloss: 0.477885        \n",
      "[97]\ttraining's multi_logloss: 0.432725\tvalid_1's multi_logloss: 0.47434         \n",
      "[98]\ttraining's multi_logloss: 0.428793\tvalid_1's multi_logloss: 0.470975        \n",
      "[99]\ttraining's multi_logloss: 0.424946\tvalid_1's multi_logloss: 0.467605        \n",
      "[100]\ttraining's multi_logloss: 0.421144\tvalid_1's multi_logloss: 0.464251       \n",
      "[101]\ttraining's multi_logloss: 0.417393\tvalid_1's multi_logloss: 0.460977       \n",
      "[102]\ttraining's multi_logloss: 0.413649\tvalid_1's multi_logloss: 0.457641       \n",
      "[103]\ttraining's multi_logloss: 0.410027\tvalid_1's multi_logloss: 0.454401       \n",
      "[104]\ttraining's multi_logloss: 0.406494\tvalid_1's multi_logloss: 0.451304       \n",
      "[105]\ttraining's multi_logloss: 0.403015\tvalid_1's multi_logloss: 0.448304       \n",
      "[106]\ttraining's multi_logloss: 0.399611\tvalid_1's multi_logloss: 0.445352       \n",
      "[107]\ttraining's multi_logloss: 0.39629\tvalid_1's multi_logloss: 0.442492        \n",
      "[108]\ttraining's multi_logloss: 0.392949\tvalid_1's multi_logloss: 0.439625       \n",
      "[109]\ttraining's multi_logloss: 0.389742\tvalid_1's multi_logloss: 0.436819       \n",
      "[110]\ttraining's multi_logloss: 0.386535\tvalid_1's multi_logloss: 0.434051       \n",
      "[111]\ttraining's multi_logloss: 0.383371\tvalid_1's multi_logloss: 0.431383       \n",
      "[112]\ttraining's multi_logloss: 0.380246\tvalid_1's multi_logloss: 0.42875        \n",
      "[113]\ttraining's multi_logloss: 0.377224\tvalid_1's multi_logloss: 0.426101       \n",
      "[114]\ttraining's multi_logloss: 0.37421\tvalid_1's multi_logloss: 0.423606        \n",
      "[115]\ttraining's multi_logloss: 0.371245\tvalid_1's multi_logloss: 0.421111       \n",
      "[116]\ttraining's multi_logloss: 0.36836\tvalid_1's multi_logloss: 0.418696        \n",
      "[117]\ttraining's multi_logloss: 0.365481\tvalid_1's multi_logloss: 0.416357       \n",
      "[118]\ttraining's multi_logloss: 0.362709\tvalid_1's multi_logloss: 0.414054       \n",
      "[119]\ttraining's multi_logloss: 0.359919\tvalid_1's multi_logloss: 0.411723       \n",
      "[120]\ttraining's multi_logloss: 0.357208\tvalid_1's multi_logloss: 0.409454       \n",
      "[121]\ttraining's multi_logloss: 0.354498\tvalid_1's multi_logloss: 0.407239       \n",
      "[122]\ttraining's multi_logloss: 0.351806\tvalid_1's multi_logloss: 0.405045       \n",
      "[123]\ttraining's multi_logloss: 0.349222\tvalid_1's multi_logloss: 0.402947       \n",
      "[124]\ttraining's multi_logloss: 0.346652\tvalid_1's multi_logloss: 0.400888       \n",
      "[125]\ttraining's multi_logloss: 0.344117\tvalid_1's multi_logloss: 0.398848       \n",
      "[126]\ttraining's multi_logloss: 0.341621\tvalid_1's multi_logloss: 0.396854       \n",
      "[127]\ttraining's multi_logloss: 0.339192\tvalid_1's multi_logloss: 0.394903       \n",
      "[128]\ttraining's multi_logloss: 0.336775\tvalid_1's multi_logloss: 0.392949       \n",
      "[129]\ttraining's multi_logloss: 0.334408\tvalid_1's multi_logloss: 0.391039       \n",
      "[130]\ttraining's multi_logloss: 0.331981\tvalid_1's multi_logloss: 0.389079       \n",
      "[131]\ttraining's multi_logloss: 0.329643\tvalid_1's multi_logloss: 0.387204       \n",
      "[132]\ttraining's multi_logloss: 0.32734\tvalid_1's multi_logloss: 0.385356        \n",
      "[133]\ttraining's multi_logloss: 0.325057\tvalid_1's multi_logloss: 0.383503       \n",
      "[134]\ttraining's multi_logloss: 0.322781\tvalid_1's multi_logloss: 0.381657       \n",
      "[135]\ttraining's multi_logloss: 0.320587\tvalid_1's multi_logloss: 0.379863       \n",
      "[136]\ttraining's multi_logloss: 0.318412\tvalid_1's multi_logloss: 0.378091       \n",
      "[137]\ttraining's multi_logloss: 0.316294\tvalid_1's multi_logloss: 0.37638        \n",
      "[138]\ttraining's multi_logloss: 0.314188\tvalid_1's multi_logloss: 0.374678       \n",
      "[139]\ttraining's multi_logloss: 0.312149\tvalid_1's multi_logloss: 0.373118       \n",
      "[140]\ttraining's multi_logloss: 0.310111\tvalid_1's multi_logloss: 0.371518       \n",
      "[141]\ttraining's multi_logloss: 0.308149\tvalid_1's multi_logloss: 0.369949       \n",
      "[142]\ttraining's multi_logloss: 0.306201\tvalid_1's multi_logloss: 0.368451       \n",
      "[143]\ttraining's multi_logloss: 0.304269\tvalid_1's multi_logloss: 0.366948       \n",
      "[144]\ttraining's multi_logloss: 0.30235\tvalid_1's multi_logloss: 0.365482        \n",
      "[145]\ttraining's multi_logloss: 0.300489\tvalid_1's multi_logloss: 0.36408        \n",
      "[146]\ttraining's multi_logloss: 0.29859\tvalid_1's multi_logloss: 0.362644        \n",
      "[147]\ttraining's multi_logloss: 0.296772\tvalid_1's multi_logloss: 0.361258       \n",
      "[148]\ttraining's multi_logloss: 0.294987\tvalid_1's multi_logloss: 0.359938       \n",
      "[149]\ttraining's multi_logloss: 0.293129\tvalid_1's multi_logloss: 0.358527       \n",
      "[150]\ttraining's multi_logloss: 0.29132\tvalid_1's multi_logloss: 0.357147        \n",
      "[151]\ttraining's multi_logloss: 0.289493\tvalid_1's multi_logloss: 0.355717       \n",
      "[152]\ttraining's multi_logloss: 0.28769\tvalid_1's multi_logloss: 0.35429         \n",
      "[153]\ttraining's multi_logloss: 0.285967\tvalid_1's multi_logloss: 0.352996       \n",
      "[154]\ttraining's multi_logloss: 0.284192\tvalid_1's multi_logloss: 0.351712       \n",
      "[155]\ttraining's multi_logloss: 0.282545\tvalid_1's multi_logloss: 0.350526       \n",
      "[156]\ttraining's multi_logloss: 0.280857\tvalid_1's multi_logloss: 0.34935        \n",
      "[157]\ttraining's multi_logloss: 0.279251\tvalid_1's multi_logloss: 0.348211       \n",
      "[158]\ttraining's multi_logloss: 0.277603\tvalid_1's multi_logloss: 0.347016       \n",
      "[159]\ttraining's multi_logloss: 0.276053\tvalid_1's multi_logloss: 0.345987       \n",
      "[160]\ttraining's multi_logloss: 0.274445\tvalid_1's multi_logloss: 0.344824       \n",
      "[161]\ttraining's multi_logloss: 0.27294\tvalid_1's multi_logloss: 0.343776        \n",
      "[162]\ttraining's multi_logloss: 0.271392\tvalid_1's multi_logloss: 0.342738       \n",
      "[163]\ttraining's multi_logloss: 0.269915\tvalid_1's multi_logloss: 0.341751       \n",
      "[164]\ttraining's multi_logloss: 0.268397\tvalid_1's multi_logloss: 0.34074        \n",
      "[165]\ttraining's multi_logloss: 0.266948\tvalid_1's multi_logloss: 0.339681       \n",
      "[166]\ttraining's multi_logloss: 0.265524\tvalid_1's multi_logloss: 0.338684       \n",
      "[167]\ttraining's multi_logloss: 0.264108\tvalid_1's multi_logloss: 0.337676       \n",
      "[168]\ttraining's multi_logloss: 0.262678\tvalid_1's multi_logloss: 0.336679       \n",
      "[169]\ttraining's multi_logloss: 0.261234\tvalid_1's multi_logloss: 0.335723       \n",
      "[170]\ttraining's multi_logloss: 0.259867\tvalid_1's multi_logloss: 0.334806       \n",
      "[171]\ttraining's multi_logloss: 0.258458\tvalid_1's multi_logloss: 0.333862       \n",
      "[172]\ttraining's multi_logloss: 0.257101\tvalid_1's multi_logloss: 0.332947       \n",
      "[173]\ttraining's multi_logloss: 0.255708\tvalid_1's multi_logloss: 0.332067       \n",
      "[174]\ttraining's multi_logloss: 0.254381\tvalid_1's multi_logloss: 0.331158       \n",
      "[175]\ttraining's multi_logloss: 0.253087\tvalid_1's multi_logloss: 0.33034        \n",
      "[176]\ttraining's multi_logloss: 0.251796\tvalid_1's multi_logloss: 0.329526       \n",
      "[177]\ttraining's multi_logloss: 0.250481\tvalid_1's multi_logloss: 0.328666       \n",
      "[178]\ttraining's multi_logloss: 0.249175\tvalid_1's multi_logloss: 0.32785        \n",
      "[179]\ttraining's multi_logloss: 0.247934\tvalid_1's multi_logloss: 0.327052       \n",
      "[180]\ttraining's multi_logloss: 0.246722\tvalid_1's multi_logloss: 0.326233       \n",
      "[181]\ttraining's multi_logloss: 0.245468\tvalid_1's multi_logloss: 0.325464       \n",
      "[182]\ttraining's multi_logloss: 0.244241\tvalid_1's multi_logloss: 0.324719       \n",
      "[183]\ttraining's multi_logloss: 0.243053\tvalid_1's multi_logloss: 0.324001       \n",
      "[184]\ttraining's multi_logloss: 0.241842\tvalid_1's multi_logloss: 0.323264       \n",
      "[185]\ttraining's multi_logloss: 0.240674\tvalid_1's multi_logloss: 0.322528       \n",
      "[186]\ttraining's multi_logloss: 0.239479\tvalid_1's multi_logloss: 0.321852       \n",
      "[187]\ttraining's multi_logloss: 0.238287\tvalid_1's multi_logloss: 0.321167       \n",
      "[188]\ttraining's multi_logloss: 0.23712\tvalid_1's multi_logloss: 0.320519        \n",
      "[189]\ttraining's multi_logloss: 0.235977\tvalid_1's multi_logloss: 0.319883       \n",
      "[190]\ttraining's multi_logloss: 0.234878\tvalid_1's multi_logloss: 0.319317       \n",
      "[191]\ttraining's multi_logloss: 0.233779\tvalid_1's multi_logloss: 0.318728       \n",
      "[192]\ttraining's multi_logloss: 0.232653\tvalid_1's multi_logloss: 0.318058       \n",
      "[193]\ttraining's multi_logloss: 0.231538\tvalid_1's multi_logloss: 0.317539       \n",
      "[194]\ttraining's multi_logloss: 0.230483\tvalid_1's multi_logloss: 0.316969       \n",
      "[195]\ttraining's multi_logloss: 0.22941\tvalid_1's multi_logloss: 0.316424        \n",
      "[196]\ttraining's multi_logloss: 0.228385\tvalid_1's multi_logloss: 0.315918       \n",
      "[197]\ttraining's multi_logloss: 0.227331\tvalid_1's multi_logloss: 0.315353       \n",
      "[198]\ttraining's multi_logloss: 0.226311\tvalid_1's multi_logloss: 0.314863       \n",
      "[199]\ttraining's multi_logloss: 0.225254\tvalid_1's multi_logloss: 0.314337       \n",
      "[200]\ttraining's multi_logloss: 0.224245\tvalid_1's multi_logloss: 0.313795       \n",
      "[201]\ttraining's multi_logloss: 0.223199\tvalid_1's multi_logloss: 0.313255       \n",
      "[202]\ttraining's multi_logloss: 0.222189\tvalid_1's multi_logloss: 0.312676       \n",
      "[203]\ttraining's multi_logloss: 0.221149\tvalid_1's multi_logloss: 0.312134       \n",
      "[204]\ttraining's multi_logloss: 0.220156\tvalid_1's multi_logloss: 0.311631       \n",
      "[205]\ttraining's multi_logloss: 0.219154\tvalid_1's multi_logloss: 0.311107       \n",
      "[206]\ttraining's multi_logloss: 0.218178\tvalid_1's multi_logloss: 0.310646       \n",
      "[207]\ttraining's multi_logloss: 0.217196\tvalid_1's multi_logloss: 0.310183       \n",
      "[208]\ttraining's multi_logloss: 0.216233\tvalid_1's multi_logloss: 0.309739       \n",
      "[209]\ttraining's multi_logloss: 0.215232\tvalid_1's multi_logloss: 0.309248       \n",
      "[210]\ttraining's multi_logloss: 0.214305\tvalid_1's multi_logloss: 0.308801       \n",
      "[211]\ttraining's multi_logloss: 0.213338\tvalid_1's multi_logloss: 0.308326       \n",
      "[212]\ttraining's multi_logloss: 0.212388\tvalid_1's multi_logloss: 0.307907       \n",
      "[213]\ttraining's multi_logloss: 0.211451\tvalid_1's multi_logloss: 0.307431       \n",
      "[214]\ttraining's multi_logloss: 0.210526\tvalid_1's multi_logloss: 0.306992       \n",
      "[215]\ttraining's multi_logloss: 0.209611\tvalid_1's multi_logloss: 0.306541       \n",
      "[216]\ttraining's multi_logloss: 0.208734\tvalid_1's multi_logloss: 0.306131       \n",
      "[217]\ttraining's multi_logloss: 0.207847\tvalid_1's multi_logloss: 0.305716       \n",
      "[218]\ttraining's multi_logloss: 0.206964\tvalid_1's multi_logloss: 0.305348       \n",
      "[219]\ttraining's multi_logloss: 0.206067\tvalid_1's multi_logloss: 0.304974       \n",
      "[220]\ttraining's multi_logloss: 0.205165\tvalid_1's multi_logloss: 0.304609       \n",
      "[221]\ttraining's multi_logloss: 0.204275\tvalid_1's multi_logloss: 0.304235       \n",
      "[222]\ttraining's multi_logloss: 0.203415\tvalid_1's multi_logloss: 0.303903       \n",
      "[223]\ttraining's multi_logloss: 0.202537\tvalid_1's multi_logloss: 0.303502       \n",
      "[224]\ttraining's multi_logloss: 0.201695\tvalid_1's multi_logloss: 0.303171       \n",
      "[225]\ttraining's multi_logloss: 0.20086\tvalid_1's multi_logloss: 0.302865        \n",
      "[226]\ttraining's multi_logloss: 0.200034\tvalid_1's multi_logloss: 0.302544       \n",
      "[227]\ttraining's multi_logloss: 0.199205\tvalid_1's multi_logloss: 0.302131       \n",
      "[228]\ttraining's multi_logloss: 0.198427\tvalid_1's multi_logloss: 0.301867       \n",
      "[229]\ttraining's multi_logloss: 0.19764\tvalid_1's multi_logloss: 0.301585        \n",
      "[230]\ttraining's multi_logloss: 0.19681\tvalid_1's multi_logloss: 0.301217        \n",
      "[231]\ttraining's multi_logloss: 0.196069\tvalid_1's multi_logloss: 0.300913       \n",
      "[232]\ttraining's multi_logloss: 0.195263\tvalid_1's multi_logloss: 0.300602       \n",
      "[233]\ttraining's multi_logloss: 0.194513\tvalid_1's multi_logloss: 0.30032        \n",
      "[234]\ttraining's multi_logloss: 0.193708\tvalid_1's multi_logloss: 0.299939       \n",
      "[235]\ttraining's multi_logloss: 0.192963\tvalid_1's multi_logloss: 0.299631       \n",
      "[236]\ttraining's multi_logloss: 0.192214\tvalid_1's multi_logloss: 0.299338       \n",
      "[237]\ttraining's multi_logloss: 0.191464\tvalid_1's multi_logloss: 0.299041       \n",
      "[238]\ttraining's multi_logloss: 0.190716\tvalid_1's multi_logloss: 0.298761       \n",
      "[239]\ttraining's multi_logloss: 0.189972\tvalid_1's multi_logloss: 0.298503       \n",
      "[240]\ttraining's multi_logloss: 0.189233\tvalid_1's multi_logloss: 0.298167       \n",
      "[241]\ttraining's multi_logloss: 0.188483\tvalid_1's multi_logloss: 0.297925       \n",
      "[242]\ttraining's multi_logloss: 0.187739\tvalid_1's multi_logloss: 0.297679       \n",
      "[243]\ttraining's multi_logloss: 0.187023\tvalid_1's multi_logloss: 0.29744        \n",
      "[244]\ttraining's multi_logloss: 0.186293\tvalid_1's multi_logloss: 0.297207       \n",
      "[245]\ttraining's multi_logloss: 0.185601\tvalid_1's multi_logloss: 0.296951       \n",
      "[246]\ttraining's multi_logloss: 0.184896\tvalid_1's multi_logloss: 0.296742       \n",
      "[247]\ttraining's multi_logloss: 0.184188\tvalid_1's multi_logloss: 0.296497       \n",
      "[248]\ttraining's multi_logloss: 0.183505\tvalid_1's multi_logloss: 0.296246       \n",
      "[249]\ttraining's multi_logloss: 0.182819\tvalid_1's multi_logloss: 0.296018       \n",
      "[250]\ttraining's multi_logloss: 0.18213\tvalid_1's multi_logloss: 0.295811        \n",
      "[251]\ttraining's multi_logloss: 0.181418\tvalid_1's multi_logloss: 0.295565       \n",
      "[252]\ttraining's multi_logloss: 0.180736\tvalid_1's multi_logloss: 0.295404       \n",
      "[253]\ttraining's multi_logloss: 0.180059\tvalid_1's multi_logloss: 0.295205       \n",
      "[254]\ttraining's multi_logloss: 0.179359\tvalid_1's multi_logloss: 0.295006       \n",
      "[255]\ttraining's multi_logloss: 0.178709\tvalid_1's multi_logloss: 0.294852       \n",
      "[256]\ttraining's multi_logloss: 0.178022\tvalid_1's multi_logloss: 0.29462        \n",
      "[257]\ttraining's multi_logloss: 0.177362\tvalid_1's multi_logloss: 0.294414       \n",
      "[258]\ttraining's multi_logloss: 0.176695\tvalid_1's multi_logloss: 0.294174       \n",
      "[259]\ttraining's multi_logloss: 0.176033\tvalid_1's multi_logloss: 0.294034       \n",
      "[260]\ttraining's multi_logloss: 0.175409\tvalid_1's multi_logloss: 0.293876       \n",
      "[261]\ttraining's multi_logloss: 0.174756\tvalid_1's multi_logloss: 0.293705       \n",
      "[262]\ttraining's multi_logloss: 0.174119\tvalid_1's multi_logloss: 0.293528       \n",
      "[263]\ttraining's multi_logloss: 0.173467\tvalid_1's multi_logloss: 0.293364       \n",
      "[264]\ttraining's multi_logloss: 0.172856\tvalid_1's multi_logloss: 0.293223       \n",
      "[265]\ttraining's multi_logloss: 0.172217\tvalid_1's multi_logloss: 0.293068       \n",
      "[266]\ttraining's multi_logloss: 0.171588\tvalid_1's multi_logloss: 0.292977       \n",
      "[267]\ttraining's multi_logloss: 0.170944\tvalid_1's multi_logloss: 0.292744       \n",
      "[268]\ttraining's multi_logloss: 0.17033\tvalid_1's multi_logloss: 0.292605        \n",
      "[269]\ttraining's multi_logloss: 0.169693\tvalid_1's multi_logloss: 0.292509       \n",
      "[270]\ttraining's multi_logloss: 0.16904\tvalid_1's multi_logloss: 0.292367        \n",
      "[271]\ttraining's multi_logloss: 0.16841\tvalid_1's multi_logloss: 0.292233        \n",
      "[272]\ttraining's multi_logloss: 0.167775\tvalid_1's multi_logloss: 0.292029       \n",
      "[273]\ttraining's multi_logloss: 0.167152\tvalid_1's multi_logloss: 0.291856       \n",
      "[274]\ttraining's multi_logloss: 0.166493\tvalid_1's multi_logloss: 0.291694       \n",
      "[275]\ttraining's multi_logloss: 0.165879\tvalid_1's multi_logloss: 0.291575       \n",
      "[276]\ttraining's multi_logloss: 0.165292\tvalid_1's multi_logloss: 0.291432       \n",
      "[277]\ttraining's multi_logloss: 0.16469\tvalid_1's multi_logloss: 0.29128         \n",
      "[278]\ttraining's multi_logloss: 0.164123\tvalid_1's multi_logloss: 0.291148       \n",
      "[279]\ttraining's multi_logloss: 0.16352\tvalid_1's multi_logloss: 0.291024        \n",
      "[280]\ttraining's multi_logloss: 0.162936\tvalid_1's multi_logloss: 0.290961       \n",
      "[281]\ttraining's multi_logloss: 0.162331\tvalid_1's multi_logloss: 0.290778       \n",
      "[282]\ttraining's multi_logloss: 0.161741\tvalid_1's multi_logloss: 0.290682       \n",
      "[283]\ttraining's multi_logloss: 0.161149\tvalid_1's multi_logloss: 0.290572       \n",
      "[284]\ttraining's multi_logloss: 0.160554\tvalid_1's multi_logloss: 0.290404       \n",
      "[285]\ttraining's multi_logloss: 0.159969\tvalid_1's multi_logloss: 0.290211       \n",
      "[286]\ttraining's multi_logloss: 0.159386\tvalid_1's multi_logloss: 0.290068       \n",
      "[287]\ttraining's multi_logloss: 0.158821\tvalid_1's multi_logloss: 0.289913       \n",
      "[288]\ttraining's multi_logloss: 0.158233\tvalid_1's multi_logloss: 0.289747       \n",
      "[289]\ttraining's multi_logloss: 0.157639\tvalid_1's multi_logloss: 0.28955        \n",
      "[290]\ttraining's multi_logloss: 0.15709\tvalid_1's multi_logloss: 0.289427        \n",
      "[291]\ttraining's multi_logloss: 0.15648\tvalid_1's multi_logloss: 0.289298        \n",
      "[292]\ttraining's multi_logloss: 0.155938\tvalid_1's multi_logloss: 0.28917        \n",
      "[293]\ttraining's multi_logloss: 0.155379\tvalid_1's multi_logloss: 0.28905        \n",
      "[294]\ttraining's multi_logloss: 0.15481\tvalid_1's multi_logloss: 0.288953        \n",
      "[295]\ttraining's multi_logloss: 0.154231\tvalid_1's multi_logloss: 0.288894       \n",
      "[296]\ttraining's multi_logloss: 0.153654\tvalid_1's multi_logloss: 0.28882        \n",
      "[297]\ttraining's multi_logloss: 0.153067\tvalid_1's multi_logloss: 0.288699       \n",
      "[298]\ttraining's multi_logloss: 0.152503\tvalid_1's multi_logloss: 0.288609       \n",
      "[299]\ttraining's multi_logloss: 0.151982\tvalid_1's multi_logloss: 0.288559       \n",
      "[300]\ttraining's multi_logloss: 0.151427\tvalid_1's multi_logloss: 0.288443       \n",
      "[301]\ttraining's multi_logloss: 0.150873\tvalid_1's multi_logloss: 0.288325       \n",
      "[302]\ttraining's multi_logloss: 0.150352\tvalid_1's multi_logloss: 0.288256       \n",
      "[303]\ttraining's multi_logloss: 0.149823\tvalid_1's multi_logloss: 0.288158       \n",
      "[304]\ttraining's multi_logloss: 0.1493\tvalid_1's multi_logloss: 0.288041         \n",
      "[305]\ttraining's multi_logloss: 0.148766\tvalid_1's multi_logloss: 0.288          \n",
      "[306]\ttraining's multi_logloss: 0.148279\tvalid_1's multi_logloss: 0.287955       \n",
      "[307]\ttraining's multi_logloss: 0.147742\tvalid_1's multi_logloss: 0.287843       \n",
      "[308]\ttraining's multi_logloss: 0.147218\tvalid_1's multi_logloss: 0.287783       \n",
      "[309]\ttraining's multi_logloss: 0.146692\tvalid_1's multi_logloss: 0.287703       \n",
      "[310]\ttraining's multi_logloss: 0.146183\tvalid_1's multi_logloss: 0.287631       \n",
      "[311]\ttraining's multi_logloss: 0.145685\tvalid_1's multi_logloss: 0.287543       \n",
      "[312]\ttraining's multi_logloss: 0.145154\tvalid_1's multi_logloss: 0.287456       \n",
      "[313]\ttraining's multi_logloss: 0.14466\tvalid_1's multi_logloss: 0.287365        \n",
      "[314]\ttraining's multi_logloss: 0.144154\tvalid_1's multi_logloss: 0.287308       \n",
      "[315]\ttraining's multi_logloss: 0.143655\tvalid_1's multi_logloss: 0.287168       \n",
      "[316]\ttraining's multi_logloss: 0.143158\tvalid_1's multi_logloss: 0.287061       \n",
      "[317]\ttraining's multi_logloss: 0.142692\tvalid_1's multi_logloss: 0.287008       \n",
      "[318]\ttraining's multi_logloss: 0.142188\tvalid_1's multi_logloss: 0.286832       \n",
      "[319]\ttraining's multi_logloss: 0.141724\tvalid_1's multi_logloss: 0.286746       \n",
      "[320]\ttraining's multi_logloss: 0.141232\tvalid_1's multi_logloss: 0.286697       \n",
      "[321]\ttraining's multi_logloss: 0.140762\tvalid_1's multi_logloss: 0.286605       \n",
      "[322]\ttraining's multi_logloss: 0.140289\tvalid_1's multi_logloss: 0.286528       \n",
      "[323]\ttraining's multi_logloss: 0.139816\tvalid_1's multi_logloss: 0.286491       \n",
      "[324]\ttraining's multi_logloss: 0.139362\tvalid_1's multi_logloss: 0.286456       \n",
      "[325]\ttraining's multi_logloss: 0.138902\tvalid_1's multi_logloss: 0.286366       \n",
      "[326]\ttraining's multi_logloss: 0.138446\tvalid_1's multi_logloss: 0.286296       \n",
      "[327]\ttraining's multi_logloss: 0.137998\tvalid_1's multi_logloss: 0.286262       \n",
      "[328]\ttraining's multi_logloss: 0.137516\tvalid_1's multi_logloss: 0.286188       \n",
      "[329]\ttraining's multi_logloss: 0.13706\tvalid_1's multi_logloss: 0.286126        \n",
      "[330]\ttraining's multi_logloss: 0.13658\tvalid_1's multi_logloss: 0.286139        \n",
      "[331]\ttraining's multi_logloss: 0.136135\tvalid_1's multi_logloss: 0.286107       \n",
      "[332]\ttraining's multi_logloss: 0.135672\tvalid_1's multi_logloss: 0.28602        \n",
      "[333]\ttraining's multi_logloss: 0.135221\tvalid_1's multi_logloss: 0.285903       \n",
      "[334]\ttraining's multi_logloss: 0.134764\tvalid_1's multi_logloss: 0.285797       \n",
      "[335]\ttraining's multi_logloss: 0.134308\tvalid_1's multi_logloss: 0.285693       \n",
      "[336]\ttraining's multi_logloss: 0.133832\tvalid_1's multi_logloss: 0.285598       \n",
      "[337]\ttraining's multi_logloss: 0.133371\tvalid_1's multi_logloss: 0.285577       \n",
      "[338]\ttraining's multi_logloss: 0.132934\tvalid_1's multi_logloss: 0.285501       \n",
      "[339]\ttraining's multi_logloss: 0.132493\tvalid_1's multi_logloss: 0.285481       \n",
      "[340]\ttraining's multi_logloss: 0.132054\tvalid_1's multi_logloss: 0.285359       \n",
      "[341]\ttraining's multi_logloss: 0.131625\tvalid_1's multi_logloss: 0.285298       \n",
      "[342]\ttraining's multi_logloss: 0.131206\tvalid_1's multi_logloss: 0.285235       \n",
      "[343]\ttraining's multi_logloss: 0.130778\tvalid_1's multi_logloss: 0.285118       \n",
      "[344]\ttraining's multi_logloss: 0.130327\tvalid_1's multi_logloss: 0.285033       \n",
      "[345]\ttraining's multi_logloss: 0.129905\tvalid_1's multi_logloss: 0.284964       \n",
      "[346]\ttraining's multi_logloss: 0.129451\tvalid_1's multi_logloss: 0.284939       \n",
      "[347]\ttraining's multi_logloss: 0.129034\tvalid_1's multi_logloss: 0.284874       \n",
      "[348]\ttraining's multi_logloss: 0.128603\tvalid_1's multi_logloss: 0.284822       \n",
      "[349]\ttraining's multi_logloss: 0.128174\tvalid_1's multi_logloss: 0.284763       \n",
      "[350]\ttraining's multi_logloss: 0.127756\tvalid_1's multi_logloss: 0.28473        \n",
      "[351]\ttraining's multi_logloss: 0.127318\tvalid_1's multi_logloss: 0.284693       \n",
      "[352]\ttraining's multi_logloss: 0.126918\tvalid_1's multi_logloss: 0.284658       \n",
      "[353]\ttraining's multi_logloss: 0.126502\tvalid_1's multi_logloss: 0.284657       \n",
      "[354]\ttraining's multi_logloss: 0.126091\tvalid_1's multi_logloss: 0.284667       \n",
      "[355]\ttraining's multi_logloss: 0.125695\tvalid_1's multi_logloss: 0.284666       \n",
      "[356]\ttraining's multi_logloss: 0.125293\tvalid_1's multi_logloss: 0.284623       \n",
      "[357]\ttraining's multi_logloss: 0.124882\tvalid_1's multi_logloss: 0.284626       \n",
      "[358]\ttraining's multi_logloss: 0.124476\tvalid_1's multi_logloss: 0.284597       \n",
      "[359]\ttraining's multi_logloss: 0.124072\tvalid_1's multi_logloss: 0.284525       \n",
      "[360]\ttraining's multi_logloss: 0.123671\tvalid_1's multi_logloss: 0.284505       \n",
      "[361]\ttraining's multi_logloss: 0.123259\tvalid_1's multi_logloss: 0.284468       \n",
      "[362]\ttraining's multi_logloss: 0.122858\tvalid_1's multi_logloss: 0.284441       \n",
      "[363]\ttraining's multi_logloss: 0.122437\tvalid_1's multi_logloss: 0.284371       \n",
      "[364]\ttraining's multi_logloss: 0.122015\tvalid_1's multi_logloss: 0.284309       \n",
      "[365]\ttraining's multi_logloss: 0.121617\tvalid_1's multi_logloss: 0.284287       \n",
      "[366]\ttraining's multi_logloss: 0.121224\tvalid_1's multi_logloss: 0.284307       \n",
      "[367]\ttraining's multi_logloss: 0.12083\tvalid_1's multi_logloss: 0.284276        \n",
      "[368]\ttraining's multi_logloss: 0.120441\tvalid_1's multi_logloss: 0.284318       \n",
      "[369]\ttraining's multi_logloss: 0.120047\tvalid_1's multi_logloss: 0.284335       \n",
      "[370]\ttraining's multi_logloss: 0.119649\tvalid_1's multi_logloss: 0.284385       \n",
      "[371]\ttraining's multi_logloss: 0.119255\tvalid_1's multi_logloss: 0.284417       \n",
      "[372]\ttraining's multi_logloss: 0.118879\tvalid_1's multi_logloss: 0.284405       \n",
      "[373]\ttraining's multi_logloss: 0.118469\tvalid_1's multi_logloss: 0.284392       \n",
      "[374]\ttraining's multi_logloss: 0.118094\tvalid_1's multi_logloss: 0.284421       \n",
      "[375]\ttraining's multi_logloss: 0.117678\tvalid_1's multi_logloss: 0.284444       \n",
      "[376]\ttraining's multi_logloss: 0.117289\tvalid_1's multi_logloss: 0.284439       \n",
      "[377]\ttraining's multi_logloss: 0.116912\tvalid_1's multi_logloss: 0.28445        \n",
      "[378]\ttraining's multi_logloss: 0.116526\tvalid_1's multi_logloss: 0.284458       \n",
      "[379]\ttraining's multi_logloss: 0.116157\tvalid_1's multi_logloss: 0.284481       \n",
      "[380]\ttraining's multi_logloss: 0.115776\tvalid_1's multi_logloss: 0.2845         \n",
      "[381]\ttraining's multi_logloss: 0.115408\tvalid_1's multi_logloss: 0.284513       \n",
      "[382]\ttraining's multi_logloss: 0.115047\tvalid_1's multi_logloss: 0.284496       \n",
      "[383]\ttraining's multi_logloss: 0.114674\tvalid_1's multi_logloss: 0.284502       \n",
      "[384]\ttraining's multi_logloss: 0.11431\tvalid_1's multi_logloss: 0.284555        \n",
      "[385]\ttraining's multi_logloss: 0.113959\tvalid_1's multi_logloss: 0.284505       \n",
      "[386]\ttraining's multi_logloss: 0.113588\tvalid_1's multi_logloss: 0.284502       \n",
      "[387]\ttraining's multi_logloss: 0.113229\tvalid_1's multi_logloss: 0.284521       \n",
      "[388]\ttraining's multi_logloss: 0.112863\tvalid_1's multi_logloss: 0.284552       \n",
      "[389]\ttraining's multi_logloss: 0.112507\tvalid_1's multi_logloss: 0.28457        \n",
      "[390]\ttraining's multi_logloss: 0.112149\tvalid_1's multi_logloss: 0.284554       \n",
      "[391]\ttraining's multi_logloss: 0.111807\tvalid_1's multi_logloss: 0.284525       \n",
      "[392]\ttraining's multi_logloss: 0.111465\tvalid_1's multi_logloss: 0.284538       \n",
      "[393]\ttraining's multi_logloss: 0.111101\tvalid_1's multi_logloss: 0.284565       \n",
      "[394]\ttraining's multi_logloss: 0.110733\tvalid_1's multi_logloss: 0.284544       \n",
      "[395]\ttraining's multi_logloss: 0.110396\tvalid_1's multi_logloss: 0.284565       \n",
      "[396]\ttraining's multi_logloss: 0.110055\tvalid_1's multi_logloss: 0.284574       \n",
      "[397]\ttraining's multi_logloss: 0.109714\tvalid_1's multi_logloss: 0.284585       \n",
      "Early stopping, best iteration is:                                               \n",
      "[367]\ttraining's multi_logloss: 0.12083\tvalid_1's multi_logloss: 0.284276\n",
      "[1]\ttraining's multi_logloss: 1.87214\tvalid_1's multi_logloss: 1.8745            \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.81825\tvalid_1's multi_logloss: 1.82109           \n",
      "[3]\ttraining's multi_logloss: 1.76775\tvalid_1's multi_logloss: 1.77109           \n",
      "[4]\ttraining's multi_logloss: 1.72032\tvalid_1's multi_logloss: 1.72415           \n",
      "[5]\ttraining's multi_logloss: 1.67558\tvalid_1's multi_logloss: 1.67995           \n",
      "[6]\ttraining's multi_logloss: 1.63334\tvalid_1's multi_logloss: 1.63825           \n",
      "[7]\ttraining's multi_logloss: 1.59306\tvalid_1's multi_logloss: 1.59843           \n",
      "[8]\ttraining's multi_logloss: 1.55493\tvalid_1's multi_logloss: 1.56073           \n",
      "[9]\ttraining's multi_logloss: 1.51838\tvalid_1's multi_logloss: 1.52457           \n",
      "[10]\ttraining's multi_logloss: 1.48338\tvalid_1's multi_logloss: 1.4899           \n",
      "[11]\ttraining's multi_logloss: 1.44995\tvalid_1's multi_logloss: 1.45679          \n",
      "[12]\ttraining's multi_logloss: 1.41795\tvalid_1's multi_logloss: 1.42505          \n",
      "[13]\ttraining's multi_logloss: 1.38724\tvalid_1's multi_logloss: 1.39472          \n",
      "[14]\ttraining's multi_logloss: 1.35784\tvalid_1's multi_logloss: 1.36558          \n",
      "[15]\ttraining's multi_logloss: 1.32948\tvalid_1's multi_logloss: 1.33748          \n",
      "[16]\ttraining's multi_logloss: 1.30216\tvalid_1's multi_logloss: 1.31039          \n",
      "[17]\ttraining's multi_logloss: 1.27583\tvalid_1's multi_logloss: 1.2843           \n",
      "[18]\ttraining's multi_logloss: 1.25048\tvalid_1's multi_logloss: 1.2592           \n",
      "[19]\ttraining's multi_logloss: 1.22605\tvalid_1's multi_logloss: 1.23498          \n",
      "[20]\ttraining's multi_logloss: 1.20246\tvalid_1's multi_logloss: 1.21171          \n",
      "[21]\ttraining's multi_logloss: 1.17964\tvalid_1's multi_logloss: 1.18914          \n",
      "[22]\ttraining's multi_logloss: 1.15758\tvalid_1's multi_logloss: 1.16734          \n",
      "[23]\ttraining's multi_logloss: 1.13632\tvalid_1's multi_logloss: 1.14636          \n",
      "[24]\ttraining's multi_logloss: 1.11566\tvalid_1's multi_logloss: 1.12592          \n",
      "[25]\ttraining's multi_logloss: 1.09553\tvalid_1's multi_logloss: 1.10611          \n",
      "[26]\ttraining's multi_logloss: 1.0761\tvalid_1's multi_logloss: 1.08686           \n",
      "[27]\ttraining's multi_logloss: 1.05717\tvalid_1's multi_logloss: 1.06822          \n",
      "[28]\ttraining's multi_logloss: 1.03885\tvalid_1's multi_logloss: 1.05019          \n",
      "[29]\ttraining's multi_logloss: 1.02107\tvalid_1's multi_logloss: 1.03267          \n",
      "[30]\ttraining's multi_logloss: 1.0038\tvalid_1's multi_logloss: 1.01565           \n",
      "[31]\ttraining's multi_logloss: 0.987053\tvalid_1's multi_logloss: 0.999086        \n",
      "[32]\ttraining's multi_logloss: 0.970701\tvalid_1's multi_logloss: 0.982974        \n",
      "[33]\ttraining's multi_logloss: 0.954751\tvalid_1's multi_logloss: 0.967211        \n",
      "[34]\ttraining's multi_logloss: 0.939291\tvalid_1's multi_logloss: 0.95194         \n",
      "[35]\ttraining's multi_logloss: 0.924287\tvalid_1's multi_logloss: 0.937183        \n",
      "[36]\ttraining's multi_logloss: 0.909654\tvalid_1's multi_logloss: 0.922735        \n",
      "[37]\ttraining's multi_logloss: 0.895412\tvalid_1's multi_logloss: 0.908807        \n",
      "[38]\ttraining's multi_logloss: 0.881479\tvalid_1's multi_logloss: 0.895216        \n",
      "[39]\ttraining's multi_logloss: 0.867985\tvalid_1's multi_logloss: 0.881927        \n",
      "[40]\ttraining's multi_logloss: 0.854656\tvalid_1's multi_logloss: 0.868888        \n",
      "[41]\ttraining's multi_logloss: 0.84183\tvalid_1's multi_logloss: 0.856334         \n",
      "[42]\ttraining's multi_logloss: 0.829305\tvalid_1's multi_logloss: 0.844178        \n",
      "[43]\ttraining's multi_logloss: 0.816959\tvalid_1's multi_logloss: 0.832132        \n",
      "[44]\ttraining's multi_logloss: 0.804937\tvalid_1's multi_logloss: 0.820379        \n",
      "[45]\ttraining's multi_logloss: 0.793268\tvalid_1's multi_logloss: 0.809032        \n",
      "[46]\ttraining's multi_logloss: 0.781839\tvalid_1's multi_logloss: 0.79791         \n",
      "[47]\ttraining's multi_logloss: 0.770707\tvalid_1's multi_logloss: 0.787102        \n",
      "[48]\ttraining's multi_logloss: 0.759813\tvalid_1's multi_logloss: 0.776528        \n",
      "[49]\ttraining's multi_logloss: 0.749199\tvalid_1's multi_logloss: 0.766172        \n",
      "[50]\ttraining's multi_logloss: 0.738897\tvalid_1's multi_logloss: 0.75619         \n",
      "[51]\ttraining's multi_logloss: 0.728736\tvalid_1's multi_logloss: 0.746361        \n",
      "[52]\ttraining's multi_logloss: 0.718853\tvalid_1's multi_logloss: 0.736783        \n",
      "[53]\ttraining's multi_logloss: 0.709223\tvalid_1's multi_logloss: 0.727384        \n",
      "[54]\ttraining's multi_logloss: 0.699842\tvalid_1's multi_logloss: 0.718352        \n",
      "[55]\ttraining's multi_logloss: 0.690578\tvalid_1's multi_logloss: 0.709406        \n",
      "[56]\ttraining's multi_logloss: 0.681629\tvalid_1's multi_logloss: 0.700752        \n",
      "[57]\ttraining's multi_logloss: 0.672859\tvalid_1's multi_logloss: 0.692294        \n",
      "[58]\ttraining's multi_logloss: 0.664174\tvalid_1's multi_logloss: 0.683885        \n",
      "[59]\ttraining's multi_logloss: 0.655796\tvalid_1's multi_logloss: 0.675819        \n",
      "[60]\ttraining's multi_logloss: 0.647524\tvalid_1's multi_logloss: 0.667895        \n",
      "[61]\ttraining's multi_logloss: 0.639449\tvalid_1's multi_logloss: 0.66015         \n",
      "[62]\ttraining's multi_logloss: 0.6315\tvalid_1's multi_logloss: 0.652505          \n",
      "[63]\ttraining's multi_logloss: 0.623772\tvalid_1's multi_logloss: 0.645135        \n",
      "[64]\ttraining's multi_logloss: 0.616163\tvalid_1's multi_logloss: 0.637912        \n",
      "[65]\ttraining's multi_logloss: 0.608703\tvalid_1's multi_logloss: 0.630866        \n",
      "[66]\ttraining's multi_logloss: 0.601528\tvalid_1's multi_logloss: 0.624059        \n",
      "[67]\ttraining's multi_logloss: 0.59443\tvalid_1's multi_logloss: 0.617324         \n",
      "[68]\ttraining's multi_logloss: 0.587534\tvalid_1's multi_logloss: 0.610782        \n",
      "[69]\ttraining's multi_logloss: 0.580839\tvalid_1's multi_logloss: 0.604489        \n",
      "[70]\ttraining's multi_logloss: 0.574108\tvalid_1's multi_logloss: 0.598168        \n",
      "[71]\ttraining's multi_logloss: 0.567686\tvalid_1's multi_logloss: 0.592131        \n",
      "[72]\ttraining's multi_logloss: 0.561324\tvalid_1's multi_logloss: 0.586139        \n",
      "[73]\ttraining's multi_logloss: 0.554987\tvalid_1's multi_logloss: 0.580159        \n",
      "[74]\ttraining's multi_logloss: 0.548888\tvalid_1's multi_logloss: 0.574459        \n",
      "[75]\ttraining's multi_logloss: 0.542928\tvalid_1's multi_logloss: 0.568841        \n",
      "[76]\ttraining's multi_logloss: 0.537116\tvalid_1's multi_logloss: 0.563392        \n",
      "[77]\ttraining's multi_logloss: 0.531419\tvalid_1's multi_logloss: 0.558069        \n",
      "[78]\ttraining's multi_logloss: 0.525815\tvalid_1's multi_logloss: 0.552775        \n",
      "[79]\ttraining's multi_logloss: 0.520253\tvalid_1's multi_logloss: 0.547589        \n",
      "[80]\ttraining's multi_logloss: 0.514783\tvalid_1's multi_logloss: 0.542441        \n",
      "[81]\ttraining's multi_logloss: 0.509553\tvalid_1's multi_logloss: 0.537624        \n",
      "[82]\ttraining's multi_logloss: 0.504362\tvalid_1's multi_logloss: 0.532823        \n",
      "[83]\ttraining's multi_logloss: 0.499244\tvalid_1's multi_logloss: 0.528045        \n",
      "[84]\ttraining's multi_logloss: 0.494202\tvalid_1's multi_logloss: 0.523346        \n",
      "[85]\ttraining's multi_logloss: 0.489334\tvalid_1's multi_logloss: 0.518817        \n",
      "[86]\ttraining's multi_logloss: 0.484451\tvalid_1's multi_logloss: 0.514255        \n",
      "[87]\ttraining's multi_logloss: 0.479697\tvalid_1's multi_logloss: 0.509857        \n",
      "[88]\ttraining's multi_logloss: 0.475067\tvalid_1's multi_logloss: 0.505563        \n",
      "[89]\ttraining's multi_logloss: 0.470496\tvalid_1's multi_logloss: 0.501359        \n",
      "[90]\ttraining's multi_logloss: 0.466034\tvalid_1's multi_logloss: 0.497224        \n",
      "[91]\ttraining's multi_logloss: 0.461561\tvalid_1's multi_logloss: 0.493055        \n",
      "[92]\ttraining's multi_logloss: 0.457185\tvalid_1's multi_logloss: 0.489036        \n",
      "[93]\ttraining's multi_logloss: 0.452949\tvalid_1's multi_logloss: 0.485128        \n",
      "[94]\ttraining's multi_logloss: 0.448722\tvalid_1's multi_logloss: 0.481267        \n",
      "[95]\ttraining's multi_logloss: 0.444602\tvalid_1's multi_logloss: 0.477507        \n",
      "[96]\ttraining's multi_logloss: 0.440538\tvalid_1's multi_logloss: 0.473789        \n",
      "[97]\ttraining's multi_logloss: 0.43657\tvalid_1's multi_logloss: 0.470171         \n",
      "[98]\ttraining's multi_logloss: 0.432689\tvalid_1's multi_logloss: 0.466649        \n",
      "[99]\ttraining's multi_logloss: 0.428872\tvalid_1's multi_logloss: 0.463174        \n",
      "[100]\ttraining's multi_logloss: 0.425166\tvalid_1's multi_logloss: 0.459816       \n",
      "[101]\ttraining's multi_logloss: 0.421486\tvalid_1's multi_logloss: 0.45644        \n",
      "[102]\ttraining's multi_logloss: 0.417881\tvalid_1's multi_logloss: 0.453169       \n",
      "[103]\ttraining's multi_logloss: 0.414322\tvalid_1's multi_logloss: 0.449932       \n",
      "[104]\ttraining's multi_logloss: 0.41081\tvalid_1's multi_logloss: 0.446738        \n",
      "[105]\ttraining's multi_logloss: 0.407313\tvalid_1's multi_logloss: 0.44357        \n",
      "[106]\ttraining's multi_logloss: 0.403848\tvalid_1's multi_logloss: 0.440442       \n",
      "[107]\ttraining's multi_logloss: 0.400483\tvalid_1's multi_logloss: 0.4374         \n",
      "[108]\ttraining's multi_logloss: 0.397188\tvalid_1's multi_logloss: 0.434456       \n",
      "[109]\ttraining's multi_logloss: 0.393925\tvalid_1's multi_logloss: 0.431521       \n",
      "[110]\ttraining's multi_logloss: 0.390779\tvalid_1's multi_logloss: 0.428685       \n",
      "[111]\ttraining's multi_logloss: 0.387671\tvalid_1's multi_logloss: 0.425928       \n",
      "[112]\ttraining's multi_logloss: 0.384628\tvalid_1's multi_logloss: 0.423256       \n",
      "[113]\ttraining's multi_logloss: 0.381556\tvalid_1's multi_logloss: 0.420529       \n",
      "[114]\ttraining's multi_logloss: 0.378639\tvalid_1's multi_logloss: 0.417962       \n",
      "[115]\ttraining's multi_logloss: 0.37576\tvalid_1's multi_logloss: 0.415415        \n",
      "[116]\ttraining's multi_logloss: 0.372857\tvalid_1's multi_logloss: 0.412881       \n",
      "[117]\ttraining's multi_logloss: 0.370081\tvalid_1's multi_logloss: 0.410488       \n",
      "[118]\ttraining's multi_logloss: 0.367318\tvalid_1's multi_logloss: 0.408128       \n",
      "[119]\ttraining's multi_logloss: 0.36454\tvalid_1's multi_logloss: 0.405701        \n",
      "[120]\ttraining's multi_logloss: 0.361812\tvalid_1's multi_logloss: 0.403397       \n",
      "[121]\ttraining's multi_logloss: 0.359131\tvalid_1's multi_logloss: 0.401071       \n",
      "[122]\ttraining's multi_logloss: 0.356518\tvalid_1's multi_logloss: 0.398843       \n",
      "[123]\ttraining's multi_logloss: 0.353954\tvalid_1's multi_logloss: 0.396673       \n",
      "[124]\ttraining's multi_logloss: 0.351358\tvalid_1's multi_logloss: 0.394371       \n",
      "[125]\ttraining's multi_logloss: 0.34883\tvalid_1's multi_logloss: 0.392165        \n",
      "[126]\ttraining's multi_logloss: 0.346375\tvalid_1's multi_logloss: 0.390079       \n",
      "[127]\ttraining's multi_logloss: 0.343891\tvalid_1's multi_logloss: 0.387943       \n",
      "[128]\ttraining's multi_logloss: 0.341495\tvalid_1's multi_logloss: 0.385909       \n",
      "[129]\ttraining's multi_logloss: 0.339122\tvalid_1's multi_logloss: 0.383851       \n",
      "[130]\ttraining's multi_logloss: 0.336754\tvalid_1's multi_logloss: 0.381861       \n",
      "[131]\ttraining's multi_logloss: 0.334545\tvalid_1's multi_logloss: 0.379989       \n",
      "[132]\ttraining's multi_logloss: 0.332191\tvalid_1's multi_logloss: 0.377972       \n",
      "[133]\ttraining's multi_logloss: 0.329998\tvalid_1's multi_logloss: 0.376142       \n",
      "[134]\ttraining's multi_logloss: 0.327779\tvalid_1's multi_logloss: 0.374303       \n",
      "[135]\ttraining's multi_logloss: 0.325598\tvalid_1's multi_logloss: 0.372449       \n",
      "[136]\ttraining's multi_logloss: 0.323452\tvalid_1's multi_logloss: 0.370647       \n",
      "[137]\ttraining's multi_logloss: 0.321338\tvalid_1's multi_logloss: 0.368899       \n",
      "[138]\ttraining's multi_logloss: 0.319251\tvalid_1's multi_logloss: 0.367113       \n",
      "[139]\ttraining's multi_logloss: 0.317227\tvalid_1's multi_logloss: 0.365491       \n",
      "[140]\ttraining's multi_logloss: 0.315221\tvalid_1's multi_logloss: 0.363808       \n",
      "[141]\ttraining's multi_logloss: 0.313225\tvalid_1's multi_logloss: 0.362201       \n",
      "[142]\ttraining's multi_logloss: 0.311263\tvalid_1's multi_logloss: 0.360591       \n",
      "[143]\ttraining's multi_logloss: 0.309338\tvalid_1's multi_logloss: 0.359068       \n",
      "[144]\ttraining's multi_logloss: 0.307409\tvalid_1's multi_logloss: 0.357556       \n",
      "[145]\ttraining's multi_logloss: 0.305527\tvalid_1's multi_logloss: 0.356075       \n",
      "[146]\ttraining's multi_logloss: 0.303642\tvalid_1's multi_logloss: 0.354617       \n",
      "[147]\ttraining's multi_logloss: 0.301782\tvalid_1's multi_logloss: 0.353212       \n",
      "[148]\ttraining's multi_logloss: 0.29998\tvalid_1's multi_logloss: 0.351779        \n",
      "[149]\ttraining's multi_logloss: 0.298187\tvalid_1's multi_logloss: 0.350406       \n",
      "[150]\ttraining's multi_logloss: 0.296388\tvalid_1's multi_logloss: 0.349033       \n",
      "[151]\ttraining's multi_logloss: 0.294612\tvalid_1's multi_logloss: 0.34773        \n",
      "[152]\ttraining's multi_logloss: 0.292867\tvalid_1's multi_logloss: 0.346444       \n",
      "[153]\ttraining's multi_logloss: 0.291146\tvalid_1's multi_logloss: 0.345125       \n",
      "[154]\ttraining's multi_logloss: 0.289483\tvalid_1's multi_logloss: 0.343881       \n",
      "[155]\ttraining's multi_logloss: 0.287812\tvalid_1's multi_logloss: 0.342588       \n",
      "[156]\ttraining's multi_logloss: 0.28615\tvalid_1's multi_logloss: 0.34139         \n",
      "[157]\ttraining's multi_logloss: 0.284454\tvalid_1's multi_logloss: 0.340169       \n",
      "[158]\ttraining's multi_logloss: 0.282872\tvalid_1's multi_logloss: 0.338963       \n",
      "[159]\ttraining's multi_logloss: 0.281265\tvalid_1's multi_logloss: 0.337846       \n",
      "[160]\ttraining's multi_logloss: 0.279706\tvalid_1's multi_logloss: 0.336727       \n",
      "[161]\ttraining's multi_logloss: 0.27817\tvalid_1's multi_logloss: 0.335689        \n",
      "[162]\ttraining's multi_logloss: 0.276672\tvalid_1's multi_logloss: 0.334594       \n",
      "[163]\ttraining's multi_logloss: 0.275195\tvalid_1's multi_logloss: 0.333598       \n",
      "[164]\ttraining's multi_logloss: 0.273678\tvalid_1's multi_logloss: 0.332513       \n",
      "[165]\ttraining's multi_logloss: 0.272261\tvalid_1's multi_logloss: 0.331533       \n",
      "[166]\ttraining's multi_logloss: 0.270811\tvalid_1's multi_logloss: 0.33053        \n",
      "[167]\ttraining's multi_logloss: 0.26938\tvalid_1's multi_logloss: 0.329518        \n",
      "[168]\ttraining's multi_logloss: 0.267914\tvalid_1's multi_logloss: 0.328465       \n",
      "[169]\ttraining's multi_logloss: 0.266511\tvalid_1's multi_logloss: 0.327539       \n",
      "[170]\ttraining's multi_logloss: 0.265131\tvalid_1's multi_logloss: 0.326523       \n",
      "[171]\ttraining's multi_logloss: 0.263784\tvalid_1's multi_logloss: 0.3256         \n",
      "[172]\ttraining's multi_logloss: 0.26245\tvalid_1's multi_logloss: 0.324667        \n",
      "[173]\ttraining's multi_logloss: 0.261109\tvalid_1's multi_logloss: 0.323717       \n",
      "[174]\ttraining's multi_logloss: 0.259806\tvalid_1's multi_logloss: 0.322848       \n",
      "[175]\ttraining's multi_logloss: 0.25853\tvalid_1's multi_logloss: 0.321961        \n",
      "[176]\ttraining's multi_logloss: 0.257257\tvalid_1's multi_logloss: 0.321115       \n",
      "[177]\ttraining's multi_logloss: 0.255984\tvalid_1's multi_logloss: 0.320243       \n",
      "[178]\ttraining's multi_logloss: 0.25475\tvalid_1's multi_logloss: 0.319397        \n",
      "[179]\ttraining's multi_logloss: 0.253509\tvalid_1's multi_logloss: 0.318611       \n",
      "[180]\ttraining's multi_logloss: 0.252303\tvalid_1's multi_logloss: 0.31782        \n",
      "[181]\ttraining's multi_logloss: 0.251112\tvalid_1's multi_logloss: 0.317052       \n",
      "[182]\ttraining's multi_logloss: 0.249948\tvalid_1's multi_logloss: 0.316325       \n",
      "[183]\ttraining's multi_logloss: 0.248771\tvalid_1's multi_logloss: 0.315559       \n",
      "[184]\ttraining's multi_logloss: 0.24759\tvalid_1's multi_logloss: 0.314775        \n",
      "[185]\ttraining's multi_logloss: 0.246465\tvalid_1's multi_logloss: 0.314097       \n",
      "[186]\ttraining's multi_logloss: 0.245281\tvalid_1's multi_logloss: 0.31335        \n",
      "[187]\ttraining's multi_logloss: 0.244183\tvalid_1's multi_logloss: 0.312662       \n",
      "[188]\ttraining's multi_logloss: 0.243064\tvalid_1's multi_logloss: 0.312          \n",
      "[189]\ttraining's multi_logloss: 0.241956\tvalid_1's multi_logloss: 0.311316       \n",
      "[190]\ttraining's multi_logloss: 0.240844\tvalid_1's multi_logloss: 0.31066        \n",
      "[191]\ttraining's multi_logloss: 0.239765\tvalid_1's multi_logloss: 0.310019       \n",
      "[192]\ttraining's multi_logloss: 0.238666\tvalid_1's multi_logloss: 0.30935        \n",
      "[193]\ttraining's multi_logloss: 0.237557\tvalid_1's multi_logloss: 0.308679       \n",
      "[194]\ttraining's multi_logloss: 0.236465\tvalid_1's multi_logloss: 0.308032       \n",
      "[195]\ttraining's multi_logloss: 0.235404\tvalid_1's multi_logloss: 0.307396       \n",
      "[196]\ttraining's multi_logloss: 0.234342\tvalid_1's multi_logloss: 0.306767       \n",
      "[197]\ttraining's multi_logloss: 0.233312\tvalid_1's multi_logloss: 0.306156       \n",
      "[198]\ttraining's multi_logloss: 0.232296\tvalid_1's multi_logloss: 0.305595       \n",
      "[199]\ttraining's multi_logloss: 0.231278\tvalid_1's multi_logloss: 0.304984       \n",
      "[200]\ttraining's multi_logloss: 0.230264\tvalid_1's multi_logloss: 0.304432       \n",
      "[201]\ttraining's multi_logloss: 0.229299\tvalid_1's multi_logloss: 0.303885       \n",
      "[202]\ttraining's multi_logloss: 0.228326\tvalid_1's multi_logloss: 0.303371       \n",
      "[203]\ttraining's multi_logloss: 0.227335\tvalid_1's multi_logloss: 0.302872       \n",
      "[204]\ttraining's multi_logloss: 0.226345\tvalid_1's multi_logloss: 0.302318       \n",
      "[205]\ttraining's multi_logloss: 0.225388\tvalid_1's multi_logloss: 0.301795       \n",
      "[206]\ttraining's multi_logloss: 0.224415\tvalid_1's multi_logloss: 0.301248       \n",
      "[207]\ttraining's multi_logloss: 0.223462\tvalid_1's multi_logloss: 0.300703       \n",
      "[208]\ttraining's multi_logloss: 0.222531\tvalid_1's multi_logloss: 0.300251       \n",
      "[209]\ttraining's multi_logloss: 0.221596\tvalid_1's multi_logloss: 0.299707       \n",
      "[210]\ttraining's multi_logloss: 0.220648\tvalid_1's multi_logloss: 0.2992         \n",
      "[211]\ttraining's multi_logloss: 0.219736\tvalid_1's multi_logloss: 0.298721       \n",
      "[212]\ttraining's multi_logloss: 0.21883\tvalid_1's multi_logloss: 0.298307        \n",
      "[213]\ttraining's multi_logloss: 0.217937\tvalid_1's multi_logloss: 0.297868       \n",
      "[214]\ttraining's multi_logloss: 0.217038\tvalid_1's multi_logloss: 0.297445       \n",
      "[215]\ttraining's multi_logloss: 0.216164\tvalid_1's multi_logloss: 0.296948       \n",
      "[216]\ttraining's multi_logloss: 0.215278\tvalid_1's multi_logloss: 0.296548       \n",
      "[217]\ttraining's multi_logloss: 0.214412\tvalid_1's multi_logloss: 0.29617        \n",
      "[218]\ttraining's multi_logloss: 0.213556\tvalid_1's multi_logloss: 0.295783       \n",
      "[219]\ttraining's multi_logloss: 0.212674\tvalid_1's multi_logloss: 0.295319       \n",
      "[220]\ttraining's multi_logloss: 0.211824\tvalid_1's multi_logloss: 0.294954       \n",
      "[221]\ttraining's multi_logloss: 0.210984\tvalid_1's multi_logloss: 0.294534       \n",
      "[222]\ttraining's multi_logloss: 0.210148\tvalid_1's multi_logloss: 0.294154       \n",
      "[223]\ttraining's multi_logloss: 0.209317\tvalid_1's multi_logloss: 0.293727       \n",
      "[224]\ttraining's multi_logloss: 0.208501\tvalid_1's multi_logloss: 0.293338       \n",
      "[225]\ttraining's multi_logloss: 0.20763\tvalid_1's multi_logloss: 0.292909        \n",
      "[226]\ttraining's multi_logloss: 0.206836\tvalid_1's multi_logloss: 0.292577       \n",
      "[227]\ttraining's multi_logloss: 0.205985\tvalid_1's multi_logloss: 0.292148       \n",
      "[228]\ttraining's multi_logloss: 0.205194\tvalid_1's multi_logloss: 0.291905       \n",
      "[229]\ttraining's multi_logloss: 0.204393\tvalid_1's multi_logloss: 0.29157        \n",
      "[230]\ttraining's multi_logloss: 0.20361\tvalid_1's multi_logloss: 0.291224        \n",
      "[231]\ttraining's multi_logloss: 0.202853\tvalid_1's multi_logloss: 0.290918       \n",
      "[232]\ttraining's multi_logloss: 0.202036\tvalid_1's multi_logloss: 0.290564       \n",
      "[233]\ttraining's multi_logloss: 0.201278\tvalid_1's multi_logloss: 0.290161       \n",
      "[234]\ttraining's multi_logloss: 0.200489\tvalid_1's multi_logloss: 0.289804       \n",
      "[235]\ttraining's multi_logloss: 0.199726\tvalid_1's multi_logloss: 0.289422       \n",
      "[236]\ttraining's multi_logloss: 0.198976\tvalid_1's multi_logloss: 0.289124       \n",
      "[237]\ttraining's multi_logloss: 0.198246\tvalid_1's multi_logloss: 0.288729       \n",
      "[238]\ttraining's multi_logloss: 0.197462\tvalid_1's multi_logloss: 0.288415       \n",
      "[239]\ttraining's multi_logloss: 0.19671\tvalid_1's multi_logloss: 0.288062        \n",
      "[240]\ttraining's multi_logloss: 0.19599\tvalid_1's multi_logloss: 0.28774         \n",
      "[241]\ttraining's multi_logloss: 0.195258\tvalid_1's multi_logloss: 0.287529       \n",
      "[242]\ttraining's multi_logloss: 0.194519\tvalid_1's multi_logloss: 0.287205       \n",
      "[243]\ttraining's multi_logloss: 0.193807\tvalid_1's multi_logloss: 0.286915       \n",
      "[244]\ttraining's multi_logloss: 0.1931\tvalid_1's multi_logloss: 0.286629         \n",
      "[245]\ttraining's multi_logloss: 0.192372\tvalid_1's multi_logloss: 0.286348       \n",
      "[246]\ttraining's multi_logloss: 0.191654\tvalid_1's multi_logloss: 0.286092       \n",
      "[247]\ttraining's multi_logloss: 0.190966\tvalid_1's multi_logloss: 0.285834       \n",
      "[248]\ttraining's multi_logloss: 0.190253\tvalid_1's multi_logloss: 0.285538       \n",
      "[249]\ttraining's multi_logloss: 0.189542\tvalid_1's multi_logloss: 0.285246       \n",
      "[250]\ttraining's multi_logloss: 0.188851\tvalid_1's multi_logloss: 0.284972       \n",
      "[251]\ttraining's multi_logloss: 0.18812\tvalid_1's multi_logloss: 0.284728        \n",
      "[252]\ttraining's multi_logloss: 0.187443\tvalid_1's multi_logloss: 0.28449        \n",
      "[253]\ttraining's multi_logloss: 0.186779\tvalid_1's multi_logloss: 0.284249       \n",
      "[254]\ttraining's multi_logloss: 0.186092\tvalid_1's multi_logloss: 0.283965       \n",
      "[255]\ttraining's multi_logloss: 0.185458\tvalid_1's multi_logloss: 0.283791       \n",
      "[256]\ttraining's multi_logloss: 0.184768\tvalid_1's multi_logloss: 0.283615       \n",
      "[257]\ttraining's multi_logloss: 0.184092\tvalid_1's multi_logloss: 0.283441       \n",
      "[258]\ttraining's multi_logloss: 0.183429\tvalid_1's multi_logloss: 0.283184       \n",
      "[259]\ttraining's multi_logloss: 0.182754\tvalid_1's multi_logloss: 0.282927       \n",
      "[260]\ttraining's multi_logloss: 0.182076\tvalid_1's multi_logloss: 0.282696       \n",
      "[261]\ttraining's multi_logloss: 0.181451\tvalid_1's multi_logloss: 0.282514       \n",
      "[262]\ttraining's multi_logloss: 0.180772\tvalid_1's multi_logloss: 0.28231        \n",
      "[263]\ttraining's multi_logloss: 0.180146\tvalid_1's multi_logloss: 0.28208        \n",
      "[264]\ttraining's multi_logloss: 0.179438\tvalid_1's multi_logloss: 0.281859       \n",
      "[265]\ttraining's multi_logloss: 0.178772\tvalid_1's multi_logloss: 0.281721       \n",
      "[266]\ttraining's multi_logloss: 0.178093\tvalid_1's multi_logloss: 0.281478       \n",
      "[267]\ttraining's multi_logloss: 0.177439\tvalid_1's multi_logloss: 0.281275       \n",
      "[268]\ttraining's multi_logloss: 0.17681\tvalid_1's multi_logloss: 0.281075        \n",
      "[269]\ttraining's multi_logloss: 0.176142\tvalid_1's multi_logloss: 0.280917       \n",
      "[270]\ttraining's multi_logloss: 0.175501\tvalid_1's multi_logloss: 0.280724       \n",
      "[271]\ttraining's multi_logloss: 0.174872\tvalid_1's multi_logloss: 0.280507       \n",
      "[272]\ttraining's multi_logloss: 0.174254\tvalid_1's multi_logloss: 0.280341       \n",
      "[273]\ttraining's multi_logloss: 0.173619\tvalid_1's multi_logloss: 0.280209       \n",
      "[274]\ttraining's multi_logloss: 0.172986\tvalid_1's multi_logloss: 0.280038       \n",
      "[275]\ttraining's multi_logloss: 0.172375\tvalid_1's multi_logloss: 0.279837       \n",
      "[276]\ttraining's multi_logloss: 0.171769\tvalid_1's multi_logloss: 0.279702       \n",
      "[277]\ttraining's multi_logloss: 0.171137\tvalid_1's multi_logloss: 0.279508       \n",
      "[278]\ttraining's multi_logloss: 0.170519\tvalid_1's multi_logloss: 0.279373       \n",
      "[279]\ttraining's multi_logloss: 0.169897\tvalid_1's multi_logloss: 0.279234       \n",
      "[280]\ttraining's multi_logloss: 0.169307\tvalid_1's multi_logloss: 0.279014       \n",
      "[281]\ttraining's multi_logloss: 0.16871\tvalid_1's multi_logloss: 0.278864        \n",
      "[282]\ttraining's multi_logloss: 0.168107\tvalid_1's multi_logloss: 0.278711       \n",
      "[283]\ttraining's multi_logloss: 0.167523\tvalid_1's multi_logloss: 0.278516       \n",
      "[284]\ttraining's multi_logloss: 0.166918\tvalid_1's multi_logloss: 0.278381       \n",
      "[285]\ttraining's multi_logloss: 0.16633\tvalid_1's multi_logloss: 0.278215        \n",
      "[286]\ttraining's multi_logloss: 0.165739\tvalid_1's multi_logloss: 0.278061       \n",
      "[287]\ttraining's multi_logloss: 0.165177\tvalid_1's multi_logloss: 0.277912       \n",
      "[288]\ttraining's multi_logloss: 0.164599\tvalid_1's multi_logloss: 0.277787       \n",
      "[289]\ttraining's multi_logloss: 0.164012\tvalid_1's multi_logloss: 0.277675       \n",
      "[290]\ttraining's multi_logloss: 0.163439\tvalid_1's multi_logloss: 0.27756        \n",
      "[291]\ttraining's multi_logloss: 0.162875\tvalid_1's multi_logloss: 0.277441       \n",
      "[292]\ttraining's multi_logloss: 0.162314\tvalid_1's multi_logloss: 0.277322       \n",
      "[293]\ttraining's multi_logloss: 0.161767\tvalid_1's multi_logloss: 0.277254       \n",
      "[294]\ttraining's multi_logloss: 0.161203\tvalid_1's multi_logloss: 0.277142       \n",
      "[295]\ttraining's multi_logloss: 0.160641\tvalid_1's multi_logloss: 0.277055       \n",
      "[296]\ttraining's multi_logloss: 0.160091\tvalid_1's multi_logloss: 0.276957       \n",
      "[297]\ttraining's multi_logloss: 0.159541\tvalid_1's multi_logloss: 0.276855       \n",
      "[298]\ttraining's multi_logloss: 0.158989\tvalid_1's multi_logloss: 0.276814       \n",
      "[299]\ttraining's multi_logloss: 0.158418\tvalid_1's multi_logloss: 0.276685       \n",
      "[300]\ttraining's multi_logloss: 0.157869\tvalid_1's multi_logloss: 0.276589       \n",
      "[301]\ttraining's multi_logloss: 0.157338\tvalid_1's multi_logloss: 0.276572       \n",
      "[302]\ttraining's multi_logloss: 0.156811\tvalid_1's multi_logloss: 0.276512       \n",
      "[303]\ttraining's multi_logloss: 0.156263\tvalid_1's multi_logloss: 0.276437       \n",
      "[304]\ttraining's multi_logloss: 0.155723\tvalid_1's multi_logloss: 0.276312       \n",
      "[305]\ttraining's multi_logloss: 0.155223\tvalid_1's multi_logloss: 0.276209       \n",
      "[306]\ttraining's multi_logloss: 0.15471\tvalid_1's multi_logloss: 0.276158        \n",
      "[307]\ttraining's multi_logloss: 0.154198\tvalid_1's multi_logloss: 0.276038       \n",
      "[308]\ttraining's multi_logloss: 0.153702\tvalid_1's multi_logloss: 0.275928       \n",
      "[309]\ttraining's multi_logloss: 0.153157\tvalid_1's multi_logloss: 0.275839       \n",
      "[310]\ttraining's multi_logloss: 0.15268\tvalid_1's multi_logloss: 0.275779        \n",
      "[311]\ttraining's multi_logloss: 0.152171\tvalid_1's multi_logloss: 0.2757         \n",
      "[312]\ttraining's multi_logloss: 0.151678\tvalid_1's multi_logloss: 0.275623       \n",
      "[313]\ttraining's multi_logloss: 0.151173\tvalid_1's multi_logloss: 0.275522       \n",
      "[314]\ttraining's multi_logloss: 0.150687\tvalid_1's multi_logloss: 0.275472       \n",
      "[315]\ttraining's multi_logloss: 0.150157\tvalid_1's multi_logloss: 0.275332       \n",
      "[316]\ttraining's multi_logloss: 0.149669\tvalid_1's multi_logloss: 0.275238       \n",
      "[317]\ttraining's multi_logloss: 0.149145\tvalid_1's multi_logloss: 0.275108       \n",
      "[318]\ttraining's multi_logloss: 0.148653\tvalid_1's multi_logloss: 0.275007       \n",
      "[319]\ttraining's multi_logloss: 0.148131\tvalid_1's multi_logloss: 0.274821       \n",
      "[320]\ttraining's multi_logloss: 0.147653\tvalid_1's multi_logloss: 0.27473        \n",
      "[321]\ttraining's multi_logloss: 0.147151\tvalid_1's multi_logloss: 0.274653       \n",
      "[322]\ttraining's multi_logloss: 0.146666\tvalid_1's multi_logloss: 0.27458        \n",
      "[323]\ttraining's multi_logloss: 0.146166\tvalid_1's multi_logloss: 0.274526       \n",
      "[324]\ttraining's multi_logloss: 0.145658\tvalid_1's multi_logloss: 0.27446        \n",
      "[325]\ttraining's multi_logloss: 0.145186\tvalid_1's multi_logloss: 0.274436       \n",
      "[326]\ttraining's multi_logloss: 0.14471\tvalid_1's multi_logloss: 0.274367        \n",
      "[327]\ttraining's multi_logloss: 0.144209\tvalid_1's multi_logloss: 0.274244       \n",
      "[328]\ttraining's multi_logloss: 0.143673\tvalid_1's multi_logloss: 0.274118       \n",
      "[329]\ttraining's multi_logloss: 0.143182\tvalid_1's multi_logloss: 0.274055       \n",
      "[330]\ttraining's multi_logloss: 0.142688\tvalid_1's multi_logloss: 0.273947       \n",
      "[331]\ttraining's multi_logloss: 0.142229\tvalid_1's multi_logloss: 0.273882       \n",
      "[332]\ttraining's multi_logloss: 0.141763\tvalid_1's multi_logloss: 0.273789       \n",
      "[333]\ttraining's multi_logloss: 0.141292\tvalid_1's multi_logloss: 0.273656       \n",
      "[334]\ttraining's multi_logloss: 0.140825\tvalid_1's multi_logloss: 0.273591       \n",
      "[335]\ttraining's multi_logloss: 0.140359\tvalid_1's multi_logloss: 0.273476       \n",
      "[336]\ttraining's multi_logloss: 0.139895\tvalid_1's multi_logloss: 0.273405       \n",
      "[337]\ttraining's multi_logloss: 0.139422\tvalid_1's multi_logloss: 0.273342       \n",
      "[338]\ttraining's multi_logloss: 0.138961\tvalid_1's multi_logloss: 0.273244       \n",
      "[339]\ttraining's multi_logloss: 0.138517\tvalid_1's multi_logloss: 0.273171       \n",
      "[340]\ttraining's multi_logloss: 0.13809\tvalid_1's multi_logloss: 0.27311         \n",
      "[341]\ttraining's multi_logloss: 0.137644\tvalid_1's multi_logloss: 0.273048       \n",
      "[342]\ttraining's multi_logloss: 0.137226\tvalid_1's multi_logloss: 0.272998       \n",
      "[343]\ttraining's multi_logloss: 0.136776\tvalid_1's multi_logloss: 0.272903       \n",
      "[344]\ttraining's multi_logloss: 0.136341\tvalid_1's multi_logloss: 0.2728         \n",
      "[345]\ttraining's multi_logloss: 0.135919\tvalid_1's multi_logloss: 0.272772       \n",
      "[346]\ttraining's multi_logloss: 0.135465\tvalid_1's multi_logloss: 0.272696       \n",
      "[347]\ttraining's multi_logloss: 0.135007\tvalid_1's multi_logloss: 0.272624       \n",
      "[348]\ttraining's multi_logloss: 0.134579\tvalid_1's multi_logloss: 0.272558       \n",
      "[349]\ttraining's multi_logloss: 0.134142\tvalid_1's multi_logloss: 0.272467       \n",
      "[350]\ttraining's multi_logloss: 0.133707\tvalid_1's multi_logloss: 0.272386       \n",
      "[351]\ttraining's multi_logloss: 0.133289\tvalid_1's multi_logloss: 0.27236        \n",
      "[352]\ttraining's multi_logloss: 0.13287\tvalid_1's multi_logloss: 0.272309        \n",
      "[353]\ttraining's multi_logloss: 0.132433\tvalid_1's multi_logloss: 0.272248       \n",
      "[354]\ttraining's multi_logloss: 0.132016\tvalid_1's multi_logloss: 0.272136       \n",
      "[355]\ttraining's multi_logloss: 0.131599\tvalid_1's multi_logloss: 0.272055       \n",
      "[356]\ttraining's multi_logloss: 0.131207\tvalid_1's multi_logloss: 0.271975       \n",
      "[357]\ttraining's multi_logloss: 0.130784\tvalid_1's multi_logloss: 0.271947       \n",
      "[358]\ttraining's multi_logloss: 0.130363\tvalid_1's multi_logloss: 0.2719         \n",
      "[359]\ttraining's multi_logloss: 0.129959\tvalid_1's multi_logloss: 0.271835       \n",
      "[360]\ttraining's multi_logloss: 0.129542\tvalid_1's multi_logloss: 0.271736       \n",
      "[361]\ttraining's multi_logloss: 0.12914\tvalid_1's multi_logloss: 0.271725        \n",
      "[362]\ttraining's multi_logloss: 0.128718\tvalid_1's multi_logloss: 0.271664       \n",
      "[363]\ttraining's multi_logloss: 0.128313\tvalid_1's multi_logloss: 0.271641       \n",
      "[364]\ttraining's multi_logloss: 0.127935\tvalid_1's multi_logloss: 0.271605       \n",
      "[365]\ttraining's multi_logloss: 0.127517\tvalid_1's multi_logloss: 0.27157        \n",
      "[366]\ttraining's multi_logloss: 0.127106\tvalid_1's multi_logloss: 0.271577       \n",
      "[367]\ttraining's multi_logloss: 0.126705\tvalid_1's multi_logloss: 0.271539       \n",
      "[368]\ttraining's multi_logloss: 0.126305\tvalid_1's multi_logloss: 0.271498       \n",
      "[369]\ttraining's multi_logloss: 0.125901\tvalid_1's multi_logloss: 0.27142        \n",
      "[370]\ttraining's multi_logloss: 0.125502\tvalid_1's multi_logloss: 0.27137        \n",
      "[371]\ttraining's multi_logloss: 0.125099\tvalid_1's multi_logloss: 0.271326       \n",
      "[372]\ttraining's multi_logloss: 0.124725\tvalid_1's multi_logloss: 0.271325       \n",
      "[373]\ttraining's multi_logloss: 0.124317\tvalid_1's multi_logloss: 0.271268       \n",
      "[374]\ttraining's multi_logloss: 0.12393\tvalid_1's multi_logloss: 0.271226        \n",
      "[375]\ttraining's multi_logloss: 0.123527\tvalid_1's multi_logloss: 0.271181       \n",
      "[376]\ttraining's multi_logloss: 0.123139\tvalid_1's multi_logloss: 0.271165       \n",
      "[377]\ttraining's multi_logloss: 0.122772\tvalid_1's multi_logloss: 0.271147       \n",
      "[378]\ttraining's multi_logloss: 0.122407\tvalid_1's multi_logloss: 0.27111        \n",
      "[379]\ttraining's multi_logloss: 0.122018\tvalid_1's multi_logloss: 0.271118       \n",
      "[380]\ttraining's multi_logloss: 0.12162\tvalid_1's multi_logloss: 0.271066        \n",
      "[381]\ttraining's multi_logloss: 0.121245\tvalid_1's multi_logloss: 0.271058       \n",
      "[382]\ttraining's multi_logloss: 0.120862\tvalid_1's multi_logloss: 0.270992       \n",
      "[383]\ttraining's multi_logloss: 0.120467\tvalid_1's multi_logloss: 0.270998       \n",
      "[384]\ttraining's multi_logloss: 0.120093\tvalid_1's multi_logloss: 0.270925       \n",
      "[385]\ttraining's multi_logloss: 0.119724\tvalid_1's multi_logloss: 0.270934       \n",
      "[386]\ttraining's multi_logloss: 0.119348\tvalid_1's multi_logloss: 0.270878       \n",
      "[387]\ttraining's multi_logloss: 0.118972\tvalid_1's multi_logloss: 0.270891       \n",
      "[388]\ttraining's multi_logloss: 0.118612\tvalid_1's multi_logloss: 0.270856       \n",
      "[389]\ttraining's multi_logloss: 0.118252\tvalid_1's multi_logloss: 0.270837       \n",
      "[390]\ttraining's multi_logloss: 0.117891\tvalid_1's multi_logloss: 0.270813       \n",
      "[391]\ttraining's multi_logloss: 0.117555\tvalid_1's multi_logloss: 0.270784       \n",
      "[392]\ttraining's multi_logloss: 0.117218\tvalid_1's multi_logloss: 0.27074        \n",
      "[393]\ttraining's multi_logloss: 0.116843\tvalid_1's multi_logloss: 0.270692       \n",
      "[394]\ttraining's multi_logloss: 0.116517\tvalid_1's multi_logloss: 0.270671       \n",
      "[395]\ttraining's multi_logloss: 0.116159\tvalid_1's multi_logloss: 0.270627       \n",
      "[396]\ttraining's multi_logloss: 0.11582\tvalid_1's multi_logloss: 0.270581        \n",
      "[397]\ttraining's multi_logloss: 0.115491\tvalid_1's multi_logloss: 0.270542       \n",
      "[398]\ttraining's multi_logloss: 0.115171\tvalid_1's multi_logloss: 0.270567       \n",
      "[399]\ttraining's multi_logloss: 0.114839\tvalid_1's multi_logloss: 0.270526       \n",
      "[400]\ttraining's multi_logloss: 0.114485\tvalid_1's multi_logloss: 0.270432       \n",
      "Did not meet early stopping. Best iteration is:                                  \n",
      "[400]\ttraining's multi_logloss: 0.114485\tvalid_1's multi_logloss: 0.270432\n",
      "[1]\ttraining's multi_logloss: 1.6579\tvalid_1's multi_logloss: 1.6617             \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.45981\tvalid_1's multi_logloss: 1.46761           \n",
      "[3]\ttraining's multi_logloss: 1.3066\tvalid_1's multi_logloss: 1.31976            \n",
      "[4]\ttraining's multi_logloss: 1.18146\tvalid_1's multi_logloss: 1.19825           \n",
      "[5]\ttraining's multi_logloss: 1.07739\tvalid_1's multi_logloss: 1.09734           \n",
      "[6]\ttraining's multi_logloss: 0.988957\tvalid_1's multi_logloss: 1.01111          \n",
      "[7]\ttraining's multi_logloss: 0.91116\tvalid_1's multi_logloss: 0.935759          \n",
      "[8]\ttraining's multi_logloss: 0.84451\tvalid_1's multi_logloss: 0.871345          \n",
      "[9]\ttraining's multi_logloss: 0.78581\tvalid_1's multi_logloss: 0.814836          \n",
      "[10]\ttraining's multi_logloss: 0.733882\tvalid_1's multi_logloss: 0.764728        \n",
      "[11]\ttraining's multi_logloss: 0.688047\tvalid_1's multi_logloss: 0.720673        \n",
      "[12]\ttraining's multi_logloss: 0.645946\tvalid_1's multi_logloss: 0.680737        \n",
      "[13]\ttraining's multi_logloss: 0.608381\tvalid_1's multi_logloss: 0.644857        \n",
      "[14]\ttraining's multi_logloss: 0.574798\tvalid_1's multi_logloss: 0.612648        \n",
      "[15]\ttraining's multi_logloss: 0.544418\tvalid_1's multi_logloss: 0.583957        \n",
      "[16]\ttraining's multi_logloss: 0.51689\tvalid_1's multi_logloss: 0.557915         \n",
      "[17]\ttraining's multi_logloss: 0.492212\tvalid_1's multi_logloss: 0.534791        \n",
      "[18]\ttraining's multi_logloss: 0.469465\tvalid_1's multi_logloss: 0.513811        \n",
      "[19]\ttraining's multi_logloss: 0.448855\tvalid_1's multi_logloss: 0.494981        \n",
      "[20]\ttraining's multi_logloss: 0.430124\tvalid_1's multi_logloss: 0.477902        \n",
      "[21]\ttraining's multi_logloss: 0.4127\tvalid_1's multi_logloss: 0.46198           \n",
      "[22]\ttraining's multi_logloss: 0.396707\tvalid_1's multi_logloss: 0.448059        \n",
      "[23]\ttraining's multi_logloss: 0.381739\tvalid_1's multi_logloss: 0.434812        \n",
      "[24]\ttraining's multi_logloss: 0.368454\tvalid_1's multi_logloss: 0.422976        \n",
      "[25]\ttraining's multi_logloss: 0.356165\tvalid_1's multi_logloss: 0.412498        \n",
      "[26]\ttraining's multi_logloss: 0.344635\tvalid_1's multi_logloss: 0.402611        \n",
      "[27]\ttraining's multi_logloss: 0.334314\tvalid_1's multi_logloss: 0.393953        \n",
      "[28]\ttraining's multi_logloss: 0.324502\tvalid_1's multi_logloss: 0.385859        \n",
      "[29]\ttraining's multi_logloss: 0.315351\tvalid_1's multi_logloss: 0.378309        \n",
      "[30]\ttraining's multi_logloss: 0.306565\tvalid_1's multi_logloss: 0.371197        \n",
      "[31]\ttraining's multi_logloss: 0.298313\tvalid_1's multi_logloss: 0.364837        \n",
      "[32]\ttraining's multi_logloss: 0.290726\tvalid_1's multi_logloss: 0.359287        \n",
      "[33]\ttraining's multi_logloss: 0.283399\tvalid_1's multi_logloss: 0.353677        \n",
      "[34]\ttraining's multi_logloss: 0.27664\tvalid_1's multi_logloss: 0.348976         \n",
      "[35]\ttraining's multi_logloss: 0.270174\tvalid_1's multi_logloss: 0.34466         \n",
      "[36]\ttraining's multi_logloss: 0.264211\tvalid_1's multi_logloss: 0.340539        \n",
      "[37]\ttraining's multi_logloss: 0.258534\tvalid_1's multi_logloss: 0.336611        \n",
      "[38]\ttraining's multi_logloss: 0.253002\tvalid_1's multi_logloss: 0.333104        \n",
      "[39]\ttraining's multi_logloss: 0.247675\tvalid_1's multi_logloss: 0.329725        \n",
      "[40]\ttraining's multi_logloss: 0.242476\tvalid_1's multi_logloss: 0.326475        \n",
      "[41]\ttraining's multi_logloss: 0.237559\tvalid_1's multi_logloss: 0.323326        \n",
      "[42]\ttraining's multi_logloss: 0.233029\tvalid_1's multi_logloss: 0.320884        \n",
      "[43]\ttraining's multi_logloss: 0.228684\tvalid_1's multi_logloss: 0.318264        \n",
      "[44]\ttraining's multi_logloss: 0.22431\tvalid_1's multi_logloss: 0.315869         \n",
      "[45]\ttraining's multi_logloss: 0.220225\tvalid_1's multi_logloss: 0.313871        \n",
      "[46]\ttraining's multi_logloss: 0.21644\tvalid_1's multi_logloss: 0.312144         \n",
      "[47]\ttraining's multi_logloss: 0.212805\tvalid_1's multi_logloss: 0.310308        \n",
      "[48]\ttraining's multi_logloss: 0.209112\tvalid_1's multi_logloss: 0.308712        \n",
      "[49]\ttraining's multi_logloss: 0.205517\tvalid_1's multi_logloss: 0.306977        \n",
      "[50]\ttraining's multi_logloss: 0.202212\tvalid_1's multi_logloss: 0.305744        \n",
      "[51]\ttraining's multi_logloss: 0.198794\tvalid_1's multi_logloss: 0.304198        \n",
      "[52]\ttraining's multi_logloss: 0.195601\tvalid_1's multi_logloss: 0.303           \n",
      "[53]\ttraining's multi_logloss: 0.192322\tvalid_1's multi_logloss: 0.301975        \n",
      "[54]\ttraining's multi_logloss: 0.189283\tvalid_1's multi_logloss: 0.300846        \n",
      "[55]\ttraining's multi_logloss: 0.18627\tvalid_1's multi_logloss: 0.29993          \n",
      "[56]\ttraining's multi_logloss: 0.183382\tvalid_1's multi_logloss: 0.299137        \n",
      "[57]\ttraining's multi_logloss: 0.180307\tvalid_1's multi_logloss: 0.297936        \n",
      "[58]\ttraining's multi_logloss: 0.177486\tvalid_1's multi_logloss: 0.297558        \n",
      "[59]\ttraining's multi_logloss: 0.174707\tvalid_1's multi_logloss: 0.29675         \n",
      "[60]\ttraining's multi_logloss: 0.171628\tvalid_1's multi_logloss: 0.29627         \n",
      "[61]\ttraining's multi_logloss: 0.168934\tvalid_1's multi_logloss: 0.295519        \n",
      "[62]\ttraining's multi_logloss: 0.166221\tvalid_1's multi_logloss: 0.294932        \n",
      "[63]\ttraining's multi_logloss: 0.163723\tvalid_1's multi_logloss: 0.2946          \n",
      "[64]\ttraining's multi_logloss: 0.161104\tvalid_1's multi_logloss: 0.294331        \n",
      "[65]\ttraining's multi_logloss: 0.158586\tvalid_1's multi_logloss: 0.293689        \n",
      "[66]\ttraining's multi_logloss: 0.156213\tvalid_1's multi_logloss: 0.293381        \n",
      "[67]\ttraining's multi_logloss: 0.153861\tvalid_1's multi_logloss: 0.293263        \n",
      "[68]\ttraining's multi_logloss: 0.151434\tvalid_1's multi_logloss: 0.293039        \n",
      "[69]\ttraining's multi_logloss: 0.149058\tvalid_1's multi_logloss: 0.292829        \n",
      "[70]\ttraining's multi_logloss: 0.146773\tvalid_1's multi_logloss: 0.292591        \n",
      "[71]\ttraining's multi_logloss: 0.144544\tvalid_1's multi_logloss: 0.292224        \n",
      "[72]\ttraining's multi_logloss: 0.142466\tvalid_1's multi_logloss: 0.292034        \n",
      "[73]\ttraining's multi_logloss: 0.140301\tvalid_1's multi_logloss: 0.291688        \n",
      "[74]\ttraining's multi_logloss: 0.138292\tvalid_1's multi_logloss: 0.291554        \n",
      "[75]\ttraining's multi_logloss: 0.136292\tvalid_1's multi_logloss: 0.291407        \n",
      "[76]\ttraining's multi_logloss: 0.134122\tvalid_1's multi_logloss: 0.291077        \n",
      "[77]\ttraining's multi_logloss: 0.132223\tvalid_1's multi_logloss: 0.290876        \n",
      "[78]\ttraining's multi_logloss: 0.130267\tvalid_1's multi_logloss: 0.290489        \n",
      "[79]\ttraining's multi_logloss: 0.128252\tvalid_1's multi_logloss: 0.29036         \n",
      "[80]\ttraining's multi_logloss: 0.126421\tvalid_1's multi_logloss: 0.29021         \n",
      "[81]\ttraining's multi_logloss: 0.124592\tvalid_1's multi_logloss: 0.290131        \n",
      "[82]\ttraining's multi_logloss: 0.122796\tvalid_1's multi_logloss: 0.290159        \n",
      "[83]\ttraining's multi_logloss: 0.1209\tvalid_1's multi_logloss: 0.290221          \n",
      "[84]\ttraining's multi_logloss: 0.119065\tvalid_1's multi_logloss: 0.29022         \n",
      "[85]\ttraining's multi_logloss: 0.117244\tvalid_1's multi_logloss: 0.290259        \n",
      "[86]\ttraining's multi_logloss: 0.115663\tvalid_1's multi_logloss: 0.29051         \n",
      "[87]\ttraining's multi_logloss: 0.113986\tvalid_1's multi_logloss: 0.29068         \n",
      "[88]\ttraining's multi_logloss: 0.112317\tvalid_1's multi_logloss: 0.290786        \n",
      "[89]\ttraining's multi_logloss: 0.110729\tvalid_1's multi_logloss: 0.291048        \n",
      "[90]\ttraining's multi_logloss: 0.109158\tvalid_1's multi_logloss: 0.291174        \n",
      "[91]\ttraining's multi_logloss: 0.107643\tvalid_1's multi_logloss: 0.291188        \n",
      "[92]\ttraining's multi_logloss: 0.106114\tvalid_1's multi_logloss: 0.291179        \n",
      "[93]\ttraining's multi_logloss: 0.10468\tvalid_1's multi_logloss: 0.291262         \n",
      "[94]\ttraining's multi_logloss: 0.103215\tvalid_1's multi_logloss: 0.291282        \n",
      "[95]\ttraining's multi_logloss: 0.101888\tvalid_1's multi_logloss: 0.291325        \n",
      "[96]\ttraining's multi_logloss: 0.100473\tvalid_1's multi_logloss: 0.291576        \n",
      "[97]\ttraining's multi_logloss: 0.0988716\tvalid_1's multi_logloss: 0.291676       \n",
      "[98]\ttraining's multi_logloss: 0.0976946\tvalid_1's multi_logloss: 0.291783       \n",
      "[99]\ttraining's multi_logloss: 0.0962918\tvalid_1's multi_logloss: 0.29177        \n",
      "[100]\ttraining's multi_logloss: 0.0948342\tvalid_1's multi_logloss: 0.291927      \n",
      "[101]\ttraining's multi_logloss: 0.0936136\tvalid_1's multi_logloss: 0.292166      \n",
      "[102]\ttraining's multi_logloss: 0.092284\tvalid_1's multi_logloss: 0.292278       \n",
      "[103]\ttraining's multi_logloss: 0.0910602\tvalid_1's multi_logloss: 0.292753      \n",
      "[104]\ttraining's multi_logloss: 0.0898715\tvalid_1's multi_logloss: 0.292713      \n",
      "[105]\ttraining's multi_logloss: 0.0888772\tvalid_1's multi_logloss: 0.293075      \n",
      "[106]\ttraining's multi_logloss: 0.0877531\tvalid_1's multi_logloss: 0.293461      \n",
      "[107]\ttraining's multi_logloss: 0.0864372\tvalid_1's multi_logloss: 0.293371      \n",
      "[108]\ttraining's multi_logloss: 0.0854336\tvalid_1's multi_logloss: 0.293759      \n",
      "[109]\ttraining's multi_logloss: 0.0843671\tvalid_1's multi_logloss: 0.294084      \n",
      "[110]\ttraining's multi_logloss: 0.0834332\tvalid_1's multi_logloss: 0.294524      \n",
      "[111]\ttraining's multi_logloss: 0.0823013\tvalid_1's multi_logloss: 0.29474       \n",
      "Early stopping, best iteration is:                                               \n",
      "[81]\ttraining's multi_logloss: 0.124592\tvalid_1's multi_logloss: 0.290131\n",
      "[1]\ttraining's multi_logloss: 1.65624\tvalid_1's multi_logloss: 1.6597            \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.46088\tvalid_1's multi_logloss: 1.46481           \n",
      "[3]\ttraining's multi_logloss: 1.30944\tvalid_1's multi_logloss: 1.31548           \n",
      "[4]\ttraining's multi_logloss: 1.18564\tvalid_1's multi_logloss: 1.19405           \n",
      "[5]\ttraining's multi_logloss: 1.08203\tvalid_1's multi_logloss: 1.09152           \n",
      "[6]\ttraining's multi_logloss: 0.993694\tvalid_1's multi_logloss: 1.00453          \n",
      "[7]\ttraining's multi_logloss: 0.917236\tvalid_1's multi_logloss: 0.929619         \n",
      "[8]\ttraining's multi_logloss: 0.850698\tvalid_1's multi_logloss: 0.864579         \n",
      "[9]\ttraining's multi_logloss: 0.792237\tvalid_1's multi_logloss: 0.808016         \n",
      "[10]\ttraining's multi_logloss: 0.739634\tvalid_1's multi_logloss: 0.757146        \n",
      "[11]\ttraining's multi_logloss: 0.693514\tvalid_1's multi_logloss: 0.712876        \n",
      "[12]\ttraining's multi_logloss: 0.651719\tvalid_1's multi_logloss: 0.67276         \n",
      "[13]\ttraining's multi_logloss: 0.614398\tvalid_1's multi_logloss: 0.636958        \n",
      "[14]\ttraining's multi_logloss: 0.580776\tvalid_1's multi_logloss: 0.604664        \n",
      "[15]\ttraining's multi_logloss: 0.550763\tvalid_1's multi_logloss: 0.576593        \n",
      "[16]\ttraining's multi_logloss: 0.523462\tvalid_1's multi_logloss: 0.551035        \n",
      "[17]\ttraining's multi_logloss: 0.498856\tvalid_1's multi_logloss: 0.52836         \n",
      "[18]\ttraining's multi_logloss: 0.476038\tvalid_1's multi_logloss: 0.507001        \n",
      "[19]\ttraining's multi_logloss: 0.454441\tvalid_1's multi_logloss: 0.487088        \n",
      "[20]\ttraining's multi_logloss: 0.435368\tvalid_1's multi_logloss: 0.469814        \n",
      "[21]\ttraining's multi_logloss: 0.417879\tvalid_1's multi_logloss: 0.453787        \n",
      "[22]\ttraining's multi_logloss: 0.402302\tvalid_1's multi_logloss: 0.440111        \n",
      "[23]\ttraining's multi_logloss: 0.387597\tvalid_1's multi_logloss: 0.427318        \n",
      "[24]\ttraining's multi_logloss: 0.373936\tvalid_1's multi_logloss: 0.415139        \n",
      "[25]\ttraining's multi_logloss: 0.361639\tvalid_1's multi_logloss: 0.404569        \n",
      "[26]\ttraining's multi_logloss: 0.350056\tvalid_1's multi_logloss: 0.394606        \n",
      "[27]\ttraining's multi_logloss: 0.339237\tvalid_1's multi_logloss: 0.385581        \n",
      "[28]\ttraining's multi_logloss: 0.329115\tvalid_1's multi_logloss: 0.37736         \n",
      "[29]\ttraining's multi_logloss: 0.319524\tvalid_1's multi_logloss: 0.369814        \n",
      "[30]\ttraining's multi_logloss: 0.310407\tvalid_1's multi_logloss: 0.36287         \n",
      "[31]\ttraining's multi_logloss: 0.301869\tvalid_1's multi_logloss: 0.355936        \n",
      "[32]\ttraining's multi_logloss: 0.294047\tvalid_1's multi_logloss: 0.349681        \n",
      "[33]\ttraining's multi_logloss: 0.286656\tvalid_1's multi_logloss: 0.344428        \n",
      "[34]\ttraining's multi_logloss: 0.279782\tvalid_1's multi_logloss: 0.339383        \n",
      "[35]\ttraining's multi_logloss: 0.273118\tvalid_1's multi_logloss: 0.334894        \n",
      "[36]\ttraining's multi_logloss: 0.266992\tvalid_1's multi_logloss: 0.330572        \n",
      "[37]\ttraining's multi_logloss: 0.261055\tvalid_1's multi_logloss: 0.326477        \n",
      "[38]\ttraining's multi_logloss: 0.255542\tvalid_1's multi_logloss: 0.323131        \n",
      "[39]\ttraining's multi_logloss: 0.250384\tvalid_1's multi_logloss: 0.320142        \n",
      "[40]\ttraining's multi_logloss: 0.245133\tvalid_1's multi_logloss: 0.316907        \n",
      "[41]\ttraining's multi_logloss: 0.240224\tvalid_1's multi_logloss: 0.314302        \n",
      "[42]\ttraining's multi_logloss: 0.235301\tvalid_1's multi_logloss: 0.311516        \n",
      "[43]\ttraining's multi_logloss: 0.230853\tvalid_1's multi_logloss: 0.309346        \n",
      "[44]\ttraining's multi_logloss: 0.226407\tvalid_1's multi_logloss: 0.307299        \n",
      "[45]\ttraining's multi_logloss: 0.222182\tvalid_1's multi_logloss: 0.305342        \n",
      "[46]\ttraining's multi_logloss: 0.218085\tvalid_1's multi_logloss: 0.303533        \n",
      "[47]\ttraining's multi_logloss: 0.214213\tvalid_1's multi_logloss: 0.302258        \n",
      "[48]\ttraining's multi_logloss: 0.210391\tvalid_1's multi_logloss: 0.30074         \n",
      "[49]\ttraining's multi_logloss: 0.206627\tvalid_1's multi_logloss: 0.299174        \n",
      "[50]\ttraining's multi_logloss: 0.202893\tvalid_1's multi_logloss: 0.297721        \n",
      "[51]\ttraining's multi_logloss: 0.199396\tvalid_1's multi_logloss: 0.296595        \n",
      "[52]\ttraining's multi_logloss: 0.19579\tvalid_1's multi_logloss: 0.295395         \n",
      "[53]\ttraining's multi_logloss: 0.192447\tvalid_1's multi_logloss: 0.294291        \n",
      "[54]\ttraining's multi_logloss: 0.189069\tvalid_1's multi_logloss: 0.293143        \n",
      "[55]\ttraining's multi_logloss: 0.185942\tvalid_1's multi_logloss: 0.292046        \n",
      "[56]\ttraining's multi_logloss: 0.18287\tvalid_1's multi_logloss: 0.290974         \n",
      "[57]\ttraining's multi_logloss: 0.179971\tvalid_1's multi_logloss: 0.290188        \n",
      "[58]\ttraining's multi_logloss: 0.177042\tvalid_1's multi_logloss: 0.289466        \n",
      "[59]\ttraining's multi_logloss: 0.174135\tvalid_1's multi_logloss: 0.288593        \n",
      "[60]\ttraining's multi_logloss: 0.171382\tvalid_1's multi_logloss: 0.287921        \n",
      "[61]\ttraining's multi_logloss: 0.168686\tvalid_1's multi_logloss: 0.287158        \n",
      "[62]\ttraining's multi_logloss: 0.165918\tvalid_1's multi_logloss: 0.286352        \n",
      "[63]\ttraining's multi_logloss: 0.163273\tvalid_1's multi_logloss: 0.28578         \n",
      "[64]\ttraining's multi_logloss: 0.160717\tvalid_1's multi_logloss: 0.285544        \n",
      "[65]\ttraining's multi_logloss: 0.158155\tvalid_1's multi_logloss: 0.285119        \n",
      "[66]\ttraining's multi_logloss: 0.155649\tvalid_1's multi_logloss: 0.284861        \n",
      "[67]\ttraining's multi_logloss: 0.153414\tvalid_1's multi_logloss: 0.28458         \n",
      "[68]\ttraining's multi_logloss: 0.151218\tvalid_1's multi_logloss: 0.28423         \n",
      "[69]\ttraining's multi_logloss: 0.148931\tvalid_1's multi_logloss: 0.283722        \n",
      "[70]\ttraining's multi_logloss: 0.146513\tvalid_1's multi_logloss: 0.283154        \n",
      "[71]\ttraining's multi_logloss: 0.144312\tvalid_1's multi_logloss: 0.283022        \n",
      "[72]\ttraining's multi_logloss: 0.142161\tvalid_1's multi_logloss: 0.282954        \n",
      "[73]\ttraining's multi_logloss: 0.13999\tvalid_1's multi_logloss: 0.282936         \n",
      "[74]\ttraining's multi_logloss: 0.137848\tvalid_1's multi_logloss: 0.282734        \n",
      "[75]\ttraining's multi_logloss: 0.135818\tvalid_1's multi_logloss: 0.282727        \n",
      "[76]\ttraining's multi_logloss: 0.133714\tvalid_1's multi_logloss: 0.282874        \n",
      "[77]\ttraining's multi_logloss: 0.131678\tvalid_1's multi_logloss: 0.282901        \n",
      "[78]\ttraining's multi_logloss: 0.129715\tvalid_1's multi_logloss: 0.28283         \n",
      "[79]\ttraining's multi_logloss: 0.127764\tvalid_1's multi_logloss: 0.282888        \n",
      "[80]\ttraining's multi_logloss: 0.125977\tvalid_1's multi_logloss: 0.282857        \n",
      "[81]\ttraining's multi_logloss: 0.123959\tvalid_1's multi_logloss: 0.282872        \n",
      "[82]\ttraining's multi_logloss: 0.122094\tvalid_1's multi_logloss: 0.283004        \n",
      "[83]\ttraining's multi_logloss: 0.120166\tvalid_1's multi_logloss: 0.28281         \n",
      "[84]\ttraining's multi_logloss: 0.118363\tvalid_1's multi_logloss: 0.282757        \n",
      "[85]\ttraining's multi_logloss: 0.116573\tvalid_1's multi_logloss: 0.282727        \n",
      "[86]\ttraining's multi_logloss: 0.114775\tvalid_1's multi_logloss: 0.282991        \n",
      "[87]\ttraining's multi_logloss: 0.113051\tvalid_1's multi_logloss: 0.282983        \n",
      "[88]\ttraining's multi_logloss: 0.111326\tvalid_1's multi_logloss: 0.28308         \n",
      "[89]\ttraining's multi_logloss: 0.109784\tvalid_1's multi_logloss: 0.283224        \n",
      "[90]\ttraining's multi_logloss: 0.108205\tvalid_1's multi_logloss: 0.283112        \n",
      "[91]\ttraining's multi_logloss: 0.106618\tvalid_1's multi_logloss: 0.283127        \n",
      "[92]\ttraining's multi_logloss: 0.105032\tvalid_1's multi_logloss: 0.283453        \n",
      "[93]\ttraining's multi_logloss: 0.103481\tvalid_1's multi_logloss: 0.283456        \n",
      "[94]\ttraining's multi_logloss: 0.101949\tvalid_1's multi_logloss: 0.283482        \n",
      "[95]\ttraining's multi_logloss: 0.100531\tvalid_1's multi_logloss: 0.283743        \n",
      "[96]\ttraining's multi_logloss: 0.0991546\tvalid_1's multi_logloss: 0.283809       \n",
      "[97]\ttraining's multi_logloss: 0.0977866\tvalid_1's multi_logloss: 0.284352       \n",
      "[98]\ttraining's multi_logloss: 0.0965162\tvalid_1's multi_logloss: 0.284368       \n",
      "[99]\ttraining's multi_logloss: 0.095262\tvalid_1's multi_logloss: 0.284336        \n",
      "[100]\ttraining's multi_logloss: 0.0940556\tvalid_1's multi_logloss: 0.284758      \n",
      "[101]\ttraining's multi_logloss: 0.0927967\tvalid_1's multi_logloss: 0.28507       \n",
      "[102]\ttraining's multi_logloss: 0.0916014\tvalid_1's multi_logloss: 0.285375      \n",
      "[103]\ttraining's multi_logloss: 0.0903348\tvalid_1's multi_logloss: 0.285418      \n",
      "[104]\ttraining's multi_logloss: 0.0891633\tvalid_1's multi_logloss: 0.285854      \n",
      "[105]\ttraining's multi_logloss: 0.0878554\tvalid_1's multi_logloss: 0.285857      \n",
      "[106]\ttraining's multi_logloss: 0.0866978\tvalid_1's multi_logloss: 0.28616       \n",
      "[107]\ttraining's multi_logloss: 0.0854119\tvalid_1's multi_logloss: 0.286399      \n",
      "[108]\ttraining's multi_logloss: 0.0842563\tvalid_1's multi_logloss: 0.286886      \n",
      "[109]\ttraining's multi_logloss: 0.0832019\tvalid_1's multi_logloss: 0.287274      \n",
      "[110]\ttraining's multi_logloss: 0.0820997\tvalid_1's multi_logloss: 0.287372      \n",
      "[111]\ttraining's multi_logloss: 0.0809678\tvalid_1's multi_logloss: 0.287716      \n",
      "[112]\ttraining's multi_logloss: 0.0798316\tvalid_1's multi_logloss: 0.287994      \n",
      "[113]\ttraining's multi_logloss: 0.0786829\tvalid_1's multi_logloss: 0.288291      \n",
      "[114]\ttraining's multi_logloss: 0.0776063\tvalid_1's multi_logloss: 0.288812      \n",
      "[115]\ttraining's multi_logloss: 0.076505\tvalid_1's multi_logloss: 0.289037       \n",
      "Early stopping, best iteration is:                                               \n",
      "[85]\ttraining's multi_logloss: 0.116573\tvalid_1's multi_logloss: 0.282727\n",
      "[1]\ttraining's multi_logloss: 1.65776\tvalid_1's multi_logloss: 1.66108           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.46332\tvalid_1's multi_logloss: 1.46827           \n",
      "[3]\ttraining's multi_logloss: 1.31158\tvalid_1's multi_logloss: 1.31777           \n",
      "[4]\ttraining's multi_logloss: 1.18733\tvalid_1's multi_logloss: 1.1944            \n",
      "[5]\ttraining's multi_logloss: 1.08399\tvalid_1's multi_logloss: 1.09204           \n",
      "[6]\ttraining's multi_logloss: 0.996088\tvalid_1's multi_logloss: 1.00512          \n",
      "[7]\ttraining's multi_logloss: 0.919153\tvalid_1's multi_logloss: 0.929092         \n",
      "[8]\ttraining's multi_logloss: 0.85187\tvalid_1's multi_logloss: 0.862943          \n",
      "[9]\ttraining's multi_logloss: 0.793133\tvalid_1's multi_logloss: 0.805374         \n",
      "[10]\ttraining's multi_logloss: 0.741619\tvalid_1's multi_logloss: 0.755004        \n",
      "[11]\ttraining's multi_logloss: 0.694668\tvalid_1's multi_logloss: 0.709082        \n",
      "[12]\ttraining's multi_logloss: 0.6531\tvalid_1's multi_logloss: 0.668776          \n",
      "[13]\ttraining's multi_logloss: 0.616102\tvalid_1's multi_logloss: 0.633324        \n",
      "[14]\ttraining's multi_logloss: 0.582905\tvalid_1's multi_logloss: 0.601533        \n",
      "[15]\ttraining's multi_logloss: 0.552707\tvalid_1's multi_logloss: 0.572711        \n",
      "[16]\ttraining's multi_logloss: 0.525382\tvalid_1's multi_logloss: 0.54643         \n",
      "[17]\ttraining's multi_logloss: 0.50087\tvalid_1's multi_logloss: 0.523273         \n",
      "[18]\ttraining's multi_logloss: 0.478061\tvalid_1's multi_logloss: 0.501632        \n",
      "[19]\ttraining's multi_logloss: 0.457791\tvalid_1's multi_logloss: 0.482596        \n",
      "[20]\ttraining's multi_logloss: 0.439209\tvalid_1's multi_logloss: 0.465176        \n",
      "[21]\ttraining's multi_logloss: 0.422042\tvalid_1's multi_logloss: 0.449052        \n",
      "[22]\ttraining's multi_logloss: 0.406067\tvalid_1's multi_logloss: 0.434465        \n",
      "[23]\ttraining's multi_logloss: 0.391729\tvalid_1's multi_logloss: 0.421292        \n",
      "[24]\ttraining's multi_logloss: 0.378208\tvalid_1's multi_logloss: 0.409081        \n",
      "[25]\ttraining's multi_logloss: 0.365566\tvalid_1's multi_logloss: 0.397978        \n",
      "[26]\ttraining's multi_logloss: 0.354264\tvalid_1's multi_logloss: 0.387865        \n",
      "[27]\ttraining's multi_logloss: 0.343317\tvalid_1's multi_logloss: 0.378318        \n",
      "[28]\ttraining's multi_logloss: 0.333544\tvalid_1's multi_logloss: 0.36982         \n",
      "[29]\ttraining's multi_logloss: 0.324346\tvalid_1's multi_logloss: 0.36213         \n",
      "[30]\ttraining's multi_logloss: 0.315602\tvalid_1's multi_logloss: 0.355112        \n",
      "[31]\ttraining's multi_logloss: 0.307472\tvalid_1's multi_logloss: 0.348352        \n",
      "[32]\ttraining's multi_logloss: 0.299603\tvalid_1's multi_logloss: 0.342284        \n",
      "[33]\ttraining's multi_logloss: 0.292267\tvalid_1's multi_logloss: 0.336528        \n",
      "[34]\ttraining's multi_logloss: 0.285185\tvalid_1's multi_logloss: 0.331267        \n",
      "[35]\ttraining's multi_logloss: 0.278646\tvalid_1's multi_logloss: 0.326918        \n",
      "[36]\ttraining's multi_logloss: 0.272499\tvalid_1's multi_logloss: 0.322162        \n",
      "[37]\ttraining's multi_logloss: 0.26661\tvalid_1's multi_logloss: 0.317851         \n",
      "[38]\ttraining's multi_logloss: 0.261132\tvalid_1's multi_logloss: 0.314309        \n",
      "[39]\ttraining's multi_logloss: 0.25552\tvalid_1's multi_logloss: 0.31076          \n",
      "[40]\ttraining's multi_logloss: 0.25046\tvalid_1's multi_logloss: 0.307646         \n",
      "[41]\ttraining's multi_logloss: 0.245531\tvalid_1's multi_logloss: 0.304824        \n",
      "[42]\ttraining's multi_logloss: 0.240751\tvalid_1's multi_logloss: 0.302095        \n",
      "[43]\ttraining's multi_logloss: 0.23617\tvalid_1's multi_logloss: 0.299362         \n",
      "[44]\ttraining's multi_logloss: 0.231967\tvalid_1's multi_logloss: 0.297077        \n",
      "[45]\ttraining's multi_logloss: 0.227839\tvalid_1's multi_logloss: 0.294922        \n",
      "[46]\ttraining's multi_logloss: 0.223855\tvalid_1's multi_logloss: 0.292894        \n",
      "[47]\ttraining's multi_logloss: 0.220149\tvalid_1's multi_logloss: 0.291021        \n",
      "[48]\ttraining's multi_logloss: 0.216456\tvalid_1's multi_logloss: 0.289177        \n",
      "[49]\ttraining's multi_logloss: 0.212879\tvalid_1's multi_logloss: 0.287683        \n",
      "[50]\ttraining's multi_logloss: 0.209353\tvalid_1's multi_logloss: 0.285975        \n",
      "[51]\ttraining's multi_logloss: 0.205984\tvalid_1's multi_logloss: 0.284751        \n",
      "[52]\ttraining's multi_logloss: 0.202382\tvalid_1's multi_logloss: 0.283392        \n",
      "[53]\ttraining's multi_logloss: 0.199095\tvalid_1's multi_logloss: 0.282285        \n",
      "[54]\ttraining's multi_logloss: 0.195932\tvalid_1's multi_logloss: 0.281342        \n",
      "[55]\ttraining's multi_logloss: 0.192565\tvalid_1's multi_logloss: 0.280392        \n",
      "[56]\ttraining's multi_logloss: 0.189547\tvalid_1's multi_logloss: 0.279615        \n",
      "[57]\ttraining's multi_logloss: 0.186514\tvalid_1's multi_logloss: 0.278686        \n",
      "[58]\ttraining's multi_logloss: 0.183635\tvalid_1's multi_logloss: 0.277549        \n",
      "[59]\ttraining's multi_logloss: 0.180694\tvalid_1's multi_logloss: 0.276733        \n",
      "[60]\ttraining's multi_logloss: 0.177986\tvalid_1's multi_logloss: 0.276146        \n",
      "[61]\ttraining's multi_logloss: 0.175313\tvalid_1's multi_logloss: 0.275454        \n",
      "[62]\ttraining's multi_logloss: 0.172528\tvalid_1's multi_logloss: 0.274837        \n",
      "[63]\ttraining's multi_logloss: 0.169846\tvalid_1's multi_logloss: 0.273955        \n",
      "[64]\ttraining's multi_logloss: 0.167284\tvalid_1's multi_logloss: 0.273317        \n",
      "[65]\ttraining's multi_logloss: 0.164732\tvalid_1's multi_logloss: 0.272948        \n",
      "[66]\ttraining's multi_logloss: 0.162143\tvalid_1's multi_logloss: 0.27235         \n",
      "[67]\ttraining's multi_logloss: 0.159569\tvalid_1's multi_logloss: 0.272298        \n",
      "[68]\ttraining's multi_logloss: 0.15703\tvalid_1's multi_logloss: 0.272076         \n",
      "[69]\ttraining's multi_logloss: 0.154652\tvalid_1's multi_logloss: 0.271865        \n",
      "[70]\ttraining's multi_logloss: 0.152289\tvalid_1's multi_logloss: 0.271563        \n",
      "[71]\ttraining's multi_logloss: 0.149902\tvalid_1's multi_logloss: 0.271294        \n",
      "[72]\ttraining's multi_logloss: 0.147669\tvalid_1's multi_logloss: 0.270869        \n",
      "[73]\ttraining's multi_logloss: 0.145497\tvalid_1's multi_logloss: 0.270639        \n",
      "[74]\ttraining's multi_logloss: 0.143403\tvalid_1's multi_logloss: 0.27052         \n",
      "[75]\ttraining's multi_logloss: 0.141258\tvalid_1's multi_logloss: 0.27017         \n",
      "[76]\ttraining's multi_logloss: 0.139315\tvalid_1's multi_logloss: 0.270267        \n",
      "[77]\ttraining's multi_logloss: 0.137221\tvalid_1's multi_logloss: 0.270273        \n",
      "[78]\ttraining's multi_logloss: 0.135258\tvalid_1's multi_logloss: 0.270197        \n",
      "[79]\ttraining's multi_logloss: 0.13311\tvalid_1's multi_logloss: 0.270096         \n",
      "[80]\ttraining's multi_logloss: 0.131215\tvalid_1's multi_logloss: 0.269965        \n",
      "[81]\ttraining's multi_logloss: 0.129389\tvalid_1's multi_logloss: 0.269905        \n",
      "[82]\ttraining's multi_logloss: 0.127582\tvalid_1's multi_logloss: 0.26937         \n",
      "[83]\ttraining's multi_logloss: 0.125741\tvalid_1's multi_logloss: 0.269094        \n",
      "[84]\ttraining's multi_logloss: 0.124106\tvalid_1's multi_logloss: 0.268864        \n",
      "[85]\ttraining's multi_logloss: 0.122247\tvalid_1's multi_logloss: 0.268658        \n",
      "[86]\ttraining's multi_logloss: 0.120437\tvalid_1's multi_logloss: 0.268527        \n",
      "[87]\ttraining's multi_logloss: 0.118677\tvalid_1's multi_logloss: 0.268859        \n",
      "[88]\ttraining's multi_logloss: 0.117047\tvalid_1's multi_logloss: 0.268619        \n",
      "[89]\ttraining's multi_logloss: 0.115543\tvalid_1's multi_logloss: 0.268658        \n",
      "[90]\ttraining's multi_logloss: 0.113807\tvalid_1's multi_logloss: 0.268487        \n",
      "[91]\ttraining's multi_logloss: 0.112216\tvalid_1's multi_logloss: 0.268318        \n",
      "[92]\ttraining's multi_logloss: 0.110733\tvalid_1's multi_logloss: 0.268369        \n",
      "[93]\ttraining's multi_logloss: 0.109285\tvalid_1's multi_logloss: 0.268794        \n",
      "[94]\ttraining's multi_logloss: 0.107736\tvalid_1's multi_logloss: 0.268983        \n",
      "[95]\ttraining's multi_logloss: 0.106405\tvalid_1's multi_logloss: 0.269131        \n",
      "[96]\ttraining's multi_logloss: 0.104999\tvalid_1's multi_logloss: 0.269216        \n",
      "[97]\ttraining's multi_logloss: 0.103537\tvalid_1's multi_logloss: 0.269494        \n",
      "[98]\ttraining's multi_logloss: 0.102141\tvalid_1's multi_logloss: 0.269759        \n",
      "[99]\ttraining's multi_logloss: 0.100711\tvalid_1's multi_logloss: 0.269806        \n",
      "[100]\ttraining's multi_logloss: 0.0995061\tvalid_1's multi_logloss: 0.26997       \n",
      "[101]\ttraining's multi_logloss: 0.0983251\tvalid_1's multi_logloss: 0.270151      \n",
      "[102]\ttraining's multi_logloss: 0.0970663\tvalid_1's multi_logloss: 0.270369      \n",
      "[103]\ttraining's multi_logloss: 0.0958768\tvalid_1's multi_logloss: 0.270746      \n",
      "[104]\ttraining's multi_logloss: 0.0945702\tvalid_1's multi_logloss: 0.27084       \n",
      "[105]\ttraining's multi_logloss: 0.0933223\tvalid_1's multi_logloss: 0.27096       \n",
      "[106]\ttraining's multi_logloss: 0.0920445\tvalid_1's multi_logloss: 0.271113      \n",
      "[107]\ttraining's multi_logloss: 0.0909731\tvalid_1's multi_logloss: 0.271272      \n",
      "[108]\ttraining's multi_logloss: 0.0898428\tvalid_1's multi_logloss: 0.271523      \n",
      "[109]\ttraining's multi_logloss: 0.0886421\tvalid_1's multi_logloss: 0.272161      \n",
      "[110]\ttraining's multi_logloss: 0.0875446\tvalid_1's multi_logloss: 0.27245       \n",
      "[111]\ttraining's multi_logloss: 0.0864614\tvalid_1's multi_logloss: 0.272664      \n",
      "[112]\ttraining's multi_logloss: 0.0853887\tvalid_1's multi_logloss: 0.273174      \n",
      "[113]\ttraining's multi_logloss: 0.0843573\tvalid_1's multi_logloss: 0.273238      \n",
      "[114]\ttraining's multi_logloss: 0.0832689\tvalid_1's multi_logloss: 0.273379      \n",
      "[115]\ttraining's multi_logloss: 0.0822316\tvalid_1's multi_logloss: 0.273525      \n",
      "[116]\ttraining's multi_logloss: 0.0811659\tvalid_1's multi_logloss: 0.27383       \n",
      "[117]\ttraining's multi_logloss: 0.0801013\tvalid_1's multi_logloss: 0.27385       \n",
      "[118]\ttraining's multi_logloss: 0.0788778\tvalid_1's multi_logloss: 0.274044      \n",
      "[119]\ttraining's multi_logloss: 0.0778498\tvalid_1's multi_logloss: 0.274246      \n",
      "[120]\ttraining's multi_logloss: 0.0767526\tvalid_1's multi_logloss: 0.274798      \n",
      "[121]\ttraining's multi_logloss: 0.0758579\tvalid_1's multi_logloss: 0.275084      \n",
      "Early stopping, best iteration is:                                               \n",
      "[91]\ttraining's multi_logloss: 0.112216\tvalid_1's multi_logloss: 0.268318\n",
      "[1]\ttraining's multi_logloss: 1.83161\tvalid_1's multi_logloss: 1.83126           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.74246\tvalid_1's multi_logloss: 1.74424           \n",
      "[3]\ttraining's multi_logloss: 1.66252\tvalid_1's multi_logloss: 1.66603           \n",
      "[4]\ttraining's multi_logloss: 1.58968\tvalid_1's multi_logloss: 1.59522           \n",
      "[5]\ttraining's multi_logloss: 1.52333\tvalid_1's multi_logloss: 1.53061           \n",
      "[6]\ttraining's multi_logloss: 1.46242\tvalid_1's multi_logloss: 1.47127           \n",
      "[7]\ttraining's multi_logloss: 1.40619\tvalid_1's multi_logloss: 1.41678           \n",
      "[8]\ttraining's multi_logloss: 1.35378\tvalid_1's multi_logloss: 1.3658            \n",
      "[9]\ttraining's multi_logloss: 1.30496\tvalid_1's multi_logloss: 1.31836           \n",
      "[10]\ttraining's multi_logloss: 1.25957\tvalid_1's multi_logloss: 1.2741           \n",
      "[11]\ttraining's multi_logloss: 1.21685\tvalid_1's multi_logloss: 1.23264          \n",
      "[12]\ttraining's multi_logloss: 1.17661\tvalid_1's multi_logloss: 1.19367          \n",
      "[13]\ttraining's multi_logloss: 1.13878\tvalid_1's multi_logloss: 1.15717          \n",
      "[14]\ttraining's multi_logloss: 1.10315\tvalid_1's multi_logloss: 1.1226           \n",
      "[15]\ttraining's multi_logloss: 1.06906\tvalid_1's multi_logloss: 1.08955          \n",
      "[16]\ttraining's multi_logloss: 1.03692\tvalid_1's multi_logloss: 1.05836          \n",
      "[17]\ttraining's multi_logloss: 1.00644\tvalid_1's multi_logloss: 1.02904          \n",
      "[18]\ttraining's multi_logloss: 0.977746\tvalid_1's multi_logloss: 1.00117         \n",
      "[19]\ttraining's multi_logloss: 0.950093\tvalid_1's multi_logloss: 0.974438        \n",
      "[20]\ttraining's multi_logloss: 0.92366\tvalid_1's multi_logloss: 0.948978         \n",
      "[21]\ttraining's multi_logloss: 0.89875\tvalid_1's multi_logloss: 0.924914         \n",
      "[22]\ttraining's multi_logloss: 0.874814\tvalid_1's multi_logloss: 0.901842        \n",
      "[23]\ttraining's multi_logloss: 0.851662\tvalid_1's multi_logloss: 0.879467        \n",
      "[24]\ttraining's multi_logloss: 0.82964\tvalid_1's multi_logloss: 0.858161         \n",
      "[25]\ttraining's multi_logloss: 0.808724\tvalid_1's multi_logloss: 0.837824        \n",
      "[26]\ttraining's multi_logloss: 0.788743\tvalid_1's multi_logloss: 0.818493        \n",
      "[27]\ttraining's multi_logloss: 0.76963\tvalid_1's multi_logloss: 0.800026         \n",
      "[28]\ttraining's multi_logloss: 0.751407\tvalid_1's multi_logloss: 0.782476        \n",
      "[29]\ttraining's multi_logloss: 0.733878\tvalid_1's multi_logloss: 0.765478        \n",
      "[30]\ttraining's multi_logloss: 0.716757\tvalid_1's multi_logloss: 0.748996        \n",
      "[31]\ttraining's multi_logloss: 0.700467\tvalid_1's multi_logloss: 0.733278        \n",
      "[32]\ttraining's multi_logloss: 0.684695\tvalid_1's multi_logloss: 0.718173        \n",
      "[33]\ttraining's multi_logloss: 0.669676\tvalid_1's multi_logloss: 0.70371         \n",
      "[34]\ttraining's multi_logloss: 0.655006\tvalid_1's multi_logloss: 0.689721        \n",
      "[35]\ttraining's multi_logloss: 0.641175\tvalid_1's multi_logloss: 0.676439        \n",
      "[36]\ttraining's multi_logloss: 0.627545\tvalid_1's multi_logloss: 0.663487        \n",
      "[37]\ttraining's multi_logloss: 0.614461\tvalid_1's multi_logloss: 0.650964        \n",
      "[38]\ttraining's multi_logloss: 0.601904\tvalid_1's multi_logloss: 0.638929        \n",
      "[39]\ttraining's multi_logloss: 0.589845\tvalid_1's multi_logloss: 0.627546        \n",
      "[40]\ttraining's multi_logloss: 0.578056\tvalid_1's multi_logloss: 0.61645         \n",
      "[41]\ttraining's multi_logloss: 0.566875\tvalid_1's multi_logloss: 0.605814        \n",
      "[42]\ttraining's multi_logloss: 0.556109\tvalid_1's multi_logloss: 0.595637        \n",
      "[43]\ttraining's multi_logloss: 0.545656\tvalid_1's multi_logloss: 0.585835        \n",
      "[44]\ttraining's multi_logloss: 0.535666\tvalid_1's multi_logloss: 0.576361        \n",
      "[45]\ttraining's multi_logloss: 0.525969\tvalid_1's multi_logloss: 0.567276        \n",
      "[46]\ttraining's multi_logloss: 0.516596\tvalid_1's multi_logloss: 0.558591        \n",
      "[47]\ttraining's multi_logloss: 0.507441\tvalid_1's multi_logloss: 0.549941        \n",
      "[48]\ttraining's multi_logloss: 0.498599\tvalid_1's multi_logloss: 0.541699        \n",
      "[49]\ttraining's multi_logloss: 0.490116\tvalid_1's multi_logloss: 0.533833        \n",
      "[50]\ttraining's multi_logloss: 0.481821\tvalid_1's multi_logloss: 0.526248        \n",
      "[51]\ttraining's multi_logloss: 0.473885\tvalid_1's multi_logloss: 0.518959        \n",
      "[52]\ttraining's multi_logloss: 0.466126\tvalid_1's multi_logloss: 0.511849        \n",
      "[53]\ttraining's multi_logloss: 0.458646\tvalid_1's multi_logloss: 0.504936        \n",
      "[54]\ttraining's multi_logloss: 0.45142\tvalid_1's multi_logloss: 0.498398         \n",
      "[55]\ttraining's multi_logloss: 0.444388\tvalid_1's multi_logloss: 0.491894        \n",
      "[56]\ttraining's multi_logloss: 0.437561\tvalid_1's multi_logloss: 0.485652        \n",
      "[57]\ttraining's multi_logloss: 0.431021\tvalid_1's multi_logloss: 0.479649        \n",
      "[58]\ttraining's multi_logloss: 0.424677\tvalid_1's multi_logloss: 0.473743        \n",
      "[59]\ttraining's multi_logloss: 0.418505\tvalid_1's multi_logloss: 0.46812         \n",
      "[60]\ttraining's multi_logloss: 0.412402\tvalid_1's multi_logloss: 0.462474        \n",
      "[61]\ttraining's multi_logloss: 0.406567\tvalid_1's multi_logloss: 0.457269        \n",
      "[62]\ttraining's multi_logloss: 0.400889\tvalid_1's multi_logloss: 0.452145        \n",
      "[63]\ttraining's multi_logloss: 0.395442\tvalid_1's multi_logloss: 0.447205        \n",
      "[64]\ttraining's multi_logloss: 0.390089\tvalid_1's multi_logloss: 0.44237         \n",
      "[65]\ttraining's multi_logloss: 0.384957\tvalid_1's multi_logloss: 0.437855        \n",
      "[66]\ttraining's multi_logloss: 0.379966\tvalid_1's multi_logloss: 0.433355        \n",
      "[67]\ttraining's multi_logloss: 0.375162\tvalid_1's multi_logloss: 0.429104        \n",
      "[68]\ttraining's multi_logloss: 0.370446\tvalid_1's multi_logloss: 0.424972        \n",
      "[69]\ttraining's multi_logloss: 0.365875\tvalid_1's multi_logloss: 0.420926        \n",
      "[70]\ttraining's multi_logloss: 0.36146\tvalid_1's multi_logloss: 0.417088         \n",
      "[71]\ttraining's multi_logloss: 0.357073\tvalid_1's multi_logloss: 0.413224        \n",
      "[72]\ttraining's multi_logloss: 0.352854\tvalid_1's multi_logloss: 0.40949         \n",
      "[73]\ttraining's multi_logloss: 0.348859\tvalid_1's multi_logloss: 0.406026        \n",
      "[74]\ttraining's multi_logloss: 0.34483\tvalid_1's multi_logloss: 0.402704         \n",
      "[75]\ttraining's multi_logloss: 0.341065\tvalid_1's multi_logloss: 0.39957         \n",
      "[76]\ttraining's multi_logloss: 0.337306\tvalid_1's multi_logloss: 0.39634         \n",
      "[77]\ttraining's multi_logloss: 0.333685\tvalid_1's multi_logloss: 0.393344        \n",
      "[78]\ttraining's multi_logloss: 0.330236\tvalid_1's multi_logloss: 0.390502        \n",
      "[79]\ttraining's multi_logloss: 0.326832\tvalid_1's multi_logloss: 0.387682        \n",
      "[80]\ttraining's multi_logloss: 0.323483\tvalid_1's multi_logloss: 0.385024        \n",
      "[81]\ttraining's multi_logloss: 0.320271\tvalid_1's multi_logloss: 0.382486        \n",
      "[82]\ttraining's multi_logloss: 0.317133\tvalid_1's multi_logloss: 0.37994         \n",
      "[83]\ttraining's multi_logloss: 0.314016\tvalid_1's multi_logloss: 0.377499        \n",
      "[84]\ttraining's multi_logloss: 0.310909\tvalid_1's multi_logloss: 0.37503         \n",
      "[85]\ttraining's multi_logloss: 0.307952\tvalid_1's multi_logloss: 0.372647        \n",
      "[86]\ttraining's multi_logloss: 0.304958\tvalid_1's multi_logloss: 0.370245        \n",
      "[87]\ttraining's multi_logloss: 0.302225\tvalid_1's multi_logloss: 0.368069        \n",
      "[88]\ttraining's multi_logloss: 0.299329\tvalid_1's multi_logloss: 0.365792        \n",
      "[89]\ttraining's multi_logloss: 0.296599\tvalid_1's multi_logloss: 0.363698        \n",
      "[90]\ttraining's multi_logloss: 0.293824\tvalid_1's multi_logloss: 0.361537        \n",
      "[91]\ttraining's multi_logloss: 0.291148\tvalid_1's multi_logloss: 0.359448        \n",
      "[92]\ttraining's multi_logloss: 0.288563\tvalid_1's multi_logloss: 0.357418        \n",
      "[93]\ttraining's multi_logloss: 0.286053\tvalid_1's multi_logloss: 0.35545         \n",
      "[94]\ttraining's multi_logloss: 0.28358\tvalid_1's multi_logloss: 0.353572         \n",
      "[95]\ttraining's multi_logloss: 0.281213\tvalid_1's multi_logloss: 0.351742        \n",
      "[96]\ttraining's multi_logloss: 0.278844\tvalid_1's multi_logloss: 0.349968        \n",
      "[97]\ttraining's multi_logloss: 0.27638\tvalid_1's multi_logloss: 0.348211         \n",
      "[98]\ttraining's multi_logloss: 0.274046\tvalid_1's multi_logloss: 0.346482        \n",
      "[99]\ttraining's multi_logloss: 0.271823\tvalid_1's multi_logloss: 0.344819        \n",
      "[100]\ttraining's multi_logloss: 0.269613\tvalid_1's multi_logloss: 0.343257       \n",
      "[101]\ttraining's multi_logloss: 0.267496\tvalid_1's multi_logloss: 0.341771       \n",
      "[102]\ttraining's multi_logloss: 0.265379\tvalid_1's multi_logloss: 0.340308       \n",
      "[103]\ttraining's multi_logloss: 0.26333\tvalid_1's multi_logloss: 0.338975        \n",
      "[104]\ttraining's multi_logloss: 0.261364\tvalid_1's multi_logloss: 0.337699       \n",
      "[105]\ttraining's multi_logloss: 0.259403\tvalid_1's multi_logloss: 0.336376       \n",
      "[106]\ttraining's multi_logloss: 0.257496\tvalid_1's multi_logloss: 0.335077       \n",
      "[107]\ttraining's multi_logloss: 0.255568\tvalid_1's multi_logloss: 0.33384        \n",
      "[108]\ttraining's multi_logloss: 0.253684\tvalid_1's multi_logloss: 0.332688       \n",
      "[109]\ttraining's multi_logloss: 0.25181\tvalid_1's multi_logloss: 0.331479        \n",
      "[110]\ttraining's multi_logloss: 0.250008\tvalid_1's multi_logloss: 0.330407       \n",
      "[111]\ttraining's multi_logloss: 0.248231\tvalid_1's multi_logloss: 0.329393       \n",
      "[112]\ttraining's multi_logloss: 0.246451\tvalid_1's multi_logloss: 0.328329       \n",
      "[113]\ttraining's multi_logloss: 0.244711\tvalid_1's multi_logloss: 0.327275       \n",
      "[114]\ttraining's multi_logloss: 0.243023\tvalid_1's multi_logloss: 0.326167       \n",
      "[115]\ttraining's multi_logloss: 0.241377\tvalid_1's multi_logloss: 0.325141       \n",
      "[116]\ttraining's multi_logloss: 0.239684\tvalid_1's multi_logloss: 0.324056       \n",
      "[117]\ttraining's multi_logloss: 0.238087\tvalid_1's multi_logloss: 0.323004       \n",
      "[118]\ttraining's multi_logloss: 0.23655\tvalid_1's multi_logloss: 0.322055        \n",
      "[119]\ttraining's multi_logloss: 0.235033\tvalid_1's multi_logloss: 0.321117       \n",
      "[120]\ttraining's multi_logloss: 0.233483\tvalid_1's multi_logloss: 0.320218       \n",
      "[121]\ttraining's multi_logloss: 0.231984\tvalid_1's multi_logloss: 0.319401       \n",
      "[122]\ttraining's multi_logloss: 0.230532\tvalid_1's multi_logloss: 0.318553       \n",
      "[123]\ttraining's multi_logloss: 0.22908\tvalid_1's multi_logloss: 0.317861        \n",
      "[124]\ttraining's multi_logloss: 0.227614\tvalid_1's multi_logloss: 0.317074       \n",
      "[125]\ttraining's multi_logloss: 0.22617\tvalid_1's multi_logloss: 0.316416        \n",
      "[126]\ttraining's multi_logloss: 0.224746\tvalid_1's multi_logloss: 0.315724       \n",
      "[127]\ttraining's multi_logloss: 0.22338\tvalid_1's multi_logloss: 0.315059        \n",
      "[128]\ttraining's multi_logloss: 0.222006\tvalid_1's multi_logloss: 0.314363       \n",
      "[129]\ttraining's multi_logloss: 0.220682\tvalid_1's multi_logloss: 0.3137         \n",
      "[130]\ttraining's multi_logloss: 0.219306\tvalid_1's multi_logloss: 0.313044       \n",
      "[131]\ttraining's multi_logloss: 0.218051\tvalid_1's multi_logloss: 0.312517       \n",
      "[132]\ttraining's multi_logloss: 0.216744\tvalid_1's multi_logloss: 0.311886       \n",
      "[133]\ttraining's multi_logloss: 0.215446\tvalid_1's multi_logloss: 0.31126        \n",
      "[134]\ttraining's multi_logloss: 0.214247\tvalid_1's multi_logloss: 0.310787       \n",
      "[135]\ttraining's multi_logloss: 0.212948\tvalid_1's multi_logloss: 0.310139       \n",
      "[136]\ttraining's multi_logloss: 0.211755\tvalid_1's multi_logloss: 0.309597       \n",
      "[137]\ttraining's multi_logloss: 0.210543\tvalid_1's multi_logloss: 0.309054       \n",
      "[138]\ttraining's multi_logloss: 0.209374\tvalid_1's multi_logloss: 0.30845        \n",
      "[139]\ttraining's multi_logloss: 0.20822\tvalid_1's multi_logloss: 0.307967        \n",
      "[140]\ttraining's multi_logloss: 0.207071\tvalid_1's multi_logloss: 0.307397       \n",
      "[141]\ttraining's multi_logloss: 0.205887\tvalid_1's multi_logloss: 0.306883       \n",
      "[142]\ttraining's multi_logloss: 0.204731\tvalid_1's multi_logloss: 0.306519       \n",
      "[143]\ttraining's multi_logloss: 0.203577\tvalid_1's multi_logloss: 0.306015       \n",
      "[144]\ttraining's multi_logloss: 0.202418\tvalid_1's multi_logloss: 0.305561       \n",
      "[145]\ttraining's multi_logloss: 0.201308\tvalid_1's multi_logloss: 0.305133       \n",
      "[146]\ttraining's multi_logloss: 0.200222\tvalid_1's multi_logloss: 0.304691       \n",
      "[147]\ttraining's multi_logloss: 0.199138\tvalid_1's multi_logloss: 0.304367       \n",
      "[148]\ttraining's multi_logloss: 0.198084\tvalid_1's multi_logloss: 0.303905       \n",
      "[149]\ttraining's multi_logloss: 0.197021\tvalid_1's multi_logloss: 0.303455       \n",
      "[150]\ttraining's multi_logloss: 0.196022\tvalid_1's multi_logloss: 0.303125       \n",
      "[151]\ttraining's multi_logloss: 0.19499\tvalid_1's multi_logloss: 0.302756        \n",
      "[152]\ttraining's multi_logloss: 0.193932\tvalid_1's multi_logloss: 0.302343       \n",
      "[153]\ttraining's multi_logloss: 0.192939\tvalid_1's multi_logloss: 0.30202        \n",
      "[154]\ttraining's multi_logloss: 0.191921\tvalid_1's multi_logloss: 0.301598       \n",
      "[155]\ttraining's multi_logloss: 0.190939\tvalid_1's multi_logloss: 0.301212       \n",
      "[156]\ttraining's multi_logloss: 0.189948\tvalid_1's multi_logloss: 0.300716       \n",
      "[157]\ttraining's multi_logloss: 0.188993\tvalid_1's multi_logloss: 0.300449       \n",
      "[158]\ttraining's multi_logloss: 0.188027\tvalid_1's multi_logloss: 0.300225       \n",
      "[159]\ttraining's multi_logloss: 0.187084\tvalid_1's multi_logloss: 0.29996        \n",
      "[160]\ttraining's multi_logloss: 0.186088\tvalid_1's multi_logloss: 0.299667       \n",
      "[161]\ttraining's multi_logloss: 0.185198\tvalid_1's multi_logloss: 0.299448       \n",
      "[162]\ttraining's multi_logloss: 0.184308\tvalid_1's multi_logloss: 0.299137       \n",
      "[163]\ttraining's multi_logloss: 0.183382\tvalid_1's multi_logloss: 0.298777       \n",
      "[164]\ttraining's multi_logloss: 0.18243\tvalid_1's multi_logloss: 0.29853         \n",
      "[165]\ttraining's multi_logloss: 0.181542\tvalid_1's multi_logloss: 0.298296       \n",
      "[166]\ttraining's multi_logloss: 0.180628\tvalid_1's multi_logloss: 0.298119       \n",
      "[167]\ttraining's multi_logloss: 0.1797\tvalid_1's multi_logloss: 0.297885         \n",
      "[168]\ttraining's multi_logloss: 0.178804\tvalid_1's multi_logloss: 0.297642       \n",
      "[169]\ttraining's multi_logloss: 0.177877\tvalid_1's multi_logloss: 0.297449       \n",
      "[170]\ttraining's multi_logloss: 0.176966\tvalid_1's multi_logloss: 0.297221       \n",
      "[171]\ttraining's multi_logloss: 0.176078\tvalid_1's multi_logloss: 0.29704        \n",
      "[172]\ttraining's multi_logloss: 0.17517\tvalid_1's multi_logloss: 0.296905        \n",
      "[173]\ttraining's multi_logloss: 0.174319\tvalid_1's multi_logloss: 0.296657       \n",
      "[174]\ttraining's multi_logloss: 0.17341\tvalid_1's multi_logloss: 0.296498        \n",
      "[175]\ttraining's multi_logloss: 0.172527\tvalid_1's multi_logloss: 0.296301       \n",
      "[176]\ttraining's multi_logloss: 0.171699\tvalid_1's multi_logloss: 0.296116       \n",
      "[177]\ttraining's multi_logloss: 0.170827\tvalid_1's multi_logloss: 0.295905       \n",
      "[178]\ttraining's multi_logloss: 0.170014\tvalid_1's multi_logloss: 0.295778       \n",
      "[179]\ttraining's multi_logloss: 0.169194\tvalid_1's multi_logloss: 0.295571       \n",
      "[180]\ttraining's multi_logloss: 0.168368\tvalid_1's multi_logloss: 0.295397       \n",
      "[181]\ttraining's multi_logloss: 0.16758\tvalid_1's multi_logloss: 0.295167        \n",
      "[182]\ttraining's multi_logloss: 0.166776\tvalid_1's multi_logloss: 0.295016       \n",
      "[183]\ttraining's multi_logloss: 0.165992\tvalid_1's multi_logloss: 0.294815       \n",
      "[184]\ttraining's multi_logloss: 0.16521\tvalid_1's multi_logloss: 0.294632        \n",
      "[185]\ttraining's multi_logloss: 0.164414\tvalid_1's multi_logloss: 0.29447        \n",
      "[186]\ttraining's multi_logloss: 0.163641\tvalid_1's multi_logloss: 0.294261       \n",
      "[187]\ttraining's multi_logloss: 0.162907\tvalid_1's multi_logloss: 0.294135       \n",
      "[188]\ttraining's multi_logloss: 0.162139\tvalid_1's multi_logloss: 0.293982       \n",
      "[189]\ttraining's multi_logloss: 0.161377\tvalid_1's multi_logloss: 0.29384        \n",
      "[190]\ttraining's multi_logloss: 0.16063\tvalid_1's multi_logloss: 0.293684        \n",
      "[191]\ttraining's multi_logloss: 0.15985\tvalid_1's multi_logloss: 0.29351         \n",
      "[192]\ttraining's multi_logloss: 0.159137\tvalid_1's multi_logloss: 0.293487       \n",
      "[193]\ttraining's multi_logloss: 0.158352\tvalid_1's multi_logloss: 0.293326       \n",
      "[194]\ttraining's multi_logloss: 0.157629\tvalid_1's multi_logloss: 0.293244       \n",
      "[195]\ttraining's multi_logloss: 0.156878\tvalid_1's multi_logloss: 0.293212       \n",
      "[196]\ttraining's multi_logloss: 0.156091\tvalid_1's multi_logloss: 0.293068       \n",
      "[197]\ttraining's multi_logloss: 0.155359\tvalid_1's multi_logloss: 0.292989       \n",
      "[198]\ttraining's multi_logloss: 0.154649\tvalid_1's multi_logloss: 0.292819       \n",
      "[199]\ttraining's multi_logloss: 0.153954\tvalid_1's multi_logloss: 0.292732       \n",
      "[200]\ttraining's multi_logloss: 0.153246\tvalid_1's multi_logloss: 0.292709       \n",
      "[201]\ttraining's multi_logloss: 0.152504\tvalid_1's multi_logloss: 0.292533       \n",
      "[202]\ttraining's multi_logloss: 0.15182\tvalid_1's multi_logloss: 0.292499        \n",
      "[203]\ttraining's multi_logloss: 0.151114\tvalid_1's multi_logloss: 0.292372       \n",
      "[204]\ttraining's multi_logloss: 0.150434\tvalid_1's multi_logloss: 0.292292       \n",
      "[205]\ttraining's multi_logloss: 0.149753\tvalid_1's multi_logloss: 0.292156       \n",
      "[206]\ttraining's multi_logloss: 0.149115\tvalid_1's multi_logloss: 0.292136       \n",
      "[207]\ttraining's multi_logloss: 0.148457\tvalid_1's multi_logloss: 0.292069       \n",
      "[208]\ttraining's multi_logloss: 0.147783\tvalid_1's multi_logloss: 0.291938       \n",
      "[209]\ttraining's multi_logloss: 0.147168\tvalid_1's multi_logloss: 0.291835       \n",
      "[210]\ttraining's multi_logloss: 0.14653\tvalid_1's multi_logloss: 0.291673        \n",
      "[211]\ttraining's multi_logloss: 0.145914\tvalid_1's multi_logloss: 0.291479       \n",
      "[212]\ttraining's multi_logloss: 0.145306\tvalid_1's multi_logloss: 0.291427       \n",
      "[213]\ttraining's multi_logloss: 0.144686\tvalid_1's multi_logloss: 0.291365       \n",
      "[214]\ttraining's multi_logloss: 0.144058\tvalid_1's multi_logloss: 0.291228       \n",
      "[215]\ttraining's multi_logloss: 0.143421\tvalid_1's multi_logloss: 0.291119       \n",
      "[216]\ttraining's multi_logloss: 0.14278\tvalid_1's multi_logloss: 0.291049        \n",
      "[217]\ttraining's multi_logloss: 0.14215\tvalid_1's multi_logloss: 0.291046        \n",
      "[218]\ttraining's multi_logloss: 0.141543\tvalid_1's multi_logloss: 0.291015       \n",
      "[219]\ttraining's multi_logloss: 0.140914\tvalid_1's multi_logloss: 0.290922       \n",
      "[220]\ttraining's multi_logloss: 0.140271\tvalid_1's multi_logloss: 0.290758       \n",
      "[221]\ttraining's multi_logloss: 0.139642\tvalid_1's multi_logloss: 0.29066        \n",
      "[222]\ttraining's multi_logloss: 0.139052\tvalid_1's multi_logloss: 0.290641       \n",
      "[223]\ttraining's multi_logloss: 0.138437\tvalid_1's multi_logloss: 0.290579       \n",
      "[224]\ttraining's multi_logloss: 0.137886\tvalid_1's multi_logloss: 0.290525       \n",
      "[225]\ttraining's multi_logloss: 0.137223\tvalid_1's multi_logloss: 0.290449       \n",
      "[226]\ttraining's multi_logloss: 0.136636\tvalid_1's multi_logloss: 0.290431       \n",
      "[227]\ttraining's multi_logloss: 0.136046\tvalid_1's multi_logloss: 0.290405       \n",
      "[228]\ttraining's multi_logloss: 0.135493\tvalid_1's multi_logloss: 0.290412       \n",
      "[229]\ttraining's multi_logloss: 0.134899\tvalid_1's multi_logloss: 0.290403       \n",
      "[230]\ttraining's multi_logloss: 0.134372\tvalid_1's multi_logloss: 0.290386       \n",
      "[231]\ttraining's multi_logloss: 0.13379\tvalid_1's multi_logloss: 0.2902          \n",
      "[232]\ttraining's multi_logloss: 0.133238\tvalid_1's multi_logloss: 0.290136       \n",
      "[233]\ttraining's multi_logloss: 0.132635\tvalid_1's multi_logloss: 0.290157       \n",
      "[234]\ttraining's multi_logloss: 0.132065\tvalid_1's multi_logloss: 0.290043       \n",
      "[235]\ttraining's multi_logloss: 0.131522\tvalid_1's multi_logloss: 0.290105       \n",
      "[236]\ttraining's multi_logloss: 0.130977\tvalid_1's multi_logloss: 0.290033       \n",
      "[237]\ttraining's multi_logloss: 0.130442\tvalid_1's multi_logloss: 0.290023       \n",
      "[238]\ttraining's multi_logloss: 0.129899\tvalid_1's multi_logloss: 0.289985       \n",
      "[239]\ttraining's multi_logloss: 0.129348\tvalid_1's multi_logloss: 0.290011       \n",
      "[240]\ttraining's multi_logloss: 0.128855\tvalid_1's multi_logloss: 0.289974       \n",
      "[241]\ttraining's multi_logloss: 0.128369\tvalid_1's multi_logloss: 0.289873       \n",
      "[242]\ttraining's multi_logloss: 0.127837\tvalid_1's multi_logloss: 0.289835       \n",
      "[243]\ttraining's multi_logloss: 0.12727\tvalid_1's multi_logloss: 0.289864        \n",
      "[244]\ttraining's multi_logloss: 0.126736\tvalid_1's multi_logloss: 0.289882       \n",
      "[245]\ttraining's multi_logloss: 0.126242\tvalid_1's multi_logloss: 0.289888       \n",
      "[246]\ttraining's multi_logloss: 0.125723\tvalid_1's multi_logloss: 0.289987       \n",
      "[247]\ttraining's multi_logloss: 0.125201\tvalid_1's multi_logloss: 0.289997       \n",
      "[248]\ttraining's multi_logloss: 0.124683\tvalid_1's multi_logloss: 0.290005       \n",
      "[249]\ttraining's multi_logloss: 0.124142\tvalid_1's multi_logloss: 0.290013       \n",
      "[250]\ttraining's multi_logloss: 0.12364\tvalid_1's multi_logloss: 0.290112        \n",
      "[251]\ttraining's multi_logloss: 0.123158\tvalid_1's multi_logloss: 0.290136       \n",
      "[252]\ttraining's multi_logloss: 0.122627\tvalid_1's multi_logloss: 0.2902         \n",
      "[253]\ttraining's multi_logloss: 0.122137\tvalid_1's multi_logloss: 0.290177       \n",
      "[254]\ttraining's multi_logloss: 0.121663\tvalid_1's multi_logloss: 0.290196       \n",
      "[255]\ttraining's multi_logloss: 0.121135\tvalid_1's multi_logloss: 0.290193       \n",
      "[256]\ttraining's multi_logloss: 0.120649\tvalid_1's multi_logloss: 0.290173       \n",
      "[257]\ttraining's multi_logloss: 0.12014\tvalid_1's multi_logloss: 0.290176        \n",
      "[258]\ttraining's multi_logloss: 0.119647\tvalid_1's multi_logloss: 0.290251       \n",
      "[259]\ttraining's multi_logloss: 0.119154\tvalid_1's multi_logloss: 0.290203       \n",
      "[260]\ttraining's multi_logloss: 0.118671\tvalid_1's multi_logloss: 0.290208       \n",
      "[261]\ttraining's multi_logloss: 0.118149\tvalid_1's multi_logloss: 0.290231       \n",
      "[262]\ttraining's multi_logloss: 0.117628\tvalid_1's multi_logloss: 0.290276       \n",
      "[263]\ttraining's multi_logloss: 0.117151\tvalid_1's multi_logloss: 0.290309       \n",
      "[264]\ttraining's multi_logloss: 0.116644\tvalid_1's multi_logloss: 0.290359       \n",
      "[265]\ttraining's multi_logloss: 0.116148\tvalid_1's multi_logloss: 0.2904         \n",
      "[266]\ttraining's multi_logloss: 0.115693\tvalid_1's multi_logloss: 0.290419       \n",
      "[267]\ttraining's multi_logloss: 0.115191\tvalid_1's multi_logloss: 0.290436       \n",
      "[268]\ttraining's multi_logloss: 0.114729\tvalid_1's multi_logloss: 0.290514       \n",
      "[269]\ttraining's multi_logloss: 0.114274\tvalid_1's multi_logloss: 0.290592       \n",
      "[270]\ttraining's multi_logloss: 0.113843\tvalid_1's multi_logloss: 0.290615       \n",
      "[271]\ttraining's multi_logloss: 0.1134\tvalid_1's multi_logloss: 0.290691         \n",
      "[272]\ttraining's multi_logloss: 0.112974\tvalid_1's multi_logloss: 0.290661       \n",
      "Early stopping, best iteration is:                                               \n",
      "[242]\ttraining's multi_logloss: 0.127837\tvalid_1's multi_logloss: 0.289835\n",
      "[1]\ttraining's multi_logloss: 1.83003\tvalid_1's multi_logloss: 1.83225           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.7419\tvalid_1's multi_logloss: 1.7447             \n",
      "[3]\ttraining's multi_logloss: 1.66274\tvalid_1's multi_logloss: 1.66605           \n",
      "[4]\ttraining's multi_logloss: 1.59099\tvalid_1's multi_logloss: 1.59471           \n",
      "[5]\ttraining's multi_logloss: 1.52527\tvalid_1's multi_logloss: 1.52957           \n",
      "[6]\ttraining's multi_logloss: 1.46499\tvalid_1's multi_logloss: 1.4695            \n",
      "[7]\ttraining's multi_logloss: 1.40947\tvalid_1's multi_logloss: 1.41464           \n",
      "[8]\ttraining's multi_logloss: 1.35787\tvalid_1's multi_logloss: 1.36359           \n",
      "[9]\ttraining's multi_logloss: 1.30934\tvalid_1's multi_logloss: 1.3156            \n",
      "[10]\ttraining's multi_logloss: 1.26426\tvalid_1's multi_logloss: 1.27128          \n",
      "[11]\ttraining's multi_logloss: 1.22178\tvalid_1's multi_logloss: 1.22938          \n",
      "[12]\ttraining's multi_logloss: 1.18216\tvalid_1's multi_logloss: 1.19041          \n",
      "[13]\ttraining's multi_logloss: 1.14464\tvalid_1's multi_logloss: 1.15344          \n",
      "[14]\ttraining's multi_logloss: 1.1092\tvalid_1's multi_logloss: 1.11859           \n",
      "[15]\ttraining's multi_logloss: 1.07567\tvalid_1's multi_logloss: 1.08564          \n",
      "[16]\ttraining's multi_logloss: 1.04359\tvalid_1's multi_logloss: 1.05416          \n",
      "[17]\ttraining's multi_logloss: 1.01325\tvalid_1's multi_logloss: 1.02437          \n",
      "[18]\ttraining's multi_logloss: 0.984346\tvalid_1's multi_logloss: 0.996004        \n",
      "[19]\ttraining's multi_logloss: 0.95694\tvalid_1's multi_logloss: 0.969166         \n",
      "[20]\ttraining's multi_logloss: 0.931083\tvalid_1's multi_logloss: 0.943996        \n",
      "[21]\ttraining's multi_logloss: 0.906373\tvalid_1's multi_logloss: 0.91987         \n",
      "[22]\ttraining's multi_logloss: 0.882417\tvalid_1's multi_logloss: 0.896394        \n",
      "[23]\ttraining's multi_logloss: 0.85965\tvalid_1's multi_logloss: 0.87409          \n",
      "[24]\ttraining's multi_logloss: 0.837867\tvalid_1's multi_logloss: 0.852861        \n",
      "[25]\ttraining's multi_logloss: 0.81663\tvalid_1's multi_logloss: 0.832171         \n",
      "[26]\ttraining's multi_logloss: 0.796551\tvalid_1's multi_logloss: 0.812705        \n",
      "[27]\ttraining's multi_logloss: 0.777025\tvalid_1's multi_logloss: 0.793894        \n",
      "[28]\ttraining's multi_logloss: 0.758443\tvalid_1's multi_logloss: 0.775902        \n",
      "[29]\ttraining's multi_logloss: 0.740734\tvalid_1's multi_logloss: 0.758832        \n",
      "[30]\ttraining's multi_logloss: 0.72357\tvalid_1's multi_logloss: 0.742298         \n",
      "[31]\ttraining's multi_logloss: 0.707059\tvalid_1's multi_logloss: 0.726435        \n",
      "[32]\ttraining's multi_logloss: 0.69129\tvalid_1's multi_logloss: 0.711359         \n",
      "[33]\ttraining's multi_logloss: 0.676207\tvalid_1's multi_logloss: 0.697011        \n",
      "[34]\ttraining's multi_logloss: 0.661767\tvalid_1's multi_logloss: 0.683248        \n",
      "[35]\ttraining's multi_logloss: 0.647626\tvalid_1's multi_logloss: 0.669619        \n",
      "[36]\ttraining's multi_logloss: 0.634056\tvalid_1's multi_logloss: 0.656539        \n",
      "[37]\ttraining's multi_logloss: 0.62101\tvalid_1's multi_logloss: 0.643944         \n",
      "[38]\ttraining's multi_logloss: 0.6086\tvalid_1's multi_logloss: 0.632165          \n",
      "[39]\ttraining's multi_logloss: 0.596496\tvalid_1's multi_logloss: 0.620539        \n",
      "[40]\ttraining's multi_logloss: 0.584718\tvalid_1's multi_logloss: 0.60931         \n",
      "[41]\ttraining's multi_logloss: 0.573524\tvalid_1's multi_logloss: 0.598741        \n",
      "[42]\ttraining's multi_logloss: 0.562486\tvalid_1's multi_logloss: 0.588318        \n",
      "[43]\ttraining's multi_logloss: 0.551858\tvalid_1's multi_logloss: 0.578167        \n",
      "[44]\ttraining's multi_logloss: 0.541865\tvalid_1's multi_logloss: 0.568727        \n",
      "[45]\ttraining's multi_logloss: 0.532167\tvalid_1's multi_logloss: 0.559682        \n",
      "[46]\ttraining's multi_logloss: 0.522673\tvalid_1's multi_logloss: 0.550687        \n",
      "[47]\ttraining's multi_logloss: 0.513652\tvalid_1's multi_logloss: 0.542194        \n",
      "[48]\ttraining's multi_logloss: 0.504787\tvalid_1's multi_logloss: 0.53382         \n",
      "[49]\ttraining's multi_logloss: 0.496225\tvalid_1's multi_logloss: 0.525797        \n",
      "[50]\ttraining's multi_logloss: 0.487984\tvalid_1's multi_logloss: 0.518109        \n",
      "[51]\ttraining's multi_logloss: 0.480041\tvalid_1's multi_logloss: 0.510727        \n",
      "[52]\ttraining's multi_logloss: 0.472439\tvalid_1's multi_logloss: 0.503671        \n",
      "[53]\ttraining's multi_logloss: 0.464818\tvalid_1's multi_logloss: 0.496744        \n",
      "[54]\ttraining's multi_logloss: 0.457433\tvalid_1's multi_logloss: 0.489907        \n",
      "[55]\ttraining's multi_logloss: 0.450398\tvalid_1's multi_logloss: 0.483404        \n",
      "[56]\ttraining's multi_logloss: 0.443506\tvalid_1's multi_logloss: 0.477189        \n",
      "[57]\ttraining's multi_logloss: 0.436884\tvalid_1's multi_logloss: 0.471214        \n",
      "[58]\ttraining's multi_logloss: 0.430445\tvalid_1's multi_logloss: 0.465397        \n",
      "[59]\ttraining's multi_logloss: 0.424253\tvalid_1's multi_logloss: 0.459897        \n",
      "[60]\ttraining's multi_logloss: 0.418248\tvalid_1's multi_logloss: 0.454615        \n",
      "[61]\ttraining's multi_logloss: 0.412475\tvalid_1's multi_logloss: 0.449465        \n",
      "[62]\ttraining's multi_logloss: 0.406852\tvalid_1's multi_logloss: 0.44455         \n",
      "[63]\ttraining's multi_logloss: 0.401333\tvalid_1's multi_logloss: 0.439673        \n",
      "[64]\ttraining's multi_logloss: 0.395959\tvalid_1's multi_logloss: 0.435023        \n",
      "[65]\ttraining's multi_logloss: 0.390815\tvalid_1's multi_logloss: 0.430616        \n",
      "[66]\ttraining's multi_logloss: 0.385762\tvalid_1's multi_logloss: 0.426245        \n",
      "[67]\ttraining's multi_logloss: 0.380928\tvalid_1's multi_logloss: 0.422019        \n",
      "[68]\ttraining's multi_logloss: 0.376223\tvalid_1's multi_logloss: 0.417869        \n",
      "[69]\ttraining's multi_logloss: 0.37161\tvalid_1's multi_logloss: 0.413857         \n",
      "[70]\ttraining's multi_logloss: 0.367203\tvalid_1's multi_logloss: 0.409995        \n",
      "[71]\ttraining's multi_logloss: 0.362711\tvalid_1's multi_logloss: 0.406116        \n",
      "[72]\ttraining's multi_logloss: 0.358456\tvalid_1's multi_logloss: 0.402548        \n",
      "[73]\ttraining's multi_logloss: 0.354173\tvalid_1's multi_logloss: 0.398844        \n",
      "[74]\ttraining's multi_logloss: 0.350086\tvalid_1's multi_logloss: 0.395343        \n",
      "[75]\ttraining's multi_logloss: 0.346212\tvalid_1's multi_logloss: 0.392099        \n",
      "[76]\ttraining's multi_logloss: 0.342342\tvalid_1's multi_logloss: 0.388808        \n",
      "[77]\ttraining's multi_logloss: 0.338546\tvalid_1's multi_logloss: 0.385687        \n",
      "[78]\ttraining's multi_logloss: 0.334881\tvalid_1's multi_logloss: 0.382562        \n",
      "[79]\ttraining's multi_logloss: 0.331331\tvalid_1's multi_logloss: 0.37952         \n",
      "[80]\ttraining's multi_logloss: 0.327885\tvalid_1's multi_logloss: 0.376725        \n",
      "[81]\ttraining's multi_logloss: 0.324462\tvalid_1's multi_logloss: 0.373987        \n",
      "[82]\ttraining's multi_logloss: 0.321136\tvalid_1's multi_logloss: 0.371192        \n",
      "[83]\ttraining's multi_logloss: 0.317758\tvalid_1's multi_logloss: 0.368516        \n",
      "[84]\ttraining's multi_logloss: 0.314598\tvalid_1's multi_logloss: 0.365912        \n",
      "[85]\ttraining's multi_logloss: 0.311322\tvalid_1's multi_logloss: 0.363293        \n",
      "[86]\ttraining's multi_logloss: 0.308355\tvalid_1's multi_logloss: 0.360887        \n",
      "[87]\ttraining's multi_logloss: 0.305371\tvalid_1's multi_logloss: 0.358463        \n",
      "[88]\ttraining's multi_logloss: 0.302484\tvalid_1's multi_logloss: 0.356203        \n",
      "[89]\ttraining's multi_logloss: 0.299548\tvalid_1's multi_logloss: 0.353955        \n",
      "[90]\ttraining's multi_logloss: 0.296845\tvalid_1's multi_logloss: 0.351866        \n",
      "[91]\ttraining's multi_logloss: 0.294081\tvalid_1's multi_logloss: 0.349639        \n",
      "[92]\ttraining's multi_logloss: 0.29139\tvalid_1's multi_logloss: 0.347628         \n",
      "[93]\ttraining's multi_logloss: 0.288683\tvalid_1's multi_logloss: 0.345595        \n",
      "[94]\ttraining's multi_logloss: 0.286124\tvalid_1's multi_logloss: 0.343686        \n",
      "[95]\ttraining's multi_logloss: 0.283528\tvalid_1's multi_logloss: 0.341686        \n",
      "[96]\ttraining's multi_logloss: 0.281035\tvalid_1's multi_logloss: 0.339807        \n",
      "[97]\ttraining's multi_logloss: 0.278664\tvalid_1's multi_logloss: 0.338197        \n",
      "[98]\ttraining's multi_logloss: 0.276336\tvalid_1's multi_logloss: 0.336623        \n",
      "[99]\ttraining's multi_logloss: 0.273997\tvalid_1's multi_logloss: 0.334901        \n",
      "[100]\ttraining's multi_logloss: 0.271805\tvalid_1's multi_logloss: 0.333436       \n",
      "[101]\ttraining's multi_logloss: 0.269555\tvalid_1's multi_logloss: 0.331883       \n",
      "[102]\ttraining's multi_logloss: 0.267462\tvalid_1's multi_logloss: 0.330479       \n",
      "[103]\ttraining's multi_logloss: 0.265346\tvalid_1's multi_logloss: 0.329137       \n",
      "[104]\ttraining's multi_logloss: 0.263323\tvalid_1's multi_logloss: 0.327781       \n",
      "[105]\ttraining's multi_logloss: 0.2613\tvalid_1's multi_logloss: 0.326495         \n",
      "[106]\ttraining's multi_logloss: 0.259303\tvalid_1's multi_logloss: 0.325142       \n",
      "[107]\ttraining's multi_logloss: 0.257423\tvalid_1's multi_logloss: 0.323991       \n",
      "[108]\ttraining's multi_logloss: 0.255481\tvalid_1's multi_logloss: 0.322739       \n",
      "[109]\ttraining's multi_logloss: 0.253628\tvalid_1's multi_logloss: 0.321696       \n",
      "[110]\ttraining's multi_logloss: 0.25176\tvalid_1's multi_logloss: 0.320623        \n",
      "[111]\ttraining's multi_logloss: 0.249908\tvalid_1's multi_logloss: 0.31956        \n",
      "[112]\ttraining's multi_logloss: 0.248174\tvalid_1's multi_logloss: 0.318612       \n",
      "[113]\ttraining's multi_logloss: 0.246409\tvalid_1's multi_logloss: 0.317659       \n",
      "[114]\ttraining's multi_logloss: 0.244589\tvalid_1's multi_logloss: 0.316624       \n",
      "[115]\ttraining's multi_logloss: 0.242828\tvalid_1's multi_logloss: 0.315639       \n",
      "[116]\ttraining's multi_logloss: 0.24104\tvalid_1's multi_logloss: 0.314613        \n",
      "[117]\ttraining's multi_logloss: 0.239354\tvalid_1's multi_logloss: 0.313629       \n",
      "[118]\ttraining's multi_logloss: 0.237666\tvalid_1's multi_logloss: 0.31275        \n",
      "[119]\ttraining's multi_logloss: 0.236018\tvalid_1's multi_logloss: 0.311895       \n",
      "[120]\ttraining's multi_logloss: 0.234403\tvalid_1's multi_logloss: 0.311078       \n",
      "[121]\ttraining's multi_logloss: 0.232824\tvalid_1's multi_logloss: 0.310282       \n",
      "[122]\ttraining's multi_logloss: 0.231253\tvalid_1's multi_logloss: 0.309511       \n",
      "[123]\ttraining's multi_logloss: 0.229804\tvalid_1's multi_logloss: 0.308726       \n",
      "[124]\ttraining's multi_logloss: 0.228315\tvalid_1's multi_logloss: 0.307945       \n",
      "[125]\ttraining's multi_logloss: 0.226911\tvalid_1's multi_logloss: 0.307195       \n",
      "[126]\ttraining's multi_logloss: 0.225473\tvalid_1's multi_logloss: 0.306454       \n",
      "[127]\ttraining's multi_logloss: 0.224068\tvalid_1's multi_logloss: 0.305793       \n",
      "[128]\ttraining's multi_logloss: 0.222677\tvalid_1's multi_logloss: 0.305091       \n",
      "[129]\ttraining's multi_logloss: 0.221283\tvalid_1's multi_logloss: 0.304303       \n",
      "[130]\ttraining's multi_logloss: 0.219924\tvalid_1's multi_logloss: 0.303751       \n",
      "[131]\ttraining's multi_logloss: 0.2186\tvalid_1's multi_logloss: 0.303175         \n",
      "[132]\ttraining's multi_logloss: 0.217294\tvalid_1's multi_logloss: 0.302588       \n",
      "[133]\ttraining's multi_logloss: 0.216013\tvalid_1's multi_logloss: 0.302108       \n",
      "[134]\ttraining's multi_logloss: 0.214755\tvalid_1's multi_logloss: 0.301645       \n",
      "[135]\ttraining's multi_logloss: 0.213531\tvalid_1's multi_logloss: 0.30111        \n",
      "[136]\ttraining's multi_logloss: 0.212298\tvalid_1's multi_logloss: 0.300653       \n",
      "[137]\ttraining's multi_logloss: 0.21107\tvalid_1's multi_logloss: 0.300204        \n",
      "[138]\ttraining's multi_logloss: 0.209894\tvalid_1's multi_logloss: 0.299627       \n",
      "[139]\ttraining's multi_logloss: 0.208666\tvalid_1's multi_logloss: 0.299105       \n",
      "[140]\ttraining's multi_logloss: 0.207507\tvalid_1's multi_logloss: 0.298696       \n",
      "[141]\ttraining's multi_logloss: 0.206299\tvalid_1's multi_logloss: 0.298192       \n",
      "[142]\ttraining's multi_logloss: 0.205129\tvalid_1's multi_logloss: 0.297625       \n",
      "[143]\ttraining's multi_logloss: 0.203935\tvalid_1's multi_logloss: 0.297161       \n",
      "[144]\ttraining's multi_logloss: 0.202782\tvalid_1's multi_logloss: 0.296606       \n",
      "[145]\ttraining's multi_logloss: 0.201621\tvalid_1's multi_logloss: 0.296209       \n",
      "[146]\ttraining's multi_logloss: 0.200538\tvalid_1's multi_logloss: 0.295855       \n",
      "[147]\ttraining's multi_logloss: 0.199394\tvalid_1's multi_logloss: 0.295453       \n",
      "[148]\ttraining's multi_logloss: 0.198269\tvalid_1's multi_logloss: 0.294993       \n",
      "[149]\ttraining's multi_logloss: 0.197172\tvalid_1's multi_logloss: 0.294523       \n",
      "[150]\ttraining's multi_logloss: 0.196078\tvalid_1's multi_logloss: 0.294098       \n",
      "[151]\ttraining's multi_logloss: 0.194965\tvalid_1's multi_logloss: 0.293585       \n",
      "[152]\ttraining's multi_logloss: 0.19393\tvalid_1's multi_logloss: 0.293221        \n",
      "[153]\ttraining's multi_logloss: 0.192872\tvalid_1's multi_logloss: 0.292855       \n",
      "[154]\ttraining's multi_logloss: 0.191785\tvalid_1's multi_logloss: 0.29239        \n",
      "[155]\ttraining's multi_logloss: 0.190731\tvalid_1's multi_logloss: 0.292117       \n",
      "[156]\ttraining's multi_logloss: 0.189652\tvalid_1's multi_logloss: 0.291749       \n",
      "[157]\ttraining's multi_logloss: 0.188628\tvalid_1's multi_logloss: 0.291343       \n",
      "[158]\ttraining's multi_logloss: 0.1876\tvalid_1's multi_logloss: 0.290845         \n",
      "[159]\ttraining's multi_logloss: 0.18661\tvalid_1's multi_logloss: 0.290497        \n",
      "[160]\ttraining's multi_logloss: 0.185586\tvalid_1's multi_logloss: 0.290164       \n",
      "[161]\ttraining's multi_logloss: 0.184584\tvalid_1's multi_logloss: 0.289882       \n",
      "[162]\ttraining's multi_logloss: 0.183573\tvalid_1's multi_logloss: 0.289585       \n",
      "[163]\ttraining's multi_logloss: 0.182585\tvalid_1's multi_logloss: 0.289266       \n",
      "[164]\ttraining's multi_logloss: 0.181642\tvalid_1's multi_logloss: 0.288935       \n",
      "[165]\ttraining's multi_logloss: 0.180669\tvalid_1's multi_logloss: 0.28857        \n",
      "[166]\ttraining's multi_logloss: 0.17974\tvalid_1's multi_logloss: 0.288282        \n",
      "[167]\ttraining's multi_logloss: 0.178783\tvalid_1's multi_logloss: 0.288104       \n",
      "[168]\ttraining's multi_logloss: 0.17788\tvalid_1's multi_logloss: 0.287851        \n",
      "[169]\ttraining's multi_logloss: 0.17696\tvalid_1's multi_logloss: 0.287501        \n",
      "[170]\ttraining's multi_logloss: 0.176033\tvalid_1's multi_logloss: 0.287261       \n",
      "[171]\ttraining's multi_logloss: 0.175103\tvalid_1's multi_logloss: 0.287004       \n",
      "[172]\ttraining's multi_logloss: 0.174172\tvalid_1's multi_logloss: 0.286915       \n",
      "[173]\ttraining's multi_logloss: 0.173256\tvalid_1's multi_logloss: 0.286658       \n",
      "[174]\ttraining's multi_logloss: 0.17233\tvalid_1's multi_logloss: 0.286504        \n",
      "[175]\ttraining's multi_logloss: 0.171494\tvalid_1's multi_logloss: 0.286342       \n",
      "[176]\ttraining's multi_logloss: 0.170595\tvalid_1's multi_logloss: 0.286122       \n",
      "[177]\ttraining's multi_logloss: 0.169797\tvalid_1's multi_logloss: 0.285951       \n",
      "[178]\ttraining's multi_logloss: 0.168881\tvalid_1's multi_logloss: 0.285694       \n",
      "[179]\ttraining's multi_logloss: 0.168074\tvalid_1's multi_logloss: 0.285593       \n",
      "[180]\ttraining's multi_logloss: 0.167248\tvalid_1's multi_logloss: 0.285504       \n",
      "[181]\ttraining's multi_logloss: 0.166376\tvalid_1's multi_logloss: 0.28523        \n",
      "[182]\ttraining's multi_logloss: 0.165564\tvalid_1's multi_logloss: 0.285104       \n",
      "[183]\ttraining's multi_logloss: 0.164764\tvalid_1's multi_logloss: 0.284951       \n",
      "[184]\ttraining's multi_logloss: 0.163955\tvalid_1's multi_logloss: 0.284735       \n",
      "[185]\ttraining's multi_logloss: 0.163158\tvalid_1's multi_logloss: 0.28462        \n",
      "[186]\ttraining's multi_logloss: 0.162395\tvalid_1's multi_logloss: 0.284634       \n",
      "[187]\ttraining's multi_logloss: 0.161608\tvalid_1's multi_logloss: 0.284535       \n",
      "[188]\ttraining's multi_logloss: 0.160851\tvalid_1's multi_logloss: 0.284488       \n",
      "[189]\ttraining's multi_logloss: 0.16009\tvalid_1's multi_logloss: 0.284323        \n",
      "[190]\ttraining's multi_logloss: 0.159336\tvalid_1's multi_logloss: 0.284233       \n",
      "[191]\ttraining's multi_logloss: 0.158575\tvalid_1's multi_logloss: 0.284105       \n",
      "[192]\ttraining's multi_logloss: 0.157806\tvalid_1's multi_logloss: 0.284066       \n",
      "[193]\ttraining's multi_logloss: 0.157021\tvalid_1's multi_logloss: 0.283879       \n",
      "[194]\ttraining's multi_logloss: 0.156274\tvalid_1's multi_logloss: 0.283852       \n",
      "[195]\ttraining's multi_logloss: 0.155506\tvalid_1's multi_logloss: 0.28378        \n",
      "[196]\ttraining's multi_logloss: 0.154812\tvalid_1's multi_logloss: 0.283694       \n",
      "[197]\ttraining's multi_logloss: 0.15412\tvalid_1's multi_logloss: 0.283628        \n",
      "[198]\ttraining's multi_logloss: 0.153363\tvalid_1's multi_logloss: 0.28351        \n",
      "[199]\ttraining's multi_logloss: 0.152701\tvalid_1's multi_logloss: 0.283439       \n",
      "[200]\ttraining's multi_logloss: 0.151977\tvalid_1's multi_logloss: 0.283346       \n",
      "[201]\ttraining's multi_logloss: 0.151262\tvalid_1's multi_logloss: 0.283248       \n",
      "[202]\ttraining's multi_logloss: 0.150541\tvalid_1's multi_logloss: 0.283108       \n",
      "[203]\ttraining's multi_logloss: 0.14989\tvalid_1's multi_logloss: 0.28304         \n",
      "[204]\ttraining's multi_logloss: 0.149191\tvalid_1's multi_logloss: 0.283029       \n",
      "[205]\ttraining's multi_logloss: 0.148539\tvalid_1's multi_logloss: 0.282976       \n",
      "[206]\ttraining's multi_logloss: 0.147884\tvalid_1's multi_logloss: 0.282875       \n",
      "[207]\ttraining's multi_logloss: 0.147165\tvalid_1's multi_logloss: 0.282729       \n",
      "[208]\ttraining's multi_logloss: 0.146545\tvalid_1's multi_logloss: 0.282624       \n",
      "[209]\ttraining's multi_logloss: 0.145826\tvalid_1's multi_logloss: 0.282561       \n",
      "[210]\ttraining's multi_logloss: 0.14517\tvalid_1's multi_logloss: 0.282544        \n",
      "[211]\ttraining's multi_logloss: 0.144529\tvalid_1's multi_logloss: 0.282475       \n",
      "[212]\ttraining's multi_logloss: 0.14392\tvalid_1's multi_logloss: 0.282423        \n",
      "[213]\ttraining's multi_logloss: 0.143292\tvalid_1's multi_logloss: 0.282318       \n",
      "[214]\ttraining's multi_logloss: 0.142699\tvalid_1's multi_logloss: 0.282264       \n",
      "[215]\ttraining's multi_logloss: 0.142069\tvalid_1's multi_logloss: 0.282191       \n",
      "[216]\ttraining's multi_logloss: 0.141431\tvalid_1's multi_logloss: 0.282194       \n",
      "[217]\ttraining's multi_logloss: 0.140792\tvalid_1's multi_logloss: 0.28215        \n",
      "[218]\ttraining's multi_logloss: 0.140148\tvalid_1's multi_logloss: 0.282104       \n",
      "[219]\ttraining's multi_logloss: 0.13952\tvalid_1's multi_logloss: 0.282108        \n",
      "[220]\ttraining's multi_logloss: 0.138948\tvalid_1's multi_logloss: 0.282011       \n",
      "[221]\ttraining's multi_logloss: 0.138351\tvalid_1's multi_logloss: 0.281983       \n",
      "[222]\ttraining's multi_logloss: 0.137745\tvalid_1's multi_logloss: 0.281974       \n",
      "[223]\ttraining's multi_logloss: 0.137161\tvalid_1's multi_logloss: 0.281964       \n",
      "[224]\ttraining's multi_logloss: 0.136572\tvalid_1's multi_logloss: 0.281967       \n",
      "[225]\ttraining's multi_logloss: 0.136015\tvalid_1's multi_logloss: 0.282011       \n",
      "[226]\ttraining's multi_logloss: 0.135395\tvalid_1's multi_logloss: 0.281984       \n",
      "[227]\ttraining's multi_logloss: 0.134844\tvalid_1's multi_logloss: 0.281976       \n",
      "[228]\ttraining's multi_logloss: 0.134242\tvalid_1's multi_logloss: 0.281981       \n",
      "[229]\ttraining's multi_logloss: 0.133648\tvalid_1's multi_logloss: 0.281934       \n",
      "[230]\ttraining's multi_logloss: 0.133011\tvalid_1's multi_logloss: 0.281906       \n",
      "[231]\ttraining's multi_logloss: 0.132424\tvalid_1's multi_logloss: 0.281843       \n",
      "[232]\ttraining's multi_logloss: 0.131842\tvalid_1's multi_logloss: 0.281844       \n",
      "[233]\ttraining's multi_logloss: 0.131261\tvalid_1's multi_logloss: 0.281775       \n",
      "[234]\ttraining's multi_logloss: 0.130697\tvalid_1's multi_logloss: 0.281696       \n",
      "[235]\ttraining's multi_logloss: 0.130153\tvalid_1's multi_logloss: 0.281561       \n",
      "[236]\ttraining's multi_logloss: 0.129588\tvalid_1's multi_logloss: 0.281569       \n",
      "[237]\ttraining's multi_logloss: 0.128994\tvalid_1's multi_logloss: 0.281485       \n",
      "[238]\ttraining's multi_logloss: 0.128418\tvalid_1's multi_logloss: 0.281469       \n",
      "[239]\ttraining's multi_logloss: 0.127848\tvalid_1's multi_logloss: 0.281452       \n",
      "[240]\ttraining's multi_logloss: 0.127276\tvalid_1's multi_logloss: 0.281495       \n",
      "[241]\ttraining's multi_logloss: 0.126691\tvalid_1's multi_logloss: 0.281508       \n",
      "[242]\ttraining's multi_logloss: 0.126148\tvalid_1's multi_logloss: 0.281548       \n",
      "[243]\ttraining's multi_logloss: 0.12558\tvalid_1's multi_logloss: 0.281635        \n",
      "[244]\ttraining's multi_logloss: 0.125054\tvalid_1's multi_logloss: 0.281612       \n",
      "[245]\ttraining's multi_logloss: 0.124506\tvalid_1's multi_logloss: 0.28157        \n",
      "[246]\ttraining's multi_logloss: 0.123963\tvalid_1's multi_logloss: 0.281556       \n",
      "[247]\ttraining's multi_logloss: 0.123452\tvalid_1's multi_logloss: 0.281497       \n",
      "[248]\ttraining's multi_logloss: 0.122901\tvalid_1's multi_logloss: 0.281494       \n",
      "[249]\ttraining's multi_logloss: 0.122398\tvalid_1's multi_logloss: 0.281452       \n",
      "[250]\ttraining's multi_logloss: 0.121888\tvalid_1's multi_logloss: 0.281555       \n",
      "[251]\ttraining's multi_logloss: 0.121383\tvalid_1's multi_logloss: 0.281592       \n",
      "[252]\ttraining's multi_logloss: 0.120874\tvalid_1's multi_logloss: 0.281493       \n",
      "[253]\ttraining's multi_logloss: 0.120399\tvalid_1's multi_logloss: 0.281411       \n",
      "[254]\ttraining's multi_logloss: 0.119888\tvalid_1's multi_logloss: 0.281378       \n",
      "[255]\ttraining's multi_logloss: 0.119409\tvalid_1's multi_logloss: 0.281366       \n",
      "[256]\ttraining's multi_logloss: 0.118889\tvalid_1's multi_logloss: 0.281446       \n",
      "[257]\ttraining's multi_logloss: 0.118391\tvalid_1's multi_logloss: 0.281537       \n",
      "[258]\ttraining's multi_logloss: 0.117883\tvalid_1's multi_logloss: 0.281551       \n",
      "[259]\ttraining's multi_logloss: 0.117404\tvalid_1's multi_logloss: 0.281608       \n",
      "[260]\ttraining's multi_logloss: 0.116947\tvalid_1's multi_logloss: 0.281609       \n",
      "[261]\ttraining's multi_logloss: 0.116465\tvalid_1's multi_logloss: 0.28165        \n",
      "[262]\ttraining's multi_logloss: 0.115999\tvalid_1's multi_logloss: 0.28167        \n",
      "[263]\ttraining's multi_logloss: 0.115518\tvalid_1's multi_logloss: 0.281679       \n",
      "[264]\ttraining's multi_logloss: 0.11502\tvalid_1's multi_logloss: 0.281735        \n",
      "[265]\ttraining's multi_logloss: 0.114548\tvalid_1's multi_logloss: 0.281731       \n",
      "[266]\ttraining's multi_logloss: 0.114088\tvalid_1's multi_logloss: 0.281747       \n",
      "[267]\ttraining's multi_logloss: 0.113613\tvalid_1's multi_logloss: 0.281764       \n",
      "[268]\ttraining's multi_logloss: 0.113179\tvalid_1's multi_logloss: 0.281786       \n",
      "[269]\ttraining's multi_logloss: 0.112713\tvalid_1's multi_logloss: 0.281765       \n",
      "[270]\ttraining's multi_logloss: 0.112251\tvalid_1's multi_logloss: 0.28183        \n",
      "[271]\ttraining's multi_logloss: 0.111853\tvalid_1's multi_logloss: 0.281858       \n",
      "[272]\ttraining's multi_logloss: 0.111382\tvalid_1's multi_logloss: 0.281862       \n",
      "[273]\ttraining's multi_logloss: 0.110951\tvalid_1's multi_logloss: 0.281901       \n",
      "[274]\ttraining's multi_logloss: 0.110523\tvalid_1's multi_logloss: 0.281881       \n",
      "[275]\ttraining's multi_logloss: 0.110084\tvalid_1's multi_logloss: 0.281923       \n",
      "[276]\ttraining's multi_logloss: 0.109672\tvalid_1's multi_logloss: 0.281985       \n",
      "[277]\ttraining's multi_logloss: 0.109236\tvalid_1's multi_logloss: 0.282139       \n",
      "[278]\ttraining's multi_logloss: 0.108811\tvalid_1's multi_logloss: 0.282176       \n",
      "[279]\ttraining's multi_logloss: 0.10839\tvalid_1's multi_logloss: 0.282246        \n",
      "[280]\ttraining's multi_logloss: 0.107999\tvalid_1's multi_logloss: 0.282414       \n",
      "[281]\ttraining's multi_logloss: 0.107601\tvalid_1's multi_logloss: 0.282495       \n",
      "[282]\ttraining's multi_logloss: 0.107218\tvalid_1's multi_logloss: 0.282626       \n",
      "[283]\ttraining's multi_logloss: 0.106797\tvalid_1's multi_logloss: 0.282716       \n",
      "[284]\ttraining's multi_logloss: 0.106403\tvalid_1's multi_logloss: 0.282847       \n",
      "[285]\ttraining's multi_logloss: 0.106003\tvalid_1's multi_logloss: 0.282862       \n",
      "Early stopping, best iteration is:                                               \n",
      "[255]\ttraining's multi_logloss: 0.119409\tvalid_1's multi_logloss: 0.281366\n",
      "[1]\ttraining's multi_logloss: 1.83072\tvalid_1's multi_logloss: 1.83334           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.74299\tvalid_1's multi_logloss: 1.74617           \n",
      "[3]\ttraining's multi_logloss: 1.66417\tvalid_1's multi_logloss: 1.66802           \n",
      "[4]\ttraining's multi_logloss: 1.59225\tvalid_1's multi_logloss: 1.59677           \n",
      "[5]\ttraining's multi_logloss: 1.52647\tvalid_1's multi_logloss: 1.53135           \n",
      "[6]\ttraining's multi_logloss: 1.4658\tvalid_1's multi_logloss: 1.47101            \n",
      "[7]\ttraining's multi_logloss: 1.41012\tvalid_1's multi_logloss: 1.41577           \n",
      "[8]\ttraining's multi_logloss: 1.35805\tvalid_1's multi_logloss: 1.36425           \n",
      "[9]\ttraining's multi_logloss: 1.30934\tvalid_1's multi_logloss: 1.31599           \n",
      "[10]\ttraining's multi_logloss: 1.26409\tvalid_1's multi_logloss: 1.2711           \n",
      "[11]\ttraining's multi_logloss: 1.22172\tvalid_1's multi_logloss: 1.22906          \n",
      "[12]\ttraining's multi_logloss: 1.18196\tvalid_1's multi_logloss: 1.18977          \n",
      "[13]\ttraining's multi_logloss: 1.14439\tvalid_1's multi_logloss: 1.15252          \n",
      "[14]\ttraining's multi_logloss: 1.10881\tvalid_1's multi_logloss: 1.11732          \n",
      "[15]\ttraining's multi_logloss: 1.07521\tvalid_1's multi_logloss: 1.08411          \n",
      "[16]\ttraining's multi_logloss: 1.04337\tvalid_1's multi_logloss: 1.05255          \n",
      "[17]\ttraining's multi_logloss: 1.01312\tvalid_1's multi_logloss: 1.02265          \n",
      "[18]\ttraining's multi_logloss: 0.984262\tvalid_1's multi_logloss: 0.994019        \n",
      "[19]\ttraining's multi_logloss: 0.956887\tvalid_1's multi_logloss: 0.966888        \n",
      "[20]\ttraining's multi_logloss: 0.930814\tvalid_1's multi_logloss: 0.941061        \n",
      "[21]\ttraining's multi_logloss: 0.905872\tvalid_1's multi_logloss: 0.916577        \n",
      "[22]\ttraining's multi_logloss: 0.881838\tvalid_1's multi_logloss: 0.89296         \n",
      "[23]\ttraining's multi_logloss: 0.85909\tvalid_1's multi_logloss: 0.870418         \n",
      "[24]\ttraining's multi_logloss: 0.837205\tvalid_1's multi_logloss: 0.849043        \n",
      "[25]\ttraining's multi_logloss: 0.816232\tvalid_1's multi_logloss: 0.828405        \n",
      "[26]\ttraining's multi_logloss: 0.795956\tvalid_1's multi_logloss: 0.808513        \n",
      "[27]\ttraining's multi_logloss: 0.776682\tvalid_1's multi_logloss: 0.789556        \n",
      "[28]\ttraining's multi_logloss: 0.758192\tvalid_1's multi_logloss: 0.771517        \n",
      "[29]\ttraining's multi_logloss: 0.740445\tvalid_1's multi_logloss: 0.754298        \n",
      "[30]\ttraining's multi_logloss: 0.72365\tvalid_1's multi_logloss: 0.737769         \n",
      "[31]\ttraining's multi_logloss: 0.707444\tvalid_1's multi_logloss: 0.722053        \n",
      "[32]\ttraining's multi_logloss: 0.691803\tvalid_1's multi_logloss: 0.706812        \n",
      "[33]\ttraining's multi_logloss: 0.676763\tvalid_1's multi_logloss: 0.692216        \n",
      "[34]\ttraining's multi_logloss: 0.662395\tvalid_1's multi_logloss: 0.678342        \n",
      "[35]\ttraining's multi_logloss: 0.648344\tvalid_1's multi_logloss: 0.664691        \n",
      "[36]\ttraining's multi_logloss: 0.634853\tvalid_1's multi_logloss: 0.651597        \n",
      "[37]\ttraining's multi_logloss: 0.621859\tvalid_1's multi_logloss: 0.639026        \n",
      "[38]\ttraining's multi_logloss: 0.609316\tvalid_1's multi_logloss: 0.627085        \n",
      "[39]\ttraining's multi_logloss: 0.59722\tvalid_1's multi_logloss: 0.61534          \n",
      "[40]\ttraining's multi_logloss: 0.585774\tvalid_1's multi_logloss: 0.604384        \n",
      "[41]\ttraining's multi_logloss: 0.574646\tvalid_1's multi_logloss: 0.593816        \n",
      "[42]\ttraining's multi_logloss: 0.563753\tvalid_1's multi_logloss: 0.583302        \n",
      "[43]\ttraining's multi_logloss: 0.553394\tvalid_1's multi_logloss: 0.573426        \n",
      "[44]\ttraining's multi_logloss: 0.543365\tvalid_1's multi_logloss: 0.563941        \n",
      "[45]\ttraining's multi_logloss: 0.533841\tvalid_1's multi_logloss: 0.554855        \n",
      "[46]\ttraining's multi_logloss: 0.524564\tvalid_1's multi_logloss: 0.546018        \n",
      "[47]\ttraining's multi_logloss: 0.515594\tvalid_1's multi_logloss: 0.537494        \n",
      "[48]\ttraining's multi_logloss: 0.506881\tvalid_1's multi_logloss: 0.529309        \n",
      "[49]\ttraining's multi_logloss: 0.498395\tvalid_1's multi_logloss: 0.521356        \n",
      "[50]\ttraining's multi_logloss: 0.490335\tvalid_1's multi_logloss: 0.51376         \n",
      "[51]\ttraining's multi_logloss: 0.482476\tvalid_1's multi_logloss: 0.506394        \n",
      "[52]\ttraining's multi_logloss: 0.474867\tvalid_1's multi_logloss: 0.499238        \n",
      "[53]\ttraining's multi_logloss: 0.467454\tvalid_1's multi_logloss: 0.492271        \n",
      "[54]\ttraining's multi_logloss: 0.460453\tvalid_1's multi_logloss: 0.485729        \n",
      "[55]\ttraining's multi_logloss: 0.453573\tvalid_1's multi_logloss: 0.479285        \n",
      "[56]\ttraining's multi_logloss: 0.446897\tvalid_1's multi_logloss: 0.473077        \n",
      "[57]\ttraining's multi_logloss: 0.440453\tvalid_1's multi_logloss: 0.46712         \n",
      "[58]\ttraining's multi_logloss: 0.434041\tvalid_1's multi_logloss: 0.46117         \n",
      "[59]\ttraining's multi_logloss: 0.427904\tvalid_1's multi_logloss: 0.455508        \n",
      "[60]\ttraining's multi_logloss: 0.421962\tvalid_1's multi_logloss: 0.449933        \n",
      "[61]\ttraining's multi_logloss: 0.416046\tvalid_1's multi_logloss: 0.444409        \n",
      "[62]\ttraining's multi_logloss: 0.410495\tvalid_1's multi_logloss: 0.439293        \n",
      "[63]\ttraining's multi_logloss: 0.404948\tvalid_1's multi_logloss: 0.434156        \n",
      "[64]\ttraining's multi_logloss: 0.399623\tvalid_1's multi_logloss: 0.429288        \n",
      "[65]\ttraining's multi_logloss: 0.39448\tvalid_1's multi_logloss: 0.424624         \n",
      "[66]\ttraining's multi_logloss: 0.389474\tvalid_1's multi_logloss: 0.420013        \n",
      "[67]\ttraining's multi_logloss: 0.384673\tvalid_1's multi_logloss: 0.415675        \n",
      "[68]\ttraining's multi_logloss: 0.379867\tvalid_1's multi_logloss: 0.411405        \n",
      "[69]\ttraining's multi_logloss: 0.375215\tvalid_1's multi_logloss: 0.407306        \n",
      "[70]\ttraining's multi_logloss: 0.370687\tvalid_1's multi_logloss: 0.403364        \n",
      "[71]\ttraining's multi_logloss: 0.366298\tvalid_1's multi_logloss: 0.399622        \n",
      "[72]\ttraining's multi_logloss: 0.362022\tvalid_1's multi_logloss: 0.395805        \n",
      "[73]\ttraining's multi_logloss: 0.35792\tvalid_1's multi_logloss: 0.392169         \n",
      "[74]\ttraining's multi_logloss: 0.353818\tvalid_1's multi_logloss: 0.38852         \n",
      "[75]\ttraining's multi_logloss: 0.349929\tvalid_1's multi_logloss: 0.385088        \n",
      "[76]\ttraining's multi_logloss: 0.346083\tvalid_1's multi_logloss: 0.381621        \n",
      "[77]\ttraining's multi_logloss: 0.342374\tvalid_1's multi_logloss: 0.378355        \n",
      "[78]\ttraining's multi_logloss: 0.338795\tvalid_1's multi_logloss: 0.375175        \n",
      "[79]\ttraining's multi_logloss: 0.335327\tvalid_1's multi_logloss: 0.372125        \n",
      "[80]\ttraining's multi_logloss: 0.331894\tvalid_1's multi_logloss: 0.369199        \n",
      "[81]\ttraining's multi_logloss: 0.328597\tvalid_1's multi_logloss: 0.366275        \n",
      "[82]\ttraining's multi_logloss: 0.325277\tvalid_1's multi_logloss: 0.363554        \n",
      "[83]\ttraining's multi_logloss: 0.322071\tvalid_1's multi_logloss: 0.36087         \n",
      "[84]\ttraining's multi_logloss: 0.318895\tvalid_1's multi_logloss: 0.358222        \n",
      "[85]\ttraining's multi_logloss: 0.315763\tvalid_1's multi_logloss: 0.355567        \n",
      "[86]\ttraining's multi_logloss: 0.312819\tvalid_1's multi_logloss: 0.353162        \n",
      "[87]\ttraining's multi_logloss: 0.309926\tvalid_1's multi_logloss: 0.350759        \n",
      "[88]\ttraining's multi_logloss: 0.307017\tvalid_1's multi_logloss: 0.348379        \n",
      "[89]\ttraining's multi_logloss: 0.304281\tvalid_1's multi_logloss: 0.346172        \n",
      "[90]\ttraining's multi_logloss: 0.301515\tvalid_1's multi_logloss: 0.343909        \n",
      "[91]\ttraining's multi_logloss: 0.298804\tvalid_1's multi_logloss: 0.341796        \n",
      "[92]\ttraining's multi_logloss: 0.296218\tvalid_1's multi_logloss: 0.339742        \n",
      "[93]\ttraining's multi_logloss: 0.293682\tvalid_1's multi_logloss: 0.33771         \n",
      "[94]\ttraining's multi_logloss: 0.291127\tvalid_1's multi_logloss: 0.335789        \n",
      "[95]\ttraining's multi_logloss: 0.288685\tvalid_1's multi_logloss: 0.333797        \n",
      "[96]\ttraining's multi_logloss: 0.286328\tvalid_1's multi_logloss: 0.332072        \n",
      "[97]\ttraining's multi_logloss: 0.28394\tvalid_1's multi_logloss: 0.330307         \n",
      "[98]\ttraining's multi_logloss: 0.281564\tvalid_1's multi_logloss: 0.328453        \n",
      "[99]\ttraining's multi_logloss: 0.279314\tvalid_1's multi_logloss: 0.326779        \n",
      "[100]\ttraining's multi_logloss: 0.277064\tvalid_1's multi_logloss: 0.325145       \n",
      "[101]\ttraining's multi_logloss: 0.274846\tvalid_1's multi_logloss: 0.323555       \n",
      "[102]\ttraining's multi_logloss: 0.272695\tvalid_1's multi_logloss: 0.321891       \n",
      "[103]\ttraining's multi_logloss: 0.270662\tvalid_1's multi_logloss: 0.320462       \n",
      "[104]\ttraining's multi_logloss: 0.268608\tvalid_1's multi_logloss: 0.318887       \n",
      "[105]\ttraining's multi_logloss: 0.266598\tvalid_1's multi_logloss: 0.317394       \n",
      "[106]\ttraining's multi_logloss: 0.264625\tvalid_1's multi_logloss: 0.316104       \n",
      "[107]\ttraining's multi_logloss: 0.262736\tvalid_1's multi_logloss: 0.314746       \n",
      "[108]\ttraining's multi_logloss: 0.260845\tvalid_1's multi_logloss: 0.313487       \n",
      "[109]\ttraining's multi_logloss: 0.258985\tvalid_1's multi_logloss: 0.312282       \n",
      "[110]\ttraining's multi_logloss: 0.257173\tvalid_1's multi_logloss: 0.311175       \n",
      "[111]\ttraining's multi_logloss: 0.255438\tvalid_1's multi_logloss: 0.310002       \n",
      "[112]\ttraining's multi_logloss: 0.253656\tvalid_1's multi_logloss: 0.308912       \n",
      "[113]\ttraining's multi_logloss: 0.251942\tvalid_1's multi_logloss: 0.307781       \n",
      "[114]\ttraining's multi_logloss: 0.250232\tvalid_1's multi_logloss: 0.306773       \n",
      "[115]\ttraining's multi_logloss: 0.248637\tvalid_1's multi_logloss: 0.305671       \n",
      "[116]\ttraining's multi_logloss: 0.246984\tvalid_1's multi_logloss: 0.304714       \n",
      "[117]\ttraining's multi_logloss: 0.245335\tvalid_1's multi_logloss: 0.303748       \n",
      "[118]\ttraining's multi_logloss: 0.243639\tvalid_1's multi_logloss: 0.302628       \n",
      "[119]\ttraining's multi_logloss: 0.24201\tvalid_1's multi_logloss: 0.301621        \n",
      "[120]\ttraining's multi_logloss: 0.24043\tvalid_1's multi_logloss: 0.300683        \n",
      "[121]\ttraining's multi_logloss: 0.23886\tvalid_1's multi_logloss: 0.299644        \n",
      "[122]\ttraining's multi_logloss: 0.237324\tvalid_1's multi_logloss: 0.298735       \n",
      "[123]\ttraining's multi_logloss: 0.235836\tvalid_1's multi_logloss: 0.297876       \n",
      "[124]\ttraining's multi_logloss: 0.234371\tvalid_1's multi_logloss: 0.297122       \n",
      "[125]\ttraining's multi_logloss: 0.232897\tvalid_1's multi_logloss: 0.296309       \n",
      "[126]\ttraining's multi_logloss: 0.231487\tvalid_1's multi_logloss: 0.295577       \n",
      "[127]\ttraining's multi_logloss: 0.230091\tvalid_1's multi_logloss: 0.29486        \n",
      "[128]\ttraining's multi_logloss: 0.228695\tvalid_1's multi_logloss: 0.294227       \n",
      "[129]\ttraining's multi_logloss: 0.227332\tvalid_1's multi_logloss: 0.293638       \n",
      "[130]\ttraining's multi_logloss: 0.226028\tvalid_1's multi_logloss: 0.292917       \n",
      "[131]\ttraining's multi_logloss: 0.224734\tvalid_1's multi_logloss: 0.29222        \n",
      "[132]\ttraining's multi_logloss: 0.223421\tvalid_1's multi_logloss: 0.29148        \n",
      "[133]\ttraining's multi_logloss: 0.222179\tvalid_1's multi_logloss: 0.290837       \n",
      "[134]\ttraining's multi_logloss: 0.220919\tvalid_1's multi_logloss: 0.290167       \n",
      "[135]\ttraining's multi_logloss: 0.219665\tvalid_1's multi_logloss: 0.289494       \n",
      "[136]\ttraining's multi_logloss: 0.218433\tvalid_1's multi_logloss: 0.288751       \n",
      "[137]\ttraining's multi_logloss: 0.217203\tvalid_1's multi_logloss: 0.288185       \n",
      "[138]\ttraining's multi_logloss: 0.216075\tvalid_1's multi_logloss: 0.287768       \n",
      "[139]\ttraining's multi_logloss: 0.214937\tvalid_1's multi_logloss: 0.287174       \n",
      "[140]\ttraining's multi_logloss: 0.21376\tvalid_1's multi_logloss: 0.286678        \n",
      "[141]\ttraining's multi_logloss: 0.212602\tvalid_1's multi_logloss: 0.286167       \n",
      "[142]\ttraining's multi_logloss: 0.21142\tvalid_1's multi_logloss: 0.285559        \n",
      "[143]\ttraining's multi_logloss: 0.210289\tvalid_1's multi_logloss: 0.285086       \n",
      "[144]\ttraining's multi_logloss: 0.209113\tvalid_1's multi_logloss: 0.284623       \n",
      "[145]\ttraining's multi_logloss: 0.207984\tvalid_1's multi_logloss: 0.284109       \n",
      "[146]\ttraining's multi_logloss: 0.206901\tvalid_1's multi_logloss: 0.283707       \n",
      "[147]\ttraining's multi_logloss: 0.205737\tvalid_1's multi_logloss: 0.283295       \n",
      "[148]\ttraining's multi_logloss: 0.204581\tvalid_1's multi_logloss: 0.282826       \n",
      "[149]\ttraining's multi_logloss: 0.203532\tvalid_1's multi_logloss: 0.282424       \n",
      "[150]\ttraining's multi_logloss: 0.202448\tvalid_1's multi_logloss: 0.282021       \n",
      "[151]\ttraining's multi_logloss: 0.201331\tvalid_1's multi_logloss: 0.281555       \n",
      "[152]\ttraining's multi_logloss: 0.200249\tvalid_1's multi_logloss: 0.281088       \n",
      "[153]\ttraining's multi_logloss: 0.199211\tvalid_1's multi_logloss: 0.280646       \n",
      "[154]\ttraining's multi_logloss: 0.198143\tvalid_1's multi_logloss: 0.280347       \n",
      "[155]\ttraining's multi_logloss: 0.197067\tvalid_1's multi_logloss: 0.279928       \n",
      "[156]\ttraining's multi_logloss: 0.196019\tvalid_1's multi_logloss: 0.279577       \n",
      "[157]\ttraining's multi_logloss: 0.195075\tvalid_1's multi_logloss: 0.279281       \n",
      "[158]\ttraining's multi_logloss: 0.194077\tvalid_1's multi_logloss: 0.278979       \n",
      "[159]\ttraining's multi_logloss: 0.193058\tvalid_1's multi_logloss: 0.278669       \n",
      "[160]\ttraining's multi_logloss: 0.192072\tvalid_1's multi_logloss: 0.278293       \n",
      "[161]\ttraining's multi_logloss: 0.191113\tvalid_1's multi_logloss: 0.27795        \n",
      "[162]\ttraining's multi_logloss: 0.190121\tvalid_1's multi_logloss: 0.277658       \n",
      "[163]\ttraining's multi_logloss: 0.189243\tvalid_1's multi_logloss: 0.277441       \n",
      "[164]\ttraining's multi_logloss: 0.188251\tvalid_1's multi_logloss: 0.277121       \n",
      "[165]\ttraining's multi_logloss: 0.187327\tvalid_1's multi_logloss: 0.276918       \n",
      "[166]\ttraining's multi_logloss: 0.186386\tvalid_1's multi_logloss: 0.276578       \n",
      "[167]\ttraining's multi_logloss: 0.185419\tvalid_1's multi_logloss: 0.276288       \n",
      "[168]\ttraining's multi_logloss: 0.184492\tvalid_1's multi_logloss: 0.276051       \n",
      "[169]\ttraining's multi_logloss: 0.18353\tvalid_1's multi_logloss: 0.275747        \n",
      "[170]\ttraining's multi_logloss: 0.182595\tvalid_1's multi_logloss: 0.275435       \n",
      "[171]\ttraining's multi_logloss: 0.181688\tvalid_1's multi_logloss: 0.275165       \n",
      "[172]\ttraining's multi_logloss: 0.180792\tvalid_1's multi_logloss: 0.274971       \n",
      "[173]\ttraining's multi_logloss: 0.17987\tvalid_1's multi_logloss: 0.27474         \n",
      "[174]\ttraining's multi_logloss: 0.178993\tvalid_1's multi_logloss: 0.274491       \n",
      "[175]\ttraining's multi_logloss: 0.178098\tvalid_1's multi_logloss: 0.274291       \n",
      "[176]\ttraining's multi_logloss: 0.177269\tvalid_1's multi_logloss: 0.2741         \n",
      "[177]\ttraining's multi_logloss: 0.176438\tvalid_1's multi_logloss: 0.27391        \n",
      "[178]\ttraining's multi_logloss: 0.175571\tvalid_1's multi_logloss: 0.273744       \n",
      "[179]\ttraining's multi_logloss: 0.174777\tvalid_1's multi_logloss: 0.273615       \n",
      "[180]\ttraining's multi_logloss: 0.173908\tvalid_1's multi_logloss: 0.273461       \n",
      "[181]\ttraining's multi_logloss: 0.173108\tvalid_1's multi_logloss: 0.273351       \n",
      "[182]\ttraining's multi_logloss: 0.172322\tvalid_1's multi_logloss: 0.273256       \n",
      "[183]\ttraining's multi_logloss: 0.171478\tvalid_1's multi_logloss: 0.272986       \n",
      "[184]\ttraining's multi_logloss: 0.170708\tvalid_1's multi_logloss: 0.272836       \n",
      "[185]\ttraining's multi_logloss: 0.169886\tvalid_1's multi_logloss: 0.272604       \n",
      "[186]\ttraining's multi_logloss: 0.169143\tvalid_1's multi_logloss: 0.272435       \n",
      "[187]\ttraining's multi_logloss: 0.168371\tvalid_1's multi_logloss: 0.272327       \n",
      "[188]\ttraining's multi_logloss: 0.167618\tvalid_1's multi_logloss: 0.272182       \n",
      "[189]\ttraining's multi_logloss: 0.166916\tvalid_1's multi_logloss: 0.272081       \n",
      "[190]\ttraining's multi_logloss: 0.166155\tvalid_1's multi_logloss: 0.27189        \n",
      "[191]\ttraining's multi_logloss: 0.165422\tvalid_1's multi_logloss: 0.271682       \n",
      "[192]\ttraining's multi_logloss: 0.164703\tvalid_1's multi_logloss: 0.271477       \n",
      "[193]\ttraining's multi_logloss: 0.163951\tvalid_1's multi_logloss: 0.271258       \n",
      "[194]\ttraining's multi_logloss: 0.163243\tvalid_1's multi_logloss: 0.271097       \n",
      "[195]\ttraining's multi_logloss: 0.162529\tvalid_1's multi_logloss: 0.271076       \n",
      "[196]\ttraining's multi_logloss: 0.161795\tvalid_1's multi_logloss: 0.270915       \n",
      "[197]\ttraining's multi_logloss: 0.16108\tvalid_1's multi_logloss: 0.270851        \n",
      "[198]\ttraining's multi_logloss: 0.160273\tvalid_1's multi_logloss: 0.270653       \n",
      "[199]\ttraining's multi_logloss: 0.15957\tvalid_1's multi_logloss: 0.270489        \n",
      "[200]\ttraining's multi_logloss: 0.158817\tvalid_1's multi_logloss: 0.270307       \n",
      "[201]\ttraining's multi_logloss: 0.158072\tvalid_1's multi_logloss: 0.270207       \n",
      "[202]\ttraining's multi_logloss: 0.157349\tvalid_1's multi_logloss: 0.269994       \n",
      "[203]\ttraining's multi_logloss: 0.156631\tvalid_1's multi_logloss: 0.269839       \n",
      "[204]\ttraining's multi_logloss: 0.15592\tvalid_1's multi_logloss: 0.269701        \n",
      "[205]\ttraining's multi_logloss: 0.155208\tvalid_1's multi_logloss: 0.26967        \n",
      "[206]\ttraining's multi_logloss: 0.154501\tvalid_1's multi_logloss: 0.269539       \n",
      "[207]\ttraining's multi_logloss: 0.153792\tvalid_1's multi_logloss: 0.269327       \n",
      "[208]\ttraining's multi_logloss: 0.153111\tvalid_1's multi_logloss: 0.269191       \n",
      "[209]\ttraining's multi_logloss: 0.152398\tvalid_1's multi_logloss: 0.268999       \n",
      "[210]\ttraining's multi_logloss: 0.151657\tvalid_1's multi_logloss: 0.268937       \n",
      "[211]\ttraining's multi_logloss: 0.150966\tvalid_1's multi_logloss: 0.268797       \n",
      "[212]\ttraining's multi_logloss: 0.150296\tvalid_1's multi_logloss: 0.268714       \n",
      "[213]\ttraining's multi_logloss: 0.149651\tvalid_1's multi_logloss: 0.268602       \n",
      "[214]\ttraining's multi_logloss: 0.149\tvalid_1's multi_logloss: 0.268526          \n",
      "[215]\ttraining's multi_logloss: 0.148386\tvalid_1's multi_logloss: 0.268414       \n",
      "[216]\ttraining's multi_logloss: 0.147754\tvalid_1's multi_logloss: 0.268404       \n",
      "[217]\ttraining's multi_logloss: 0.147094\tvalid_1's multi_logloss: 0.268326       \n",
      "[218]\ttraining's multi_logloss: 0.146448\tvalid_1's multi_logloss: 0.268228       \n",
      "[219]\ttraining's multi_logloss: 0.145787\tvalid_1's multi_logloss: 0.268105       \n",
      "[220]\ttraining's multi_logloss: 0.145155\tvalid_1's multi_logloss: 0.268036       \n",
      "[221]\ttraining's multi_logloss: 0.144548\tvalid_1's multi_logloss: 0.268019       \n",
      "[222]\ttraining's multi_logloss: 0.143919\tvalid_1's multi_logloss: 0.267965       \n",
      "[223]\ttraining's multi_logloss: 0.143329\tvalid_1's multi_logloss: 0.267898       \n",
      "[224]\ttraining's multi_logloss: 0.142715\tvalid_1's multi_logloss: 0.267858       \n",
      "[225]\ttraining's multi_logloss: 0.142095\tvalid_1's multi_logloss: 0.267826       \n",
      "[226]\ttraining's multi_logloss: 0.141513\tvalid_1's multi_logloss: 0.26774        \n",
      "[227]\ttraining's multi_logloss: 0.1409\tvalid_1's multi_logloss: 0.267647         \n",
      "[228]\ttraining's multi_logloss: 0.140273\tvalid_1's multi_logloss: 0.267612       \n",
      "[229]\ttraining's multi_logloss: 0.139713\tvalid_1's multi_logloss: 0.267532       \n",
      "[230]\ttraining's multi_logloss: 0.139117\tvalid_1's multi_logloss: 0.267425       \n",
      "[231]\ttraining's multi_logloss: 0.138515\tvalid_1's multi_logloss: 0.26739        \n",
      "[232]\ttraining's multi_logloss: 0.137932\tvalid_1's multi_logloss: 0.267394       \n",
      "[233]\ttraining's multi_logloss: 0.137351\tvalid_1's multi_logloss: 0.267348       \n",
      "[234]\ttraining's multi_logloss: 0.136812\tvalid_1's multi_logloss: 0.267308       \n",
      "[235]\ttraining's multi_logloss: 0.136229\tvalid_1's multi_logloss: 0.267267       \n",
      "[236]\ttraining's multi_logloss: 0.135648\tvalid_1's multi_logloss: 0.267269       \n",
      "[237]\ttraining's multi_logloss: 0.135109\tvalid_1's multi_logloss: 0.267244       \n",
      "[238]\ttraining's multi_logloss: 0.134587\tvalid_1's multi_logloss: 0.267204       \n",
      "[239]\ttraining's multi_logloss: 0.134057\tvalid_1's multi_logloss: 0.267176       \n",
      "[240]\ttraining's multi_logloss: 0.133521\tvalid_1's multi_logloss: 0.26712        \n",
      "[241]\ttraining's multi_logloss: 0.133029\tvalid_1's multi_logloss: 0.267137       \n",
      "[242]\ttraining's multi_logloss: 0.132505\tvalid_1's multi_logloss: 0.267143       \n",
      "[243]\ttraining's multi_logloss: 0.131985\tvalid_1's multi_logloss: 0.267236       \n",
      "[244]\ttraining's multi_logloss: 0.131438\tvalid_1's multi_logloss: 0.267246       \n",
      "[245]\ttraining's multi_logloss: 0.130924\tvalid_1's multi_logloss: 0.267133       \n",
      "[246]\ttraining's multi_logloss: 0.1304\tvalid_1's multi_logloss: 0.2671           \n",
      "[247]\ttraining's multi_logloss: 0.1299\tvalid_1's multi_logloss: 0.267122         \n",
      "[248]\ttraining's multi_logloss: 0.129431\tvalid_1's multi_logloss: 0.267167       \n",
      "[249]\ttraining's multi_logloss: 0.128908\tvalid_1's multi_logloss: 0.267118       \n",
      "[250]\ttraining's multi_logloss: 0.1284\tvalid_1's multi_logloss: 0.267178         \n",
      "[251]\ttraining's multi_logloss: 0.127902\tvalid_1's multi_logloss: 0.267256       \n",
      "[252]\ttraining's multi_logloss: 0.127393\tvalid_1's multi_logloss: 0.267352       \n",
      "[253]\ttraining's multi_logloss: 0.126905\tvalid_1's multi_logloss: 0.267438       \n",
      "[254]\ttraining's multi_logloss: 0.1264\tvalid_1's multi_logloss: 0.267423         \n",
      "[255]\ttraining's multi_logloss: 0.125944\tvalid_1's multi_logloss: 0.267417       \n",
      "[256]\ttraining's multi_logloss: 0.125456\tvalid_1's multi_logloss: 0.267414       \n",
      "[257]\ttraining's multi_logloss: 0.124972\tvalid_1's multi_logloss: 0.267434       \n",
      "[258]\ttraining's multi_logloss: 0.124474\tvalid_1's multi_logloss: 0.267439       \n",
      "[259]\ttraining's multi_logloss: 0.124027\tvalid_1's multi_logloss: 0.267417       \n",
      "[260]\ttraining's multi_logloss: 0.123528\tvalid_1's multi_logloss: 0.267447       \n",
      "[261]\ttraining's multi_logloss: 0.12305\tvalid_1's multi_logloss: 0.267436        \n",
      "[262]\ttraining's multi_logloss: 0.122591\tvalid_1's multi_logloss: 0.26739        \n",
      "[263]\ttraining's multi_logloss: 0.122155\tvalid_1's multi_logloss: 0.267353       \n",
      "[264]\ttraining's multi_logloss: 0.121651\tvalid_1's multi_logloss: 0.267372       \n",
      "[265]\ttraining's multi_logloss: 0.121169\tvalid_1's multi_logloss: 0.267445       \n",
      "[266]\ttraining's multi_logloss: 0.120723\tvalid_1's multi_logloss: 0.26751        \n",
      "[267]\ttraining's multi_logloss: 0.120277\tvalid_1's multi_logloss: 0.267551       \n",
      "[268]\ttraining's multi_logloss: 0.119831\tvalid_1's multi_logloss: 0.267601       \n",
      "[269]\ttraining's multi_logloss: 0.119387\tvalid_1's multi_logloss: 0.267613       \n",
      "[270]\ttraining's multi_logloss: 0.118971\tvalid_1's multi_logloss: 0.267617       \n",
      "[271]\ttraining's multi_logloss: 0.118525\tvalid_1's multi_logloss: 0.267671       \n",
      "[272]\ttraining's multi_logloss: 0.118103\tvalid_1's multi_logloss: 0.267598       \n",
      "[273]\ttraining's multi_logloss: 0.117575\tvalid_1's multi_logloss: 0.267553       \n",
      "[274]\ttraining's multi_logloss: 0.11717\tvalid_1's multi_logloss: 0.267656        \n",
      "[275]\ttraining's multi_logloss: 0.116731\tvalid_1's multi_logloss: 0.267691       \n",
      "[276]\ttraining's multi_logloss: 0.116332\tvalid_1's multi_logloss: 0.267683       \n",
      "Early stopping, best iteration is:                                               \n",
      "[246]\ttraining's multi_logloss: 0.1304\tvalid_1's multi_logloss: 0.2671\n",
      "[1]\ttraining's multi_logloss: 1.50859\tvalid_1's multi_logloss: 1.51554           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.25578\tvalid_1's multi_logloss: 1.27036           \n",
      "[3]\ttraining's multi_logloss: 1.0766\tvalid_1's multi_logloss: 1.09587            \n",
      "[4]\ttraining's multi_logloss: 0.938638\tvalid_1's multi_logloss: 0.963075         \n",
      "[5]\ttraining's multi_logloss: 0.830253\tvalid_1's multi_logloss: 0.858366         \n",
      "[6]\ttraining's multi_logloss: 0.740836\tvalid_1's multi_logloss: 0.772305         \n",
      "[7]\ttraining's multi_logloss: 0.668123\tvalid_1's multi_logloss: 0.702504         \n",
      "[8]\ttraining's multi_logloss: 0.607018\tvalid_1's multi_logloss: 0.644023         \n",
      "[9]\ttraining's multi_logloss: 0.555366\tvalid_1's multi_logloss: 0.595416         \n",
      "[10]\ttraining's multi_logloss: 0.511033\tvalid_1's multi_logloss: 0.553532        \n",
      "[11]\ttraining's multi_logloss: 0.473224\tvalid_1's multi_logloss: 0.51808         \n",
      "[12]\ttraining's multi_logloss: 0.440876\tvalid_1's multi_logloss: 0.488544        \n",
      "[13]\ttraining's multi_logloss: 0.411804\tvalid_1's multi_logloss: 0.462825        \n",
      "[14]\ttraining's multi_logloss: 0.386978\tvalid_1's multi_logloss: 0.440512        \n",
      "[15]\ttraining's multi_logloss: 0.364772\tvalid_1's multi_logloss: 0.420564        \n",
      "[16]\ttraining's multi_logloss: 0.345241\tvalid_1's multi_logloss: 0.404139        \n",
      "[17]\ttraining's multi_logloss: 0.32864\tvalid_1's multi_logloss: 0.390087         \n",
      "[18]\ttraining's multi_logloss: 0.313635\tvalid_1's multi_logloss: 0.377889        \n",
      "[19]\ttraining's multi_logloss: 0.299831\tvalid_1's multi_logloss: 0.367057        \n",
      "[20]\ttraining's multi_logloss: 0.287377\tvalid_1's multi_logloss: 0.357997        \n",
      "[21]\ttraining's multi_logloss: 0.276223\tvalid_1's multi_logloss: 0.349535        \n",
      "[22]\ttraining's multi_logloss: 0.26641\tvalid_1's multi_logloss: 0.342575         \n",
      "[23]\ttraining's multi_logloss: 0.257156\tvalid_1's multi_logloss: 0.336248        \n",
      "[24]\ttraining's multi_logloss: 0.248444\tvalid_1's multi_logloss: 0.330611        \n",
      "[25]\ttraining's multi_logloss: 0.240125\tvalid_1's multi_logloss: 0.325635        \n",
      "[26]\ttraining's multi_logloss: 0.23265\tvalid_1's multi_logloss: 0.321189         \n",
      "[27]\ttraining's multi_logloss: 0.225779\tvalid_1's multi_logloss: 0.317576        \n",
      "[28]\ttraining's multi_logloss: 0.219241\tvalid_1's multi_logloss: 0.313727        \n",
      "[29]\ttraining's multi_logloss: 0.213063\tvalid_1's multi_logloss: 0.31063         \n",
      "[30]\ttraining's multi_logloss: 0.207313\tvalid_1's multi_logloss: 0.307977        \n",
      "[31]\ttraining's multi_logloss: 0.201948\tvalid_1's multi_logloss: 0.304871        \n",
      "[32]\ttraining's multi_logloss: 0.196613\tvalid_1's multi_logloss: 0.302784        \n",
      "[33]\ttraining's multi_logloss: 0.191607\tvalid_1's multi_logloss: 0.301156        \n",
      "[34]\ttraining's multi_logloss: 0.186822\tvalid_1's multi_logloss: 0.299586        \n",
      "[35]\ttraining's multi_logloss: 0.181922\tvalid_1's multi_logloss: 0.298372        \n",
      "[36]\ttraining's multi_logloss: 0.177603\tvalid_1's multi_logloss: 0.297206        \n",
      "[37]\ttraining's multi_logloss: 0.173028\tvalid_1's multi_logloss: 0.29624         \n",
      "[38]\ttraining's multi_logloss: 0.168592\tvalid_1's multi_logloss: 0.295294        \n",
      "[39]\ttraining's multi_logloss: 0.164414\tvalid_1's multi_logloss: 0.294464        \n",
      "[40]\ttraining's multi_logloss: 0.160776\tvalid_1's multi_logloss: 0.293507        \n",
      "[41]\ttraining's multi_logloss: 0.157084\tvalid_1's multi_logloss: 0.292807        \n",
      "[42]\ttraining's multi_logloss: 0.153589\tvalid_1's multi_logloss: 0.292494        \n",
      "[43]\ttraining's multi_logloss: 0.150057\tvalid_1's multi_logloss: 0.292462        \n",
      "[44]\ttraining's multi_logloss: 0.146546\tvalid_1's multi_logloss: 0.291954        \n",
      "[45]\ttraining's multi_logloss: 0.143355\tvalid_1's multi_logloss: 0.29143         \n",
      "[46]\ttraining's multi_logloss: 0.13983\tvalid_1's multi_logloss: 0.291673         \n",
      "[47]\ttraining's multi_logloss: 0.136537\tvalid_1's multi_logloss: 0.291749        \n",
      "[48]\ttraining's multi_logloss: 0.133474\tvalid_1's multi_logloss: 0.291637        \n",
      "[49]\ttraining's multi_logloss: 0.130584\tvalid_1's multi_logloss: 0.291221        \n",
      "[50]\ttraining's multi_logloss: 0.12737\tvalid_1's multi_logloss: 0.291013         \n",
      "[51]\ttraining's multi_logloss: 0.124395\tvalid_1's multi_logloss: 0.29046         \n",
      "[52]\ttraining's multi_logloss: 0.121515\tvalid_1's multi_logloss: 0.290709        \n",
      "[53]\ttraining's multi_logloss: 0.118856\tvalid_1's multi_logloss: 0.290396        \n",
      "[54]\ttraining's multi_logloss: 0.116152\tvalid_1's multi_logloss: 0.290902        \n",
      "[55]\ttraining's multi_logloss: 0.113428\tvalid_1's multi_logloss: 0.290934        \n",
      "[56]\ttraining's multi_logloss: 0.111039\tvalid_1's multi_logloss: 0.291427        \n",
      "[57]\ttraining's multi_logloss: 0.108602\tvalid_1's multi_logloss: 0.291651        \n",
      "[58]\ttraining's multi_logloss: 0.106427\tvalid_1's multi_logloss: 0.291722        \n",
      "[59]\ttraining's multi_logloss: 0.104155\tvalid_1's multi_logloss: 0.291787        \n",
      "[60]\ttraining's multi_logloss: 0.102017\tvalid_1's multi_logloss: 0.292146        \n",
      "[61]\ttraining's multi_logloss: 0.0998434\tvalid_1's multi_logloss: 0.292106       \n",
      "[62]\ttraining's multi_logloss: 0.0978721\tvalid_1's multi_logloss: 0.292708       \n",
      "[63]\ttraining's multi_logloss: 0.0955229\tvalid_1's multi_logloss: 0.293151       \n",
      "[64]\ttraining's multi_logloss: 0.0937531\tvalid_1's multi_logloss: 0.293647       \n",
      "[65]\ttraining's multi_logloss: 0.0919222\tvalid_1's multi_logloss: 0.294265       \n",
      "[66]\ttraining's multi_logloss: 0.0900508\tvalid_1's multi_logloss: 0.294693       \n",
      "[67]\ttraining's multi_logloss: 0.0883086\tvalid_1's multi_logloss: 0.295255       \n",
      "[68]\ttraining's multi_logloss: 0.086303\tvalid_1's multi_logloss: 0.295762        \n",
      "[69]\ttraining's multi_logloss: 0.0848658\tvalid_1's multi_logloss: 0.296015       \n",
      "[70]\ttraining's multi_logloss: 0.0833497\tvalid_1's multi_logloss: 0.296444       \n",
      "[71]\ttraining's multi_logloss: 0.0819528\tvalid_1's multi_logloss: 0.296763       \n",
      "[72]\ttraining's multi_logloss: 0.0803045\tvalid_1's multi_logloss: 0.297032       \n",
      "[73]\ttraining's multi_logloss: 0.0787431\tvalid_1's multi_logloss: 0.297612       \n",
      "[74]\ttraining's multi_logloss: 0.0769651\tvalid_1's multi_logloss: 0.297558       \n",
      "[75]\ttraining's multi_logloss: 0.0754296\tvalid_1's multi_logloss: 0.29802        \n",
      "[76]\ttraining's multi_logloss: 0.0741278\tvalid_1's multi_logloss: 0.298452       \n",
      "[77]\ttraining's multi_logloss: 0.0727019\tvalid_1's multi_logloss: 0.299473       \n",
      "[78]\ttraining's multi_logloss: 0.0711286\tvalid_1's multi_logloss: 0.300289       \n",
      "[79]\ttraining's multi_logloss: 0.0697788\tvalid_1's multi_logloss: 0.30054        \n",
      "[80]\ttraining's multi_logloss: 0.068395\tvalid_1's multi_logloss: 0.300967        \n",
      "[81]\ttraining's multi_logloss: 0.0668832\tvalid_1's multi_logloss: 0.301429       \n",
      "[82]\ttraining's multi_logloss: 0.0655316\tvalid_1's multi_logloss: 0.302165       \n",
      "[83]\ttraining's multi_logloss: 0.0642657\tvalid_1's multi_logloss: 0.302654       \n",
      "Early stopping, best iteration is:                                               \n",
      "[53]\ttraining's multi_logloss: 0.118856\tvalid_1's multi_logloss: 0.290396\n",
      "[1]\ttraining's multi_logloss: 1.50705\tvalid_1's multi_logloss: 1.51139           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.25667\tvalid_1's multi_logloss: 1.26415           \n",
      "[3]\ttraining's multi_logloss: 1.08029\tvalid_1's multi_logloss: 1.08999           \n",
      "[4]\ttraining's multi_logloss: 0.943931\tvalid_1's multi_logloss: 0.956922         \n",
      "[5]\ttraining's multi_logloss: 0.835615\tvalid_1's multi_logloss: 0.849904         \n",
      "[6]\ttraining's multi_logloss: 0.747954\tvalid_1's multi_logloss: 0.76503          \n",
      "[7]\ttraining's multi_logloss: 0.67463\tvalid_1's multi_logloss: 0.694961          \n",
      "[8]\ttraining's multi_logloss: 0.613788\tvalid_1's multi_logloss: 0.637395         \n",
      "[9]\ttraining's multi_logloss: 0.561806\tvalid_1's multi_logloss: 0.58742          \n",
      "[10]\ttraining's multi_logloss: 0.517926\tvalid_1's multi_logloss: 0.546295        \n",
      "[11]\ttraining's multi_logloss: 0.479916\tvalid_1's multi_logloss: 0.510506        \n",
      "[12]\ttraining's multi_logloss: 0.446827\tvalid_1's multi_logloss: 0.480116        \n",
      "[13]\ttraining's multi_logloss: 0.418153\tvalid_1's multi_logloss: 0.454021        \n",
      "[14]\ttraining's multi_logloss: 0.393262\tvalid_1's multi_logloss: 0.431883        \n",
      "[15]\ttraining's multi_logloss: 0.371534\tvalid_1's multi_logloss: 0.412348        \n",
      "[16]\ttraining's multi_logloss: 0.352465\tvalid_1's multi_logloss: 0.395883        \n",
      "[17]\ttraining's multi_logloss: 0.335005\tvalid_1's multi_logloss: 0.38086         \n",
      "[18]\ttraining's multi_logloss: 0.319597\tvalid_1's multi_logloss: 0.368945        \n",
      "[19]\ttraining's multi_logloss: 0.305702\tvalid_1's multi_logloss: 0.357955        \n",
      "[20]\ttraining's multi_logloss: 0.292975\tvalid_1's multi_logloss: 0.348222        \n",
      "[21]\ttraining's multi_logloss: 0.281433\tvalid_1's multi_logloss: 0.340004        \n",
      "[22]\ttraining's multi_logloss: 0.270686\tvalid_1's multi_logloss: 0.332316        \n",
      "[23]\ttraining's multi_logloss: 0.260984\tvalid_1's multi_logloss: 0.326116        \n",
      "[24]\ttraining's multi_logloss: 0.252063\tvalid_1's multi_logloss: 0.320239        \n",
      "[25]\ttraining's multi_logloss: 0.244062\tvalid_1's multi_logloss: 0.315689        \n",
      "[26]\ttraining's multi_logloss: 0.236139\tvalid_1's multi_logloss: 0.311753        \n",
      "[27]\ttraining's multi_logloss: 0.228804\tvalid_1's multi_logloss: 0.308365        \n",
      "[28]\ttraining's multi_logloss: 0.222206\tvalid_1's multi_logloss: 0.305176        \n",
      "[29]\ttraining's multi_logloss: 0.216081\tvalid_1's multi_logloss: 0.302841        \n",
      "[30]\ttraining's multi_logloss: 0.20979\tvalid_1's multi_logloss: 0.299818         \n",
      "[31]\ttraining's multi_logloss: 0.204196\tvalid_1's multi_logloss: 0.297743        \n",
      "[32]\ttraining's multi_logloss: 0.198133\tvalid_1's multi_logloss: 0.295666        \n",
      "[33]\ttraining's multi_logloss: 0.192724\tvalid_1's multi_logloss: 0.293711        \n",
      "[34]\ttraining's multi_logloss: 0.187655\tvalid_1's multi_logloss: 0.292699        \n",
      "[35]\ttraining's multi_logloss: 0.182539\tvalid_1's multi_logloss: 0.291335        \n",
      "[36]\ttraining's multi_logloss: 0.17784\tvalid_1's multi_logloss: 0.289811         \n",
      "[37]\ttraining's multi_logloss: 0.173151\tvalid_1's multi_logloss: 0.288683        \n",
      "[38]\ttraining's multi_logloss: 0.168722\tvalid_1's multi_logloss: 0.287918        \n",
      "[39]\ttraining's multi_logloss: 0.164538\tvalid_1's multi_logloss: 0.287159        \n",
      "[40]\ttraining's multi_logloss: 0.160435\tvalid_1's multi_logloss: 0.286848        \n",
      "[41]\ttraining's multi_logloss: 0.15648\tvalid_1's multi_logloss: 0.28605          \n",
      "[42]\ttraining's multi_logloss: 0.152746\tvalid_1's multi_logloss: 0.285916        \n",
      "[43]\ttraining's multi_logloss: 0.148958\tvalid_1's multi_logloss: 0.285305        \n",
      "[44]\ttraining's multi_logloss: 0.145595\tvalid_1's multi_logloss: 0.285003        \n",
      "[45]\ttraining's multi_logloss: 0.142247\tvalid_1's multi_logloss: 0.284727        \n",
      "[46]\ttraining's multi_logloss: 0.138755\tvalid_1's multi_logloss: 0.284516        \n",
      "[47]\ttraining's multi_logloss: 0.135577\tvalid_1's multi_logloss: 0.284518        \n",
      "[48]\ttraining's multi_logloss: 0.132548\tvalid_1's multi_logloss: 0.284366        \n",
      "[49]\ttraining's multi_logloss: 0.129534\tvalid_1's multi_logloss: 0.284258        \n",
      "[50]\ttraining's multi_logloss: 0.126646\tvalid_1's multi_logloss: 0.284223        \n",
      "[51]\ttraining's multi_logloss: 0.123765\tvalid_1's multi_logloss: 0.284217        \n",
      "[52]\ttraining's multi_logloss: 0.120859\tvalid_1's multi_logloss: 0.284288        \n",
      "[53]\ttraining's multi_logloss: 0.118182\tvalid_1's multi_logloss: 0.284205        \n",
      "[54]\ttraining's multi_logloss: 0.115515\tvalid_1's multi_logloss: 0.284195        \n",
      "[55]\ttraining's multi_logloss: 0.112907\tvalid_1's multi_logloss: 0.284149        \n",
      "[56]\ttraining's multi_logloss: 0.110341\tvalid_1's multi_logloss: 0.284479        \n",
      "[57]\ttraining's multi_logloss: 0.107681\tvalid_1's multi_logloss: 0.284445        \n",
      "[58]\ttraining's multi_logloss: 0.105242\tvalid_1's multi_logloss: 0.284862        \n",
      "[59]\ttraining's multi_logloss: 0.103043\tvalid_1's multi_logloss: 0.285161        \n",
      "[60]\ttraining's multi_logloss: 0.100828\tvalid_1's multi_logloss: 0.285847        \n",
      "[61]\ttraining's multi_logloss: 0.0987216\tvalid_1's multi_logloss: 0.286253       \n",
      "[62]\ttraining's multi_logloss: 0.0967947\tvalid_1's multi_logloss: 0.286237       \n",
      "[63]\ttraining's multi_logloss: 0.0947287\tvalid_1's multi_logloss: 0.28687        \n",
      "[64]\ttraining's multi_logloss: 0.0928101\tvalid_1's multi_logloss: 0.287243       \n",
      "[65]\ttraining's multi_logloss: 0.090672\tvalid_1's multi_logloss: 0.287464        \n",
      "[66]\ttraining's multi_logloss: 0.0889306\tvalid_1's multi_logloss: 0.288003       \n",
      "[67]\ttraining's multi_logloss: 0.0870582\tvalid_1's multi_logloss: 0.288537       \n",
      "[68]\ttraining's multi_logloss: 0.0852942\tvalid_1's multi_logloss: 0.289327       \n",
      "[69]\ttraining's multi_logloss: 0.0836236\tvalid_1's multi_logloss: 0.289813       \n",
      "[70]\ttraining's multi_logloss: 0.0817315\tvalid_1's multi_logloss: 0.290022       \n",
      "[71]\ttraining's multi_logloss: 0.0802021\tvalid_1's multi_logloss: 0.290607       \n",
      "[72]\ttraining's multi_logloss: 0.0784807\tvalid_1's multi_logloss: 0.290836       \n",
      "[73]\ttraining's multi_logloss: 0.0768739\tvalid_1's multi_logloss: 0.291653       \n",
      "[74]\ttraining's multi_logloss: 0.075208\tvalid_1's multi_logloss: 0.29206         \n",
      "[75]\ttraining's multi_logloss: 0.0736548\tvalid_1's multi_logloss: 0.292824       \n",
      "[76]\ttraining's multi_logloss: 0.0722674\tvalid_1's multi_logloss: 0.293729       \n",
      "[77]\ttraining's multi_logloss: 0.0707183\tvalid_1's multi_logloss: 0.294423       \n",
      "[78]\ttraining's multi_logloss: 0.0692467\tvalid_1's multi_logloss: 0.294999       \n",
      "[79]\ttraining's multi_logloss: 0.0680527\tvalid_1's multi_logloss: 0.295601       \n",
      "[80]\ttraining's multi_logloss: 0.0666612\tvalid_1's multi_logloss: 0.296467       \n",
      "[81]\ttraining's multi_logloss: 0.0653\tvalid_1's multi_logloss: 0.29744           \n",
      "[82]\ttraining's multi_logloss: 0.064034\tvalid_1's multi_logloss: 0.297749        \n",
      "[83]\ttraining's multi_logloss: 0.0628021\tvalid_1's multi_logloss: 0.298894       \n",
      "[84]\ttraining's multi_logloss: 0.061645\tvalid_1's multi_logloss: 0.299714        \n",
      "[85]\ttraining's multi_logloss: 0.0604788\tvalid_1's multi_logloss: 0.300559       \n",
      "Early stopping, best iteration is:                                               \n",
      "[55]\ttraining's multi_logloss: 0.112907\tvalid_1's multi_logloss: 0.284149\n",
      "[1]\ttraining's multi_logloss: 1.51013\tvalid_1's multi_logloss: 1.51446           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.25914\tvalid_1's multi_logloss: 1.26568           \n",
      "[3]\ttraining's multi_logloss: 1.08162\tvalid_1's multi_logloss: 1.09021           \n",
      "[4]\ttraining's multi_logloss: 0.945724\tvalid_1's multi_logloss: 0.956904         \n",
      "[5]\ttraining's multi_logloss: 0.83608\tvalid_1's multi_logloss: 0.848967          \n",
      "[6]\ttraining's multi_logloss: 0.747269\tvalid_1's multi_logloss: 0.76165          \n",
      "[7]\ttraining's multi_logloss: 0.675069\tvalid_1's multi_logloss: 0.69123          \n",
      "[8]\ttraining's multi_logloss: 0.614684\tvalid_1's multi_logloss: 0.632857         \n",
      "[9]\ttraining's multi_logloss: 0.562244\tvalid_1's multi_logloss: 0.582323         \n",
      "[10]\ttraining's multi_logloss: 0.518624\tvalid_1's multi_logloss: 0.540782        \n",
      "[11]\ttraining's multi_logloss: 0.481402\tvalid_1's multi_logloss: 0.505724        \n",
      "[12]\ttraining's multi_logloss: 0.448865\tvalid_1's multi_logloss: 0.474991        \n",
      "[13]\ttraining's multi_logloss: 0.420706\tvalid_1's multi_logloss: 0.449159        \n",
      "[14]\ttraining's multi_logloss: 0.395902\tvalid_1's multi_logloss: 0.426538        \n",
      "[15]\ttraining's multi_logloss: 0.37405\tvalid_1's multi_logloss: 0.406818         \n",
      "[16]\ttraining's multi_logloss: 0.354767\tvalid_1's multi_logloss: 0.389974        \n",
      "[17]\ttraining's multi_logloss: 0.338064\tvalid_1's multi_logloss: 0.375331        \n",
      "[18]\ttraining's multi_logloss: 0.322797\tvalid_1's multi_logloss: 0.362254        \n",
      "[19]\ttraining's multi_logloss: 0.309291\tvalid_1's multi_logloss: 0.351511        \n",
      "[20]\ttraining's multi_logloss: 0.29671\tvalid_1's multi_logloss: 0.341284         \n",
      "[21]\ttraining's multi_logloss: 0.285236\tvalid_1's multi_logloss: 0.333102        \n",
      "[22]\ttraining's multi_logloss: 0.274745\tvalid_1's multi_logloss: 0.325782        \n",
      "[23]\ttraining's multi_logloss: 0.26549\tvalid_1's multi_logloss: 0.319762         \n",
      "[24]\ttraining's multi_logloss: 0.256706\tvalid_1's multi_logloss: 0.313858        \n",
      "[25]\ttraining's multi_logloss: 0.248435\tvalid_1's multi_logloss: 0.308936        \n",
      "[26]\ttraining's multi_logloss: 0.240701\tvalid_1's multi_logloss: 0.304372        \n",
      "[27]\ttraining's multi_logloss: 0.233594\tvalid_1's multi_logloss: 0.300385        \n",
      "[28]\ttraining's multi_logloss: 0.226647\tvalid_1's multi_logloss: 0.296799        \n",
      "[29]\ttraining's multi_logloss: 0.220552\tvalid_1's multi_logloss: 0.293951        \n",
      "[30]\ttraining's multi_logloss: 0.214641\tvalid_1's multi_logloss: 0.290559        \n",
      "[31]\ttraining's multi_logloss: 0.209377\tvalid_1's multi_logloss: 0.288029        \n",
      "[32]\ttraining's multi_logloss: 0.203921\tvalid_1's multi_logloss: 0.285858        \n",
      "[33]\ttraining's multi_logloss: 0.198705\tvalid_1's multi_logloss: 0.283691        \n",
      "[34]\ttraining's multi_logloss: 0.193597\tvalid_1's multi_logloss: 0.281777        \n",
      "[35]\ttraining's multi_logloss: 0.188726\tvalid_1's multi_logloss: 0.280506        \n",
      "[36]\ttraining's multi_logloss: 0.184199\tvalid_1's multi_logloss: 0.279508        \n",
      "[37]\ttraining's multi_logloss: 0.179634\tvalid_1's multi_logloss: 0.277678        \n",
      "[38]\ttraining's multi_logloss: 0.174959\tvalid_1's multi_logloss: 0.276057        \n",
      "[39]\ttraining's multi_logloss: 0.170853\tvalid_1's multi_logloss: 0.275112        \n",
      "[40]\ttraining's multi_logloss: 0.166904\tvalid_1's multi_logloss: 0.274286        \n",
      "[41]\ttraining's multi_logloss: 0.163076\tvalid_1's multi_logloss: 0.274045        \n",
      "[42]\ttraining's multi_logloss: 0.159047\tvalid_1's multi_logloss: 0.273127        \n",
      "[43]\ttraining's multi_logloss: 0.155258\tvalid_1's multi_logloss: 0.272467        \n",
      "[44]\ttraining's multi_logloss: 0.151673\tvalid_1's multi_logloss: 0.271795        \n",
      "[45]\ttraining's multi_logloss: 0.148289\tvalid_1's multi_logloss: 0.271341        \n",
      "[46]\ttraining's multi_logloss: 0.144537\tvalid_1's multi_logloss: 0.270841        \n",
      "[47]\ttraining's multi_logloss: 0.141287\tvalid_1's multi_logloss: 0.270736        \n",
      "[48]\ttraining's multi_logloss: 0.138216\tvalid_1's multi_logloss: 0.270276        \n",
      "[49]\ttraining's multi_logloss: 0.135047\tvalid_1's multi_logloss: 0.26997         \n",
      "[50]\ttraining's multi_logloss: 0.132212\tvalid_1's multi_logloss: 0.269739        \n",
      "[51]\ttraining's multi_logloss: 0.129036\tvalid_1's multi_logloss: 0.269417        \n",
      "[52]\ttraining's multi_logloss: 0.126487\tvalid_1's multi_logloss: 0.269056        \n",
      "[53]\ttraining's multi_logloss: 0.124002\tvalid_1's multi_logloss: 0.268993        \n",
      "[54]\ttraining's multi_logloss: 0.121377\tvalid_1's multi_logloss: 0.268882        \n",
      "[55]\ttraining's multi_logloss: 0.118722\tvalid_1's multi_logloss: 0.268779        \n",
      "[56]\ttraining's multi_logloss: 0.1163\tvalid_1's multi_logloss: 0.268573          \n",
      "[57]\ttraining's multi_logloss: 0.113677\tvalid_1's multi_logloss: 0.268574        \n",
      "[58]\ttraining's multi_logloss: 0.111368\tvalid_1's multi_logloss: 0.268917        \n",
      "[59]\ttraining's multi_logloss: 0.109106\tvalid_1's multi_logloss: 0.269089        \n",
      "[60]\ttraining's multi_logloss: 0.106757\tvalid_1's multi_logloss: 0.269758        \n",
      "[61]\ttraining's multi_logloss: 0.104679\tvalid_1's multi_logloss: 0.269317        \n",
      "[62]\ttraining's multi_logloss: 0.102647\tvalid_1's multi_logloss: 0.269754        \n",
      "[63]\ttraining's multi_logloss: 0.100527\tvalid_1's multi_logloss: 0.270142        \n",
      "[64]\ttraining's multi_logloss: 0.0986385\tvalid_1's multi_logloss: 0.270608       \n",
      "[65]\ttraining's multi_logloss: 0.0965582\tvalid_1's multi_logloss: 0.270794       \n",
      "[66]\ttraining's multi_logloss: 0.0946844\tvalid_1's multi_logloss: 0.271021       \n",
      "[67]\ttraining's multi_logloss: 0.0926219\tvalid_1's multi_logloss: 0.271198       \n",
      "[68]\ttraining's multi_logloss: 0.0907299\tvalid_1's multi_logloss: 0.271718       \n",
      "[69]\ttraining's multi_logloss: 0.0887947\tvalid_1's multi_logloss: 0.272046       \n",
      "[70]\ttraining's multi_logloss: 0.0870916\tvalid_1's multi_logloss: 0.27273        \n",
      "[71]\ttraining's multi_logloss: 0.0852809\tvalid_1's multi_logloss: 0.273135       \n",
      "[72]\ttraining's multi_logloss: 0.0836717\tvalid_1's multi_logloss: 0.273615       \n",
      "[73]\ttraining's multi_logloss: 0.0819651\tvalid_1's multi_logloss: 0.274346       \n",
      "[74]\ttraining's multi_logloss: 0.0803402\tvalid_1's multi_logloss: 0.274888       \n",
      "[75]\ttraining's multi_logloss: 0.0787273\tvalid_1's multi_logloss: 0.275478       \n",
      "[76]\ttraining's multi_logloss: 0.0772744\tvalid_1's multi_logloss: 0.276038       \n",
      "[77]\ttraining's multi_logloss: 0.0757281\tvalid_1's multi_logloss: 0.276293       \n",
      "[78]\ttraining's multi_logloss: 0.074092\tvalid_1's multi_logloss: 0.276809        \n",
      "[79]\ttraining's multi_logloss: 0.0727641\tvalid_1's multi_logloss: 0.277222       \n",
      "[80]\ttraining's multi_logloss: 0.0713781\tvalid_1's multi_logloss: 0.278089       \n",
      "[81]\ttraining's multi_logloss: 0.0701045\tvalid_1's multi_logloss: 0.278924       \n",
      "[82]\ttraining's multi_logloss: 0.0687536\tvalid_1's multi_logloss: 0.279152       \n",
      "[83]\ttraining's multi_logloss: 0.0675688\tvalid_1's multi_logloss: 0.27958        \n",
      "[84]\ttraining's multi_logloss: 0.0663796\tvalid_1's multi_logloss: 0.280248       \n",
      "[85]\ttraining's multi_logloss: 0.0650255\tvalid_1's multi_logloss: 0.280612       \n",
      "[86]\ttraining's multi_logloss: 0.0637343\tvalid_1's multi_logloss: 0.281319       \n",
      "Early stopping, best iteration is:                                               \n",
      "[56]\ttraining's multi_logloss: 0.1163\tvalid_1's multi_logloss: 0.268573\n",
      "[1]\ttraining's multi_logloss: 1.39125\tvalid_1's multi_logloss: 1.40159           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.11199\tvalid_1's multi_logloss: 1.13029           \n",
      "[3]\ttraining's multi_logloss: 0.924936\tvalid_1's multi_logloss: 0.948788         \n",
      "[4]\ttraining's multi_logloss: 0.7883\tvalid_1's multi_logloss: 0.816609           \n",
      "[5]\ttraining's multi_logloss: 0.685508\tvalid_1's multi_logloss: 0.718251         \n",
      "[6]\ttraining's multi_logloss: 0.603383\tvalid_1's multi_logloss: 0.639909         \n",
      "[7]\ttraining's multi_logloss: 0.538207\tvalid_1's multi_logloss: 0.578158         \n",
      "[8]\ttraining's multi_logloss: 0.484855\tvalid_1's multi_logloss: 0.528034         \n",
      "[9]\ttraining's multi_logloss: 0.440614\tvalid_1's multi_logloss: 0.487563         \n",
      "[10]\ttraining's multi_logloss: 0.404824\tvalid_1's multi_logloss: 0.455239        \n",
      "[11]\ttraining's multi_logloss: 0.374006\tvalid_1's multi_logloss: 0.427832        \n",
      "[12]\ttraining's multi_logloss: 0.349215\tvalid_1's multi_logloss: 0.406623        \n",
      "[13]\ttraining's multi_logloss: 0.327123\tvalid_1's multi_logloss: 0.388892        \n",
      "[14]\ttraining's multi_logloss: 0.308225\tvalid_1's multi_logloss: 0.372881        \n",
      "[15]\ttraining's multi_logloss: 0.29171\tvalid_1's multi_logloss: 0.360761         \n",
      "[16]\ttraining's multi_logloss: 0.27705\tvalid_1's multi_logloss: 0.35008          \n",
      "[17]\ttraining's multi_logloss: 0.264379\tvalid_1's multi_logloss: 0.340463        \n",
      "[18]\ttraining's multi_logloss: 0.252787\tvalid_1's multi_logloss: 0.333304        \n",
      "[19]\ttraining's multi_logloss: 0.242202\tvalid_1's multi_logloss: 0.327634        \n",
      "[20]\ttraining's multi_logloss: 0.232393\tvalid_1's multi_logloss: 0.322763        \n",
      "[21]\ttraining's multi_logloss: 0.223666\tvalid_1's multi_logloss: 0.318194        \n",
      "[22]\ttraining's multi_logloss: 0.215622\tvalid_1's multi_logloss: 0.314201        \n",
      "[23]\ttraining's multi_logloss: 0.207893\tvalid_1's multi_logloss: 0.310828        \n",
      "[24]\ttraining's multi_logloss: 0.20082\tvalid_1's multi_logloss: 0.308342         \n",
      "[25]\ttraining's multi_logloss: 0.193662\tvalid_1's multi_logloss: 0.305966        \n",
      "[26]\ttraining's multi_logloss: 0.187461\tvalid_1's multi_logloss: 0.303275        \n",
      "[27]\ttraining's multi_logloss: 0.181181\tvalid_1's multi_logloss: 0.30177         \n",
      "[28]\ttraining's multi_logloss: 0.17491\tvalid_1's multi_logloss: 0.300879         \n",
      "[29]\ttraining's multi_logloss: 0.169347\tvalid_1's multi_logloss: 0.300123        \n",
      "[30]\ttraining's multi_logloss: 0.163866\tvalid_1's multi_logloss: 0.298911        \n",
      "[31]\ttraining's multi_logloss: 0.158991\tvalid_1's multi_logloss: 0.297908        \n",
      "[32]\ttraining's multi_logloss: 0.154042\tvalid_1's multi_logloss: 0.297007        \n",
      "[33]\ttraining's multi_logloss: 0.149088\tvalid_1's multi_logloss: 0.296298        \n",
      "[34]\ttraining's multi_logloss: 0.144572\tvalid_1's multi_logloss: 0.295974        \n",
      "[35]\ttraining's multi_logloss: 0.140023\tvalid_1's multi_logloss: 0.295536        \n",
      "[36]\ttraining's multi_logloss: 0.135737\tvalid_1's multi_logloss: 0.295552        \n",
      "[37]\ttraining's multi_logloss: 0.131742\tvalid_1's multi_logloss: 0.295286        \n",
      "[38]\ttraining's multi_logloss: 0.127861\tvalid_1's multi_logloss: 0.295219        \n",
      "[39]\ttraining's multi_logloss: 0.123834\tvalid_1's multi_logloss: 0.295802        \n",
      "[40]\ttraining's multi_logloss: 0.119559\tvalid_1's multi_logloss: 0.295612        \n",
      "[41]\ttraining's multi_logloss: 0.115817\tvalid_1's multi_logloss: 0.295441        \n",
      "[42]\ttraining's multi_logloss: 0.112038\tvalid_1's multi_logloss: 0.295021        \n",
      "[43]\ttraining's multi_logloss: 0.108637\tvalid_1's multi_logloss: 0.294907        \n",
      "[44]\ttraining's multi_logloss: 0.105382\tvalid_1's multi_logloss: 0.295567        \n",
      "[45]\ttraining's multi_logloss: 0.101961\tvalid_1's multi_logloss: 0.295772        \n",
      "[46]\ttraining's multi_logloss: 0.099122\tvalid_1's multi_logloss: 0.296096        \n",
      "[47]\ttraining's multi_logloss: 0.0959665\tvalid_1's multi_logloss: 0.29644        \n",
      "[48]\ttraining's multi_logloss: 0.0933911\tvalid_1's multi_logloss: 0.297218       \n",
      "[49]\ttraining's multi_logloss: 0.0909428\tvalid_1's multi_logloss: 0.297857       \n",
      "[50]\ttraining's multi_logloss: 0.0884372\tvalid_1's multi_logloss: 0.298084       \n",
      "[51]\ttraining's multi_logloss: 0.0859836\tvalid_1's multi_logloss: 0.298569       \n",
      "[52]\ttraining's multi_logloss: 0.083591\tvalid_1's multi_logloss: 0.299119        \n",
      "[53]\ttraining's multi_logloss: 0.0809836\tvalid_1's multi_logloss: 0.299773       \n",
      "[54]\ttraining's multi_logloss: 0.078831\tvalid_1's multi_logloss: 0.300826        \n",
      "[55]\ttraining's multi_logloss: 0.0763626\tvalid_1's multi_logloss: 0.302186       \n",
      "[56]\ttraining's multi_logloss: 0.0743009\tvalid_1's multi_logloss: 0.302956       \n",
      "[57]\ttraining's multi_logloss: 0.0722861\tvalid_1's multi_logloss: 0.304109       \n",
      "[58]\ttraining's multi_logloss: 0.0703965\tvalid_1's multi_logloss: 0.305017       \n",
      "[59]\ttraining's multi_logloss: 0.0683965\tvalid_1's multi_logloss: 0.305417       \n",
      "[60]\ttraining's multi_logloss: 0.0664805\tvalid_1's multi_logloss: 0.30601        \n",
      "[61]\ttraining's multi_logloss: 0.0645486\tvalid_1's multi_logloss: 0.307468       \n",
      "[62]\ttraining's multi_logloss: 0.0627059\tvalid_1's multi_logloss: 0.308698       \n",
      "[63]\ttraining's multi_logloss: 0.0608847\tvalid_1's multi_logloss: 0.309507       \n",
      "[64]\ttraining's multi_logloss: 0.0592524\tvalid_1's multi_logloss: 0.310946       \n",
      "[65]\ttraining's multi_logloss: 0.0578158\tvalid_1's multi_logloss: 0.311551       \n",
      "[66]\ttraining's multi_logloss: 0.0560908\tvalid_1's multi_logloss: 0.312755       \n",
      "[67]\ttraining's multi_logloss: 0.0545892\tvalid_1's multi_logloss: 0.31423        \n",
      "[68]\ttraining's multi_logloss: 0.0529942\tvalid_1's multi_logloss: 0.31441        \n",
      "[69]\ttraining's multi_logloss: 0.0514828\tvalid_1's multi_logloss: 0.315735       \n",
      "[70]\ttraining's multi_logloss: 0.0499058\tvalid_1's multi_logloss: 0.316642       \n",
      "[71]\ttraining's multi_logloss: 0.0483765\tvalid_1's multi_logloss: 0.317418       \n",
      "[72]\ttraining's multi_logloss: 0.0472886\tvalid_1's multi_logloss: 0.318722       \n",
      "[73]\ttraining's multi_logloss: 0.0460329\tvalid_1's multi_logloss: 0.32034        \n",
      "Early stopping, best iteration is:                                               \n",
      "[43]\ttraining's multi_logloss: 0.108637\tvalid_1's multi_logloss: 0.294907\n",
      "[1]\ttraining's multi_logloss: 1.38949\tvalid_1's multi_logloss: 1.39525           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.11268\tvalid_1's multi_logloss: 1.12274           \n",
      "[3]\ttraining's multi_logloss: 0.929652\tvalid_1's multi_logloss: 0.943154         \n",
      "[4]\ttraining's multi_logloss: 0.794659\tvalid_1's multi_logloss: 0.810578         \n",
      "[5]\ttraining's multi_logloss: 0.691557\tvalid_1's multi_logloss: 0.710957         \n",
      "[6]\ttraining's multi_logloss: 0.609789\tvalid_1's multi_logloss: 0.632396         \n",
      "[7]\ttraining's multi_logloss: 0.544518\tvalid_1's multi_logloss: 0.570788         \n",
      "[8]\ttraining's multi_logloss: 0.490932\tvalid_1's multi_logloss: 0.520178         \n",
      "[9]\ttraining's multi_logloss: 0.44703\tvalid_1's multi_logloss: 0.480331          \n",
      "[10]\ttraining's multi_logloss: 0.410406\tvalid_1's multi_logloss: 0.447345        \n",
      "[11]\ttraining's multi_logloss: 0.379702\tvalid_1's multi_logloss: 0.420592        \n",
      "[12]\ttraining's multi_logloss: 0.354521\tvalid_1's multi_logloss: 0.398745        \n",
      "[13]\ttraining's multi_logloss: 0.332182\tvalid_1's multi_logloss: 0.38026         \n",
      "[14]\ttraining's multi_logloss: 0.313259\tvalid_1's multi_logloss: 0.365088        \n",
      "[15]\ttraining's multi_logloss: 0.295805\tvalid_1's multi_logloss: 0.351537        \n",
      "[16]\ttraining's multi_logloss: 0.280644\tvalid_1's multi_logloss: 0.3405          \n",
      "[17]\ttraining's multi_logloss: 0.266522\tvalid_1's multi_logloss: 0.331097        \n",
      "[18]\ttraining's multi_logloss: 0.254556\tvalid_1's multi_logloss: 0.32352         \n",
      "[19]\ttraining's multi_logloss: 0.244155\tvalid_1's multi_logloss: 0.317824        \n",
      "[20]\ttraining's multi_logloss: 0.233907\tvalid_1's multi_logloss: 0.312691        \n",
      "[21]\ttraining's multi_logloss: 0.22471\tvalid_1's multi_logloss: 0.307873         \n",
      "[22]\ttraining's multi_logloss: 0.216302\tvalid_1's multi_logloss: 0.304158        \n",
      "[23]\ttraining's multi_logloss: 0.208078\tvalid_1's multi_logloss: 0.301547        \n",
      "[24]\ttraining's multi_logloss: 0.200422\tvalid_1's multi_logloss: 0.298208        \n",
      "[25]\ttraining's multi_logloss: 0.193383\tvalid_1's multi_logloss: 0.296133        \n",
      "[26]\ttraining's multi_logloss: 0.186792\tvalid_1's multi_logloss: 0.29407         \n",
      "[27]\ttraining's multi_logloss: 0.180004\tvalid_1's multi_logloss: 0.292603        \n",
      "[28]\ttraining's multi_logloss: 0.174058\tvalid_1's multi_logloss: 0.291256        \n",
      "[29]\ttraining's multi_logloss: 0.16872\tvalid_1's multi_logloss: 0.289697         \n",
      "[30]\ttraining's multi_logloss: 0.163164\tvalid_1's multi_logloss: 0.288416        \n",
      "[31]\ttraining's multi_logloss: 0.157412\tvalid_1's multi_logloss: 0.287349        \n",
      "[32]\ttraining's multi_logloss: 0.152035\tvalid_1's multi_logloss: 0.286961        \n",
      "[33]\ttraining's multi_logloss: 0.147257\tvalid_1's multi_logloss: 0.28678         \n",
      "[34]\ttraining's multi_logloss: 0.14245\tvalid_1's multi_logloss: 0.28552          \n",
      "[35]\ttraining's multi_logloss: 0.138298\tvalid_1's multi_logloss: 0.284964        \n",
      "[36]\ttraining's multi_logloss: 0.133939\tvalid_1's multi_logloss: 0.284267        \n",
      "[37]\ttraining's multi_logloss: 0.129618\tvalid_1's multi_logloss: 0.284368        \n",
      "[38]\ttraining's multi_logloss: 0.12561\tvalid_1's multi_logloss: 0.283915         \n",
      "[39]\ttraining's multi_logloss: 0.121337\tvalid_1's multi_logloss: 0.28469         \n",
      "[40]\ttraining's multi_logloss: 0.117446\tvalid_1's multi_logloss: 0.284638        \n",
      "[41]\ttraining's multi_logloss: 0.113443\tvalid_1's multi_logloss: 0.284515        \n",
      "[42]\ttraining's multi_logloss: 0.109842\tvalid_1's multi_logloss: 0.284651        \n",
      "[43]\ttraining's multi_logloss: 0.106494\tvalid_1's multi_logloss: 0.284752        \n",
      "[44]\ttraining's multi_logloss: 0.10322\tvalid_1's multi_logloss: 0.28514          \n",
      "[45]\ttraining's multi_logloss: 0.0999751\tvalid_1's multi_logloss: 0.285546       \n",
      "[46]\ttraining's multi_logloss: 0.0970632\tvalid_1's multi_logloss: 0.286336       \n",
      "[47]\ttraining's multi_logloss: 0.094166\tvalid_1's multi_logloss: 0.287067        \n",
      "[48]\ttraining's multi_logloss: 0.0914969\tvalid_1's multi_logloss: 0.288112       \n",
      "[49]\ttraining's multi_logloss: 0.0889604\tvalid_1's multi_logloss: 0.288915       \n",
      "[50]\ttraining's multi_logloss: 0.0861783\tvalid_1's multi_logloss: 0.289357       \n",
      "[51]\ttraining's multi_logloss: 0.0834486\tvalid_1's multi_logloss: 0.290713       \n",
      "[52]\ttraining's multi_logloss: 0.0812952\tvalid_1's multi_logloss: 0.291632       \n",
      "[53]\ttraining's multi_logloss: 0.0788511\tvalid_1's multi_logloss: 0.292445       \n",
      "[54]\ttraining's multi_logloss: 0.076689\tvalid_1's multi_logloss: 0.292979        \n",
      "[55]\ttraining's multi_logloss: 0.0740721\tvalid_1's multi_logloss: 0.293263       \n",
      "[56]\ttraining's multi_logloss: 0.0721162\tvalid_1's multi_logloss: 0.293832       \n",
      "[57]\ttraining's multi_logloss: 0.0697983\tvalid_1's multi_logloss: 0.294791       \n",
      "[58]\ttraining's multi_logloss: 0.0675626\tvalid_1's multi_logloss: 0.295574       \n",
      "[59]\ttraining's multi_logloss: 0.0654494\tvalid_1's multi_logloss: 0.29634        \n",
      "[60]\ttraining's multi_logloss: 0.0635236\tvalid_1's multi_logloss: 0.297305       \n",
      "[61]\ttraining's multi_logloss: 0.0616854\tvalid_1's multi_logloss: 0.298059       \n",
      "[62]\ttraining's multi_logloss: 0.0600576\tvalid_1's multi_logloss: 0.298686       \n",
      "[63]\ttraining's multi_logloss: 0.0581601\tvalid_1's multi_logloss: 0.299515       \n",
      "[64]\ttraining's multi_logloss: 0.0564505\tvalid_1's multi_logloss: 0.300615       \n",
      "[65]\ttraining's multi_logloss: 0.0548665\tvalid_1's multi_logloss: 0.301907       \n",
      "[66]\ttraining's multi_logloss: 0.0535031\tvalid_1's multi_logloss: 0.30287        \n",
      "[67]\ttraining's multi_logloss: 0.051918\tvalid_1's multi_logloss: 0.303611        \n",
      "[68]\ttraining's multi_logloss: 0.0506486\tvalid_1's multi_logloss: 0.304877       \n",
      "Early stopping, best iteration is:                                               \n",
      "[38]\ttraining's multi_logloss: 0.12561\tvalid_1's multi_logloss: 0.283915\n",
      "[1]\ttraining's multi_logloss: 1.39259\tvalid_1's multi_logloss: 1.39725           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.11715\tvalid_1's multi_logloss: 1.12453           \n",
      "[3]\ttraining's multi_logloss: 0.931383\tvalid_1's multi_logloss: 0.941242         \n",
      "[4]\ttraining's multi_logloss: 0.795996\tvalid_1's multi_logloss: 0.80757          \n",
      "[5]\ttraining's multi_logloss: 0.69146\tvalid_1's multi_logloss: 0.705344          \n",
      "[6]\ttraining's multi_logloss: 0.610416\tvalid_1's multi_logloss: 0.627284         \n",
      "[7]\ttraining's multi_logloss: 0.545609\tvalid_1's multi_logloss: 0.565526         \n",
      "[8]\ttraining's multi_logloss: 0.493156\tvalid_1's multi_logloss: 0.516151         \n",
      "[9]\ttraining's multi_logloss: 0.450029\tvalid_1's multi_logloss: 0.475752         \n",
      "[10]\ttraining's multi_logloss: 0.413768\tvalid_1's multi_logloss: 0.442519        \n",
      "[11]\ttraining's multi_logloss: 0.383436\tvalid_1's multi_logloss: 0.414565        \n",
      "[12]\ttraining's multi_logloss: 0.3572\tvalid_1's multi_logloss: 0.391335          \n",
      "[13]\ttraining's multi_logloss: 0.335706\tvalid_1's multi_logloss: 0.372293        \n",
      "[14]\ttraining's multi_logloss: 0.316547\tvalid_1's multi_logloss: 0.357165        \n",
      "[15]\ttraining's multi_logloss: 0.299977\tvalid_1's multi_logloss: 0.344505        \n",
      "[16]\ttraining's multi_logloss: 0.284837\tvalid_1's multi_logloss: 0.333733        \n",
      "[17]\ttraining's multi_logloss: 0.270987\tvalid_1's multi_logloss: 0.323566        \n",
      "[18]\ttraining's multi_logloss: 0.258773\tvalid_1's multi_logloss: 0.315117        \n",
      "[19]\ttraining's multi_logloss: 0.248429\tvalid_1's multi_logloss: 0.30889         \n",
      "[20]\ttraining's multi_logloss: 0.238849\tvalid_1's multi_logloss: 0.303167        \n",
      "[21]\ttraining's multi_logloss: 0.229834\tvalid_1's multi_logloss: 0.297825        \n",
      "[22]\ttraining's multi_logloss: 0.221536\tvalid_1's multi_logloss: 0.293803        \n",
      "[23]\ttraining's multi_logloss: 0.214029\tvalid_1's multi_logloss: 0.290508        \n",
      "[24]\ttraining's multi_logloss: 0.206885\tvalid_1's multi_logloss: 0.287853        \n",
      "[25]\ttraining's multi_logloss: 0.19999\tvalid_1's multi_logloss: 0.28529          \n",
      "[26]\ttraining's multi_logloss: 0.193055\tvalid_1's multi_logloss: 0.283382        \n",
      "[27]\ttraining's multi_logloss: 0.186534\tvalid_1's multi_logloss: 0.281451        \n",
      "[28]\ttraining's multi_logloss: 0.180397\tvalid_1's multi_logloss: 0.280028        \n",
      "[29]\ttraining's multi_logloss: 0.174504\tvalid_1's multi_logloss: 0.27842         \n",
      "[30]\ttraining's multi_logloss: 0.168911\tvalid_1's multi_logloss: 0.277151        \n",
      "[31]\ttraining's multi_logloss: 0.163533\tvalid_1's multi_logloss: 0.27639         \n",
      "[32]\ttraining's multi_logloss: 0.15789\tvalid_1's multi_logloss: 0.275241         \n",
      "[33]\ttraining's multi_logloss: 0.152794\tvalid_1's multi_logloss: 0.27412         \n",
      "[34]\ttraining's multi_logloss: 0.147988\tvalid_1's multi_logloss: 0.273343        \n",
      "[35]\ttraining's multi_logloss: 0.143137\tvalid_1's multi_logloss: 0.273287        \n",
      "[36]\ttraining's multi_logloss: 0.138744\tvalid_1's multi_logloss: 0.272899        \n",
      "[37]\ttraining's multi_logloss: 0.134872\tvalid_1's multi_logloss: 0.272313        \n",
      "[38]\ttraining's multi_logloss: 0.130652\tvalid_1's multi_logloss: 0.271701        \n",
      "[39]\ttraining's multi_logloss: 0.126727\tvalid_1's multi_logloss: 0.272159        \n",
      "[40]\ttraining's multi_logloss: 0.12279\tvalid_1's multi_logloss: 0.272106         \n",
      "[41]\ttraining's multi_logloss: 0.119015\tvalid_1's multi_logloss: 0.27208         \n",
      "[42]\ttraining's multi_logloss: 0.115515\tvalid_1's multi_logloss: 0.272054        \n",
      "[43]\ttraining's multi_logloss: 0.112205\tvalid_1's multi_logloss: 0.271643        \n",
      "[44]\ttraining's multi_logloss: 0.108816\tvalid_1's multi_logloss: 0.272291        \n",
      "[45]\ttraining's multi_logloss: 0.105397\tvalid_1's multi_logloss: 0.272403        \n",
      "[46]\ttraining's multi_logloss: 0.10243\tvalid_1's multi_logloss: 0.273261         \n",
      "[47]\ttraining's multi_logloss: 0.0992765\tvalid_1's multi_logloss: 0.273397       \n",
      "[48]\ttraining's multi_logloss: 0.0964897\tvalid_1's multi_logloss: 0.274193       \n",
      "[49]\ttraining's multi_logloss: 0.093602\tvalid_1's multi_logloss: 0.274549        \n",
      "[50]\ttraining's multi_logloss: 0.0904559\tvalid_1's multi_logloss: 0.275318       \n",
      "[51]\ttraining's multi_logloss: 0.0880746\tvalid_1's multi_logloss: 0.275979       \n",
      "[52]\ttraining's multi_logloss: 0.0855135\tvalid_1's multi_logloss: 0.276842       \n",
      "[53]\ttraining's multi_logloss: 0.0829405\tvalid_1's multi_logloss: 0.276914       \n",
      "[54]\ttraining's multi_logloss: 0.0807147\tvalid_1's multi_logloss: 0.27747        \n",
      "[55]\ttraining's multi_logloss: 0.0787077\tvalid_1's multi_logloss: 0.278183       \n",
      "[56]\ttraining's multi_logloss: 0.0762211\tvalid_1's multi_logloss: 0.278647       \n",
      "[57]\ttraining's multi_logloss: 0.0740019\tvalid_1's multi_logloss: 0.27978        \n",
      "[58]\ttraining's multi_logloss: 0.0719689\tvalid_1's multi_logloss: 0.280348       \n",
      "[59]\ttraining's multi_logloss: 0.0700059\tvalid_1's multi_logloss: 0.280569       \n",
      "[60]\ttraining's multi_logloss: 0.0680726\tvalid_1's multi_logloss: 0.281332       \n",
      "[61]\ttraining's multi_logloss: 0.0662858\tvalid_1's multi_logloss: 0.282093       \n",
      "[62]\ttraining's multi_logloss: 0.0643276\tvalid_1's multi_logloss: 0.283296       \n",
      "[63]\ttraining's multi_logloss: 0.0624726\tvalid_1's multi_logloss: 0.284869       \n",
      "[64]\ttraining's multi_logloss: 0.060648\tvalid_1's multi_logloss: 0.285586        \n",
      "[65]\ttraining's multi_logloss: 0.0591027\tvalid_1's multi_logloss: 0.286481       \n",
      "[66]\ttraining's multi_logloss: 0.0574274\tvalid_1's multi_logloss: 0.287194       \n",
      "[67]\ttraining's multi_logloss: 0.0559432\tvalid_1's multi_logloss: 0.287494       \n",
      "[68]\ttraining's multi_logloss: 0.0542996\tvalid_1's multi_logloss: 0.287903       \n",
      "[69]\ttraining's multi_logloss: 0.0526932\tvalid_1's multi_logloss: 0.288485       \n",
      "[70]\ttraining's multi_logloss: 0.0513118\tvalid_1's multi_logloss: 0.288946       \n",
      "[71]\ttraining's multi_logloss: 0.0500391\tvalid_1's multi_logloss: 0.289922       \n",
      "[72]\ttraining's multi_logloss: 0.0486857\tvalid_1's multi_logloss: 0.290415       \n",
      "[73]\ttraining's multi_logloss: 0.0473416\tvalid_1's multi_logloss: 0.291286       \n",
      "Early stopping, best iteration is:                                               \n",
      "[43]\ttraining's multi_logloss: 0.112205\tvalid_1's multi_logloss: 0.271643\n",
      "[1]\ttraining's multi_logloss: 1.50371\tvalid_1's multi_logloss: 1.5113            \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.24751\tvalid_1's multi_logloss: 1.26289           \n",
      "[3]\ttraining's multi_logloss: 1.06551\tvalid_1's multi_logloss: 1.08622           \n",
      "[4]\ttraining's multi_logloss: 0.926577\tvalid_1's multi_logloss: 0.952325         \n",
      "[5]\ttraining's multi_logloss: 0.817269\tvalid_1's multi_logloss: 0.847078         \n",
      "[6]\ttraining's multi_logloss: 0.728356\tvalid_1's multi_logloss: 0.7615           \n",
      "[7]\ttraining's multi_logloss: 0.654468\tvalid_1's multi_logloss: 0.691372         \n",
      "[8]\ttraining's multi_logloss: 0.593258\tvalid_1's multi_logloss: 0.633686         \n",
      "[9]\ttraining's multi_logloss: 0.541277\tvalid_1's multi_logloss: 0.585204         \n",
      "[10]\ttraining's multi_logloss: 0.496964\tvalid_1's multi_logloss: 0.544195        \n",
      "[11]\ttraining's multi_logloss: 0.458634\tvalid_1's multi_logloss: 0.508985        \n",
      "[12]\ttraining's multi_logloss: 0.425897\tvalid_1's multi_logloss: 0.479413        \n",
      "[13]\ttraining's multi_logloss: 0.397423\tvalid_1's multi_logloss: 0.453643        \n",
      "[14]\ttraining's multi_logloss: 0.372569\tvalid_1's multi_logloss: 0.431912        \n",
      "[15]\ttraining's multi_logloss: 0.351105\tvalid_1's multi_logloss: 0.413417        \n",
      "[16]\ttraining's multi_logloss: 0.331408\tvalid_1's multi_logloss: 0.39663         \n",
      "[17]\ttraining's multi_logloss: 0.314424\tvalid_1's multi_logloss: 0.382949        \n",
      "[18]\ttraining's multi_logloss: 0.29909\tvalid_1's multi_logloss: 0.371531         \n",
      "[19]\ttraining's multi_logloss: 0.285316\tvalid_1's multi_logloss: 0.361018        \n",
      "[20]\ttraining's multi_logloss: 0.273299\tvalid_1's multi_logloss: 0.352386        \n",
      "[21]\ttraining's multi_logloss: 0.262069\tvalid_1's multi_logloss: 0.34449         \n",
      "[22]\ttraining's multi_logloss: 0.25203\tvalid_1's multi_logloss: 0.33811          \n",
      "[23]\ttraining's multi_logloss: 0.24285\tvalid_1's multi_logloss: 0.332119         \n",
      "[24]\ttraining's multi_logloss: 0.233972\tvalid_1's multi_logloss: 0.327031        \n",
      "[25]\ttraining's multi_logloss: 0.225661\tvalid_1's multi_logloss: 0.322309        \n",
      "[26]\ttraining's multi_logloss: 0.217976\tvalid_1's multi_logloss: 0.318039        \n",
      "[27]\ttraining's multi_logloss: 0.210643\tvalid_1's multi_logloss: 0.314609        \n",
      "[28]\ttraining's multi_logloss: 0.203855\tvalid_1's multi_logloss: 0.311865        \n",
      "[29]\ttraining's multi_logloss: 0.197508\tvalid_1's multi_logloss: 0.309523        \n",
      "[30]\ttraining's multi_logloss: 0.191369\tvalid_1's multi_logloss: 0.307499        \n",
      "[31]\ttraining's multi_logloss: 0.185657\tvalid_1's multi_logloss: 0.305551        \n",
      "[32]\ttraining's multi_logloss: 0.180174\tvalid_1's multi_logloss: 0.303907        \n",
      "[33]\ttraining's multi_logloss: 0.174822\tvalid_1's multi_logloss: 0.302295        \n",
      "[34]\ttraining's multi_logloss: 0.169656\tvalid_1's multi_logloss: 0.300566        \n",
      "[35]\ttraining's multi_logloss: 0.164726\tvalid_1's multi_logloss: 0.299503        \n",
      "[36]\ttraining's multi_logloss: 0.160346\tvalid_1's multi_logloss: 0.298455        \n",
      "[37]\ttraining's multi_logloss: 0.155938\tvalid_1's multi_logloss: 0.297345        \n",
      "[38]\ttraining's multi_logloss: 0.151929\tvalid_1's multi_logloss: 0.296252        \n",
      "[39]\ttraining's multi_logloss: 0.147779\tvalid_1's multi_logloss: 0.295467        \n",
      "[40]\ttraining's multi_logloss: 0.144017\tvalid_1's multi_logloss: 0.294658        \n",
      "[41]\ttraining's multi_logloss: 0.140071\tvalid_1's multi_logloss: 0.294355        \n",
      "[42]\ttraining's multi_logloss: 0.136289\tvalid_1's multi_logloss: 0.294066        \n",
      "[43]\ttraining's multi_logloss: 0.132787\tvalid_1's multi_logloss: 0.293181        \n",
      "[44]\ttraining's multi_logloss: 0.129589\tvalid_1's multi_logloss: 0.293113        \n",
      "[45]\ttraining's multi_logloss: 0.126272\tvalid_1's multi_logloss: 0.292404        \n",
      "[46]\ttraining's multi_logloss: 0.123027\tvalid_1's multi_logloss: 0.292413        \n",
      "[47]\ttraining's multi_logloss: 0.119993\tvalid_1's multi_logloss: 0.292216        \n",
      "[48]\ttraining's multi_logloss: 0.117261\tvalid_1's multi_logloss: 0.292199        \n",
      "[49]\ttraining's multi_logloss: 0.114115\tvalid_1's multi_logloss: 0.292199        \n",
      "[50]\ttraining's multi_logloss: 0.11149\tvalid_1's multi_logloss: 0.29252          \n",
      "[51]\ttraining's multi_logloss: 0.108986\tvalid_1's multi_logloss: 0.292743        \n",
      "[52]\ttraining's multi_logloss: 0.106201\tvalid_1's multi_logloss: 0.292592        \n",
      "[53]\ttraining's multi_logloss: 0.103705\tvalid_1's multi_logloss: 0.292544        \n",
      "[54]\ttraining's multi_logloss: 0.101296\tvalid_1's multi_logloss: 0.292661        \n",
      "[55]\ttraining's multi_logloss: 0.0988599\tvalid_1's multi_logloss: 0.293537       \n",
      "[56]\ttraining's multi_logloss: 0.0967796\tvalid_1's multi_logloss: 0.293547       \n",
      "[57]\ttraining's multi_logloss: 0.0946765\tvalid_1's multi_logloss: 0.293807       \n",
      "[58]\ttraining's multi_logloss: 0.0926103\tvalid_1's multi_logloss: 0.294095       \n",
      "[59]\ttraining's multi_logloss: 0.0905584\tvalid_1's multi_logloss: 0.29413        \n",
      "[60]\ttraining's multi_logloss: 0.0885949\tvalid_1's multi_logloss: 0.294431       \n",
      "[61]\ttraining's multi_logloss: 0.0865905\tvalid_1's multi_logloss: 0.294747       \n",
      "[62]\ttraining's multi_logloss: 0.0848243\tvalid_1's multi_logloss: 0.295485       \n",
      "[63]\ttraining's multi_logloss: 0.0829844\tvalid_1's multi_logloss: 0.295684       \n",
      "[64]\ttraining's multi_logloss: 0.0813636\tvalid_1's multi_logloss: 0.296101       \n",
      "[65]\ttraining's multi_logloss: 0.0796317\tvalid_1's multi_logloss: 0.29637        \n",
      "[66]\ttraining's multi_logloss: 0.0779475\tvalid_1's multi_logloss: 0.296763       \n",
      "[67]\ttraining's multi_logloss: 0.0764428\tvalid_1's multi_logloss: 0.296862       \n",
      "[68]\ttraining's multi_logloss: 0.0749557\tvalid_1's multi_logloss: 0.297469       \n",
      "[69]\ttraining's multi_logloss: 0.0735037\tvalid_1's multi_logloss: 0.29819        \n",
      "[70]\ttraining's multi_logloss: 0.07206\tvalid_1's multi_logloss: 0.298429         \n",
      "[71]\ttraining's multi_logloss: 0.0704976\tvalid_1's multi_logloss: 0.299083       \n",
      "[72]\ttraining's multi_logloss: 0.0690938\tvalid_1's multi_logloss: 0.299307       \n",
      "[73]\ttraining's multi_logloss: 0.0676836\tvalid_1's multi_logloss: 0.299743       \n",
      "[74]\ttraining's multi_logloss: 0.0663722\tvalid_1's multi_logloss: 0.300116       \n",
      "[75]\ttraining's multi_logloss: 0.0652238\tvalid_1's multi_logloss: 0.300635       \n",
      "[76]\ttraining's multi_logloss: 0.0638611\tvalid_1's multi_logloss: 0.301092       \n",
      "[77]\ttraining's multi_logloss: 0.0625482\tvalid_1's multi_logloss: 0.301497       \n",
      "[78]\ttraining's multi_logloss: 0.0613527\tvalid_1's multi_logloss: 0.302098       \n",
      "[79]\ttraining's multi_logloss: 0.0600121\tvalid_1's multi_logloss: 0.302812       \n",
      "Early stopping, best iteration is:                                               \n",
      "[49]\ttraining's multi_logloss: 0.114115\tvalid_1's multi_logloss: 0.292199\n",
      "[1]\ttraining's multi_logloss: 1.50148\tvalid_1's multi_logloss: 1.5075            \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.24711\tvalid_1's multi_logloss: 1.25559           \n",
      "[3]\ttraining's multi_logloss: 1.06797\tvalid_1's multi_logloss: 1.07978           \n",
      "[4]\ttraining's multi_logloss: 0.929937\tvalid_1's multi_logloss: 0.944564         \n",
      "[5]\ttraining's multi_logloss: 0.821177\tvalid_1's multi_logloss: 0.838537         \n",
      "[6]\ttraining's multi_logloss: 0.732807\tvalid_1's multi_logloss: 0.754048         \n",
      "[7]\ttraining's multi_logloss: 0.658426\tvalid_1's multi_logloss: 0.683375         \n",
      "[8]\ttraining's multi_logloss: 0.596789\tvalid_1's multi_logloss: 0.625221         \n",
      "[9]\ttraining's multi_logloss: 0.543995\tvalid_1's multi_logloss: 0.575591         \n",
      "[10]\ttraining's multi_logloss: 0.499779\tvalid_1's multi_logloss: 0.534246        \n",
      "[11]\ttraining's multi_logloss: 0.462746\tvalid_1's multi_logloss: 0.50031         \n",
      "[12]\ttraining's multi_logloss: 0.430077\tvalid_1's multi_logloss: 0.471479        \n",
      "[13]\ttraining's multi_logloss: 0.401804\tvalid_1's multi_logloss: 0.446559        \n",
      "[14]\ttraining's multi_logloss: 0.377151\tvalid_1's multi_logloss: 0.425182        \n",
      "[15]\ttraining's multi_logloss: 0.355312\tvalid_1's multi_logloss: 0.406987        \n",
      "[16]\ttraining's multi_logloss: 0.335881\tvalid_1's multi_logloss: 0.3912          \n",
      "[17]\ttraining's multi_logloss: 0.318777\tvalid_1's multi_logloss: 0.377608        \n",
      "[18]\ttraining's multi_logloss: 0.303501\tvalid_1's multi_logloss: 0.365672        \n",
      "[19]\ttraining's multi_logloss: 0.289502\tvalid_1's multi_logloss: 0.355017        \n",
      "[20]\ttraining's multi_logloss: 0.276884\tvalid_1's multi_logloss: 0.345996        \n",
      "[21]\ttraining's multi_logloss: 0.264734\tvalid_1's multi_logloss: 0.337839        \n",
      "[22]\ttraining's multi_logloss: 0.253966\tvalid_1's multi_logloss: 0.330962        \n",
      "[23]\ttraining's multi_logloss: 0.244273\tvalid_1's multi_logloss: 0.325129        \n",
      "[24]\ttraining's multi_logloss: 0.235124\tvalid_1's multi_logloss: 0.319635        \n",
      "[25]\ttraining's multi_logloss: 0.22661\tvalid_1's multi_logloss: 0.314933         \n",
      "[26]\ttraining's multi_logloss: 0.2187\tvalid_1's multi_logloss: 0.311124          \n",
      "[27]\ttraining's multi_logloss: 0.211558\tvalid_1's multi_logloss: 0.308117        \n",
      "[28]\ttraining's multi_logloss: 0.204675\tvalid_1's multi_logloss: 0.305666        \n",
      "[29]\ttraining's multi_logloss: 0.198041\tvalid_1's multi_logloss: 0.302892        \n",
      "[30]\ttraining's multi_logloss: 0.19177\tvalid_1's multi_logloss: 0.300828         \n",
      "[31]\ttraining's multi_logloss: 0.18598\tvalid_1's multi_logloss: 0.298953         \n",
      "[32]\ttraining's multi_logloss: 0.180408\tvalid_1's multi_logloss: 0.296983        \n",
      "[33]\ttraining's multi_logloss: 0.175316\tvalid_1's multi_logloss: 0.295526        \n",
      "[34]\ttraining's multi_logloss: 0.170243\tvalid_1's multi_logloss: 0.294121        \n",
      "[35]\ttraining's multi_logloss: 0.165348\tvalid_1's multi_logloss: 0.292749        \n",
      "[36]\ttraining's multi_logloss: 0.160589\tvalid_1's multi_logloss: 0.291086        \n",
      "[37]\ttraining's multi_logloss: 0.156171\tvalid_1's multi_logloss: 0.290077        \n",
      "[38]\ttraining's multi_logloss: 0.151861\tvalid_1's multi_logloss: 0.288874        \n",
      "[39]\ttraining's multi_logloss: 0.14771\tvalid_1's multi_logloss: 0.287863         \n",
      "[40]\ttraining's multi_logloss: 0.143666\tvalid_1's multi_logloss: 0.287359        \n",
      "[41]\ttraining's multi_logloss: 0.139914\tvalid_1's multi_logloss: 0.286829        \n",
      "[42]\ttraining's multi_logloss: 0.13623\tvalid_1's multi_logloss: 0.286195         \n",
      "[43]\ttraining's multi_logloss: 0.132608\tvalid_1's multi_logloss: 0.286012        \n",
      "[44]\ttraining's multi_logloss: 0.128985\tvalid_1's multi_logloss: 0.285838        \n",
      "[45]\ttraining's multi_logloss: 0.125515\tvalid_1's multi_logloss: 0.285874        \n",
      "[46]\ttraining's multi_logloss: 0.122181\tvalid_1's multi_logloss: 0.285739        \n",
      "[47]\ttraining's multi_logloss: 0.119136\tvalid_1's multi_logloss: 0.286106        \n",
      "[48]\ttraining's multi_logloss: 0.11622\tvalid_1's multi_logloss: 0.286297         \n",
      "[49]\ttraining's multi_logloss: 0.113462\tvalid_1's multi_logloss: 0.286012        \n",
      "[50]\ttraining's multi_logloss: 0.110659\tvalid_1's multi_logloss: 0.285732        \n",
      "[51]\ttraining's multi_logloss: 0.107938\tvalid_1's multi_logloss: 0.285703        \n",
      "[52]\ttraining's multi_logloss: 0.105299\tvalid_1's multi_logloss: 0.286252        \n",
      "[53]\ttraining's multi_logloss: 0.102987\tvalid_1's multi_logloss: 0.286637        \n",
      "[54]\ttraining's multi_logloss: 0.100362\tvalid_1's multi_logloss: 0.286748        \n",
      "[55]\ttraining's multi_logloss: 0.0980764\tvalid_1's multi_logloss: 0.286559       \n",
      "[56]\ttraining's multi_logloss: 0.0957577\tvalid_1's multi_logloss: 0.286543       \n",
      "[57]\ttraining's multi_logloss: 0.0936163\tvalid_1's multi_logloss: 0.286657       \n",
      "[58]\ttraining's multi_logloss: 0.0913226\tvalid_1's multi_logloss: 0.287085       \n",
      "[59]\ttraining's multi_logloss: 0.0890627\tvalid_1's multi_logloss: 0.28739        \n",
      "[60]\ttraining's multi_logloss: 0.087044\tvalid_1's multi_logloss: 0.287854        \n",
      "[61]\ttraining's multi_logloss: 0.0850467\tvalid_1's multi_logloss: 0.288304       \n",
      "[62]\ttraining's multi_logloss: 0.083045\tvalid_1's multi_logloss: 0.288675        \n",
      "[63]\ttraining's multi_logloss: 0.0811384\tvalid_1's multi_logloss: 0.288993       \n",
      "[64]\ttraining's multi_logloss: 0.0793734\tvalid_1's multi_logloss: 0.289644       \n",
      "[65]\ttraining's multi_logloss: 0.0777023\tvalid_1's multi_logloss: 0.290148       \n",
      "[66]\ttraining's multi_logloss: 0.075944\tvalid_1's multi_logloss: 0.290103        \n",
      "[67]\ttraining's multi_logloss: 0.0743035\tvalid_1's multi_logloss: 0.290321       \n",
      "[68]\ttraining's multi_logloss: 0.0726849\tvalid_1's multi_logloss: 0.290984       \n",
      "[69]\ttraining's multi_logloss: 0.07094\tvalid_1's multi_logloss: 0.29179          \n",
      "[70]\ttraining's multi_logloss: 0.0694773\tvalid_1's multi_logloss: 0.292506       \n",
      "[71]\ttraining's multi_logloss: 0.0679064\tvalid_1's multi_logloss: 0.292821       \n",
      "[72]\ttraining's multi_logloss: 0.0664668\tvalid_1's multi_logloss: 0.293361       \n",
      "[73]\ttraining's multi_logloss: 0.0651543\tvalid_1's multi_logloss: 0.293844       \n",
      "[74]\ttraining's multi_logloss: 0.0638226\tvalid_1's multi_logloss: 0.294512       \n",
      "[75]\ttraining's multi_logloss: 0.0625718\tvalid_1's multi_logloss: 0.294824       \n",
      "[76]\ttraining's multi_logloss: 0.0612725\tvalid_1's multi_logloss: 0.29568        \n",
      "[77]\ttraining's multi_logloss: 0.0599428\tvalid_1's multi_logloss: 0.296628       \n",
      "[78]\ttraining's multi_logloss: 0.0586886\tvalid_1's multi_logloss: 0.297592       \n",
      "[79]\ttraining's multi_logloss: 0.0575193\tvalid_1's multi_logloss: 0.298216       \n",
      "[80]\ttraining's multi_logloss: 0.0562717\tvalid_1's multi_logloss: 0.298794       \n",
      "[81]\ttraining's multi_logloss: 0.0551624\tvalid_1's multi_logloss: 0.299415       \n",
      "Early stopping, best iteration is:                                               \n",
      "[51]\ttraining's multi_logloss: 0.107938\tvalid_1's multi_logloss: 0.285703\n",
      "[1]\ttraining's multi_logloss: 1.50391\tvalid_1's multi_logloss: 1.50923           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.25052\tvalid_1's multi_logloss: 1.25858           \n",
      "[3]\ttraining's multi_logloss: 1.06954\tvalid_1's multi_logloss: 1.07971           \n",
      "[4]\ttraining's multi_logloss: 0.932343\tvalid_1's multi_logloss: 0.943729         \n",
      "[5]\ttraining's multi_logloss: 0.822677\tvalid_1's multi_logloss: 0.836627         \n",
      "[6]\ttraining's multi_logloss: 0.733872\tvalid_1's multi_logloss: 0.749437         \n",
      "[7]\ttraining's multi_logloss: 0.661\tvalid_1's multi_logloss: 0.67895             \n",
      "[8]\ttraining's multi_logloss: 0.599554\tvalid_1's multi_logloss: 0.619852         \n",
      "[9]\ttraining's multi_logloss: 0.548303\tvalid_1's multi_logloss: 0.571408         \n",
      "[10]\ttraining's multi_logloss: 0.50488\tvalid_1's multi_logloss: 0.531154         \n",
      "[11]\ttraining's multi_logloss: 0.467406\tvalid_1's multi_logloss: 0.496457        \n",
      "[12]\ttraining's multi_logloss: 0.435185\tvalid_1's multi_logloss: 0.467032        \n",
      "[13]\ttraining's multi_logloss: 0.406827\tvalid_1's multi_logloss: 0.441186        \n",
      "[14]\ttraining's multi_logloss: 0.38199\tvalid_1's multi_logloss: 0.419103         \n",
      "[15]\ttraining's multi_logloss: 0.359033\tvalid_1's multi_logloss: 0.398379        \n",
      "[16]\ttraining's multi_logloss: 0.340338\tvalid_1's multi_logloss: 0.382571        \n",
      "[17]\ttraining's multi_logloss: 0.323078\tvalid_1's multi_logloss: 0.368182        \n",
      "[18]\ttraining's multi_logloss: 0.30766\tvalid_1's multi_logloss: 0.355541         \n",
      "[19]\ttraining's multi_logloss: 0.293623\tvalid_1's multi_logloss: 0.344995        \n",
      "[20]\ttraining's multi_logloss: 0.280608\tvalid_1's multi_logloss: 0.335188        \n",
      "[21]\ttraining's multi_logloss: 0.269384\tvalid_1's multi_logloss: 0.327608        \n",
      "[22]\ttraining's multi_logloss: 0.258791\tvalid_1's multi_logloss: 0.320839        \n",
      "[23]\ttraining's multi_logloss: 0.249158\tvalid_1's multi_logloss: 0.315013        \n",
      "[24]\ttraining's multi_logloss: 0.239885\tvalid_1's multi_logloss: 0.309099        \n",
      "[25]\ttraining's multi_logloss: 0.231686\tvalid_1's multi_logloss: 0.304773        \n",
      "[26]\ttraining's multi_logloss: 0.224187\tvalid_1's multi_logloss: 0.30066         \n",
      "[27]\ttraining's multi_logloss: 0.217036\tvalid_1's multi_logloss: 0.296881        \n",
      "[28]\ttraining's multi_logloss: 0.21027\tvalid_1's multi_logloss: 0.293191         \n",
      "[29]\ttraining's multi_logloss: 0.203909\tvalid_1's multi_logloss: 0.2903          \n",
      "[30]\ttraining's multi_logloss: 0.197867\tvalid_1's multi_logloss: 0.287875        \n",
      "[31]\ttraining's multi_logloss: 0.192195\tvalid_1's multi_logloss: 0.285218        \n",
      "[32]\ttraining's multi_logloss: 0.186774\tvalid_1's multi_logloss: 0.282967        \n",
      "[33]\ttraining's multi_logloss: 0.181523\tvalid_1's multi_logloss: 0.281483        \n",
      "[34]\ttraining's multi_logloss: 0.176505\tvalid_1's multi_logloss: 0.279678        \n",
      "[35]\ttraining's multi_logloss: 0.171552\tvalid_1's multi_logloss: 0.278312        \n",
      "[36]\ttraining's multi_logloss: 0.16682\tvalid_1's multi_logloss: 0.276438         \n",
      "[37]\ttraining's multi_logloss: 0.162156\tvalid_1's multi_logloss: 0.275501        \n",
      "[38]\ttraining's multi_logloss: 0.157853\tvalid_1's multi_logloss: 0.27459         \n",
      "[39]\ttraining's multi_logloss: 0.153715\tvalid_1's multi_logloss: 0.273758        \n",
      "[40]\ttraining's multi_logloss: 0.149491\tvalid_1's multi_logloss: 0.272297        \n",
      "[41]\ttraining's multi_logloss: 0.145573\tvalid_1's multi_logloss: 0.271914        \n",
      "[42]\ttraining's multi_logloss: 0.141687\tvalid_1's multi_logloss: 0.271629        \n",
      "[43]\ttraining's multi_logloss: 0.138404\tvalid_1's multi_logloss: 0.271399        \n",
      "[44]\ttraining's multi_logloss: 0.134946\tvalid_1's multi_logloss: 0.271428        \n",
      "[45]\ttraining's multi_logloss: 0.131635\tvalid_1's multi_logloss: 0.271258        \n",
      "[46]\ttraining's multi_logloss: 0.128342\tvalid_1's multi_logloss: 0.271077        \n",
      "[47]\ttraining's multi_logloss: 0.125172\tvalid_1's multi_logloss: 0.270989        \n",
      "[48]\ttraining's multi_logloss: 0.122105\tvalid_1's multi_logloss: 0.270768        \n",
      "[49]\ttraining's multi_logloss: 0.11901\tvalid_1's multi_logloss: 0.270648         \n",
      "[50]\ttraining's multi_logloss: 0.116034\tvalid_1's multi_logloss: 0.270931        \n",
      "[51]\ttraining's multi_logloss: 0.11327\tvalid_1's multi_logloss: 0.271173         \n",
      "[52]\ttraining's multi_logloss: 0.110741\tvalid_1's multi_logloss: 0.271158        \n",
      "[53]\ttraining's multi_logloss: 0.10834\tvalid_1's multi_logloss: 0.270621         \n",
      "[54]\ttraining's multi_logloss: 0.105898\tvalid_1's multi_logloss: 0.271019        \n",
      "[55]\ttraining's multi_logloss: 0.103338\tvalid_1's multi_logloss: 0.27123         \n",
      "[56]\ttraining's multi_logloss: 0.101071\tvalid_1's multi_logloss: 0.271486        \n",
      "[57]\ttraining's multi_logloss: 0.0988448\tvalid_1's multi_logloss: 0.271382       \n",
      "[58]\ttraining's multi_logloss: 0.0966109\tvalid_1's multi_logloss: 0.271218       \n",
      "[59]\ttraining's multi_logloss: 0.0946134\tvalid_1's multi_logloss: 0.271603       \n",
      "[60]\ttraining's multi_logloss: 0.0924404\tvalid_1's multi_logloss: 0.271553       \n",
      "[61]\ttraining's multi_logloss: 0.0904227\tvalid_1's multi_logloss: 0.272284       \n",
      "[62]\ttraining's multi_logloss: 0.0884336\tvalid_1's multi_logloss: 0.272487       \n",
      "[63]\ttraining's multi_logloss: 0.0864769\tvalid_1's multi_logloss: 0.272599       \n",
      "[64]\ttraining's multi_logloss: 0.0845698\tvalid_1's multi_logloss: 0.273266       \n",
      "[65]\ttraining's multi_logloss: 0.0827935\tvalid_1's multi_logloss: 0.273607       \n",
      "[66]\ttraining's multi_logloss: 0.0809735\tvalid_1's multi_logloss: 0.27378        \n",
      "[67]\ttraining's multi_logloss: 0.0792759\tvalid_1's multi_logloss: 0.274198       \n",
      "[68]\ttraining's multi_logloss: 0.077691\tvalid_1's multi_logloss: 0.274374        \n",
      "[69]\ttraining's multi_logloss: 0.0760099\tvalid_1's multi_logloss: 0.27481        \n",
      "[70]\ttraining's multi_logloss: 0.074506\tvalid_1's multi_logloss: 0.275288        \n",
      "[71]\ttraining's multi_logloss: 0.0729941\tvalid_1's multi_logloss: 0.275805       \n",
      "[72]\ttraining's multi_logloss: 0.0714513\tvalid_1's multi_logloss: 0.275889       \n",
      "[73]\ttraining's multi_logloss: 0.0699046\tvalid_1's multi_logloss: 0.276223       \n",
      "[74]\ttraining's multi_logloss: 0.068477\tvalid_1's multi_logloss: 0.276745        \n",
      "[75]\ttraining's multi_logloss: 0.0671212\tvalid_1's multi_logloss: 0.2775         \n",
      "[76]\ttraining's multi_logloss: 0.0658157\tvalid_1's multi_logloss: 0.278248       \n",
      "[77]\ttraining's multi_logloss: 0.0646101\tvalid_1's multi_logloss: 0.278975       \n",
      "[78]\ttraining's multi_logloss: 0.0633794\tvalid_1's multi_logloss: 0.27983        \n",
      "[79]\ttraining's multi_logloss: 0.0620887\tvalid_1's multi_logloss: 0.280259       \n",
      "[80]\ttraining's multi_logloss: 0.0609107\tvalid_1's multi_logloss: 0.280679       \n",
      "[81]\ttraining's multi_logloss: 0.0597196\tvalid_1's multi_logloss: 0.281488       \n",
      "[82]\ttraining's multi_logloss: 0.0585733\tvalid_1's multi_logloss: 0.281879       \n",
      "[83]\ttraining's multi_logloss: 0.057457\tvalid_1's multi_logloss: 0.282394        \n",
      "Early stopping, best iteration is:                                               \n",
      "[53]\ttraining's multi_logloss: 0.10834\tvalid_1's multi_logloss: 0.270621\n",
      "[1]\ttraining's multi_logloss: 1.71918\tvalid_1's multi_logloss: 1.72126           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.55372\tvalid_1's multi_logloss: 1.55949           \n",
      "[3]\ttraining's multi_logloss: 1.42031\tvalid_1's multi_logloss: 1.42922           \n",
      "[4]\ttraining's multi_logloss: 1.30748\tvalid_1's multi_logloss: 1.32              \n",
      "[5]\ttraining's multi_logloss: 1.21027\tvalid_1's multi_logloss: 1.22582           \n",
      "[6]\ttraining's multi_logloss: 1.1265\tvalid_1's multi_logloss: 1.14429            \n",
      "[7]\ttraining's multi_logloss: 1.0521\tvalid_1's multi_logloss: 1.07225            \n",
      "[8]\ttraining's multi_logloss: 0.986222\tvalid_1's multi_logloss: 1.0083           \n",
      "[9]\ttraining's multi_logloss: 0.926893\tvalid_1's multi_logloss: 0.950986         \n",
      "[10]\ttraining's multi_logloss: 0.873265\tvalid_1's multi_logloss: 0.899108        \n",
      "[11]\ttraining's multi_logloss: 0.825599\tvalid_1's multi_logloss: 0.853048        \n",
      "[12]\ttraining's multi_logloss: 0.781851\tvalid_1's multi_logloss: 0.810567        \n",
      "[13]\ttraining's multi_logloss: 0.742054\tvalid_1's multi_logloss: 0.772033        \n",
      "[14]\ttraining's multi_logloss: 0.705933\tvalid_1's multi_logloss: 0.736895        \n",
      "[15]\ttraining's multi_logloss: 0.672618\tvalid_1's multi_logloss: 0.704711        \n",
      "[16]\ttraining's multi_logloss: 0.641678\tvalid_1's multi_logloss: 0.674893        \n",
      "[17]\ttraining's multi_logloss: 0.613334\tvalid_1's multi_logloss: 0.647956        \n",
      "[18]\ttraining's multi_logloss: 0.587161\tvalid_1's multi_logloss: 0.622817        \n",
      "[19]\ttraining's multi_logloss: 0.562829\tvalid_1's multi_logloss: 0.60003         \n",
      "[20]\ttraining's multi_logloss: 0.540459\tvalid_1's multi_logloss: 0.578699        \n",
      "[21]\ttraining's multi_logloss: 0.519692\tvalid_1's multi_logloss: 0.559001        \n",
      "[22]\ttraining's multi_logloss: 0.500394\tvalid_1's multi_logloss: 0.540867        \n",
      "[23]\ttraining's multi_logloss: 0.482463\tvalid_1's multi_logloss: 0.524155        \n",
      "[24]\ttraining's multi_logloss: 0.465658\tvalid_1's multi_logloss: 0.508453        \n",
      "[25]\ttraining's multi_logloss: 0.450244\tvalid_1's multi_logloss: 0.494191        \n",
      "[26]\ttraining's multi_logloss: 0.435874\tvalid_1's multi_logloss: 0.481015        \n",
      "[27]\ttraining's multi_logloss: 0.42239\tvalid_1's multi_logloss: 0.468745         \n",
      "[28]\ttraining's multi_logloss: 0.409665\tvalid_1's multi_logloss: 0.457216        \n",
      "[29]\ttraining's multi_logloss: 0.397854\tvalid_1's multi_logloss: 0.44662         \n",
      "[30]\ttraining's multi_logloss: 0.386686\tvalid_1's multi_logloss: 0.436712        \n",
      "[31]\ttraining's multi_logloss: 0.376304\tvalid_1's multi_logloss: 0.427261        \n",
      "[32]\ttraining's multi_logloss: 0.366605\tvalid_1's multi_logloss: 0.418596        \n",
      "[33]\ttraining's multi_logloss: 0.357621\tvalid_1's multi_logloss: 0.410864        \n",
      "[34]\ttraining's multi_logloss: 0.349111\tvalid_1's multi_logloss: 0.403667        \n",
      "[35]\ttraining's multi_logloss: 0.341266\tvalid_1's multi_logloss: 0.397048        \n",
      "[36]\ttraining's multi_logloss: 0.33385\tvalid_1's multi_logloss: 0.390886         \n",
      "[37]\ttraining's multi_logloss: 0.326663\tvalid_1's multi_logloss: 0.384963        \n",
      "[38]\ttraining's multi_logloss: 0.319565\tvalid_1's multi_logloss: 0.378969        \n",
      "[39]\ttraining's multi_logloss: 0.313015\tvalid_1's multi_logloss: 0.37374         \n",
      "[40]\ttraining's multi_logloss: 0.30696\tvalid_1's multi_logloss: 0.368888         \n",
      "[41]\ttraining's multi_logloss: 0.301096\tvalid_1's multi_logloss: 0.364265        \n",
      "[42]\ttraining's multi_logloss: 0.295439\tvalid_1's multi_logloss: 0.359857        \n",
      "[43]\ttraining's multi_logloss: 0.290179\tvalid_1's multi_logloss: 0.355916        \n",
      "[44]\ttraining's multi_logloss: 0.28529\tvalid_1's multi_logloss: 0.352059         \n",
      "[45]\ttraining's multi_logloss: 0.280559\tvalid_1's multi_logloss: 0.348625        \n",
      "[46]\ttraining's multi_logloss: 0.275951\tvalid_1's multi_logloss: 0.345227        \n",
      "[47]\ttraining's multi_logloss: 0.271646\tvalid_1's multi_logloss: 0.342158        \n",
      "[48]\ttraining's multi_logloss: 0.267381\tvalid_1's multi_logloss: 0.339162        \n",
      "[49]\ttraining's multi_logloss: 0.263313\tvalid_1's multi_logloss: 0.336388        \n",
      "[50]\ttraining's multi_logloss: 0.259179\tvalid_1's multi_logloss: 0.333498        \n",
      "[51]\ttraining's multi_logloss: 0.255188\tvalid_1's multi_logloss: 0.330723        \n",
      "[52]\ttraining's multi_logloss: 0.251448\tvalid_1's multi_logloss: 0.328178        \n",
      "[53]\ttraining's multi_logloss: 0.247833\tvalid_1's multi_logloss: 0.326056        \n",
      "[54]\ttraining's multi_logloss: 0.244333\tvalid_1's multi_logloss: 0.323699        \n",
      "[55]\ttraining's multi_logloss: 0.241066\tvalid_1's multi_logloss: 0.321597        \n",
      "[56]\ttraining's multi_logloss: 0.237886\tvalid_1's multi_logloss: 0.319731        \n",
      "[57]\ttraining's multi_logloss: 0.234832\tvalid_1's multi_logloss: 0.317937        \n",
      "[58]\ttraining's multi_logloss: 0.231837\tvalid_1's multi_logloss: 0.316255        \n",
      "[59]\ttraining's multi_logloss: 0.228888\tvalid_1's multi_logloss: 0.314543        \n",
      "[60]\ttraining's multi_logloss: 0.2261\tvalid_1's multi_logloss: 0.313054          \n",
      "[61]\ttraining's multi_logloss: 0.223417\tvalid_1's multi_logloss: 0.311656        \n",
      "[62]\ttraining's multi_logloss: 0.220774\tvalid_1's multi_logloss: 0.310104        \n",
      "[63]\ttraining's multi_logloss: 0.218198\tvalid_1's multi_logloss: 0.308853        \n",
      "[64]\ttraining's multi_logloss: 0.215728\tvalid_1's multi_logloss: 0.307664        \n",
      "[65]\ttraining's multi_logloss: 0.213277\tvalid_1's multi_logloss: 0.306665        \n",
      "[66]\ttraining's multi_logloss: 0.210954\tvalid_1's multi_logloss: 0.305621        \n",
      "[67]\ttraining's multi_logloss: 0.208613\tvalid_1's multi_logloss: 0.304231        \n",
      "[68]\ttraining's multi_logloss: 0.206371\tvalid_1's multi_logloss: 0.30336         \n",
      "[69]\ttraining's multi_logloss: 0.204147\tvalid_1's multi_logloss: 0.302501        \n",
      "[70]\ttraining's multi_logloss: 0.202066\tvalid_1's multi_logloss: 0.301652        \n",
      "[71]\ttraining's multi_logloss: 0.200039\tvalid_1's multi_logloss: 0.300828        \n",
      "[72]\ttraining's multi_logloss: 0.197989\tvalid_1's multi_logloss: 0.300168        \n",
      "[73]\ttraining's multi_logloss: 0.19596\tvalid_1's multi_logloss: 0.299314         \n",
      "[74]\ttraining's multi_logloss: 0.194015\tvalid_1's multi_logloss: 0.298702        \n",
      "[75]\ttraining's multi_logloss: 0.191987\tvalid_1's multi_logloss: 0.298355        \n",
      "[76]\ttraining's multi_logloss: 0.189994\tvalid_1's multi_logloss: 0.297665        \n",
      "[77]\ttraining's multi_logloss: 0.188112\tvalid_1's multi_logloss: 0.296944        \n",
      "[78]\ttraining's multi_logloss: 0.186139\tvalid_1's multi_logloss: 0.29664         \n",
      "[79]\ttraining's multi_logloss: 0.184253\tvalid_1's multi_logloss: 0.296064        \n",
      "[80]\ttraining's multi_logloss: 0.182455\tvalid_1's multi_logloss: 0.295466        \n",
      "[81]\ttraining's multi_logloss: 0.180717\tvalid_1's multi_logloss: 0.295078        \n",
      "[82]\ttraining's multi_logloss: 0.178909\tvalid_1's multi_logloss: 0.294585        \n",
      "[83]\ttraining's multi_logloss: 0.177186\tvalid_1's multi_logloss: 0.294186        \n",
      "[84]\ttraining's multi_logloss: 0.175523\tvalid_1's multi_logloss: 0.293763        \n",
      "[85]\ttraining's multi_logloss: 0.173892\tvalid_1's multi_logloss: 0.293421        \n",
      "[86]\ttraining's multi_logloss: 0.172322\tvalid_1's multi_logloss: 0.293108        \n",
      "[87]\ttraining's multi_logloss: 0.170713\tvalid_1's multi_logloss: 0.292686        \n",
      "[88]\ttraining's multi_logloss: 0.169045\tvalid_1's multi_logloss: 0.292268        \n",
      "[89]\ttraining's multi_logloss: 0.167445\tvalid_1's multi_logloss: 0.292016        \n",
      "[90]\ttraining's multi_logloss: 0.165894\tvalid_1's multi_logloss: 0.29194         \n",
      "[91]\ttraining's multi_logloss: 0.164427\tvalid_1's multi_logloss: 0.291719        \n",
      "[92]\ttraining's multi_logloss: 0.162953\tvalid_1's multi_logloss: 0.29153         \n",
      "[93]\ttraining's multi_logloss: 0.161547\tvalid_1's multi_logloss: 0.291305        \n",
      "[94]\ttraining's multi_logloss: 0.160064\tvalid_1's multi_logloss: 0.291166        \n",
      "[95]\ttraining's multi_logloss: 0.158742\tvalid_1's multi_logloss: 0.291084        \n",
      "[96]\ttraining's multi_logloss: 0.157325\tvalid_1's multi_logloss: 0.290762        \n",
      "[97]\ttraining's multi_logloss: 0.15601\tvalid_1's multi_logloss: 0.2906           \n",
      "[98]\ttraining's multi_logloss: 0.154707\tvalid_1's multi_logloss: 0.290296        \n",
      "[99]\ttraining's multi_logloss: 0.15344\tvalid_1's multi_logloss: 0.290217         \n",
      "[100]\ttraining's multi_logloss: 0.15205\tvalid_1's multi_logloss: 0.290084        \n",
      "[101]\ttraining's multi_logloss: 0.150767\tvalid_1's multi_logloss: 0.289884       \n",
      "[102]\ttraining's multi_logloss: 0.149523\tvalid_1's multi_logloss: 0.289542       \n",
      "[103]\ttraining's multi_logloss: 0.14825\tvalid_1's multi_logloss: 0.289589        \n",
      "[104]\ttraining's multi_logloss: 0.147072\tvalid_1's multi_logloss: 0.289342       \n",
      "[105]\ttraining's multi_logloss: 0.145621\tvalid_1's multi_logloss: 0.289025       \n",
      "[106]\ttraining's multi_logloss: 0.144423\tvalid_1's multi_logloss: 0.288861       \n",
      "[107]\ttraining's multi_logloss: 0.143213\tvalid_1's multi_logloss: 0.288863       \n",
      "[108]\ttraining's multi_logloss: 0.142052\tvalid_1's multi_logloss: 0.28882        \n",
      "[109]\ttraining's multi_logloss: 0.140808\tvalid_1's multi_logloss: 0.288963       \n",
      "[110]\ttraining's multi_logloss: 0.139626\tvalid_1's multi_logloss: 0.289104       \n",
      "[111]\ttraining's multi_logloss: 0.138446\tvalid_1's multi_logloss: 0.288831       \n",
      "[112]\ttraining's multi_logloss: 0.137238\tvalid_1's multi_logloss: 0.288851       \n",
      "[113]\ttraining's multi_logloss: 0.136151\tvalid_1's multi_logloss: 0.288774       \n",
      "[114]\ttraining's multi_logloss: 0.135062\tvalid_1's multi_logloss: 0.288756       \n",
      "[115]\ttraining's multi_logloss: 0.134007\tvalid_1's multi_logloss: 0.288659       \n",
      "[116]\ttraining's multi_logloss: 0.132946\tvalid_1's multi_logloss: 0.288631       \n",
      "[117]\ttraining's multi_logloss: 0.131921\tvalid_1's multi_logloss: 0.288483       \n",
      "[118]\ttraining's multi_logloss: 0.130973\tvalid_1's multi_logloss: 0.288321       \n",
      "[119]\ttraining's multi_logloss: 0.129982\tvalid_1's multi_logloss: 0.288279       \n",
      "[120]\ttraining's multi_logloss: 0.129006\tvalid_1's multi_logloss: 0.288284       \n",
      "[121]\ttraining's multi_logloss: 0.128092\tvalid_1's multi_logloss: 0.288201       \n",
      "[122]\ttraining's multi_logloss: 0.127051\tvalid_1's multi_logloss: 0.288333       \n",
      "[123]\ttraining's multi_logloss: 0.126089\tvalid_1's multi_logloss: 0.288492       \n",
      "[124]\ttraining's multi_logloss: 0.125115\tvalid_1's multi_logloss: 0.288471       \n",
      "[125]\ttraining's multi_logloss: 0.124071\tvalid_1's multi_logloss: 0.288371       \n",
      "[126]\ttraining's multi_logloss: 0.123134\tvalid_1's multi_logloss: 0.288473       \n",
      "[127]\ttraining's multi_logloss: 0.122231\tvalid_1's multi_logloss: 0.288589       \n",
      "[128]\ttraining's multi_logloss: 0.121368\tvalid_1's multi_logloss: 0.288649       \n",
      "[129]\ttraining's multi_logloss: 0.120481\tvalid_1's multi_logloss: 0.288657       \n",
      "[130]\ttraining's multi_logloss: 0.119598\tvalid_1's multi_logloss: 0.28874        \n",
      "[131]\ttraining's multi_logloss: 0.118737\tvalid_1's multi_logloss: 0.288844       \n",
      "[132]\ttraining's multi_logloss: 0.117829\tvalid_1's multi_logloss: 0.289002       \n",
      "[133]\ttraining's multi_logloss: 0.116889\tvalid_1's multi_logloss: 0.288956       \n",
      "[134]\ttraining's multi_logloss: 0.115983\tvalid_1's multi_logloss: 0.289131       \n",
      "[135]\ttraining's multi_logloss: 0.115187\tvalid_1's multi_logloss: 0.289166       \n",
      "[136]\ttraining's multi_logloss: 0.114345\tvalid_1's multi_logloss: 0.289183       \n",
      "[137]\ttraining's multi_logloss: 0.113612\tvalid_1's multi_logloss: 0.28917        \n",
      "[138]\ttraining's multi_logloss: 0.112735\tvalid_1's multi_logloss: 0.289211       \n",
      "[139]\ttraining's multi_logloss: 0.111959\tvalid_1's multi_logloss: 0.289258       \n",
      "[140]\ttraining's multi_logloss: 0.111218\tvalid_1's multi_logloss: 0.289269       \n",
      "[141]\ttraining's multi_logloss: 0.110444\tvalid_1's multi_logloss: 0.289309       \n",
      "[142]\ttraining's multi_logloss: 0.109677\tvalid_1's multi_logloss: 0.28959        \n",
      "[143]\ttraining's multi_logloss: 0.108752\tvalid_1's multi_logloss: 0.289519       \n",
      "[144]\ttraining's multi_logloss: 0.108057\tvalid_1's multi_logloss: 0.2895         \n",
      "[145]\ttraining's multi_logloss: 0.107343\tvalid_1's multi_logloss: 0.289631       \n",
      "[146]\ttraining's multi_logloss: 0.106496\tvalid_1's multi_logloss: 0.289524       \n",
      "[147]\ttraining's multi_logloss: 0.105764\tvalid_1's multi_logloss: 0.289596       \n",
      "[148]\ttraining's multi_logloss: 0.104969\tvalid_1's multi_logloss: 0.289804       \n",
      "[149]\ttraining's multi_logloss: 0.104261\tvalid_1's multi_logloss: 0.290082       \n",
      "[150]\ttraining's multi_logloss: 0.103565\tvalid_1's multi_logloss: 0.290301       \n",
      "[151]\ttraining's multi_logloss: 0.102823\tvalid_1's multi_logloss: 0.290413       \n",
      "Early stopping, best iteration is:                                               \n",
      "[121]\ttraining's multi_logloss: 0.128092\tvalid_1's multi_logloss: 0.288201\n",
      "[1]\ttraining's multi_logloss: 1.71762\tvalid_1's multi_logloss: 1.72037           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.55433\tvalid_1's multi_logloss: 1.55815           \n",
      "[3]\ttraining's multi_logloss: 1.42136\tvalid_1's multi_logloss: 1.42635           \n",
      "[4]\ttraining's multi_logloss: 1.30934\tvalid_1's multi_logloss: 1.31576           \n",
      "[5]\ttraining's multi_logloss: 1.21393\tvalid_1's multi_logloss: 1.22127           \n",
      "[6]\ttraining's multi_logloss: 1.13091\tvalid_1's multi_logloss: 1.13988           \n",
      "[7]\ttraining's multi_logloss: 1.05712\tvalid_1's multi_logloss: 1.06694           \n",
      "[8]\ttraining's multi_logloss: 0.991825\tvalid_1's multi_logloss: 1.00274          \n",
      "[9]\ttraining's multi_logloss: 0.933031\tvalid_1's multi_logloss: 0.94488          \n",
      "[10]\ttraining's multi_logloss: 0.879855\tvalid_1's multi_logloss: 0.892604        \n",
      "[11]\ttraining's multi_logloss: 0.832331\tvalid_1's multi_logloss: 0.846363        \n",
      "[12]\ttraining's multi_logloss: 0.788316\tvalid_1's multi_logloss: 0.803553        \n",
      "[13]\ttraining's multi_logloss: 0.748411\tvalid_1's multi_logloss: 0.764989        \n",
      "[14]\ttraining's multi_logloss: 0.711888\tvalid_1's multi_logloss: 0.729877        \n",
      "[15]\ttraining's multi_logloss: 0.678459\tvalid_1's multi_logloss: 0.697724        \n",
      "[16]\ttraining's multi_logloss: 0.647836\tvalid_1's multi_logloss: 0.668385        \n",
      "[17]\ttraining's multi_logloss: 0.619448\tvalid_1's multi_logloss: 0.641266        \n",
      "[18]\ttraining's multi_logloss: 0.593293\tvalid_1's multi_logloss: 0.616299        \n",
      "[19]\ttraining's multi_logloss: 0.569367\tvalid_1's multi_logloss: 0.593583        \n",
      "[20]\ttraining's multi_logloss: 0.547107\tvalid_1's multi_logloss: 0.572335        \n",
      "[21]\ttraining's multi_logloss: 0.526326\tvalid_1's multi_logloss: 0.552889        \n",
      "[22]\ttraining's multi_logloss: 0.506966\tvalid_1's multi_logloss: 0.534439        \n",
      "[23]\ttraining's multi_logloss: 0.489304\tvalid_1's multi_logloss: 0.518069        \n",
      "[24]\ttraining's multi_logloss: 0.472384\tvalid_1's multi_logloss: 0.502422        \n",
      "[25]\ttraining's multi_logloss: 0.456527\tvalid_1's multi_logloss: 0.487731        \n",
      "[26]\ttraining's multi_logloss: 0.44169\tvalid_1's multi_logloss: 0.473935         \n",
      "[27]\ttraining's multi_logloss: 0.428372\tvalid_1's multi_logloss: 0.461829        \n",
      "[28]\ttraining's multi_logloss: 0.4158\tvalid_1's multi_logloss: 0.450579          \n",
      "[29]\ttraining's multi_logloss: 0.403641\tvalid_1's multi_logloss: 0.439723        \n",
      "[30]\ttraining's multi_logloss: 0.392548\tvalid_1's multi_logloss: 0.429858        \n",
      "[31]\ttraining's multi_logloss: 0.382181\tvalid_1's multi_logloss: 0.42048         \n",
      "[32]\ttraining's multi_logloss: 0.372285\tvalid_1's multi_logloss: 0.411498        \n",
      "[33]\ttraining's multi_logloss: 0.363067\tvalid_1's multi_logloss: 0.403356        \n",
      "[34]\ttraining's multi_logloss: 0.354246\tvalid_1's multi_logloss: 0.395674        \n",
      "[35]\ttraining's multi_logloss: 0.34611\tvalid_1's multi_logloss: 0.388817         \n",
      "[36]\ttraining's multi_logloss: 0.338258\tvalid_1's multi_logloss: 0.381965        \n",
      "[37]\ttraining's multi_logloss: 0.331144\tvalid_1's multi_logloss: 0.37613         \n",
      "[38]\ttraining's multi_logloss: 0.324046\tvalid_1's multi_logloss: 0.370103        \n",
      "[39]\ttraining's multi_logloss: 0.317311\tvalid_1's multi_logloss: 0.364755        \n",
      "[40]\ttraining's multi_logloss: 0.31097\tvalid_1's multi_logloss: 0.359535         \n",
      "[41]\ttraining's multi_logloss: 0.304707\tvalid_1's multi_logloss: 0.354348        \n",
      "[42]\ttraining's multi_logloss: 0.298703\tvalid_1's multi_logloss: 0.349532        \n",
      "[43]\ttraining's multi_logloss: 0.293254\tvalid_1's multi_logloss: 0.345191        \n",
      "[44]\ttraining's multi_logloss: 0.287827\tvalid_1's multi_logloss: 0.340939        \n",
      "[45]\ttraining's multi_logloss: 0.282776\tvalid_1's multi_logloss: 0.337337        \n",
      "[46]\ttraining's multi_logloss: 0.277866\tvalid_1's multi_logloss: 0.333907        \n",
      "[47]\ttraining's multi_logloss: 0.27336\tvalid_1's multi_logloss: 0.330675         \n",
      "[48]\ttraining's multi_logloss: 0.268937\tvalid_1's multi_logloss: 0.327691        \n",
      "[49]\ttraining's multi_logloss: 0.264924\tvalid_1's multi_logloss: 0.325093        \n",
      "[50]\ttraining's multi_logloss: 0.260852\tvalid_1's multi_logloss: 0.322513        \n",
      "[51]\ttraining's multi_logloss: 0.256687\tvalid_1's multi_logloss: 0.320038        \n",
      "[52]\ttraining's multi_logloss: 0.252939\tvalid_1's multi_logloss: 0.317727        \n",
      "[53]\ttraining's multi_logloss: 0.249157\tvalid_1's multi_logloss: 0.315387        \n",
      "[54]\ttraining's multi_logloss: 0.245617\tvalid_1's multi_logloss: 0.313471        \n",
      "[55]\ttraining's multi_logloss: 0.242398\tvalid_1's multi_logloss: 0.311742        \n",
      "[56]\ttraining's multi_logloss: 0.239089\tvalid_1's multi_logloss: 0.309913        \n",
      "[57]\ttraining's multi_logloss: 0.236069\tvalid_1's multi_logloss: 0.308237        \n",
      "[58]\ttraining's multi_logloss: 0.232982\tvalid_1's multi_logloss: 0.306683        \n",
      "[59]\ttraining's multi_logloss: 0.230092\tvalid_1's multi_logloss: 0.305273        \n",
      "[60]\ttraining's multi_logloss: 0.227352\tvalid_1's multi_logloss: 0.304021        \n",
      "[61]\ttraining's multi_logloss: 0.224599\tvalid_1's multi_logloss: 0.302775        \n",
      "[62]\ttraining's multi_logloss: 0.221945\tvalid_1's multi_logloss: 0.301666        \n",
      "[63]\ttraining's multi_logloss: 0.219367\tvalid_1's multi_logloss: 0.300515        \n",
      "[64]\ttraining's multi_logloss: 0.216838\tvalid_1's multi_logloss: 0.299378        \n",
      "[65]\ttraining's multi_logloss: 0.214368\tvalid_1's multi_logloss: 0.29854         \n",
      "[66]\ttraining's multi_logloss: 0.211898\tvalid_1's multi_logloss: 0.297541        \n",
      "[67]\ttraining's multi_logloss: 0.209482\tvalid_1's multi_logloss: 0.296496        \n",
      "[68]\ttraining's multi_logloss: 0.207269\tvalid_1's multi_logloss: 0.295482        \n",
      "[69]\ttraining's multi_logloss: 0.205031\tvalid_1's multi_logloss: 0.294689        \n",
      "[70]\ttraining's multi_logloss: 0.202862\tvalid_1's multi_logloss: 0.293885        \n",
      "[71]\ttraining's multi_logloss: 0.200564\tvalid_1's multi_logloss: 0.293219        \n",
      "[72]\ttraining's multi_logloss: 0.198366\tvalid_1's multi_logloss: 0.292267        \n",
      "[73]\ttraining's multi_logloss: 0.1962\tvalid_1's multi_logloss: 0.291441          \n",
      "[74]\ttraining's multi_logloss: 0.194165\tvalid_1's multi_logloss: 0.290851        \n",
      "[75]\ttraining's multi_logloss: 0.191992\tvalid_1's multi_logloss: 0.290017        \n",
      "[76]\ttraining's multi_logloss: 0.190053\tvalid_1's multi_logloss: 0.289398        \n",
      "[77]\ttraining's multi_logloss: 0.188056\tvalid_1's multi_logloss: 0.288673        \n",
      "[78]\ttraining's multi_logloss: 0.186084\tvalid_1's multi_logloss: 0.288156        \n",
      "[79]\ttraining's multi_logloss: 0.184173\tvalid_1's multi_logloss: 0.287665        \n",
      "[80]\ttraining's multi_logloss: 0.182308\tvalid_1's multi_logloss: 0.287369        \n",
      "[81]\ttraining's multi_logloss: 0.180363\tvalid_1's multi_logloss: 0.286712        \n",
      "[82]\ttraining's multi_logloss: 0.178563\tvalid_1's multi_logloss: 0.286285        \n",
      "[83]\ttraining's multi_logloss: 0.176855\tvalid_1's multi_logloss: 0.285804        \n",
      "[84]\ttraining's multi_logloss: 0.175089\tvalid_1's multi_logloss: 0.285547        \n",
      "[85]\ttraining's multi_logloss: 0.173426\tvalid_1's multi_logloss: 0.285263        \n",
      "[86]\ttraining's multi_logloss: 0.171795\tvalid_1's multi_logloss: 0.285023        \n",
      "[87]\ttraining's multi_logloss: 0.170083\tvalid_1's multi_logloss: 0.284464        \n",
      "[88]\ttraining's multi_logloss: 0.16841\tvalid_1's multi_logloss: 0.284162         \n",
      "[89]\ttraining's multi_logloss: 0.166914\tvalid_1's multi_logloss: 0.283966        \n",
      "[90]\ttraining's multi_logloss: 0.165344\tvalid_1's multi_logloss: 0.283575        \n",
      "[91]\ttraining's multi_logloss: 0.16383\tvalid_1's multi_logloss: 0.283466         \n",
      "[92]\ttraining's multi_logloss: 0.162322\tvalid_1's multi_logloss: 0.283051        \n",
      "[93]\ttraining's multi_logloss: 0.160903\tvalid_1's multi_logloss: 0.282692        \n",
      "[94]\ttraining's multi_logloss: 0.159431\tvalid_1's multi_logloss: 0.282521        \n",
      "[95]\ttraining's multi_logloss: 0.157956\tvalid_1's multi_logloss: 0.282167        \n",
      "[96]\ttraining's multi_logloss: 0.156534\tvalid_1's multi_logloss: 0.281927        \n",
      "[97]\ttraining's multi_logloss: 0.155207\tvalid_1's multi_logloss: 0.281841        \n",
      "[98]\ttraining's multi_logloss: 0.153861\tvalid_1's multi_logloss: 0.281673        \n",
      "[99]\ttraining's multi_logloss: 0.152551\tvalid_1's multi_logloss: 0.281634        \n",
      "[100]\ttraining's multi_logloss: 0.151234\tvalid_1's multi_logloss: 0.281599       \n",
      "[101]\ttraining's multi_logloss: 0.149968\tvalid_1's multi_logloss: 0.281531       \n",
      "[102]\ttraining's multi_logloss: 0.148665\tvalid_1's multi_logloss: 0.281224       \n",
      "[103]\ttraining's multi_logloss: 0.147347\tvalid_1's multi_logloss: 0.281012       \n",
      "[104]\ttraining's multi_logloss: 0.146123\tvalid_1's multi_logloss: 0.280941       \n",
      "[105]\ttraining's multi_logloss: 0.14487\tvalid_1's multi_logloss: 0.280785        \n",
      "[106]\ttraining's multi_logloss: 0.143712\tvalid_1's multi_logloss: 0.280715       \n",
      "[107]\ttraining's multi_logloss: 0.142555\tvalid_1's multi_logloss: 0.280547       \n",
      "[108]\ttraining's multi_logloss: 0.141355\tvalid_1's multi_logloss: 0.280444       \n",
      "[109]\ttraining's multi_logloss: 0.139989\tvalid_1's multi_logloss: 0.28028        \n",
      "[110]\ttraining's multi_logloss: 0.138888\tvalid_1's multi_logloss: 0.280271       \n",
      "[111]\ttraining's multi_logloss: 0.137704\tvalid_1's multi_logloss: 0.280252       \n",
      "[112]\ttraining's multi_logloss: 0.13653\tvalid_1's multi_logloss: 0.280083        \n",
      "[113]\ttraining's multi_logloss: 0.135413\tvalid_1's multi_logloss: 0.280095       \n",
      "[114]\ttraining's multi_logloss: 0.134202\tvalid_1's multi_logloss: 0.280356       \n",
      "[115]\ttraining's multi_logloss: 0.133125\tvalid_1's multi_logloss: 0.280444       \n",
      "[116]\ttraining's multi_logloss: 0.132098\tvalid_1's multi_logloss: 0.280356       \n",
      "[117]\ttraining's multi_logloss: 0.130911\tvalid_1's multi_logloss: 0.280481       \n",
      "[118]\ttraining's multi_logloss: 0.129793\tvalid_1's multi_logloss: 0.280396       \n",
      "[119]\ttraining's multi_logloss: 0.128788\tvalid_1's multi_logloss: 0.280521       \n",
      "[120]\ttraining's multi_logloss: 0.127857\tvalid_1's multi_logloss: 0.280533       \n",
      "[121]\ttraining's multi_logloss: 0.126794\tvalid_1's multi_logloss: 0.280575       \n",
      "[122]\ttraining's multi_logloss: 0.125799\tvalid_1's multi_logloss: 0.280673       \n",
      "[123]\ttraining's multi_logloss: 0.124829\tvalid_1's multi_logloss: 0.280669       \n",
      "[124]\ttraining's multi_logloss: 0.12386\tvalid_1's multi_logloss: 0.280601        \n",
      "[125]\ttraining's multi_logloss: 0.122983\tvalid_1's multi_logloss: 0.280699       \n",
      "[126]\ttraining's multi_logloss: 0.122014\tvalid_1's multi_logloss: 0.280916       \n",
      "[127]\ttraining's multi_logloss: 0.121099\tvalid_1's multi_logloss: 0.281003       \n",
      "[128]\ttraining's multi_logloss: 0.120171\tvalid_1's multi_logloss: 0.281288       \n",
      "[129]\ttraining's multi_logloss: 0.119275\tvalid_1's multi_logloss: 0.281307       \n",
      "[130]\ttraining's multi_logloss: 0.118319\tvalid_1's multi_logloss: 0.281449       \n",
      "[131]\ttraining's multi_logloss: 0.117353\tvalid_1's multi_logloss: 0.28151        \n",
      "[132]\ttraining's multi_logloss: 0.116483\tvalid_1's multi_logloss: 0.281743       \n",
      "[133]\ttraining's multi_logloss: 0.1156\tvalid_1's multi_logloss: 0.281916         \n",
      "[134]\ttraining's multi_logloss: 0.114664\tvalid_1's multi_logloss: 0.281837       \n",
      "[135]\ttraining's multi_logloss: 0.113874\tvalid_1's multi_logloss: 0.281942       \n",
      "[136]\ttraining's multi_logloss: 0.112974\tvalid_1's multi_logloss: 0.282142       \n",
      "[137]\ttraining's multi_logloss: 0.11215\tvalid_1's multi_logloss: 0.282132        \n",
      "[138]\ttraining's multi_logloss: 0.111316\tvalid_1's multi_logloss: 0.282266       \n",
      "[139]\ttraining's multi_logloss: 0.110564\tvalid_1's multi_logloss: 0.282282       \n",
      "[140]\ttraining's multi_logloss: 0.10977\tvalid_1's multi_logloss: 0.282156        \n",
      "[141]\ttraining's multi_logloss: 0.109054\tvalid_1's multi_logloss: 0.282176       \n",
      "[142]\ttraining's multi_logloss: 0.108363\tvalid_1's multi_logloss: 0.28212        \n",
      "Early stopping, best iteration is:                                               \n",
      "[112]\ttraining's multi_logloss: 0.13653\tvalid_1's multi_logloss: 0.280083\n",
      "[1]\ttraining's multi_logloss: 1.7191\tvalid_1's multi_logloss: 1.7222             \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.55698\tvalid_1's multi_logloss: 1.56154           \n",
      "[3]\ttraining's multi_logloss: 1.4234\tvalid_1's multi_logloss: 1.42868            \n",
      "[4]\ttraining's multi_logloss: 1.31153\tvalid_1's multi_logloss: 1.31777           \n",
      "[5]\ttraining's multi_logloss: 1.21607\tvalid_1's multi_logloss: 1.22304           \n",
      "[6]\ttraining's multi_logloss: 1.13248\tvalid_1's multi_logloss: 1.14015           \n",
      "[7]\ttraining's multi_logloss: 1.05899\tvalid_1's multi_logloss: 1.06731           \n",
      "[8]\ttraining's multi_logloss: 0.993347\tvalid_1's multi_logloss: 1.00216          \n",
      "[9]\ttraining's multi_logloss: 0.934633\tvalid_1's multi_logloss: 0.94402          \n",
      "[10]\ttraining's multi_logloss: 0.881649\tvalid_1's multi_logloss: 0.891687        \n",
      "[11]\ttraining's multi_logloss: 0.832948\tvalid_1's multi_logloss: 0.843751        \n",
      "[12]\ttraining's multi_logloss: 0.788593\tvalid_1's multi_logloss: 0.800409        \n",
      "[13]\ttraining's multi_logloss: 0.749114\tvalid_1's multi_logloss: 0.761978        \n",
      "[14]\ttraining's multi_logloss: 0.712931\tvalid_1's multi_logloss: 0.726668        \n",
      "[15]\ttraining's multi_logloss: 0.679517\tvalid_1's multi_logloss: 0.694142        \n",
      "[16]\ttraining's multi_logloss: 0.648945\tvalid_1's multi_logloss: 0.664558        \n",
      "[17]\ttraining's multi_logloss: 0.621021\tvalid_1's multi_logloss: 0.637752        \n",
      "[18]\ttraining's multi_logloss: 0.595103\tvalid_1's multi_logloss: 0.612656        \n",
      "[19]\ttraining's multi_logloss: 0.570763\tvalid_1's multi_logloss: 0.589038        \n",
      "[20]\ttraining's multi_logloss: 0.548643\tvalid_1's multi_logloss: 0.567819        \n",
      "[21]\ttraining's multi_logloss: 0.528185\tvalid_1's multi_logloss: 0.548273        \n",
      "[22]\ttraining's multi_logloss: 0.509139\tvalid_1's multi_logloss: 0.530016        \n",
      "[23]\ttraining's multi_logloss: 0.491471\tvalid_1's multi_logloss: 0.513349        \n",
      "[24]\ttraining's multi_logloss: 0.474967\tvalid_1's multi_logloss: 0.497731        \n",
      "[25]\ttraining's multi_logloss: 0.45959\tvalid_1's multi_logloss: 0.483255         \n",
      "[26]\ttraining's multi_logloss: 0.445279\tvalid_1's multi_logloss: 0.469724        \n",
      "[27]\ttraining's multi_logloss: 0.431706\tvalid_1's multi_logloss: 0.457008        \n",
      "[28]\ttraining's multi_logloss: 0.419062\tvalid_1's multi_logloss: 0.445246        \n",
      "[29]\ttraining's multi_logloss: 0.407146\tvalid_1's multi_logloss: 0.434277        \n",
      "[30]\ttraining's multi_logloss: 0.39616\tvalid_1's multi_logloss: 0.424291         \n",
      "[31]\ttraining's multi_logloss: 0.385636\tvalid_1's multi_logloss: 0.414531        \n",
      "[32]\ttraining's multi_logloss: 0.375998\tvalid_1's multi_logloss: 0.405641        \n",
      "[33]\ttraining's multi_logloss: 0.366845\tvalid_1's multi_logloss: 0.397308        \n",
      "[34]\ttraining's multi_logloss: 0.358244\tvalid_1's multi_logloss: 0.389368        \n",
      "[35]\ttraining's multi_logloss: 0.350032\tvalid_1's multi_logloss: 0.38196         \n",
      "[36]\ttraining's multi_logloss: 0.342342\tvalid_1's multi_logloss: 0.375363        \n",
      "[37]\ttraining's multi_logloss: 0.335275\tvalid_1's multi_logloss: 0.369466        \n",
      "[38]\ttraining's multi_logloss: 0.328517\tvalid_1's multi_logloss: 0.363626        \n",
      "[39]\ttraining's multi_logloss: 0.322049\tvalid_1's multi_logloss: 0.358238        \n",
      "[40]\ttraining's multi_logloss: 0.315758\tvalid_1's multi_logloss: 0.352819        \n",
      "[41]\ttraining's multi_logloss: 0.309763\tvalid_1's multi_logloss: 0.348001        \n",
      "[42]\ttraining's multi_logloss: 0.303732\tvalid_1's multi_logloss: 0.342972        \n",
      "[43]\ttraining's multi_logloss: 0.298376\tvalid_1's multi_logloss: 0.338893        \n",
      "[44]\ttraining's multi_logloss: 0.293153\tvalid_1's multi_logloss: 0.334805        \n",
      "[45]\ttraining's multi_logloss: 0.288027\tvalid_1's multi_logloss: 0.330646        \n",
      "[46]\ttraining's multi_logloss: 0.283309\tvalid_1's multi_logloss: 0.327269        \n",
      "[47]\ttraining's multi_logloss: 0.278791\tvalid_1's multi_logloss: 0.323994        \n",
      "[48]\ttraining's multi_logloss: 0.274539\tvalid_1's multi_logloss: 0.320922        \n",
      "[49]\ttraining's multi_logloss: 0.270316\tvalid_1's multi_logloss: 0.317972        \n",
      "[50]\ttraining's multi_logloss: 0.26627\tvalid_1's multi_logloss: 0.31496          \n",
      "[51]\ttraining's multi_logloss: 0.262335\tvalid_1's multi_logloss: 0.312416        \n",
      "[52]\ttraining's multi_logloss: 0.258738\tvalid_1's multi_logloss: 0.31003         \n",
      "[53]\ttraining's multi_logloss: 0.255363\tvalid_1's multi_logloss: 0.30768         \n",
      "[54]\ttraining's multi_logloss: 0.252088\tvalid_1's multi_logloss: 0.305624        \n",
      "[55]\ttraining's multi_logloss: 0.248759\tvalid_1's multi_logloss: 0.303545        \n",
      "[56]\ttraining's multi_logloss: 0.245604\tvalid_1's multi_logloss: 0.301539        \n",
      "[57]\ttraining's multi_logloss: 0.242495\tvalid_1's multi_logloss: 0.299862        \n",
      "[58]\ttraining's multi_logloss: 0.239629\tvalid_1's multi_logloss: 0.297996        \n",
      "[59]\ttraining's multi_logloss: 0.236698\tvalid_1's multi_logloss: 0.296105        \n",
      "[60]\ttraining's multi_logloss: 0.234052\tvalid_1's multi_logloss: 0.294757        \n",
      "[61]\ttraining's multi_logloss: 0.23124\tvalid_1's multi_logloss: 0.293306         \n",
      "[62]\ttraining's multi_logloss: 0.228582\tvalid_1's multi_logloss: 0.291858        \n",
      "[63]\ttraining's multi_logloss: 0.225928\tvalid_1's multi_logloss: 0.290446        \n",
      "[64]\ttraining's multi_logloss: 0.223447\tvalid_1's multi_logloss: 0.289198        \n",
      "[65]\ttraining's multi_logloss: 0.221047\tvalid_1's multi_logloss: 0.288087        \n",
      "[66]\ttraining's multi_logloss: 0.218662\tvalid_1's multi_logloss: 0.286796        \n",
      "[67]\ttraining's multi_logloss: 0.21638\tvalid_1's multi_logloss: 0.285623         \n",
      "[68]\ttraining's multi_logloss: 0.214023\tvalid_1's multi_logloss: 0.284505        \n",
      "[69]\ttraining's multi_logloss: 0.211723\tvalid_1's multi_logloss: 0.283721        \n",
      "[70]\ttraining's multi_logloss: 0.209566\tvalid_1's multi_logloss: 0.282749        \n",
      "[71]\ttraining's multi_logloss: 0.207371\tvalid_1's multi_logloss: 0.282079        \n",
      "[72]\ttraining's multi_logloss: 0.205137\tvalid_1's multi_logloss: 0.281312        \n",
      "[73]\ttraining's multi_logloss: 0.203087\tvalid_1's multi_logloss: 0.280348        \n",
      "[74]\ttraining's multi_logloss: 0.20105\tvalid_1's multi_logloss: 0.279512         \n",
      "[75]\ttraining's multi_logloss: 0.198905\tvalid_1's multi_logloss: 0.27887         \n",
      "[76]\ttraining's multi_logloss: 0.19687\tvalid_1's multi_logloss: 0.278117         \n",
      "[77]\ttraining's multi_logloss: 0.194952\tvalid_1's multi_logloss: 0.277413        \n",
      "[78]\ttraining's multi_logloss: 0.193036\tvalid_1's multi_logloss: 0.276893        \n",
      "[79]\ttraining's multi_logloss: 0.191183\tvalid_1's multi_logloss: 0.276641        \n",
      "[80]\ttraining's multi_logloss: 0.189262\tvalid_1's multi_logloss: 0.276279        \n",
      "[81]\ttraining's multi_logloss: 0.187432\tvalid_1's multi_logloss: 0.275635        \n",
      "[82]\ttraining's multi_logloss: 0.185709\tvalid_1's multi_logloss: 0.275244        \n",
      "[83]\ttraining's multi_logloss: 0.183886\tvalid_1's multi_logloss: 0.274896        \n",
      "[84]\ttraining's multi_logloss: 0.182133\tvalid_1's multi_logloss: 0.274507        \n",
      "[85]\ttraining's multi_logloss: 0.180532\tvalid_1's multi_logloss: 0.274181        \n",
      "[86]\ttraining's multi_logloss: 0.17895\tvalid_1's multi_logloss: 0.273856         \n",
      "[87]\ttraining's multi_logloss: 0.177318\tvalid_1's multi_logloss: 0.273519        \n",
      "[88]\ttraining's multi_logloss: 0.175695\tvalid_1's multi_logloss: 0.273282        \n",
      "[89]\ttraining's multi_logloss: 0.174088\tvalid_1's multi_logloss: 0.273095        \n",
      "[90]\ttraining's multi_logloss: 0.172463\tvalid_1's multi_logloss: 0.272662        \n",
      "[91]\ttraining's multi_logloss: 0.170878\tvalid_1's multi_logloss: 0.272361        \n",
      "[92]\ttraining's multi_logloss: 0.169302\tvalid_1's multi_logloss: 0.271951        \n",
      "[93]\ttraining's multi_logloss: 0.167838\tvalid_1's multi_logloss: 0.271642        \n",
      "[94]\ttraining's multi_logloss: 0.166327\tvalid_1's multi_logloss: 0.271517        \n",
      "[95]\ttraining's multi_logloss: 0.16485\tvalid_1's multi_logloss: 0.271203         \n",
      "[96]\ttraining's multi_logloss: 0.163407\tvalid_1's multi_logloss: 0.271045        \n",
      "[97]\ttraining's multi_logloss: 0.161987\tvalid_1's multi_logloss: 0.270798        \n",
      "[98]\ttraining's multi_logloss: 0.160611\tvalid_1's multi_logloss: 0.270651        \n",
      "[99]\ttraining's multi_logloss: 0.159202\tvalid_1's multi_logloss: 0.270453        \n",
      "[100]\ttraining's multi_logloss: 0.157829\tvalid_1's multi_logloss: 0.27025        \n",
      "[101]\ttraining's multi_logloss: 0.156464\tvalid_1's multi_logloss: 0.270088       \n",
      "[102]\ttraining's multi_logloss: 0.155131\tvalid_1's multi_logloss: 0.270032       \n",
      "[103]\ttraining's multi_logloss: 0.153863\tvalid_1's multi_logloss: 0.27           \n",
      "[104]\ttraining's multi_logloss: 0.152477\tvalid_1's multi_logloss: 0.269735       \n",
      "[105]\ttraining's multi_logloss: 0.151236\tvalid_1's multi_logloss: 0.269836       \n",
      "[106]\ttraining's multi_logloss: 0.150112\tvalid_1's multi_logloss: 0.269634       \n",
      "[107]\ttraining's multi_logloss: 0.148873\tvalid_1's multi_logloss: 0.269473       \n",
      "[108]\ttraining's multi_logloss: 0.14762\tvalid_1's multi_logloss: 0.269111        \n",
      "[109]\ttraining's multi_logloss: 0.146464\tvalid_1's multi_logloss: 0.26928        \n",
      "[110]\ttraining's multi_logloss: 0.14531\tvalid_1's multi_logloss: 0.269186        \n",
      "[111]\ttraining's multi_logloss: 0.144101\tvalid_1's multi_logloss: 0.269092       \n",
      "[112]\ttraining's multi_logloss: 0.142999\tvalid_1's multi_logloss: 0.26907        \n",
      "[113]\ttraining's multi_logloss: 0.141918\tvalid_1's multi_logloss: 0.268978       \n",
      "[114]\ttraining's multi_logloss: 0.14086\tvalid_1's multi_logloss: 0.268901        \n",
      "[115]\ttraining's multi_logloss: 0.139742\tvalid_1's multi_logloss: 0.268789       \n",
      "[116]\ttraining's multi_logloss: 0.138609\tvalid_1's multi_logloss: 0.268748       \n",
      "[117]\ttraining's multi_logloss: 0.137547\tvalid_1's multi_logloss: 0.268608       \n",
      "[118]\ttraining's multi_logloss: 0.136514\tvalid_1's multi_logloss: 0.268427       \n",
      "[119]\ttraining's multi_logloss: 0.135424\tvalid_1's multi_logloss: 0.268399       \n",
      "[120]\ttraining's multi_logloss: 0.134444\tvalid_1's multi_logloss: 0.268505       \n",
      "[121]\ttraining's multi_logloss: 0.133409\tvalid_1's multi_logloss: 0.268629       \n",
      "[122]\ttraining's multi_logloss: 0.132412\tvalid_1's multi_logloss: 0.268716       \n",
      "[123]\ttraining's multi_logloss: 0.131274\tvalid_1's multi_logloss: 0.268733       \n",
      "[124]\ttraining's multi_logloss: 0.130228\tvalid_1's multi_logloss: 0.268583       \n",
      "[125]\ttraining's multi_logloss: 0.129337\tvalid_1's multi_logloss: 0.268678       \n",
      "[126]\ttraining's multi_logloss: 0.128385\tvalid_1's multi_logloss: 0.268783       \n",
      "[127]\ttraining's multi_logloss: 0.127568\tvalid_1's multi_logloss: 0.268903       \n",
      "[128]\ttraining's multi_logloss: 0.126623\tvalid_1's multi_logloss: 0.268949       \n",
      "[129]\ttraining's multi_logloss: 0.125791\tvalid_1's multi_logloss: 0.268955       \n",
      "[130]\ttraining's multi_logloss: 0.124958\tvalid_1's multi_logloss: 0.269119       \n",
      "[131]\ttraining's multi_logloss: 0.12411\tvalid_1's multi_logloss: 0.269136        \n",
      "[132]\ttraining's multi_logloss: 0.123335\tvalid_1's multi_logloss: 0.269252       \n",
      "[133]\ttraining's multi_logloss: 0.122484\tvalid_1's multi_logloss: 0.269223       \n",
      "[134]\ttraining's multi_logloss: 0.121635\tvalid_1's multi_logloss: 0.269287       \n",
      "[135]\ttraining's multi_logloss: 0.120778\tvalid_1's multi_logloss: 0.269448       \n",
      "[136]\ttraining's multi_logloss: 0.119824\tvalid_1's multi_logloss: 0.269497       \n",
      "[137]\ttraining's multi_logloss: 0.119013\tvalid_1's multi_logloss: 0.269611       \n",
      "[138]\ttraining's multi_logloss: 0.118176\tvalid_1's multi_logloss: 0.2696         \n",
      "[139]\ttraining's multi_logloss: 0.117309\tvalid_1's multi_logloss: 0.269623       \n",
      "[140]\ttraining's multi_logloss: 0.11637\tvalid_1's multi_logloss: 0.269549        \n",
      "[141]\ttraining's multi_logloss: 0.115594\tvalid_1's multi_logloss: 0.269833       \n",
      "[142]\ttraining's multi_logloss: 0.114806\tvalid_1's multi_logloss: 0.269771       \n",
      "[143]\ttraining's multi_logloss: 0.114036\tvalid_1's multi_logloss: 0.269799       \n",
      "[144]\ttraining's multi_logloss: 0.113286\tvalid_1's multi_logloss: 0.269877       \n",
      "[145]\ttraining's multi_logloss: 0.112606\tvalid_1's multi_logloss: 0.270017       \n",
      "[146]\ttraining's multi_logloss: 0.111859\tvalid_1's multi_logloss: 0.270083       \n",
      "[147]\ttraining's multi_logloss: 0.111086\tvalid_1's multi_logloss: 0.270087       \n",
      "[148]\ttraining's multi_logloss: 0.110348\tvalid_1's multi_logloss: 0.270263       \n",
      "[149]\ttraining's multi_logloss: 0.109509\tvalid_1's multi_logloss: 0.270278       \n",
      "Early stopping, best iteration is:                                               \n",
      "[119]\ttraining's multi_logloss: 0.135424\tvalid_1's multi_logloss: 0.268399\n",
      "[1]\ttraining's multi_logloss: 1.63382\tvalid_1's multi_logloss: 1.63809           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.42375\tvalid_1's multi_logloss: 1.43291           \n",
      "[3]\ttraining's multi_logloss: 1.2629\tvalid_1's multi_logloss: 1.27681            \n",
      "[4]\ttraining's multi_logloss: 1.13415\tvalid_1's multi_logloss: 1.15172           \n",
      "[5]\ttraining's multi_logloss: 1.02754\tvalid_1's multi_logloss: 1.04869           \n",
      "[6]\ttraining's multi_logloss: 0.938164\tvalid_1's multi_logloss: 0.962232         \n",
      "[7]\ttraining's multi_logloss: 0.860732\tvalid_1's multi_logloss: 0.887568         \n",
      "[8]\ttraining's multi_logloss: 0.793804\tvalid_1's multi_logloss: 0.822878         \n",
      "[9]\ttraining's multi_logloss: 0.735389\tvalid_1's multi_logloss: 0.766595         \n",
      "[10]\ttraining's multi_logloss: 0.684232\tvalid_1's multi_logloss: 0.717602        \n",
      "[11]\ttraining's multi_logloss: 0.639194\tvalid_1's multi_logloss: 0.674708        \n",
      "[12]\ttraining's multi_logloss: 0.598869\tvalid_1's multi_logloss: 0.636385        \n",
      "[13]\ttraining's multi_logloss: 0.562785\tvalid_1's multi_logloss: 0.601985        \n",
      "[14]\ttraining's multi_logloss: 0.530182\tvalid_1's multi_logloss: 0.571694        \n",
      "[15]\ttraining's multi_logloss: 0.501398\tvalid_1's multi_logloss: 0.544516        \n",
      "[16]\ttraining's multi_logloss: 0.475254\tvalid_1's multi_logloss: 0.520125        \n",
      "[17]\ttraining's multi_logloss: 0.451637\tvalid_1's multi_logloss: 0.498253        \n",
      "[18]\ttraining's multi_logloss: 0.430397\tvalid_1's multi_logloss: 0.479066        \n",
      "[19]\ttraining's multi_logloss: 0.411145\tvalid_1's multi_logloss: 0.461468        \n",
      "[20]\ttraining's multi_logloss: 0.393875\tvalid_1's multi_logloss: 0.445762        \n",
      "[21]\ttraining's multi_logloss: 0.377947\tvalid_1's multi_logloss: 0.43108         \n",
      "[22]\ttraining's multi_logloss: 0.363698\tvalid_1's multi_logloss: 0.418662        \n",
      "[23]\ttraining's multi_logloss: 0.350538\tvalid_1's multi_logloss: 0.406967        \n",
      "[24]\ttraining's multi_logloss: 0.338338\tvalid_1's multi_logloss: 0.396716        \n",
      "[25]\ttraining's multi_logloss: 0.327188\tvalid_1's multi_logloss: 0.387621        \n",
      "[26]\ttraining's multi_logloss: 0.316906\tvalid_1's multi_logloss: 0.379357        \n",
      "[27]\ttraining's multi_logloss: 0.307549\tvalid_1's multi_logloss: 0.371724        \n",
      "[28]\ttraining's multi_logloss: 0.298548\tvalid_1's multi_logloss: 0.364369        \n",
      "[29]\ttraining's multi_logloss: 0.290199\tvalid_1's multi_logloss: 0.35804         \n",
      "[30]\ttraining's multi_logloss: 0.282303\tvalid_1's multi_logloss: 0.352237        \n",
      "[31]\ttraining's multi_logloss: 0.274892\tvalid_1's multi_logloss: 0.347078        \n",
      "[32]\ttraining's multi_logloss: 0.267758\tvalid_1's multi_logloss: 0.342173        \n",
      "[33]\ttraining's multi_logloss: 0.261374\tvalid_1's multi_logloss: 0.337635        \n",
      "[34]\ttraining's multi_logloss: 0.255364\tvalid_1's multi_logloss: 0.33346         \n",
      "[35]\ttraining's multi_logloss: 0.249771\tvalid_1's multi_logloss: 0.329957        \n",
      "[36]\ttraining's multi_logloss: 0.244299\tvalid_1's multi_logloss: 0.326538        \n",
      "[37]\ttraining's multi_logloss: 0.239026\tvalid_1's multi_logloss: 0.323238        \n",
      "[38]\ttraining's multi_logloss: 0.234233\tvalid_1's multi_logloss: 0.320476        \n",
      "[39]\ttraining's multi_logloss: 0.229419\tvalid_1's multi_logloss: 0.317933        \n",
      "[40]\ttraining's multi_logloss: 0.224899\tvalid_1's multi_logloss: 0.315543        \n",
      "[41]\ttraining's multi_logloss: 0.220688\tvalid_1's multi_logloss: 0.313339        \n",
      "[42]\ttraining's multi_logloss: 0.216624\tvalid_1's multi_logloss: 0.31164         \n",
      "[43]\ttraining's multi_logloss: 0.212564\tvalid_1's multi_logloss: 0.309704        \n",
      "[44]\ttraining's multi_logloss: 0.20877\tvalid_1's multi_logloss: 0.307663         \n",
      "[45]\ttraining's multi_logloss: 0.205218\tvalid_1's multi_logloss: 0.306095        \n",
      "[46]\ttraining's multi_logloss: 0.201802\tvalid_1's multi_logloss: 0.30491         \n",
      "[47]\ttraining's multi_logloss: 0.198355\tvalid_1's multi_logloss: 0.303542        \n",
      "[48]\ttraining's multi_logloss: 0.195163\tvalid_1's multi_logloss: 0.302654        \n",
      "[49]\ttraining's multi_logloss: 0.192202\tvalid_1's multi_logloss: 0.301441        \n",
      "[50]\ttraining's multi_logloss: 0.189177\tvalid_1's multi_logloss: 0.30041         \n",
      "[51]\ttraining's multi_logloss: 0.186091\tvalid_1's multi_logloss: 0.29938         \n",
      "[52]\ttraining's multi_logloss: 0.183046\tvalid_1's multi_logloss: 0.298658        \n",
      "[53]\ttraining's multi_logloss: 0.180211\tvalid_1's multi_logloss: 0.297625        \n",
      "[54]\ttraining's multi_logloss: 0.177308\tvalid_1's multi_logloss: 0.296733        \n",
      "[55]\ttraining's multi_logloss: 0.174786\tvalid_1's multi_logloss: 0.296019        \n",
      "[56]\ttraining's multi_logloss: 0.172013\tvalid_1's multi_logloss: 0.295208        \n",
      "[57]\ttraining's multi_logloss: 0.169373\tvalid_1's multi_logloss: 0.294672        \n",
      "[58]\ttraining's multi_logloss: 0.166881\tvalid_1's multi_logloss: 0.294073        \n",
      "[59]\ttraining's multi_logloss: 0.164325\tvalid_1's multi_logloss: 0.293553        \n",
      "[60]\ttraining's multi_logloss: 0.162023\tvalid_1's multi_logloss: 0.292935        \n",
      "[61]\ttraining's multi_logloss: 0.159793\tvalid_1's multi_logloss: 0.292399        \n",
      "[62]\ttraining's multi_logloss: 0.157667\tvalid_1's multi_logloss: 0.29187         \n",
      "[63]\ttraining's multi_logloss: 0.155378\tvalid_1's multi_logloss: 0.291492        \n",
      "[64]\ttraining's multi_logloss: 0.153172\tvalid_1's multi_logloss: 0.291088        \n",
      "[65]\ttraining's multi_logloss: 0.151006\tvalid_1's multi_logloss: 0.290764        \n",
      "[66]\ttraining's multi_logloss: 0.148954\tvalid_1's multi_logloss: 0.290331        \n",
      "[67]\ttraining's multi_logloss: 0.146873\tvalid_1's multi_logloss: 0.290128        \n",
      "[68]\ttraining's multi_logloss: 0.144771\tvalid_1's multi_logloss: 0.289824        \n",
      "[69]\ttraining's multi_logloss: 0.14284\tvalid_1's multi_logloss: 0.289509         \n",
      "[70]\ttraining's multi_logloss: 0.140891\tvalid_1's multi_logloss: 0.289519        \n",
      "[71]\ttraining's multi_logloss: 0.139193\tvalid_1's multi_logloss: 0.289421        \n",
      "[72]\ttraining's multi_logloss: 0.137289\tvalid_1's multi_logloss: 0.28933         \n",
      "[73]\ttraining's multi_logloss: 0.135528\tvalid_1's multi_logloss: 0.288907        \n",
      "[74]\ttraining's multi_logloss: 0.133717\tvalid_1's multi_logloss: 0.288896        \n",
      "[75]\ttraining's multi_logloss: 0.132185\tvalid_1's multi_logloss: 0.288592        \n",
      "[76]\ttraining's multi_logloss: 0.130541\tvalid_1's multi_logloss: 0.288609        \n",
      "[77]\ttraining's multi_logloss: 0.128821\tvalid_1's multi_logloss: 0.288651        \n",
      "[78]\ttraining's multi_logloss: 0.127162\tvalid_1's multi_logloss: 0.288466        \n",
      "[79]\ttraining's multi_logloss: 0.125456\tvalid_1's multi_logloss: 0.288351        \n",
      "[80]\ttraining's multi_logloss: 0.123958\tvalid_1's multi_logloss: 0.288127        \n",
      "[81]\ttraining's multi_logloss: 0.122406\tvalid_1's multi_logloss: 0.288254        \n",
      "[82]\ttraining's multi_logloss: 0.120785\tvalid_1's multi_logloss: 0.28811         \n",
      "[83]\ttraining's multi_logloss: 0.119439\tvalid_1's multi_logloss: 0.288163        \n",
      "[84]\ttraining's multi_logloss: 0.117983\tvalid_1's multi_logloss: 0.288241        \n",
      "[85]\ttraining's multi_logloss: 0.116541\tvalid_1's multi_logloss: 0.288588        \n",
      "[86]\ttraining's multi_logloss: 0.115151\tvalid_1's multi_logloss: 0.288496        \n",
      "[87]\ttraining's multi_logloss: 0.113818\tvalid_1's multi_logloss: 0.288742        \n",
      "[88]\ttraining's multi_logloss: 0.112471\tvalid_1's multi_logloss: 0.289033        \n",
      "[89]\ttraining's multi_logloss: 0.111161\tvalid_1's multi_logloss: 0.289221        \n",
      "[90]\ttraining's multi_logloss: 0.109951\tvalid_1's multi_logloss: 0.289376        \n",
      "[91]\ttraining's multi_logloss: 0.108629\tvalid_1's multi_logloss: 0.289591        \n",
      "[92]\ttraining's multi_logloss: 0.107364\tvalid_1's multi_logloss: 0.289793        \n",
      "[93]\ttraining's multi_logloss: 0.106182\tvalid_1's multi_logloss: 0.289757        \n",
      "[94]\ttraining's multi_logloss: 0.105051\tvalid_1's multi_logloss: 0.289665        \n",
      "[95]\ttraining's multi_logloss: 0.103887\tvalid_1's multi_logloss: 0.290006        \n",
      "[96]\ttraining's multi_logloss: 0.102629\tvalid_1's multi_logloss: 0.289904        \n",
      "[97]\ttraining's multi_logloss: 0.101601\tvalid_1's multi_logloss: 0.289929        \n",
      "[98]\ttraining's multi_logloss: 0.100561\tvalid_1's multi_logloss: 0.290029        \n",
      "[99]\ttraining's multi_logloss: 0.0994611\tvalid_1's multi_logloss: 0.289878       \n",
      "[100]\ttraining's multi_logloss: 0.0984567\tvalid_1's multi_logloss: 0.29014       \n",
      "[101]\ttraining's multi_logloss: 0.0973679\tvalid_1's multi_logloss: 0.290237      \n",
      "[102]\ttraining's multi_logloss: 0.0963853\tvalid_1's multi_logloss: 0.29018       \n",
      "[103]\ttraining's multi_logloss: 0.0953855\tvalid_1's multi_logloss: 0.290207      \n",
      "[104]\ttraining's multi_logloss: 0.0943673\tvalid_1's multi_logloss: 0.290603      \n",
      "[105]\ttraining's multi_logloss: 0.0934123\tvalid_1's multi_logloss: 0.290893      \n",
      "[106]\ttraining's multi_logloss: 0.0923982\tvalid_1's multi_logloss: 0.291361      \n",
      "[107]\ttraining's multi_logloss: 0.0913584\tvalid_1's multi_logloss: 0.291665      \n",
      "[108]\ttraining's multi_logloss: 0.0903755\tvalid_1's multi_logloss: 0.292168      \n",
      "[109]\ttraining's multi_logloss: 0.0894754\tvalid_1's multi_logloss: 0.292637      \n",
      "[110]\ttraining's multi_logloss: 0.0884841\tvalid_1's multi_logloss: 0.292933      \n",
      "[111]\ttraining's multi_logloss: 0.0875634\tvalid_1's multi_logloss: 0.293134      \n",
      "[112]\ttraining's multi_logloss: 0.0867096\tvalid_1's multi_logloss: 0.293741      \n",
      "Early stopping, best iteration is:                                               \n",
      "[82]\ttraining's multi_logloss: 0.120785\tvalid_1's multi_logloss: 0.28811\n",
      "[1]\ttraining's multi_logloss: 1.63229\tvalid_1's multi_logloss: 1.63621           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.42491\tvalid_1's multi_logloss: 1.42996           \n",
      "[3]\ttraining's multi_logloss: 1.26668\tvalid_1's multi_logloss: 1.2743            \n",
      "[4]\ttraining's multi_logloss: 1.13875\tvalid_1's multi_logloss: 1.14836           \n",
      "[5]\ttraining's multi_logloss: 1.03343\tvalid_1's multi_logloss: 1.04553           \n",
      "[6]\ttraining's multi_logloss: 0.944414\tvalid_1's multi_logloss: 0.958105         \n",
      "[7]\ttraining's multi_logloss: 0.867947\tvalid_1's multi_logloss: 0.883684         \n",
      "[8]\ttraining's multi_logloss: 0.801645\tvalid_1's multi_logloss: 0.819133         \n",
      "[9]\ttraining's multi_logloss: 0.742797\tvalid_1's multi_logloss: 0.762364         \n",
      "[10]\ttraining's multi_logloss: 0.691617\tvalid_1's multi_logloss: 0.713493        \n",
      "[11]\ttraining's multi_logloss: 0.645931\tvalid_1's multi_logloss: 0.669838        \n",
      "[12]\ttraining's multi_logloss: 0.60533\tvalid_1's multi_logloss: 0.631077         \n",
      "[13]\ttraining's multi_logloss: 0.569473\tvalid_1's multi_logloss: 0.596875        \n",
      "[14]\ttraining's multi_logloss: 0.536734\tvalid_1's multi_logloss: 0.565791        \n",
      "[15]\ttraining's multi_logloss: 0.50801\tvalid_1's multi_logloss: 0.539208         \n",
      "[16]\ttraining's multi_logloss: 0.481988\tvalid_1's multi_logloss: 0.515013        \n",
      "[17]\ttraining's multi_logloss: 0.458389\tvalid_1's multi_logloss: 0.493139        \n",
      "[18]\ttraining's multi_logloss: 0.43676\tvalid_1's multi_logloss: 0.473679         \n",
      "[19]\ttraining's multi_logloss: 0.41776\tvalid_1's multi_logloss: 0.456893         \n",
      "[20]\ttraining's multi_logloss: 0.400255\tvalid_1's multi_logloss: 0.441709        \n",
      "[21]\ttraining's multi_logloss: 0.384076\tvalid_1's multi_logloss: 0.427345        \n",
      "[22]\ttraining's multi_logloss: 0.369235\tvalid_1's multi_logloss: 0.414224        \n",
      "[23]\ttraining's multi_logloss: 0.355351\tvalid_1's multi_logloss: 0.402346        \n",
      "[24]\ttraining's multi_logloss: 0.342729\tvalid_1's multi_logloss: 0.391987        \n",
      "[25]\ttraining's multi_logloss: 0.331138\tvalid_1's multi_logloss: 0.381976        \n",
      "[26]\ttraining's multi_logloss: 0.320386\tvalid_1's multi_logloss: 0.373079        \n",
      "[27]\ttraining's multi_logloss: 0.310635\tvalid_1's multi_logloss: 0.365565        \n",
      "[28]\ttraining's multi_logloss: 0.301453\tvalid_1's multi_logloss: 0.358372        \n",
      "[29]\ttraining's multi_logloss: 0.292696\tvalid_1's multi_logloss: 0.351787        \n",
      "[30]\ttraining's multi_logloss: 0.284514\tvalid_1's multi_logloss: 0.345976        \n",
      "[31]\ttraining's multi_logloss: 0.27683\tvalid_1's multi_logloss: 0.340159         \n",
      "[32]\ttraining's multi_logloss: 0.269828\tvalid_1's multi_logloss: 0.335351        \n",
      "[33]\ttraining's multi_logloss: 0.263318\tvalid_1's multi_logloss: 0.331082        \n",
      "[34]\ttraining's multi_logloss: 0.256973\tvalid_1's multi_logloss: 0.326713        \n",
      "[35]\ttraining's multi_logloss: 0.251203\tvalid_1's multi_logloss: 0.323117        \n",
      "[36]\ttraining's multi_logloss: 0.245647\tvalid_1's multi_logloss: 0.319593        \n",
      "[37]\ttraining's multi_logloss: 0.240375\tvalid_1's multi_logloss: 0.316684        \n",
      "[38]\ttraining's multi_logloss: 0.235169\tvalid_1's multi_logloss: 0.313692        \n",
      "[39]\ttraining's multi_logloss: 0.23029\tvalid_1's multi_logloss: 0.31123          \n",
      "[40]\ttraining's multi_logloss: 0.225569\tvalid_1's multi_logloss: 0.30871         \n",
      "[41]\ttraining's multi_logloss: 0.221273\tvalid_1's multi_logloss: 0.306435        \n",
      "[42]\ttraining's multi_logloss: 0.217031\tvalid_1's multi_logloss: 0.304322        \n",
      "[43]\ttraining's multi_logloss: 0.213082\tvalid_1's multi_logloss: 0.302551        \n",
      "[44]\ttraining's multi_logloss: 0.20929\tvalid_1's multi_logloss: 0.300778         \n",
      "[45]\ttraining's multi_logloss: 0.205692\tvalid_1's multi_logloss: 0.299174        \n",
      "[46]\ttraining's multi_logloss: 0.20213\tvalid_1's multi_logloss: 0.297963         \n",
      "[47]\ttraining's multi_logloss: 0.198728\tvalid_1's multi_logloss: 0.296753        \n",
      "[48]\ttraining's multi_logloss: 0.195536\tvalid_1's multi_logloss: 0.295705        \n",
      "[49]\ttraining's multi_logloss: 0.192184\tvalid_1's multi_logloss: 0.2947          \n",
      "[50]\ttraining's multi_logloss: 0.188935\tvalid_1's multi_logloss: 0.293661        \n",
      "[51]\ttraining's multi_logloss: 0.185907\tvalid_1's multi_logloss: 0.292633        \n",
      "[52]\ttraining's multi_logloss: 0.182806\tvalid_1's multi_logloss: 0.291385        \n",
      "[53]\ttraining's multi_logloss: 0.179836\tvalid_1's multi_logloss: 0.290389        \n",
      "[54]\ttraining's multi_logloss: 0.177049\tvalid_1's multi_logloss: 0.289359        \n",
      "[55]\ttraining's multi_logloss: 0.174105\tvalid_1's multi_logloss: 0.2887          \n",
      "[56]\ttraining's multi_logloss: 0.171331\tvalid_1's multi_logloss: 0.288019        \n",
      "[57]\ttraining's multi_logloss: 0.168377\tvalid_1's multi_logloss: 0.287384        \n",
      "[58]\ttraining's multi_logloss: 0.16572\tvalid_1's multi_logloss: 0.287006         \n",
      "[59]\ttraining's multi_logloss: 0.162992\tvalid_1's multi_logloss: 0.286772        \n",
      "[60]\ttraining's multi_logloss: 0.160491\tvalid_1's multi_logloss: 0.286337        \n",
      "[61]\ttraining's multi_logloss: 0.158024\tvalid_1's multi_logloss: 0.285892        \n",
      "[62]\ttraining's multi_logloss: 0.155727\tvalid_1's multi_logloss: 0.285708        \n",
      "[63]\ttraining's multi_logloss: 0.1535\tvalid_1's multi_logloss: 0.285576          \n",
      "[64]\ttraining's multi_logloss: 0.151338\tvalid_1's multi_logloss: 0.285373        \n",
      "[65]\ttraining's multi_logloss: 0.149283\tvalid_1's multi_logloss: 0.285171        \n",
      "[66]\ttraining's multi_logloss: 0.147284\tvalid_1's multi_logloss: 0.285034        \n",
      "[67]\ttraining's multi_logloss: 0.145171\tvalid_1's multi_logloss: 0.284673        \n",
      "[68]\ttraining's multi_logloss: 0.143159\tvalid_1's multi_logloss: 0.284564        \n",
      "[69]\ttraining's multi_logloss: 0.141177\tvalid_1's multi_logloss: 0.284505        \n",
      "[70]\ttraining's multi_logloss: 0.139253\tvalid_1's multi_logloss: 0.284317        \n",
      "[71]\ttraining's multi_logloss: 0.137258\tvalid_1's multi_logloss: 0.284248        \n",
      "[72]\ttraining's multi_logloss: 0.135301\tvalid_1's multi_logloss: 0.284314        \n",
      "[73]\ttraining's multi_logloss: 0.133501\tvalid_1's multi_logloss: 0.284506        \n",
      "[74]\ttraining's multi_logloss: 0.131738\tvalid_1's multi_logloss: 0.28456         \n",
      "[75]\ttraining's multi_logloss: 0.129995\tvalid_1's multi_logloss: 0.28491         \n",
      "[76]\ttraining's multi_logloss: 0.128289\tvalid_1's multi_logloss: 0.284828        \n",
      "[77]\ttraining's multi_logloss: 0.126735\tvalid_1's multi_logloss: 0.28477         \n",
      "[78]\ttraining's multi_logloss: 0.125001\tvalid_1's multi_logloss: 0.284889        \n",
      "[79]\ttraining's multi_logloss: 0.123451\tvalid_1's multi_logloss: 0.285013        \n",
      "[80]\ttraining's multi_logloss: 0.121897\tvalid_1's multi_logloss: 0.285126        \n",
      "[81]\ttraining's multi_logloss: 0.120378\tvalid_1's multi_logloss: 0.285109        \n",
      "[82]\ttraining's multi_logloss: 0.118812\tvalid_1's multi_logloss: 0.285263        \n",
      "[83]\ttraining's multi_logloss: 0.117351\tvalid_1's multi_logloss: 0.28536         \n",
      "[84]\ttraining's multi_logloss: 0.115968\tvalid_1's multi_logloss: 0.285337        \n",
      "[85]\ttraining's multi_logloss: 0.114549\tvalid_1's multi_logloss: 0.285575        \n",
      "[86]\ttraining's multi_logloss: 0.113144\tvalid_1's multi_logloss: 0.28555         \n",
      "[87]\ttraining's multi_logloss: 0.111796\tvalid_1's multi_logloss: 0.285687        \n",
      "[88]\ttraining's multi_logloss: 0.110477\tvalid_1's multi_logloss: 0.285819        \n",
      "[89]\ttraining's multi_logloss: 0.109179\tvalid_1's multi_logloss: 0.285973        \n",
      "[90]\ttraining's multi_logloss: 0.107925\tvalid_1's multi_logloss: 0.286161        \n",
      "[91]\ttraining's multi_logloss: 0.106601\tvalid_1's multi_logloss: 0.286407        \n",
      "[92]\ttraining's multi_logloss: 0.105385\tvalid_1's multi_logloss: 0.286431        \n",
      "[93]\ttraining's multi_logloss: 0.104114\tvalid_1's multi_logloss: 0.28651         \n",
      "[94]\ttraining's multi_logloss: 0.102919\tvalid_1's multi_logloss: 0.286726        \n",
      "[95]\ttraining's multi_logloss: 0.101745\tvalid_1's multi_logloss: 0.286889        \n",
      "[96]\ttraining's multi_logloss: 0.100562\tvalid_1's multi_logloss: 0.287112        \n",
      "[97]\ttraining's multi_logloss: 0.0992739\tvalid_1's multi_logloss: 0.287098       \n",
      "[98]\ttraining's multi_logloss: 0.0980491\tvalid_1's multi_logloss: 0.287271       \n",
      "[99]\ttraining's multi_logloss: 0.0968368\tvalid_1's multi_logloss: 0.287558       \n",
      "[100]\ttraining's multi_logloss: 0.0957801\tvalid_1's multi_logloss: 0.287715      \n",
      "[101]\ttraining's multi_logloss: 0.0947801\tvalid_1's multi_logloss: 0.288056      \n",
      "Early stopping, best iteration is:                                               \n",
      "[71]\ttraining's multi_logloss: 0.137258\tvalid_1's multi_logloss: 0.284248\n",
      "[1]\ttraining's multi_logloss: 1.63436\tvalid_1's multi_logloss: 1.63857           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.42814\tvalid_1's multi_logloss: 1.43386           \n",
      "[3]\ttraining's multi_logloss: 1.26886\tvalid_1's multi_logloss: 1.27624           \n",
      "[4]\ttraining's multi_logloss: 1.14067\tvalid_1's multi_logloss: 1.14935           \n",
      "[5]\ttraining's multi_logloss: 1.03479\tvalid_1's multi_logloss: 1.04459           \n",
      "[6]\ttraining's multi_logloss: 0.945217\tvalid_1's multi_logloss: 0.956242         \n",
      "[7]\ttraining's multi_logloss: 0.868646\tvalid_1's multi_logloss: 0.880909         \n",
      "[8]\ttraining's multi_logloss: 0.802029\tvalid_1's multi_logloss: 0.81528          \n",
      "[9]\ttraining's multi_logloss: 0.7436\tvalid_1's multi_logloss: 0.758287           \n",
      "[10]\ttraining's multi_logloss: 0.693162\tvalid_1's multi_logloss: 0.709283        \n",
      "[11]\ttraining's multi_logloss: 0.647563\tvalid_1's multi_logloss: 0.665036        \n",
      "[12]\ttraining's multi_logloss: 0.607279\tvalid_1's multi_logloss: 0.626574        \n",
      "[13]\ttraining's multi_logloss: 0.571727\tvalid_1's multi_logloss: 0.592982        \n",
      "[14]\ttraining's multi_logloss: 0.539609\tvalid_1's multi_logloss: 0.562414        \n",
      "[15]\ttraining's multi_logloss: 0.511126\tvalid_1's multi_logloss: 0.53534         \n",
      "[16]\ttraining's multi_logloss: 0.485516\tvalid_1's multi_logloss: 0.510928        \n",
      "[17]\ttraining's multi_logloss: 0.462476\tvalid_1's multi_logloss: 0.48915         \n",
      "[18]\ttraining's multi_logloss: 0.441943\tvalid_1's multi_logloss: 0.470254        \n",
      "[19]\ttraining's multi_logloss: 0.422565\tvalid_1's multi_logloss: 0.452494        \n",
      "[20]\ttraining's multi_logloss: 0.404496\tvalid_1's multi_logloss: 0.435594        \n",
      "[21]\ttraining's multi_logloss: 0.388272\tvalid_1's multi_logloss: 0.420857        \n",
      "[22]\ttraining's multi_logloss: 0.373765\tvalid_1's multi_logloss: 0.40803         \n",
      "[23]\ttraining's multi_logloss: 0.360137\tvalid_1's multi_logloss: 0.395956        \n",
      "[24]\ttraining's multi_logloss: 0.347749\tvalid_1's multi_logloss: 0.385087        \n",
      "[25]\ttraining's multi_logloss: 0.33619\tvalid_1's multi_logloss: 0.375059         \n",
      "[26]\ttraining's multi_logloss: 0.325868\tvalid_1's multi_logloss: 0.366265        \n",
      "[27]\ttraining's multi_logloss: 0.315792\tvalid_1's multi_logloss: 0.358145        \n",
      "[28]\ttraining's multi_logloss: 0.306456\tvalid_1's multi_logloss: 0.350588        \n",
      "[29]\ttraining's multi_logloss: 0.298022\tvalid_1's multi_logloss: 0.343815        \n",
      "[30]\ttraining's multi_logloss: 0.289774\tvalid_1's multi_logloss: 0.337432        \n",
      "[31]\ttraining's multi_logloss: 0.282299\tvalid_1's multi_logloss: 0.331807        \n",
      "[32]\ttraining's multi_logloss: 0.275359\tvalid_1's multi_logloss: 0.326398        \n",
      "[33]\ttraining's multi_logloss: 0.268727\tvalid_1's multi_logloss: 0.321604        \n",
      "[34]\ttraining's multi_logloss: 0.262805\tvalid_1's multi_logloss: 0.31775         \n",
      "[35]\ttraining's multi_logloss: 0.256971\tvalid_1's multi_logloss: 0.313828        \n",
      "[36]\ttraining's multi_logloss: 0.251484\tvalid_1's multi_logloss: 0.310362        \n",
      "[37]\ttraining's multi_logloss: 0.246197\tvalid_1's multi_logloss: 0.307224        \n",
      "[38]\ttraining's multi_logloss: 0.241177\tvalid_1's multi_logloss: 0.304421        \n",
      "[39]\ttraining's multi_logloss: 0.236591\tvalid_1's multi_logloss: 0.301786        \n",
      "[40]\ttraining's multi_logloss: 0.232298\tvalid_1's multi_logloss: 0.299404        \n",
      "[41]\ttraining's multi_logloss: 0.227776\tvalid_1's multi_logloss: 0.296784        \n",
      "[42]\ttraining's multi_logloss: 0.223648\tvalid_1's multi_logloss: 0.294817        \n",
      "[43]\ttraining's multi_logloss: 0.219503\tvalid_1's multi_logloss: 0.292645        \n",
      "[44]\ttraining's multi_logloss: 0.21551\tvalid_1's multi_logloss: 0.29085          \n",
      "[45]\ttraining's multi_logloss: 0.211945\tvalid_1's multi_logloss: 0.289231        \n",
      "[46]\ttraining's multi_logloss: 0.208221\tvalid_1's multi_logloss: 0.287661        \n",
      "[47]\ttraining's multi_logloss: 0.204771\tvalid_1's multi_logloss: 0.285983        \n",
      "[48]\ttraining's multi_logloss: 0.201266\tvalid_1's multi_logloss: 0.284561        \n",
      "[49]\ttraining's multi_logloss: 0.197901\tvalid_1's multi_logloss: 0.283411        \n",
      "[50]\ttraining's multi_logloss: 0.194552\tvalid_1's multi_logloss: 0.282451        \n",
      "[51]\ttraining's multi_logloss: 0.191487\tvalid_1's multi_logloss: 0.281436        \n",
      "[52]\ttraining's multi_logloss: 0.188427\tvalid_1's multi_logloss: 0.280365        \n",
      "[53]\ttraining's multi_logloss: 0.18568\tvalid_1's multi_logloss: 0.279514         \n",
      "[54]\ttraining's multi_logloss: 0.182884\tvalid_1's multi_logloss: 0.278648        \n",
      "[55]\ttraining's multi_logloss: 0.180044\tvalid_1's multi_logloss: 0.278081        \n",
      "[56]\ttraining's multi_logloss: 0.177291\tvalid_1's multi_logloss: 0.277155        \n",
      "[57]\ttraining's multi_logloss: 0.174687\tvalid_1's multi_logloss: 0.276386        \n",
      "[58]\ttraining's multi_logloss: 0.172055\tvalid_1's multi_logloss: 0.27591         \n",
      "[59]\ttraining's multi_logloss: 0.169408\tvalid_1's multi_logloss: 0.275614        \n",
      "[60]\ttraining's multi_logloss: 0.167018\tvalid_1's multi_logloss: 0.274996        \n",
      "[61]\ttraining's multi_logloss: 0.164684\tvalid_1's multi_logloss: 0.274538        \n",
      "[62]\ttraining's multi_logloss: 0.16231\tvalid_1's multi_logloss: 0.274021         \n",
      "[63]\ttraining's multi_logloss: 0.160103\tvalid_1's multi_logloss: 0.27356         \n",
      "[64]\ttraining's multi_logloss: 0.157882\tvalid_1's multi_logloss: 0.272946        \n",
      "[65]\ttraining's multi_logloss: 0.155642\tvalid_1's multi_logloss: 0.272707        \n",
      "[66]\ttraining's multi_logloss: 0.153398\tvalid_1's multi_logloss: 0.272445        \n",
      "[67]\ttraining's multi_logloss: 0.151353\tvalid_1's multi_logloss: 0.272203        \n",
      "[68]\ttraining's multi_logloss: 0.149276\tvalid_1's multi_logloss: 0.271868        \n",
      "[69]\ttraining's multi_logloss: 0.147295\tvalid_1's multi_logloss: 0.271739        \n",
      "[70]\ttraining's multi_logloss: 0.145298\tvalid_1's multi_logloss: 0.271365        \n",
      "[71]\ttraining's multi_logloss: 0.143349\tvalid_1's multi_logloss: 0.271109        \n",
      "[72]\ttraining's multi_logloss: 0.141454\tvalid_1's multi_logloss: 0.27085         \n",
      "[73]\ttraining's multi_logloss: 0.139736\tvalid_1's multi_logloss: 0.27072         \n",
      "[74]\ttraining's multi_logloss: 0.138087\tvalid_1's multi_logloss: 0.270593        \n",
      "[75]\ttraining's multi_logloss: 0.136349\tvalid_1's multi_logloss: 0.270344        \n",
      "[76]\ttraining's multi_logloss: 0.134591\tvalid_1's multi_logloss: 0.270137        \n",
      "[77]\ttraining's multi_logloss: 0.133049\tvalid_1's multi_logloss: 0.270227        \n",
      "[78]\ttraining's multi_logloss: 0.13152\tvalid_1's multi_logloss: 0.270102         \n",
      "[79]\ttraining's multi_logloss: 0.129975\tvalid_1's multi_logloss: 0.269734        \n",
      "[80]\ttraining's multi_logloss: 0.128328\tvalid_1's multi_logloss: 0.269582        \n",
      "[81]\ttraining's multi_logloss: 0.126832\tvalid_1's multi_logloss: 0.269435        \n",
      "[82]\ttraining's multi_logloss: 0.125349\tvalid_1's multi_logloss: 0.269623        \n",
      "[83]\ttraining's multi_logloss: 0.123907\tvalid_1's multi_logloss: 0.269727        \n",
      "[84]\ttraining's multi_logloss: 0.122457\tvalid_1's multi_logloss: 0.270022        \n",
      "[85]\ttraining's multi_logloss: 0.121159\tvalid_1's multi_logloss: 0.270058        \n",
      "[86]\ttraining's multi_logloss: 0.119673\tvalid_1's multi_logloss: 0.270112        \n",
      "[87]\ttraining's multi_logloss: 0.118143\tvalid_1's multi_logloss: 0.26997         \n",
      "[88]\ttraining's multi_logloss: 0.116746\tvalid_1's multi_logloss: 0.269872        \n",
      "[89]\ttraining's multi_logloss: 0.115445\tvalid_1's multi_logloss: 0.27004         \n",
      "[90]\ttraining's multi_logloss: 0.114167\tvalid_1's multi_logloss: 0.270339        \n",
      "[91]\ttraining's multi_logloss: 0.1128\tvalid_1's multi_logloss: 0.270326          \n",
      "[92]\ttraining's multi_logloss: 0.111458\tvalid_1's multi_logloss: 0.270565        \n",
      "[93]\ttraining's multi_logloss: 0.110211\tvalid_1's multi_logloss: 0.270752        \n",
      "[94]\ttraining's multi_logloss: 0.108922\tvalid_1's multi_logloss: 0.270687        \n",
      "[95]\ttraining's multi_logloss: 0.107736\tvalid_1's multi_logloss: 0.270996        \n",
      "[96]\ttraining's multi_logloss: 0.106651\tvalid_1's multi_logloss: 0.271066        \n",
      "[97]\ttraining's multi_logloss: 0.105341\tvalid_1's multi_logloss: 0.271136        \n",
      "[98]\ttraining's multi_logloss: 0.104171\tvalid_1's multi_logloss: 0.271162        \n",
      "[99]\ttraining's multi_logloss: 0.103086\tvalid_1's multi_logloss: 0.27116         \n",
      "[100]\ttraining's multi_logloss: 0.101943\tvalid_1's multi_logloss: 0.271341       \n",
      "[101]\ttraining's multi_logloss: 0.100828\tvalid_1's multi_logloss: 0.271584       \n",
      "[102]\ttraining's multi_logloss: 0.0998069\tvalid_1's multi_logloss: 0.271836      \n",
      "[103]\ttraining's multi_logloss: 0.0988718\tvalid_1's multi_logloss: 0.272148      \n",
      "[104]\ttraining's multi_logloss: 0.0977189\tvalid_1's multi_logloss: 0.27239       \n",
      "[105]\ttraining's multi_logloss: 0.0967165\tvalid_1's multi_logloss: 0.272421      \n",
      "[106]\ttraining's multi_logloss: 0.0956473\tvalid_1's multi_logloss: 0.272645      \n",
      "[107]\ttraining's multi_logloss: 0.0946798\tvalid_1's multi_logloss: 0.272954      \n",
      "[108]\ttraining's multi_logloss: 0.0936301\tvalid_1's multi_logloss: 0.273223      \n",
      "[109]\ttraining's multi_logloss: 0.0927378\tvalid_1's multi_logloss: 0.27325       \n",
      "[110]\ttraining's multi_logloss: 0.0917528\tvalid_1's multi_logloss: 0.273339      \n",
      "[111]\ttraining's multi_logloss: 0.090845\tvalid_1's multi_logloss: 0.273543       \n",
      "Early stopping, best iteration is:                                               \n",
      "[81]\ttraining's multi_logloss: 0.126832\tvalid_1's multi_logloss: 0.269435\n",
      "[1]\ttraining's multi_logloss: 1.44918\tvalid_1's multi_logloss: 1.45832           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.18144\tvalid_1's multi_logloss: 1.19862           \n",
      "[3]\ttraining's multi_logloss: 0.995979\tvalid_1's multi_logloss: 1.01937          \n",
      "[4]\ttraining's multi_logloss: 0.857334\tvalid_1's multi_logloss: 0.885533         \n",
      "[5]\ttraining's multi_logloss: 0.750432\tvalid_1's multi_logloss: 0.781934         \n",
      "[6]\ttraining's multi_logloss: 0.664276\tvalid_1's multi_logloss: 0.699503         \n",
      "[7]\ttraining's multi_logloss: 0.59426\tvalid_1's multi_logloss: 0.632953          \n",
      "[8]\ttraining's multi_logloss: 0.536895\tvalid_1's multi_logloss: 0.578639         \n",
      "[9]\ttraining's multi_logloss: 0.488516\tvalid_1's multi_logloss: 0.533039         \n",
      "[10]\ttraining's multi_logloss: 0.448711\tvalid_1's multi_logloss: 0.496143        \n",
      "[11]\ttraining's multi_logloss: 0.41523\tvalid_1's multi_logloss: 0.465488         \n",
      "[12]\ttraining's multi_logloss: 0.386016\tvalid_1's multi_logloss: 0.438888        \n",
      "[13]\ttraining's multi_logloss: 0.360904\tvalid_1's multi_logloss: 0.416757        \n",
      "[14]\ttraining's multi_logloss: 0.339767\tvalid_1's multi_logloss: 0.398958        \n",
      "[15]\ttraining's multi_logloss: 0.321045\tvalid_1's multi_logloss: 0.383085        \n",
      "[16]\ttraining's multi_logloss: 0.30456\tvalid_1's multi_logloss: 0.370055         \n",
      "[17]\ttraining's multi_logloss: 0.290076\tvalid_1's multi_logloss: 0.358984        \n",
      "[18]\ttraining's multi_logloss: 0.277551\tvalid_1's multi_logloss: 0.350161        \n",
      "[19]\ttraining's multi_logloss: 0.265794\tvalid_1's multi_logloss: 0.342253        \n",
      "[20]\ttraining's multi_logloss: 0.255121\tvalid_1's multi_logloss: 0.335217        \n",
      "[21]\ttraining's multi_logloss: 0.245399\tvalid_1's multi_logloss: 0.32931         \n",
      "[22]\ttraining's multi_logloss: 0.236504\tvalid_1's multi_logloss: 0.324193        \n",
      "[23]\ttraining's multi_logloss: 0.228423\tvalid_1's multi_logloss: 0.319366        \n",
      "[24]\ttraining's multi_logloss: 0.220851\tvalid_1's multi_logloss: 0.316121        \n",
      "[25]\ttraining's multi_logloss: 0.213543\tvalid_1's multi_logloss: 0.31294         \n",
      "[26]\ttraining's multi_logloss: 0.20709\tvalid_1's multi_logloss: 0.309429         \n",
      "[27]\ttraining's multi_logloss: 0.200891\tvalid_1's multi_logloss: 0.306686        \n",
      "[28]\ttraining's multi_logloss: 0.195184\tvalid_1's multi_logloss: 0.304696        \n",
      "[29]\ttraining's multi_logloss: 0.189354\tvalid_1's multi_logloss: 0.302688        \n",
      "[30]\ttraining's multi_logloss: 0.18391\tvalid_1's multi_logloss: 0.301674         \n",
      "[31]\ttraining's multi_logloss: 0.178812\tvalid_1's multi_logloss: 0.300547        \n",
      "[32]\ttraining's multi_logloss: 0.173999\tvalid_1's multi_logloss: 0.299105        \n",
      "[33]\ttraining's multi_logloss: 0.169455\tvalid_1's multi_logloss: 0.298598        \n",
      "[34]\ttraining's multi_logloss: 0.164994\tvalid_1's multi_logloss: 0.298163        \n",
      "[35]\ttraining's multi_logloss: 0.160556\tvalid_1's multi_logloss: 0.297466        \n",
      "[36]\ttraining's multi_logloss: 0.156447\tvalid_1's multi_logloss: 0.29662         \n",
      "[37]\ttraining's multi_logloss: 0.15254\tvalid_1's multi_logloss: 0.295979         \n",
      "[38]\ttraining's multi_logloss: 0.148892\tvalid_1's multi_logloss: 0.295255        \n",
      "[39]\ttraining's multi_logloss: 0.145336\tvalid_1's multi_logloss: 0.294754        \n",
      "[40]\ttraining's multi_logloss: 0.141917\tvalid_1's multi_logloss: 0.294214        \n",
      "[41]\ttraining's multi_logloss: 0.138636\tvalid_1's multi_logloss: 0.293825        \n",
      "[42]\ttraining's multi_logloss: 0.135412\tvalid_1's multi_logloss: 0.293396        \n",
      "[43]\ttraining's multi_logloss: 0.132226\tvalid_1's multi_logloss: 0.293003        \n",
      "[44]\ttraining's multi_logloss: 0.129106\tvalid_1's multi_logloss: 0.29263         \n",
      "[45]\ttraining's multi_logloss: 0.126089\tvalid_1's multi_logloss: 0.292076        \n",
      "[46]\ttraining's multi_logloss: 0.123221\tvalid_1's multi_logloss: 0.291761        \n",
      "[47]\ttraining's multi_logloss: 0.120295\tvalid_1's multi_logloss: 0.291688        \n",
      "[48]\ttraining's multi_logloss: 0.117484\tvalid_1's multi_logloss: 0.291743        \n",
      "[49]\ttraining's multi_logloss: 0.115117\tvalid_1's multi_logloss: 0.292037        \n",
      "[50]\ttraining's multi_logloss: 0.112612\tvalid_1's multi_logloss: 0.292211        \n",
      "[51]\ttraining's multi_logloss: 0.110234\tvalid_1's multi_logloss: 0.292251        \n",
      "[52]\ttraining's multi_logloss: 0.107942\tvalid_1's multi_logloss: 0.292781        \n",
      "[53]\ttraining's multi_logloss: 0.105433\tvalid_1's multi_logloss: 0.293334        \n",
      "[54]\ttraining's multi_logloss: 0.103263\tvalid_1's multi_logloss: 0.293522        \n",
      "[55]\ttraining's multi_logloss: 0.100989\tvalid_1's multi_logloss: 0.293762        \n",
      "[56]\ttraining's multi_logloss: 0.0990452\tvalid_1's multi_logloss: 0.293503       \n",
      "[57]\ttraining's multi_logloss: 0.0970249\tvalid_1's multi_logloss: 0.293546       \n",
      "[58]\ttraining's multi_logloss: 0.095121\tvalid_1's multi_logloss: 0.294483        \n",
      "[59]\ttraining's multi_logloss: 0.0933731\tvalid_1's multi_logloss: 0.294788       \n",
      "[60]\ttraining's multi_logloss: 0.0915082\tvalid_1's multi_logloss: 0.295156       \n",
      "[61]\ttraining's multi_logloss: 0.0898634\tvalid_1's multi_logloss: 0.296068       \n",
      "[62]\ttraining's multi_logloss: 0.0882108\tvalid_1's multi_logloss: 0.296173       \n",
      "[63]\ttraining's multi_logloss: 0.086498\tvalid_1's multi_logloss: 0.296472        \n",
      "[64]\ttraining's multi_logloss: 0.0849908\tvalid_1's multi_logloss: 0.29666        \n",
      "[65]\ttraining's multi_logloss: 0.0832954\tvalid_1's multi_logloss: 0.297682       \n",
      "[66]\ttraining's multi_logloss: 0.0818754\tvalid_1's multi_logloss: 0.298635       \n",
      "[67]\ttraining's multi_logloss: 0.0803654\tvalid_1's multi_logloss: 0.299144       \n",
      "[68]\ttraining's multi_logloss: 0.0788527\tvalid_1's multi_logloss: 0.299623       \n",
      "[69]\ttraining's multi_logloss: 0.0774461\tvalid_1's multi_logloss: 0.300136       \n",
      "[70]\ttraining's multi_logloss: 0.075907\tvalid_1's multi_logloss: 0.300478        \n",
      "[71]\ttraining's multi_logloss: 0.074727\tvalid_1's multi_logloss: 0.301313        \n",
      "[72]\ttraining's multi_logloss: 0.0733376\tvalid_1's multi_logloss: 0.301813       \n",
      "[73]\ttraining's multi_logloss: 0.072017\tvalid_1's multi_logloss: 0.302424        \n",
      "[74]\ttraining's multi_logloss: 0.0705747\tvalid_1's multi_logloss: 0.303059       \n",
      "[75]\ttraining's multi_logloss: 0.0693603\tvalid_1's multi_logloss: 0.303757       \n",
      "[76]\ttraining's multi_logloss: 0.0680793\tvalid_1's multi_logloss: 0.304184       \n",
      "[77]\ttraining's multi_logloss: 0.0667133\tvalid_1's multi_logloss: 0.304975       \n",
      "Early stopping, best iteration is:                                               \n",
      "[47]\ttraining's multi_logloss: 0.120295\tvalid_1's multi_logloss: 0.291688\n",
      "[1]\ttraining's multi_logloss: 1.44734\tvalid_1's multi_logloss: 1.45284           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.18034\tvalid_1's multi_logloss: 1.18913           \n",
      "[3]\ttraining's multi_logloss: 0.997916\tvalid_1's multi_logloss: 1.0094           \n",
      "[4]\ttraining's multi_logloss: 0.862315\tvalid_1's multi_logloss: 0.876736         \n",
      "[5]\ttraining's multi_logloss: 0.754971\tvalid_1's multi_logloss: 0.772936         \n",
      "[6]\ttraining's multi_logloss: 0.669126\tvalid_1's multi_logloss: 0.691123         \n",
      "[7]\ttraining's multi_logloss: 0.600006\tvalid_1's multi_logloss: 0.625386         \n",
      "[8]\ttraining's multi_logloss: 0.542349\tvalid_1's multi_logloss: 0.570122         \n",
      "[9]\ttraining's multi_logloss: 0.494467\tvalid_1's multi_logloss: 0.525529         \n",
      "[10]\ttraining's multi_logloss: 0.45393\tvalid_1's multi_logloss: 0.488395         \n",
      "[11]\ttraining's multi_logloss: 0.419817\tvalid_1's multi_logloss: 0.457768        \n",
      "[12]\ttraining's multi_logloss: 0.391081\tvalid_1's multi_logloss: 0.432326        \n",
      "[13]\ttraining's multi_logloss: 0.366347\tvalid_1's multi_logloss: 0.411018        \n",
      "[14]\ttraining's multi_logloss: 0.344412\tvalid_1's multi_logloss: 0.392161        \n",
      "[15]\ttraining's multi_logloss: 0.325524\tvalid_1's multi_logloss: 0.376853        \n",
      "[16]\ttraining's multi_logloss: 0.308692\tvalid_1's multi_logloss: 0.362824        \n",
      "[17]\ttraining's multi_logloss: 0.292828\tvalid_1's multi_logloss: 0.350599        \n",
      "[18]\ttraining's multi_logloss: 0.279316\tvalid_1's multi_logloss: 0.339897        \n",
      "[19]\ttraining's multi_logloss: 0.267444\tvalid_1's multi_logloss: 0.33192         \n",
      "[20]\ttraining's multi_logloss: 0.256678\tvalid_1's multi_logloss: 0.324581        \n",
      "[21]\ttraining's multi_logloss: 0.24671\tvalid_1's multi_logloss: 0.31853          \n",
      "[22]\ttraining's multi_logloss: 0.237642\tvalid_1's multi_logloss: 0.313597        \n",
      "[23]\ttraining's multi_logloss: 0.229024\tvalid_1's multi_logloss: 0.308905        \n",
      "[24]\ttraining's multi_logloss: 0.221359\tvalid_1's multi_logloss: 0.305067        \n",
      "[25]\ttraining's multi_logloss: 0.214174\tvalid_1's multi_logloss: 0.301736        \n",
      "[26]\ttraining's multi_logloss: 0.207597\tvalid_1's multi_logloss: 0.299191        \n",
      "[27]\ttraining's multi_logloss: 0.201621\tvalid_1's multi_logloss: 0.297171        \n",
      "[28]\ttraining's multi_logloss: 0.195458\tvalid_1's multi_logloss: 0.29519         \n",
      "[29]\ttraining's multi_logloss: 0.189773\tvalid_1's multi_logloss: 0.293356        \n",
      "[30]\ttraining's multi_logloss: 0.184118\tvalid_1's multi_logloss: 0.292341        \n",
      "[31]\ttraining's multi_logloss: 0.179\tvalid_1's multi_logloss: 0.291198           \n",
      "[32]\ttraining's multi_logloss: 0.174014\tvalid_1's multi_logloss: 0.290087        \n",
      "[33]\ttraining's multi_logloss: 0.169229\tvalid_1's multi_logloss: 0.28913         \n",
      "[34]\ttraining's multi_logloss: 0.16466\tvalid_1's multi_logloss: 0.288541         \n",
      "[35]\ttraining's multi_logloss: 0.16029\tvalid_1's multi_logloss: 0.287813         \n",
      "[36]\ttraining's multi_logloss: 0.155806\tvalid_1's multi_logloss: 0.286619        \n",
      "[37]\ttraining's multi_logloss: 0.151918\tvalid_1's multi_logloss: 0.286222        \n",
      "[38]\ttraining's multi_logloss: 0.147963\tvalid_1's multi_logloss: 0.28548         \n",
      "[39]\ttraining's multi_logloss: 0.144275\tvalid_1's multi_logloss: 0.285272        \n",
      "[40]\ttraining's multi_logloss: 0.140445\tvalid_1's multi_logloss: 0.285055        \n",
      "[41]\ttraining's multi_logloss: 0.137213\tvalid_1's multi_logloss: 0.28481         \n",
      "[42]\ttraining's multi_logloss: 0.133886\tvalid_1's multi_logloss: 0.284169        \n",
      "[43]\ttraining's multi_logloss: 0.130718\tvalid_1's multi_logloss: 0.28415         \n",
      "[44]\ttraining's multi_logloss: 0.127447\tvalid_1's multi_logloss: 0.284297        \n",
      "[45]\ttraining's multi_logloss: 0.124673\tvalid_1's multi_logloss: 0.284192        \n",
      "[46]\ttraining's multi_logloss: 0.121661\tvalid_1's multi_logloss: 0.284679        \n",
      "[47]\ttraining's multi_logloss: 0.118642\tvalid_1's multi_logloss: 0.285042        \n",
      "[48]\ttraining's multi_logloss: 0.115622\tvalid_1's multi_logloss: 0.284854        \n",
      "[49]\ttraining's multi_logloss: 0.112915\tvalid_1's multi_logloss: 0.285236        \n",
      "[50]\ttraining's multi_logloss: 0.11058\tvalid_1's multi_logloss: 0.285561         \n",
      "[51]\ttraining's multi_logloss: 0.108208\tvalid_1's multi_logloss: 0.286049        \n",
      "[52]\ttraining's multi_logloss: 0.105682\tvalid_1's multi_logloss: 0.286076        \n",
      "[53]\ttraining's multi_logloss: 0.103374\tvalid_1's multi_logloss: 0.286289        \n",
      "[54]\ttraining's multi_logloss: 0.101212\tvalid_1's multi_logloss: 0.286246        \n",
      "[55]\ttraining's multi_logloss: 0.0991957\tvalid_1's multi_logloss: 0.286839       \n",
      "[56]\ttraining's multi_logloss: 0.0971586\tvalid_1's multi_logloss: 0.287404       \n",
      "[57]\ttraining's multi_logloss: 0.0951136\tvalid_1's multi_logloss: 0.287902       \n",
      "[58]\ttraining's multi_logloss: 0.0931885\tvalid_1's multi_logloss: 0.288237       \n",
      "[59]\ttraining's multi_logloss: 0.091291\tvalid_1's multi_logloss: 0.288887        \n",
      "[60]\ttraining's multi_logloss: 0.0895689\tvalid_1's multi_logloss: 0.289551       \n",
      "[61]\ttraining's multi_logloss: 0.0878648\tvalid_1's multi_logloss: 0.290401       \n",
      "[62]\ttraining's multi_logloss: 0.0860081\tvalid_1's multi_logloss: 0.290638       \n",
      "[63]\ttraining's multi_logloss: 0.0843495\tvalid_1's multi_logloss: 0.291622       \n",
      "[64]\ttraining's multi_logloss: 0.0824167\tvalid_1's multi_logloss: 0.2924         \n",
      "[65]\ttraining's multi_logloss: 0.0807178\tvalid_1's multi_logloss: 0.29332        \n",
      "[66]\ttraining's multi_logloss: 0.078944\tvalid_1's multi_logloss: 0.293817        \n",
      "[67]\ttraining's multi_logloss: 0.0770981\tvalid_1's multi_logloss: 0.294211       \n",
      "[68]\ttraining's multi_logloss: 0.0756589\tvalid_1's multi_logloss: 0.295024       \n",
      "[69]\ttraining's multi_logloss: 0.0742363\tvalid_1's multi_logloss: 0.295646       \n",
      "[70]\ttraining's multi_logloss: 0.0727307\tvalid_1's multi_logloss: 0.295789       \n",
      "[71]\ttraining's multi_logloss: 0.0711408\tvalid_1's multi_logloss: 0.296489       \n",
      "[72]\ttraining's multi_logloss: 0.0698554\tvalid_1's multi_logloss: 0.29711        \n",
      "[73]\ttraining's multi_logloss: 0.0685553\tvalid_1's multi_logloss: 0.297891       \n",
      "Early stopping, best iteration is:                                               \n",
      "[43]\ttraining's multi_logloss: 0.130718\tvalid_1's multi_logloss: 0.28415\n",
      "[1]\ttraining's multi_logloss: 1.45138\tvalid_1's multi_logloss: 1.45649           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.18438\tvalid_1's multi_logloss: 1.19126           \n",
      "[3]\ttraining's multi_logloss: 1.00053\tvalid_1's multi_logloss: 1.01028           \n",
      "[4]\ttraining's multi_logloss: 0.864164\tvalid_1's multi_logloss: 0.876661         \n",
      "[5]\ttraining's multi_logloss: 0.756224\tvalid_1's multi_logloss: 0.771087         \n",
      "[6]\ttraining's multi_logloss: 0.671154\tvalid_1's multi_logloss: 0.688144         \n",
      "[7]\ttraining's multi_logloss: 0.601948\tvalid_1's multi_logloss: 0.620809         \n",
      "[8]\ttraining's multi_logloss: 0.545101\tvalid_1's multi_logloss: 0.566743         \n",
      "[9]\ttraining's multi_logloss: 0.497903\tvalid_1's multi_logloss: 0.522434         \n",
      "[10]\ttraining's multi_logloss: 0.458617\tvalid_1's multi_logloss: 0.485423        \n",
      "[11]\ttraining's multi_logloss: 0.424838\tvalid_1's multi_logloss: 0.454239        \n",
      "[12]\ttraining's multi_logloss: 0.395074\tvalid_1's multi_logloss: 0.426576        \n",
      "[13]\ttraining's multi_logloss: 0.370432\tvalid_1's multi_logloss: 0.404377        \n",
      "[14]\ttraining's multi_logloss: 0.348311\tvalid_1's multi_logloss: 0.384361        \n",
      "[15]\ttraining's multi_logloss: 0.329781\tvalid_1's multi_logloss: 0.368435        \n",
      "[16]\ttraining's multi_logloss: 0.313201\tvalid_1's multi_logloss: 0.355063        \n",
      "[17]\ttraining's multi_logloss: 0.298396\tvalid_1's multi_logloss: 0.343247        \n",
      "[18]\ttraining's multi_logloss: 0.285267\tvalid_1's multi_logloss: 0.333578        \n",
      "[19]\ttraining's multi_logloss: 0.273478\tvalid_1's multi_logloss: 0.324555        \n",
      "[20]\ttraining's multi_logloss: 0.262352\tvalid_1's multi_logloss: 0.316957        \n",
      "[21]\ttraining's multi_logloss: 0.252723\tvalid_1's multi_logloss: 0.311193        \n",
      "[22]\ttraining's multi_logloss: 0.243672\tvalid_1's multi_logloss: 0.305534        \n",
      "[23]\ttraining's multi_logloss: 0.235139\tvalid_1's multi_logloss: 0.300282        \n",
      "[24]\ttraining's multi_logloss: 0.227758\tvalid_1's multi_logloss: 0.296278        \n",
      "[25]\ttraining's multi_logloss: 0.220811\tvalid_1's multi_logloss: 0.292906        \n",
      "[26]\ttraining's multi_logloss: 0.21437\tvalid_1's multi_logloss: 0.289748         \n",
      "[27]\ttraining's multi_logloss: 0.208235\tvalid_1's multi_logloss: 0.287168        \n",
      "[28]\ttraining's multi_logloss: 0.202141\tvalid_1's multi_logloss: 0.284809        \n",
      "[29]\ttraining's multi_logloss: 0.196338\tvalid_1's multi_logloss: 0.28277         \n",
      "[30]\ttraining's multi_logloss: 0.190643\tvalid_1's multi_logloss: 0.281298        \n",
      "[31]\ttraining's multi_logloss: 0.185606\tvalid_1's multi_logloss: 0.280323        \n",
      "[32]\ttraining's multi_logloss: 0.180542\tvalid_1's multi_logloss: 0.278881        \n",
      "[33]\ttraining's multi_logloss: 0.175686\tvalid_1's multi_logloss: 0.277586        \n",
      "[34]\ttraining's multi_logloss: 0.170976\tvalid_1's multi_logloss: 0.276329        \n",
      "[35]\ttraining's multi_logloss: 0.166328\tvalid_1's multi_logloss: 0.275105        \n",
      "[36]\ttraining's multi_logloss: 0.161979\tvalid_1's multi_logloss: 0.274167        \n",
      "[37]\ttraining's multi_logloss: 0.157742\tvalid_1's multi_logloss: 0.273257        \n",
      "[38]\ttraining's multi_logloss: 0.153812\tvalid_1's multi_logloss: 0.272749        \n",
      "[39]\ttraining's multi_logloss: 0.1504\tvalid_1's multi_logloss: 0.272489          \n",
      "[40]\ttraining's multi_logloss: 0.146473\tvalid_1's multi_logloss: 0.271797        \n",
      "[41]\ttraining's multi_logloss: 0.142969\tvalid_1's multi_logloss: 0.271256        \n",
      "[42]\ttraining's multi_logloss: 0.139612\tvalid_1's multi_logloss: 0.270597        \n",
      "[43]\ttraining's multi_logloss: 0.136133\tvalid_1's multi_logloss: 0.270635        \n",
      "[44]\ttraining's multi_logloss: 0.132893\tvalid_1's multi_logloss: 0.270543        \n",
      "[45]\ttraining's multi_logloss: 0.12982\tvalid_1's multi_logloss: 0.270099         \n",
      "[46]\ttraining's multi_logloss: 0.127148\tvalid_1's multi_logloss: 0.270041        \n",
      "[47]\ttraining's multi_logloss: 0.12434\tvalid_1's multi_logloss: 0.269853         \n",
      "[48]\ttraining's multi_logloss: 0.121681\tvalid_1's multi_logloss: 0.269534        \n",
      "[49]\ttraining's multi_logloss: 0.119182\tvalid_1's multi_logloss: 0.269736        \n",
      "[50]\ttraining's multi_logloss: 0.116552\tvalid_1's multi_logloss: 0.269916        \n",
      "[51]\ttraining's multi_logloss: 0.114316\tvalid_1's multi_logloss: 0.270034        \n",
      "[52]\ttraining's multi_logloss: 0.111508\tvalid_1's multi_logloss: 0.269857        \n",
      "[53]\ttraining's multi_logloss: 0.109206\tvalid_1's multi_logloss: 0.269835        \n",
      "[54]\ttraining's multi_logloss: 0.106966\tvalid_1's multi_logloss: 0.269718        \n",
      "[55]\ttraining's multi_logloss: 0.104744\tvalid_1's multi_logloss: 0.269735        \n",
      "[56]\ttraining's multi_logloss: 0.102657\tvalid_1's multi_logloss: 0.270358        \n",
      "[57]\ttraining's multi_logloss: 0.100506\tvalid_1's multi_logloss: 0.270442        \n",
      "[58]\ttraining's multi_logloss: 0.0985103\tvalid_1's multi_logloss: 0.270864       \n",
      "[59]\ttraining's multi_logloss: 0.096572\tvalid_1's multi_logloss: 0.27101         \n",
      "[60]\ttraining's multi_logloss: 0.0944213\tvalid_1's multi_logloss: 0.271748       \n",
      "[61]\ttraining's multi_logloss: 0.0925722\tvalid_1's multi_logloss: 0.27201        \n",
      "[62]\ttraining's multi_logloss: 0.0907045\tvalid_1's multi_logloss: 0.272746       \n",
      "[63]\ttraining's multi_logloss: 0.0890866\tvalid_1's multi_logloss: 0.272943       \n",
      "[64]\ttraining's multi_logloss: 0.0873557\tvalid_1's multi_logloss: 0.273065       \n",
      "[65]\ttraining's multi_logloss: 0.0858728\tvalid_1's multi_logloss: 0.273213       \n",
      "[66]\ttraining's multi_logloss: 0.0844118\tvalid_1's multi_logloss: 0.273884       \n",
      "[67]\ttraining's multi_logloss: 0.0827748\tvalid_1's multi_logloss: 0.274442       \n",
      "[68]\ttraining's multi_logloss: 0.0813077\tvalid_1's multi_logloss: 0.274852       \n",
      "[69]\ttraining's multi_logloss: 0.0796763\tvalid_1's multi_logloss: 0.275344       \n",
      "[70]\ttraining's multi_logloss: 0.0782571\tvalid_1's multi_logloss: 0.275449       \n",
      "[71]\ttraining's multi_logloss: 0.0769878\tvalid_1's multi_logloss: 0.275866       \n",
      "[72]\ttraining's multi_logloss: 0.0755959\tvalid_1's multi_logloss: 0.275936       \n",
      "[73]\ttraining's multi_logloss: 0.0742074\tvalid_1's multi_logloss: 0.276782       \n",
      "[74]\ttraining's multi_logloss: 0.0728699\tvalid_1's multi_logloss: 0.277343       \n",
      "[75]\ttraining's multi_logloss: 0.0714367\tvalid_1's multi_logloss: 0.277706       \n",
      "[76]\ttraining's multi_logloss: 0.0702324\tvalid_1's multi_logloss: 0.278348       \n",
      "[77]\ttraining's multi_logloss: 0.0690804\tvalid_1's multi_logloss: 0.278769       \n",
      "[78]\ttraining's multi_logloss: 0.0677639\tvalid_1's multi_logloss: 0.279098       \n",
      "Early stopping, best iteration is:                                               \n",
      "[48]\ttraining's multi_logloss: 0.121681\tvalid_1's multi_logloss: 0.269534\n",
      "[1]\ttraining's multi_logloss: 1.83652\tvalid_1's multi_logloss: 1.83607           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.75109\tvalid_1's multi_logloss: 1.75276           \n",
      "[3]\ttraining's multi_logloss: 1.67442\tvalid_1's multi_logloss: 1.67787           \n",
      "[4]\ttraining's multi_logloss: 1.60416\tvalid_1's multi_logloss: 1.60959           \n",
      "[5]\ttraining's multi_logloss: 1.54008\tvalid_1's multi_logloss: 1.54726           \n",
      "[6]\ttraining's multi_logloss: 1.48068\tvalid_1's multi_logloss: 1.48959           \n",
      "[7]\ttraining's multi_logloss: 1.42593\tvalid_1's multi_logloss: 1.43637           \n",
      "[8]\ttraining's multi_logloss: 1.37458\tvalid_1's multi_logloss: 1.3863            \n",
      "[9]\ttraining's multi_logloss: 1.32676\tvalid_1's multi_logloss: 1.33977           \n",
      "[10]\ttraining's multi_logloss: 1.28179\tvalid_1's multi_logloss: 1.296            \n",
      "[11]\ttraining's multi_logloss: 1.23967\tvalid_1's multi_logloss: 1.25512          \n",
      "[12]\ttraining's multi_logloss: 1.19998\tvalid_1's multi_logloss: 1.21666          \n",
      "[13]\ttraining's multi_logloss: 1.16259\tvalid_1's multi_logloss: 1.18038          \n",
      "[14]\ttraining's multi_logloss: 1.12719\tvalid_1's multi_logloss: 1.14617          \n",
      "[15]\ttraining's multi_logloss: 1.09362\tvalid_1's multi_logloss: 1.11381          \n",
      "[16]\ttraining's multi_logloss: 1.06171\tvalid_1's multi_logloss: 1.0829           \n",
      "[17]\ttraining's multi_logloss: 1.03149\tvalid_1's multi_logloss: 1.05367          \n",
      "[18]\ttraining's multi_logloss: 1.00277\tvalid_1's multi_logloss: 1.02594          \n",
      "[19]\ttraining's multi_logloss: 0.975441\tvalid_1's multi_logloss: 0.999445        \n",
      "[20]\ttraining's multi_logloss: 0.949244\tvalid_1's multi_logloss: 0.974271        \n",
      "[21]\ttraining's multi_logloss: 0.924168\tvalid_1's multi_logloss: 0.950091        \n",
      "[22]\ttraining's multi_logloss: 0.9001\tvalid_1's multi_logloss: 0.926774          \n",
      "[23]\ttraining's multi_logloss: 0.877125\tvalid_1's multi_logloss: 0.904503        \n",
      "[24]\ttraining's multi_logloss: 0.855158\tvalid_1's multi_logloss: 0.883247        \n",
      "[25]\ttraining's multi_logloss: 0.833972\tvalid_1's multi_logloss: 0.862822        \n",
      "[26]\ttraining's multi_logloss: 0.813729\tvalid_1's multi_logloss: 0.843384        \n",
      "[27]\ttraining's multi_logloss: 0.794429\tvalid_1's multi_logloss: 0.8248          \n",
      "[28]\ttraining's multi_logloss: 0.775835\tvalid_1's multi_logloss: 0.806825        \n",
      "[29]\ttraining's multi_logloss: 0.757992\tvalid_1's multi_logloss: 0.789726        \n",
      "[30]\ttraining's multi_logloss: 0.740961\tvalid_1's multi_logloss: 0.773321        \n",
      "[31]\ttraining's multi_logloss: 0.724555\tvalid_1's multi_logloss: 0.757553        \n",
      "[32]\ttraining's multi_logloss: 0.70865\tvalid_1's multi_logloss: 0.742248         \n",
      "[33]\ttraining's multi_logloss: 0.69322\tvalid_1's multi_logloss: 0.727471         \n",
      "[34]\ttraining's multi_logloss: 0.678419\tvalid_1's multi_logloss: 0.713366        \n",
      "[35]\ttraining's multi_logloss: 0.664158\tvalid_1's multi_logloss: 0.699777        \n",
      "[36]\ttraining's multi_logloss: 0.650338\tvalid_1's multi_logloss: 0.686606        \n",
      "[37]\ttraining's multi_logloss: 0.637073\tvalid_1's multi_logloss: 0.674023        \n",
      "[38]\ttraining's multi_logloss: 0.624128\tvalid_1's multi_logloss: 0.661805        \n",
      "[39]\ttraining's multi_logloss: 0.611566\tvalid_1's multi_logloss: 0.649909        \n",
      "[40]\ttraining's multi_logloss: 0.59952\tvalid_1's multi_logloss: 0.638492         \n",
      "[41]\ttraining's multi_logloss: 0.587918\tvalid_1's multi_logloss: 0.627465        \n",
      "[42]\ttraining's multi_logloss: 0.576896\tvalid_1's multi_logloss: 0.617051        \n",
      "[43]\ttraining's multi_logloss: 0.565933\tvalid_1's multi_logloss: 0.606826        \n",
      "[44]\ttraining's multi_logloss: 0.555553\tvalid_1's multi_logloss: 0.597063        \n",
      "[45]\ttraining's multi_logloss: 0.54541\tvalid_1's multi_logloss: 0.587532         \n",
      "[46]\ttraining's multi_logloss: 0.535678\tvalid_1's multi_logloss: 0.578462        \n",
      "[47]\ttraining's multi_logloss: 0.526362\tvalid_1's multi_logloss: 0.569785        \n",
      "[48]\ttraining's multi_logloss: 0.517315\tvalid_1's multi_logloss: 0.561368        \n",
      "[49]\ttraining's multi_logloss: 0.508374\tvalid_1's multi_logloss: 0.55296         \n",
      "[50]\ttraining's multi_logloss: 0.499814\tvalid_1's multi_logloss: 0.545092        \n",
      "[51]\ttraining's multi_logloss: 0.491448\tvalid_1's multi_logloss: 0.53729         \n",
      "[52]\ttraining's multi_logloss: 0.483452\tvalid_1's multi_logloss: 0.529971        \n",
      "[53]\ttraining's multi_logloss: 0.475676\tvalid_1's multi_logloss: 0.522813        \n",
      "[54]\ttraining's multi_logloss: 0.46824\tvalid_1's multi_logloss: 0.51594          \n",
      "[55]\ttraining's multi_logloss: 0.460889\tvalid_1's multi_logloss: 0.509235        \n",
      "[56]\ttraining's multi_logloss: 0.453883\tvalid_1's multi_logloss: 0.502823        \n",
      "[57]\ttraining's multi_logloss: 0.44697\tvalid_1's multi_logloss: 0.496516         \n",
      "[58]\ttraining's multi_logloss: 0.440295\tvalid_1's multi_logloss: 0.490465        \n",
      "[59]\ttraining's multi_logloss: 0.433807\tvalid_1's multi_logloss: 0.484558        \n",
      "[60]\ttraining's multi_logloss: 0.427437\tvalid_1's multi_logloss: 0.478742        \n",
      "[61]\ttraining's multi_logloss: 0.421308\tvalid_1's multi_logloss: 0.473248        \n",
      "[62]\ttraining's multi_logloss: 0.41531\tvalid_1's multi_logloss: 0.467825         \n",
      "[63]\ttraining's multi_logloss: 0.409527\tvalid_1's multi_logloss: 0.462622        \n",
      "[64]\ttraining's multi_logloss: 0.403981\tvalid_1's multi_logloss: 0.4576          \n",
      "[65]\ttraining's multi_logloss: 0.398545\tvalid_1's multi_logloss: 0.452774        \n",
      "[66]\ttraining's multi_logloss: 0.393253\tvalid_1's multi_logloss: 0.448013        \n",
      "[67]\ttraining's multi_logloss: 0.388121\tvalid_1's multi_logloss: 0.443486        \n",
      "[68]\ttraining's multi_logloss: 0.38312\tvalid_1's multi_logloss: 0.438961         \n",
      "[69]\ttraining's multi_logloss: 0.378224\tvalid_1's multi_logloss: 0.434688        \n",
      "[70]\ttraining's multi_logloss: 0.373549\tvalid_1's multi_logloss: 0.43053         \n",
      "[71]\ttraining's multi_logloss: 0.368962\tvalid_1's multi_logloss: 0.426573        \n",
      "[72]\ttraining's multi_logloss: 0.364603\tvalid_1's multi_logloss: 0.422761        \n",
      "[73]\ttraining's multi_logloss: 0.360383\tvalid_1's multi_logloss: 0.419132        \n",
      "[74]\ttraining's multi_logloss: 0.356152\tvalid_1's multi_logloss: 0.415539        \n",
      "[75]\ttraining's multi_logloss: 0.352114\tvalid_1's multi_logloss: 0.412136        \n",
      "[76]\ttraining's multi_logloss: 0.348042\tvalid_1's multi_logloss: 0.408721        \n",
      "[77]\ttraining's multi_logloss: 0.34409\tvalid_1's multi_logloss: 0.405373         \n",
      "[78]\ttraining's multi_logloss: 0.340299\tvalid_1's multi_logloss: 0.402186        \n",
      "[79]\ttraining's multi_logloss: 0.336529\tvalid_1's multi_logloss: 0.399143        \n",
      "[80]\ttraining's multi_logloss: 0.332931\tvalid_1's multi_logloss: 0.396118        \n",
      "[81]\ttraining's multi_logloss: 0.32935\tvalid_1's multi_logloss: 0.393194         \n",
      "[82]\ttraining's multi_logloss: 0.325957\tvalid_1's multi_logloss: 0.390348        \n",
      "[83]\ttraining's multi_logloss: 0.322565\tvalid_1's multi_logloss: 0.387499        \n",
      "[84]\ttraining's multi_logloss: 0.319327\tvalid_1's multi_logloss: 0.384894        \n",
      "[85]\ttraining's multi_logloss: 0.316177\tvalid_1's multi_logloss: 0.38224         \n",
      "[86]\ttraining's multi_logloss: 0.313091\tvalid_1's multi_logloss: 0.379798        \n",
      "[87]\ttraining's multi_logloss: 0.310102\tvalid_1's multi_logloss: 0.377421        \n",
      "[88]\ttraining's multi_logloss: 0.30719\tvalid_1's multi_logloss: 0.375153         \n",
      "[89]\ttraining's multi_logloss: 0.304351\tvalid_1's multi_logloss: 0.372881        \n",
      "[90]\ttraining's multi_logloss: 0.301327\tvalid_1's multi_logloss: 0.37046         \n",
      "[91]\ttraining's multi_logloss: 0.298533\tvalid_1's multi_logloss: 0.368356        \n",
      "[92]\ttraining's multi_logloss: 0.295814\tvalid_1's multi_logloss: 0.366272        \n",
      "[93]\ttraining's multi_logloss: 0.293154\tvalid_1's multi_logloss: 0.364319        \n",
      "[94]\ttraining's multi_logloss: 0.290434\tvalid_1's multi_logloss: 0.362251        \n",
      "[95]\ttraining's multi_logloss: 0.287847\tvalid_1's multi_logloss: 0.360302        \n",
      "[96]\ttraining's multi_logloss: 0.285389\tvalid_1's multi_logloss: 0.358482        \n",
      "[97]\ttraining's multi_logloss: 0.2829\tvalid_1's multi_logloss: 0.356565          \n",
      "[98]\ttraining's multi_logloss: 0.280482\tvalid_1's multi_logloss: 0.354698        \n",
      "[99]\ttraining's multi_logloss: 0.278136\tvalid_1's multi_logloss: 0.352988        \n",
      "[100]\ttraining's multi_logloss: 0.275805\tvalid_1's multi_logloss: 0.351308       \n",
      "[101]\ttraining's multi_logloss: 0.273498\tvalid_1's multi_logloss: 0.349638       \n",
      "[102]\ttraining's multi_logloss: 0.271216\tvalid_1's multi_logloss: 0.348122       \n",
      "[103]\ttraining's multi_logloss: 0.268999\tvalid_1's multi_logloss: 0.346526       \n",
      "[104]\ttraining's multi_logloss: 0.266898\tvalid_1's multi_logloss: 0.345055       \n",
      "[105]\ttraining's multi_logloss: 0.264745\tvalid_1's multi_logloss: 0.343575       \n",
      "[106]\ttraining's multi_logloss: 0.262583\tvalid_1's multi_logloss: 0.342063       \n",
      "[107]\ttraining's multi_logloss: 0.260586\tvalid_1's multi_logloss: 0.340712       \n",
      "[108]\ttraining's multi_logloss: 0.258643\tvalid_1's multi_logloss: 0.339492       \n",
      "[109]\ttraining's multi_logloss: 0.256676\tvalid_1's multi_logloss: 0.33817        \n",
      "[110]\ttraining's multi_logloss: 0.25474\tvalid_1's multi_logloss: 0.336896        \n",
      "[111]\ttraining's multi_logloss: 0.252774\tvalid_1's multi_logloss: 0.335594       \n",
      "[112]\ttraining's multi_logloss: 0.25096\tvalid_1's multi_logloss: 0.334369        \n",
      "[113]\ttraining's multi_logloss: 0.249051\tvalid_1's multi_logloss: 0.333163       \n",
      "[114]\ttraining's multi_logloss: 0.24725\tvalid_1's multi_logloss: 0.331993        \n",
      "[115]\ttraining's multi_logloss: 0.245435\tvalid_1's multi_logloss: 0.33084        \n",
      "[116]\ttraining's multi_logloss: 0.243601\tvalid_1's multi_logloss: 0.329734       \n",
      "[117]\ttraining's multi_logloss: 0.24192\tvalid_1's multi_logloss: 0.328758        \n",
      "[118]\ttraining's multi_logloss: 0.240209\tvalid_1's multi_logloss: 0.327713       \n",
      "[119]\ttraining's multi_logloss: 0.238511\tvalid_1's multi_logloss: 0.326681       \n",
      "[120]\ttraining's multi_logloss: 0.236854\tvalid_1's multi_logloss: 0.325649       \n",
      "[121]\ttraining's multi_logloss: 0.235206\tvalid_1's multi_logloss: 0.324576       \n",
      "[122]\ttraining's multi_logloss: 0.233629\tvalid_1's multi_logloss: 0.323659       \n",
      "[123]\ttraining's multi_logloss: 0.23198\tvalid_1's multi_logloss: 0.322739        \n",
      "[124]\ttraining's multi_logloss: 0.230469\tvalid_1's multi_logloss: 0.321919       \n",
      "[125]\ttraining's multi_logloss: 0.228922\tvalid_1's multi_logloss: 0.321103       \n",
      "[126]\ttraining's multi_logloss: 0.227455\tvalid_1's multi_logloss: 0.320285       \n",
      "[127]\ttraining's multi_logloss: 0.22598\tvalid_1's multi_logloss: 0.319482        \n",
      "[128]\ttraining's multi_logloss: 0.224576\tvalid_1's multi_logloss: 0.318816       \n",
      "[129]\ttraining's multi_logloss: 0.223122\tvalid_1's multi_logloss: 0.318027       \n",
      "[130]\ttraining's multi_logloss: 0.221704\tvalid_1's multi_logloss: 0.317336       \n",
      "[131]\ttraining's multi_logloss: 0.220335\tvalid_1's multi_logloss: 0.316634       \n",
      "[132]\ttraining's multi_logloss: 0.218904\tvalid_1's multi_logloss: 0.315972       \n",
      "[133]\ttraining's multi_logloss: 0.217546\tvalid_1's multi_logloss: 0.315402       \n",
      "[134]\ttraining's multi_logloss: 0.216149\tvalid_1's multi_logloss: 0.314727       \n",
      "[135]\ttraining's multi_logloss: 0.214803\tvalid_1's multi_logloss: 0.314142       \n",
      "[136]\ttraining's multi_logloss: 0.213502\tvalid_1's multi_logloss: 0.313575       \n",
      "[137]\ttraining's multi_logloss: 0.212217\tvalid_1's multi_logloss: 0.312954       \n",
      "[138]\ttraining's multi_logloss: 0.210955\tvalid_1's multi_logloss: 0.312383       \n",
      "[139]\ttraining's multi_logloss: 0.209699\tvalid_1's multi_logloss: 0.311789       \n",
      "[140]\ttraining's multi_logloss: 0.208433\tvalid_1's multi_logloss: 0.311226       \n",
      "[141]\ttraining's multi_logloss: 0.207163\tvalid_1's multi_logloss: 0.310661       \n",
      "[142]\ttraining's multi_logloss: 0.205911\tvalid_1's multi_logloss: 0.310041       \n",
      "[143]\ttraining's multi_logloss: 0.204698\tvalid_1's multi_logloss: 0.30942        \n",
      "[144]\ttraining's multi_logloss: 0.203512\tvalid_1's multi_logloss: 0.308785       \n",
      "[145]\ttraining's multi_logloss: 0.202282\tvalid_1's multi_logloss: 0.308283       \n",
      "[146]\ttraining's multi_logloss: 0.201049\tvalid_1's multi_logloss: 0.307789       \n",
      "[147]\ttraining's multi_logloss: 0.1999\tvalid_1's multi_logloss: 0.307252         \n",
      "[148]\ttraining's multi_logloss: 0.198723\tvalid_1's multi_logloss: 0.306747       \n",
      "[149]\ttraining's multi_logloss: 0.197615\tvalid_1's multi_logloss: 0.306279       \n",
      "[150]\ttraining's multi_logloss: 0.196454\tvalid_1's multi_logloss: 0.305804       \n",
      "[151]\ttraining's multi_logloss: 0.195353\tvalid_1's multi_logloss: 0.305346       \n",
      "[152]\ttraining's multi_logloss: 0.194259\tvalid_1's multi_logloss: 0.305026       \n",
      "[153]\ttraining's multi_logloss: 0.193194\tvalid_1's multi_logloss: 0.304645       \n",
      "[154]\ttraining's multi_logloss: 0.192108\tvalid_1's multi_logloss: 0.304243       \n",
      "[155]\ttraining's multi_logloss: 0.191068\tvalid_1's multi_logloss: 0.303893       \n",
      "[156]\ttraining's multi_logloss: 0.190056\tvalid_1's multi_logloss: 0.303542       \n",
      "[157]\ttraining's multi_logloss: 0.189034\tvalid_1's multi_logloss: 0.30313        \n",
      "[158]\ttraining's multi_logloss: 0.188006\tvalid_1's multi_logloss: 0.302792       \n",
      "[159]\ttraining's multi_logloss: 0.187016\tvalid_1's multi_logloss: 0.302446       \n",
      "[160]\ttraining's multi_logloss: 0.185959\tvalid_1's multi_logloss: 0.302062       \n",
      "[161]\ttraining's multi_logloss: 0.18493\tvalid_1's multi_logloss: 0.301608        \n",
      "[162]\ttraining's multi_logloss: 0.183925\tvalid_1's multi_logloss: 0.301275       \n",
      "[163]\ttraining's multi_logloss: 0.18293\tvalid_1's multi_logloss: 0.300871        \n",
      "[164]\ttraining's multi_logloss: 0.181885\tvalid_1's multi_logloss: 0.300504       \n",
      "[165]\ttraining's multi_logloss: 0.180939\tvalid_1's multi_logloss: 0.300126       \n",
      "[166]\ttraining's multi_logloss: 0.179957\tvalid_1's multi_logloss: 0.299772       \n",
      "[167]\ttraining's multi_logloss: 0.179013\tvalid_1's multi_logloss: 0.299406       \n",
      "[168]\ttraining's multi_logloss: 0.178088\tvalid_1's multi_logloss: 0.299096       \n",
      "[169]\ttraining's multi_logloss: 0.177172\tvalid_1's multi_logloss: 0.29883        \n",
      "[170]\ttraining's multi_logloss: 0.176268\tvalid_1's multi_logloss: 0.298571       \n",
      "[171]\ttraining's multi_logloss: 0.175431\tvalid_1's multi_logloss: 0.298373       \n",
      "[172]\ttraining's multi_logloss: 0.174519\tvalid_1's multi_logloss: 0.298044       \n",
      "[173]\ttraining's multi_logloss: 0.173586\tvalid_1's multi_logloss: 0.297876       \n",
      "[174]\ttraining's multi_logloss: 0.172724\tvalid_1's multi_logloss: 0.29758        \n",
      "[175]\ttraining's multi_logloss: 0.171768\tvalid_1's multi_logloss: 0.297314       \n",
      "[176]\ttraining's multi_logloss: 0.170888\tvalid_1's multi_logloss: 0.297058       \n",
      "[177]\ttraining's multi_logloss: 0.170009\tvalid_1's multi_logloss: 0.296852       \n",
      "[178]\ttraining's multi_logloss: 0.169108\tvalid_1's multi_logloss: 0.296722       \n",
      "[179]\ttraining's multi_logloss: 0.16822\tvalid_1's multi_logloss: 0.296487        \n",
      "[180]\ttraining's multi_logloss: 0.167301\tvalid_1's multi_logloss: 0.29626        \n",
      "[181]\ttraining's multi_logloss: 0.166368\tvalid_1's multi_logloss: 0.296076       \n",
      "[182]\ttraining's multi_logloss: 0.165517\tvalid_1's multi_logloss: 0.295907       \n",
      "[183]\ttraining's multi_logloss: 0.164631\tvalid_1's multi_logloss: 0.295717       \n",
      "[184]\ttraining's multi_logloss: 0.163792\tvalid_1's multi_logloss: 0.295578       \n",
      "[185]\ttraining's multi_logloss: 0.162916\tvalid_1's multi_logloss: 0.295384       \n",
      "[186]\ttraining's multi_logloss: 0.162044\tvalid_1's multi_logloss: 0.29513        \n",
      "[187]\ttraining's multi_logloss: 0.161232\tvalid_1's multi_logloss: 0.294975       \n",
      "[188]\ttraining's multi_logloss: 0.160425\tvalid_1's multi_logloss: 0.294841       \n",
      "[189]\ttraining's multi_logloss: 0.159581\tvalid_1's multi_logloss: 0.294672       \n",
      "[190]\ttraining's multi_logloss: 0.158726\tvalid_1's multi_logloss: 0.294504       \n",
      "[191]\ttraining's multi_logloss: 0.157888\tvalid_1's multi_logloss: 0.294388       \n",
      "[192]\ttraining's multi_logloss: 0.157137\tvalid_1's multi_logloss: 0.294354       \n",
      "[193]\ttraining's multi_logloss: 0.15636\tvalid_1's multi_logloss: 0.294234        \n",
      "[194]\ttraining's multi_logloss: 0.155579\tvalid_1's multi_logloss: 0.294022       \n",
      "[195]\ttraining's multi_logloss: 0.154799\tvalid_1's multi_logloss: 0.293867       \n",
      "[196]\ttraining's multi_logloss: 0.15403\tvalid_1's multi_logloss: 0.293655        \n",
      "[197]\ttraining's multi_logloss: 0.153243\tvalid_1's multi_logloss: 0.293489       \n",
      "[198]\ttraining's multi_logloss: 0.152528\tvalid_1's multi_logloss: 0.293347       \n",
      "[199]\ttraining's multi_logloss: 0.151781\tvalid_1's multi_logloss: 0.293205       \n",
      "[200]\ttraining's multi_logloss: 0.151016\tvalid_1's multi_logloss: 0.292993       \n",
      "[201]\ttraining's multi_logloss: 0.150278\tvalid_1's multi_logloss: 0.292894       \n",
      "[202]\ttraining's multi_logloss: 0.149544\tvalid_1's multi_logloss: 0.292705       \n",
      "[203]\ttraining's multi_logloss: 0.148785\tvalid_1's multi_logloss: 0.292455       \n",
      "[204]\ttraining's multi_logloss: 0.148066\tvalid_1's multi_logloss: 0.292396       \n",
      "[205]\ttraining's multi_logloss: 0.147318\tvalid_1's multi_logloss: 0.292243       \n",
      "[206]\ttraining's multi_logloss: 0.14656\tvalid_1's multi_logloss: 0.292199        \n",
      "[207]\ttraining's multi_logloss: 0.145874\tvalid_1's multi_logloss: 0.292136       \n",
      "[208]\ttraining's multi_logloss: 0.145181\tvalid_1's multi_logloss: 0.292103       \n",
      "[209]\ttraining's multi_logloss: 0.144478\tvalid_1's multi_logloss: 0.292096       \n",
      "[210]\ttraining's multi_logloss: 0.143783\tvalid_1's multi_logloss: 0.292069       \n",
      "[211]\ttraining's multi_logloss: 0.143047\tvalid_1's multi_logloss: 0.292009       \n",
      "[212]\ttraining's multi_logloss: 0.142383\tvalid_1's multi_logloss: 0.291972       \n",
      "[213]\ttraining's multi_logloss: 0.14169\tvalid_1's multi_logloss: 0.291907        \n",
      "[214]\ttraining's multi_logloss: 0.141017\tvalid_1's multi_logloss: 0.291859       \n",
      "[215]\ttraining's multi_logloss: 0.140341\tvalid_1's multi_logloss: 0.291773       \n",
      "[216]\ttraining's multi_logloss: 0.139643\tvalid_1's multi_logloss: 0.291595       \n",
      "[217]\ttraining's multi_logloss: 0.138971\tvalid_1's multi_logloss: 0.291433       \n",
      "[218]\ttraining's multi_logloss: 0.138327\tvalid_1's multi_logloss: 0.291325       \n",
      "[219]\ttraining's multi_logloss: 0.137675\tvalid_1's multi_logloss: 0.291175       \n",
      "[220]\ttraining's multi_logloss: 0.13704\tvalid_1's multi_logloss: 0.291098        \n",
      "[221]\ttraining's multi_logloss: 0.136402\tvalid_1's multi_logloss: 0.291029       \n",
      "[222]\ttraining's multi_logloss: 0.135738\tvalid_1's multi_logloss: 0.290944       \n",
      "[223]\ttraining's multi_logloss: 0.1351\tvalid_1's multi_logloss: 0.290928         \n",
      "[224]\ttraining's multi_logloss: 0.134458\tvalid_1's multi_logloss: 0.290863       \n",
      "[225]\ttraining's multi_logloss: 0.133856\tvalid_1's multi_logloss: 0.290819       \n",
      "[226]\ttraining's multi_logloss: 0.133237\tvalid_1's multi_logloss: 0.290721       \n",
      "[227]\ttraining's multi_logloss: 0.132639\tvalid_1's multi_logloss: 0.290726       \n",
      "[228]\ttraining's multi_logloss: 0.132038\tvalid_1's multi_logloss: 0.290703       \n",
      "[229]\ttraining's multi_logloss: 0.131438\tvalid_1's multi_logloss: 0.290722       \n",
      "[230]\ttraining's multi_logloss: 0.130838\tvalid_1's multi_logloss: 0.290668       \n",
      "[231]\ttraining's multi_logloss: 0.130223\tvalid_1's multi_logloss: 0.290594       \n",
      "[232]\ttraining's multi_logloss: 0.129631\tvalid_1's multi_logloss: 0.290559       \n",
      "[233]\ttraining's multi_logloss: 0.129053\tvalid_1's multi_logloss: 0.290559       \n",
      "[234]\ttraining's multi_logloss: 0.128504\tvalid_1's multi_logloss: 0.290491       \n",
      "[235]\ttraining's multi_logloss: 0.127898\tvalid_1's multi_logloss: 0.290501       \n",
      "[236]\ttraining's multi_logloss: 0.127286\tvalid_1's multi_logloss: 0.290453       \n",
      "[237]\ttraining's multi_logloss: 0.126711\tvalid_1's multi_logloss: 0.290425       \n",
      "[238]\ttraining's multi_logloss: 0.12609\tvalid_1's multi_logloss: 0.290392        \n",
      "[239]\ttraining's multi_logloss: 0.125492\tvalid_1's multi_logloss: 0.290361       \n",
      "[240]\ttraining's multi_logloss: 0.124872\tvalid_1's multi_logloss: 0.290273       \n",
      "[241]\ttraining's multi_logloss: 0.12429\tvalid_1's multi_logloss: 0.290219        \n",
      "[242]\ttraining's multi_logloss: 0.123756\tvalid_1's multi_logloss: 0.290153       \n",
      "[243]\ttraining's multi_logloss: 0.123171\tvalid_1's multi_logloss: 0.290145       \n",
      "[244]\ttraining's multi_logloss: 0.122628\tvalid_1's multi_logloss: 0.290033       \n",
      "[245]\ttraining's multi_logloss: 0.122046\tvalid_1's multi_logloss: 0.289947       \n",
      "[246]\ttraining's multi_logloss: 0.121481\tvalid_1's multi_logloss: 0.289962       \n",
      "[247]\ttraining's multi_logloss: 0.12093\tvalid_1's multi_logloss: 0.28994         \n",
      "[248]\ttraining's multi_logloss: 0.120386\tvalid_1's multi_logloss: 0.289953       \n",
      "[249]\ttraining's multi_logloss: 0.119832\tvalid_1's multi_logloss: 0.289893       \n",
      "[250]\ttraining's multi_logloss: 0.119278\tvalid_1's multi_logloss: 0.289869       \n",
      "[251]\ttraining's multi_logloss: 0.11872\tvalid_1's multi_logloss: 0.289851        \n",
      "[252]\ttraining's multi_logloss: 0.118175\tvalid_1's multi_logloss: 0.289832       \n",
      "[253]\ttraining's multi_logloss: 0.117624\tvalid_1's multi_logloss: 0.289801       \n",
      "[254]\ttraining's multi_logloss: 0.117135\tvalid_1's multi_logloss: 0.289836       \n",
      "[255]\ttraining's multi_logloss: 0.116627\tvalid_1's multi_logloss: 0.289765       \n",
      "[256]\ttraining's multi_logloss: 0.116142\tvalid_1's multi_logloss: 0.289701       \n",
      "[257]\ttraining's multi_logloss: 0.115622\tvalid_1's multi_logloss: 0.289691       \n",
      "[258]\ttraining's multi_logloss: 0.115095\tvalid_1's multi_logloss: 0.289695       \n",
      "[259]\ttraining's multi_logloss: 0.114622\tvalid_1's multi_logloss: 0.289716       \n",
      "[260]\ttraining's multi_logloss: 0.114122\tvalid_1's multi_logloss: 0.289699       \n",
      "[261]\ttraining's multi_logloss: 0.113577\tvalid_1's multi_logloss: 0.289757       \n",
      "[262]\ttraining's multi_logloss: 0.113099\tvalid_1's multi_logloss: 0.28984        \n",
      "[263]\ttraining's multi_logloss: 0.112588\tvalid_1's multi_logloss: 0.289855       \n",
      "[264]\ttraining's multi_logloss: 0.112083\tvalid_1's multi_logloss: 0.289944       \n",
      "[265]\ttraining's multi_logloss: 0.111569\tvalid_1's multi_logloss: 0.289881       \n",
      "[266]\ttraining's multi_logloss: 0.111107\tvalid_1's multi_logloss: 0.289788       \n",
      "[267]\ttraining's multi_logloss: 0.110614\tvalid_1's multi_logloss: 0.289882       \n",
      "[268]\ttraining's multi_logloss: 0.110148\tvalid_1's multi_logloss: 0.289982       \n",
      "[269]\ttraining's multi_logloss: 0.109686\tvalid_1's multi_logloss: 0.289978       \n",
      "[270]\ttraining's multi_logloss: 0.109228\tvalid_1's multi_logloss: 0.289963       \n",
      "[271]\ttraining's multi_logloss: 0.108753\tvalid_1's multi_logloss: 0.289961       \n",
      "[272]\ttraining's multi_logloss: 0.108291\tvalid_1's multi_logloss: 0.289912       \n",
      "[273]\ttraining's multi_logloss: 0.107833\tvalid_1's multi_logloss: 0.289912       \n",
      "[274]\ttraining's multi_logloss: 0.107381\tvalid_1's multi_logloss: 0.28995        \n",
      "[275]\ttraining's multi_logloss: 0.10691\tvalid_1's multi_logloss: 0.29            \n",
      "[276]\ttraining's multi_logloss: 0.106455\tvalid_1's multi_logloss: 0.290127       \n",
      "[277]\ttraining's multi_logloss: 0.106046\tvalid_1's multi_logloss: 0.290148       \n",
      "[278]\ttraining's multi_logloss: 0.105622\tvalid_1's multi_logloss: 0.290139       \n",
      "[279]\ttraining's multi_logloss: 0.105183\tvalid_1's multi_logloss: 0.290176       \n",
      "[280]\ttraining's multi_logloss: 0.104763\tvalid_1's multi_logloss: 0.290272       \n",
      "[281]\ttraining's multi_logloss: 0.104295\tvalid_1's multi_logloss: 0.290324       \n",
      "[282]\ttraining's multi_logloss: 0.103877\tvalid_1's multi_logloss: 0.290398       \n",
      "[283]\ttraining's multi_logloss: 0.10346\tvalid_1's multi_logloss: 0.290425        \n",
      "[284]\ttraining's multi_logloss: 0.103018\tvalid_1's multi_logloss: 0.290431       \n",
      "[285]\ttraining's multi_logloss: 0.102592\tvalid_1's multi_logloss: 0.290413       \n",
      "[286]\ttraining's multi_logloss: 0.102198\tvalid_1's multi_logloss: 0.290488       \n",
      "[287]\ttraining's multi_logloss: 0.1018\tvalid_1's multi_logloss: 0.290591         \n",
      "Early stopping, best iteration is:                                               \n",
      "[257]\ttraining's multi_logloss: 0.115622\tvalid_1's multi_logloss: 0.289691\n",
      "[1]\ttraining's multi_logloss: 1.83509\tvalid_1's multi_logloss: 1.83742           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.75077\tvalid_1's multi_logloss: 1.75382           \n",
      "[3]\ttraining's multi_logloss: 1.67461\tvalid_1's multi_logloss: 1.67834           \n",
      "[4]\ttraining's multi_logloss: 1.60541\tvalid_1's multi_logloss: 1.60973           \n",
      "[5]\ttraining's multi_logloss: 1.54186\tvalid_1's multi_logloss: 1.54667           \n",
      "[6]\ttraining's multi_logloss: 1.48322\tvalid_1's multi_logloss: 1.48851           \n",
      "[7]\ttraining's multi_logloss: 1.42877\tvalid_1's multi_logloss: 1.43479           \n",
      "[8]\ttraining's multi_logloss: 1.37802\tvalid_1's multi_logloss: 1.38452           \n",
      "[9]\ttraining's multi_logloss: 1.33093\tvalid_1's multi_logloss: 1.33814           \n",
      "[10]\ttraining's multi_logloss: 1.28628\tvalid_1's multi_logloss: 1.29425          \n",
      "[11]\ttraining's multi_logloss: 1.24444\tvalid_1's multi_logloss: 1.25294          \n",
      "[12]\ttraining's multi_logloss: 1.20485\tvalid_1's multi_logloss: 1.21404          \n",
      "[13]\ttraining's multi_logloss: 1.16765\tvalid_1's multi_logloss: 1.1772           \n",
      "[14]\ttraining's multi_logloss: 1.1327\tvalid_1's multi_logloss: 1.14285           \n",
      "[15]\ttraining's multi_logloss: 1.09933\tvalid_1's multi_logloss: 1.11006          \n",
      "[16]\ttraining's multi_logloss: 1.06791\tvalid_1's multi_logloss: 1.07926          \n",
      "[17]\ttraining's multi_logloss: 1.0379\tvalid_1's multi_logloss: 1.04991           \n",
      "[18]\ttraining's multi_logloss: 1.00935\tvalid_1's multi_logloss: 1.02188          \n",
      "[19]\ttraining's multi_logloss: 0.982051\tvalid_1's multi_logloss: 0.995226        \n",
      "[20]\ttraining's multi_logloss: 0.955873\tvalid_1's multi_logloss: 0.969659        \n",
      "[21]\ttraining's multi_logloss: 0.930771\tvalid_1's multi_logloss: 0.945093        \n",
      "[22]\ttraining's multi_logloss: 0.907042\tvalid_1's multi_logloss: 0.921984        \n",
      "[23]\ttraining's multi_logloss: 0.884263\tvalid_1's multi_logloss: 0.899822        \n",
      "[24]\ttraining's multi_logloss: 0.862377\tvalid_1's multi_logloss: 0.878265        \n",
      "[25]\ttraining's multi_logloss: 0.84167\tvalid_1's multi_logloss: 0.858047         \n",
      "[26]\ttraining's multi_logloss: 0.821393\tvalid_1's multi_logloss: 0.838407        \n",
      "[27]\ttraining's multi_logloss: 0.802077\tvalid_1's multi_logloss: 0.819749        \n",
      "[28]\ttraining's multi_logloss: 0.783201\tvalid_1's multi_logloss: 0.801512        \n",
      "[29]\ttraining's multi_logloss: 0.7651\tvalid_1's multi_logloss: 0.784037          \n",
      "[30]\ttraining's multi_logloss: 0.747941\tvalid_1's multi_logloss: 0.767464        \n",
      "[31]\ttraining's multi_logloss: 0.731214\tvalid_1's multi_logloss: 0.751416        \n",
      "[32]\ttraining's multi_logloss: 0.715138\tvalid_1's multi_logloss: 0.736037        \n",
      "[33]\ttraining's multi_logloss: 0.699625\tvalid_1's multi_logloss: 0.721199        \n",
      "[34]\ttraining's multi_logloss: 0.684816\tvalid_1's multi_logloss: 0.707039        \n",
      "[35]\ttraining's multi_logloss: 0.670491\tvalid_1's multi_logloss: 0.693413        \n",
      "[36]\ttraining's multi_logloss: 0.656695\tvalid_1's multi_logloss: 0.680192        \n",
      "[37]\ttraining's multi_logloss: 0.643404\tvalid_1's multi_logloss: 0.667559        \n",
      "[38]\ttraining's multi_logloss: 0.6305\tvalid_1's multi_logloss: 0.655202          \n",
      "[39]\ttraining's multi_logloss: 0.618099\tvalid_1's multi_logloss: 0.6433          \n",
      "[40]\ttraining's multi_logloss: 0.606272\tvalid_1's multi_logloss: 0.632076        \n",
      "[41]\ttraining's multi_logloss: 0.594745\tvalid_1's multi_logloss: 0.621214        \n",
      "[42]\ttraining's multi_logloss: 0.583455\tvalid_1's multi_logloss: 0.61055         \n",
      "[43]\ttraining's multi_logloss: 0.572572\tvalid_1's multi_logloss: 0.600275        \n",
      "[44]\ttraining's multi_logloss: 0.5621\tvalid_1's multi_logloss: 0.590491          \n",
      "[45]\ttraining's multi_logloss: 0.551864\tvalid_1's multi_logloss: 0.580668        \n",
      "[46]\ttraining's multi_logloss: 0.542031\tvalid_1's multi_logloss: 0.57131         \n",
      "[47]\ttraining's multi_logloss: 0.532508\tvalid_1's multi_logloss: 0.562369        \n",
      "[48]\ttraining's multi_logloss: 0.523446\tvalid_1's multi_logloss: 0.553827        \n",
      "[49]\ttraining's multi_logloss: 0.514502\tvalid_1's multi_logloss: 0.545363        \n",
      "[50]\ttraining's multi_logloss: 0.505952\tvalid_1's multi_logloss: 0.537309        \n",
      "[51]\ttraining's multi_logloss: 0.497658\tvalid_1's multi_logloss: 0.529681        \n",
      "[52]\ttraining's multi_logloss: 0.489737\tvalid_1's multi_logloss: 0.52238         \n",
      "[53]\ttraining's multi_logloss: 0.482086\tvalid_1's multi_logloss: 0.51525         \n",
      "[54]\ttraining's multi_logloss: 0.474414\tvalid_1's multi_logloss: 0.508235        \n",
      "[55]\ttraining's multi_logloss: 0.46716\tvalid_1's multi_logloss: 0.501687         \n",
      "[56]\ttraining's multi_logloss: 0.460049\tvalid_1's multi_logloss: 0.495209        \n",
      "[57]\ttraining's multi_logloss: 0.453061\tvalid_1's multi_logloss: 0.488986        \n",
      "[58]\ttraining's multi_logloss: 0.446277\tvalid_1's multi_logloss: 0.482793        \n",
      "[59]\ttraining's multi_logloss: 0.439711\tvalid_1's multi_logloss: 0.476846        \n",
      "[60]\ttraining's multi_logloss: 0.433307\tvalid_1's multi_logloss: 0.471022        \n",
      "[61]\ttraining's multi_logloss: 0.427177\tvalid_1's multi_logloss: 0.465516        \n",
      "[62]\ttraining's multi_logloss: 0.421223\tvalid_1's multi_logloss: 0.460264        \n",
      "[63]\ttraining's multi_logloss: 0.415501\tvalid_1's multi_logloss: 0.455238        \n",
      "[64]\ttraining's multi_logloss: 0.409877\tvalid_1's multi_logloss: 0.450331        \n",
      "[65]\ttraining's multi_logloss: 0.404438\tvalid_1's multi_logloss: 0.445565        \n",
      "[66]\ttraining's multi_logloss: 0.399144\tvalid_1's multi_logloss: 0.440948        \n",
      "[67]\ttraining's multi_logloss: 0.39395\tvalid_1's multi_logloss: 0.43654          \n",
      "[68]\ttraining's multi_logloss: 0.38887\tvalid_1's multi_logloss: 0.4321           \n",
      "[69]\ttraining's multi_logloss: 0.384025\tvalid_1's multi_logloss: 0.427851        \n",
      "[70]\ttraining's multi_logloss: 0.379319\tvalid_1's multi_logloss: 0.423748        \n",
      "[71]\ttraining's multi_logloss: 0.374654\tvalid_1's multi_logloss: 0.419631        \n",
      "[72]\ttraining's multi_logloss: 0.370048\tvalid_1's multi_logloss: 0.415586        \n",
      "[73]\ttraining's multi_logloss: 0.365677\tvalid_1's multi_logloss: 0.411849        \n",
      "[74]\ttraining's multi_logloss: 0.361323\tvalid_1's multi_logloss: 0.40815         \n",
      "[75]\ttraining's multi_logloss: 0.357147\tvalid_1's multi_logloss: 0.404647        \n",
      "[76]\ttraining's multi_logloss: 0.353078\tvalid_1's multi_logloss: 0.401131        \n",
      "[77]\ttraining's multi_logloss: 0.349064\tvalid_1's multi_logloss: 0.397716        \n",
      "[78]\ttraining's multi_logloss: 0.345147\tvalid_1's multi_logloss: 0.394459        \n",
      "[79]\ttraining's multi_logloss: 0.341389\tvalid_1's multi_logloss: 0.391344        \n",
      "[80]\ttraining's multi_logloss: 0.337766\tvalid_1's multi_logloss: 0.388416        \n",
      "[81]\ttraining's multi_logloss: 0.334154\tvalid_1's multi_logloss: 0.385456        \n",
      "[82]\ttraining's multi_logloss: 0.330689\tvalid_1's multi_logloss: 0.382598        \n",
      "[83]\ttraining's multi_logloss: 0.327314\tvalid_1's multi_logloss: 0.379944        \n",
      "[84]\ttraining's multi_logloss: 0.323902\tvalid_1's multi_logloss: 0.377241        \n",
      "[85]\ttraining's multi_logloss: 0.3206\tvalid_1's multi_logloss: 0.374537          \n",
      "[86]\ttraining's multi_logloss: 0.317452\tvalid_1's multi_logloss: 0.371998        \n",
      "[87]\ttraining's multi_logloss: 0.314312\tvalid_1's multi_logloss: 0.369464        \n",
      "[88]\ttraining's multi_logloss: 0.311224\tvalid_1's multi_logloss: 0.366971        \n",
      "[89]\ttraining's multi_logloss: 0.308256\tvalid_1's multi_logloss: 0.364582        \n",
      "[90]\ttraining's multi_logloss: 0.305276\tvalid_1's multi_logloss: 0.362259        \n",
      "[91]\ttraining's multi_logloss: 0.302376\tvalid_1's multi_logloss: 0.359986        \n",
      "[92]\ttraining's multi_logloss: 0.299434\tvalid_1's multi_logloss: 0.357695        \n",
      "[93]\ttraining's multi_logloss: 0.296435\tvalid_1's multi_logloss: 0.355371        \n",
      "[94]\ttraining's multi_logloss: 0.293696\tvalid_1's multi_logloss: 0.353286        \n",
      "[95]\ttraining's multi_logloss: 0.2909\tvalid_1's multi_logloss: 0.351267          \n",
      "[96]\ttraining's multi_logloss: 0.288294\tvalid_1's multi_logloss: 0.349203        \n",
      "[97]\ttraining's multi_logloss: 0.285636\tvalid_1's multi_logloss: 0.347159        \n",
      "[98]\ttraining's multi_logloss: 0.28306\tvalid_1's multi_logloss: 0.345267         \n",
      "[99]\ttraining's multi_logloss: 0.280661\tvalid_1's multi_logloss: 0.343459        \n",
      "[100]\ttraining's multi_logloss: 0.278188\tvalid_1's multi_logloss: 0.34173        \n",
      "[101]\ttraining's multi_logloss: 0.275804\tvalid_1's multi_logloss: 0.340081       \n",
      "[102]\ttraining's multi_logloss: 0.27351\tvalid_1's multi_logloss: 0.338421        \n",
      "[103]\ttraining's multi_logloss: 0.271272\tvalid_1's multi_logloss: 0.336788       \n",
      "[104]\ttraining's multi_logloss: 0.268982\tvalid_1's multi_logloss: 0.335241       \n",
      "[105]\ttraining's multi_logloss: 0.26683\tvalid_1's multi_logloss: 0.333764        \n",
      "[106]\ttraining's multi_logloss: 0.264659\tvalid_1's multi_logloss: 0.332247       \n",
      "[107]\ttraining's multi_logloss: 0.262546\tvalid_1's multi_logloss: 0.330869       \n",
      "[108]\ttraining's multi_logloss: 0.260456\tvalid_1's multi_logloss: 0.329436       \n",
      "[109]\ttraining's multi_logloss: 0.258424\tvalid_1's multi_logloss: 0.328186       \n",
      "[110]\ttraining's multi_logloss: 0.25642\tvalid_1's multi_logloss: 0.326966        \n",
      "[111]\ttraining's multi_logloss: 0.254447\tvalid_1's multi_logloss: 0.325757       \n",
      "[112]\ttraining's multi_logloss: 0.252525\tvalid_1's multi_logloss: 0.32461        \n",
      "[113]\ttraining's multi_logloss: 0.250585\tvalid_1's multi_logloss: 0.323463       \n",
      "[114]\ttraining's multi_logloss: 0.248646\tvalid_1's multi_logloss: 0.322391       \n",
      "[115]\ttraining's multi_logloss: 0.246824\tvalid_1's multi_logloss: 0.321395       \n",
      "[116]\ttraining's multi_logloss: 0.245019\tvalid_1's multi_logloss: 0.320349       \n",
      "[117]\ttraining's multi_logloss: 0.243201\tvalid_1's multi_logloss: 0.319349       \n",
      "[118]\ttraining's multi_logloss: 0.241414\tvalid_1's multi_logloss: 0.318404       \n",
      "[119]\ttraining's multi_logloss: 0.239672\tvalid_1's multi_logloss: 0.317393       \n",
      "[120]\ttraining's multi_logloss: 0.237992\tvalid_1's multi_logloss: 0.316425       \n",
      "[121]\ttraining's multi_logloss: 0.236297\tvalid_1's multi_logloss: 0.315515       \n",
      "[122]\ttraining's multi_logloss: 0.234613\tvalid_1's multi_logloss: 0.314559       \n",
      "[123]\ttraining's multi_logloss: 0.23291\tvalid_1's multi_logloss: 0.31365         \n",
      "[124]\ttraining's multi_logloss: 0.231271\tvalid_1's multi_logloss: 0.312855       \n",
      "[125]\ttraining's multi_logloss: 0.229692\tvalid_1's multi_logloss: 0.312088       \n",
      "[126]\ttraining's multi_logloss: 0.2281\tvalid_1's multi_logloss: 0.311247         \n",
      "[127]\ttraining's multi_logloss: 0.226555\tvalid_1's multi_logloss: 0.310429       \n",
      "[128]\ttraining's multi_logloss: 0.225052\tvalid_1's multi_logloss: 0.309725       \n",
      "[129]\ttraining's multi_logloss: 0.223548\tvalid_1's multi_logloss: 0.308868       \n",
      "[130]\ttraining's multi_logloss: 0.222048\tvalid_1's multi_logloss: 0.308232       \n",
      "[131]\ttraining's multi_logloss: 0.220591\tvalid_1's multi_logloss: 0.307521       \n",
      "[132]\ttraining's multi_logloss: 0.219165\tvalid_1's multi_logloss: 0.3068         \n",
      "[133]\ttraining's multi_logloss: 0.217768\tvalid_1's multi_logloss: 0.306125       \n",
      "[134]\ttraining's multi_logloss: 0.216361\tvalid_1's multi_logloss: 0.305535       \n",
      "[135]\ttraining's multi_logloss: 0.215011\tvalid_1's multi_logloss: 0.30495        \n",
      "[136]\ttraining's multi_logloss: 0.213609\tvalid_1's multi_logloss: 0.30428        \n",
      "[137]\ttraining's multi_logloss: 0.212272\tvalid_1's multi_logloss: 0.303718       \n",
      "[138]\ttraining's multi_logloss: 0.21097\tvalid_1's multi_logloss: 0.303145        \n",
      "[139]\ttraining's multi_logloss: 0.209639\tvalid_1's multi_logloss: 0.302546       \n",
      "[140]\ttraining's multi_logloss: 0.208333\tvalid_1's multi_logloss: 0.302014       \n",
      "[141]\ttraining's multi_logloss: 0.207097\tvalid_1's multi_logloss: 0.301485       \n",
      "[142]\ttraining's multi_logloss: 0.20584\tvalid_1's multi_logloss: 0.30106         \n",
      "[143]\ttraining's multi_logloss: 0.204609\tvalid_1's multi_logloss: 0.300586       \n",
      "[144]\ttraining's multi_logloss: 0.203387\tvalid_1's multi_logloss: 0.300174       \n",
      "[145]\ttraining's multi_logloss: 0.202149\tvalid_1's multi_logloss: 0.299674       \n",
      "[146]\ttraining's multi_logloss: 0.200874\tvalid_1's multi_logloss: 0.299187       \n",
      "[147]\ttraining's multi_logloss: 0.199715\tvalid_1's multi_logloss: 0.298754       \n",
      "[148]\ttraining's multi_logloss: 0.198548\tvalid_1's multi_logloss: 0.29831        \n",
      "[149]\ttraining's multi_logloss: 0.197349\tvalid_1's multi_logloss: 0.297779       \n",
      "[150]\ttraining's multi_logloss: 0.196175\tvalid_1's multi_logloss: 0.297277       \n",
      "[151]\ttraining's multi_logloss: 0.195076\tvalid_1's multi_logloss: 0.296905       \n",
      "[152]\ttraining's multi_logloss: 0.193996\tvalid_1's multi_logloss: 0.296519       \n",
      "[153]\ttraining's multi_logloss: 0.192857\tvalid_1's multi_logloss: 0.296139       \n",
      "[154]\ttraining's multi_logloss: 0.191739\tvalid_1's multi_logloss: 0.295819       \n",
      "[155]\ttraining's multi_logloss: 0.19056\tvalid_1's multi_logloss: 0.29528         \n",
      "[156]\ttraining's multi_logloss: 0.189474\tvalid_1's multi_logloss: 0.294889       \n",
      "[157]\ttraining's multi_logloss: 0.188394\tvalid_1's multi_logloss: 0.294479       \n",
      "[158]\ttraining's multi_logloss: 0.187313\tvalid_1's multi_logloss: 0.294088       \n",
      "[159]\ttraining's multi_logloss: 0.186218\tvalid_1's multi_logloss: 0.293718       \n",
      "[160]\ttraining's multi_logloss: 0.185115\tvalid_1's multi_logloss: 0.293288       \n",
      "[161]\ttraining's multi_logloss: 0.184073\tvalid_1's multi_logloss: 0.292964       \n",
      "[162]\ttraining's multi_logloss: 0.182985\tvalid_1's multi_logloss: 0.292537       \n",
      "[163]\ttraining's multi_logloss: 0.181983\tvalid_1's multi_logloss: 0.292218       \n",
      "[164]\ttraining's multi_logloss: 0.180915\tvalid_1's multi_logloss: 0.291817       \n",
      "[165]\ttraining's multi_logloss: 0.17991\tvalid_1's multi_logloss: 0.291513        \n",
      "[166]\ttraining's multi_logloss: 0.17895\tvalid_1's multi_logloss: 0.291207        \n",
      "[167]\ttraining's multi_logloss: 0.178002\tvalid_1's multi_logloss: 0.290928       \n",
      "[168]\ttraining's multi_logloss: 0.177041\tvalid_1's multi_logloss: 0.290666       \n",
      "[169]\ttraining's multi_logloss: 0.176039\tvalid_1's multi_logloss: 0.29044        \n",
      "[170]\ttraining's multi_logloss: 0.175061\tvalid_1's multi_logloss: 0.290224       \n",
      "[171]\ttraining's multi_logloss: 0.174088\tvalid_1's multi_logloss: 0.289956       \n",
      "[172]\ttraining's multi_logloss: 0.173105\tvalid_1's multi_logloss: 0.289704       \n",
      "[173]\ttraining's multi_logloss: 0.17213\tvalid_1's multi_logloss: 0.289481        \n",
      "[174]\ttraining's multi_logloss: 0.171186\tvalid_1's multi_logloss: 0.289293       \n",
      "[175]\ttraining's multi_logloss: 0.170281\tvalid_1's multi_logloss: 0.289071       \n",
      "[176]\ttraining's multi_logloss: 0.169343\tvalid_1's multi_logloss: 0.288739       \n",
      "[177]\ttraining's multi_logloss: 0.168506\tvalid_1's multi_logloss: 0.288527       \n",
      "[178]\ttraining's multi_logloss: 0.167601\tvalid_1's multi_logloss: 0.288267       \n",
      "[179]\ttraining's multi_logloss: 0.166685\tvalid_1's multi_logloss: 0.288031       \n",
      "[180]\ttraining's multi_logloss: 0.165814\tvalid_1's multi_logloss: 0.287827       \n",
      "[181]\ttraining's multi_logloss: 0.164894\tvalid_1's multi_logloss: 0.287549       \n",
      "[182]\ttraining's multi_logloss: 0.164052\tvalid_1's multi_logloss: 0.287385       \n",
      "[183]\ttraining's multi_logloss: 0.1632\tvalid_1's multi_logloss: 0.287198         \n",
      "[184]\ttraining's multi_logloss: 0.16233\tvalid_1's multi_logloss: 0.287023        \n",
      "[185]\ttraining's multi_logloss: 0.161467\tvalid_1's multi_logloss: 0.28678        \n",
      "[186]\ttraining's multi_logloss: 0.160574\tvalid_1's multi_logloss: 0.286599       \n",
      "[187]\ttraining's multi_logloss: 0.159678\tvalid_1's multi_logloss: 0.286398       \n",
      "[188]\ttraining's multi_logloss: 0.158834\tvalid_1's multi_logloss: 0.286273       \n",
      "[189]\ttraining's multi_logloss: 0.157952\tvalid_1's multi_logloss: 0.286065       \n",
      "[190]\ttraining's multi_logloss: 0.157108\tvalid_1's multi_logloss: 0.285913       \n",
      "[191]\ttraining's multi_logloss: 0.156256\tvalid_1's multi_logloss: 0.285809       \n",
      "[192]\ttraining's multi_logloss: 0.155443\tvalid_1's multi_logloss: 0.285661       \n",
      "[193]\ttraining's multi_logloss: 0.154584\tvalid_1's multi_logloss: 0.28544        \n",
      "[194]\ttraining's multi_logloss: 0.153748\tvalid_1's multi_logloss: 0.285304       \n",
      "[195]\ttraining's multi_logloss: 0.152947\tvalid_1's multi_logloss: 0.285184       \n",
      "[196]\ttraining's multi_logloss: 0.152162\tvalid_1's multi_logloss: 0.28508        \n",
      "[197]\ttraining's multi_logloss: 0.151387\tvalid_1's multi_logloss: 0.284982       \n",
      "[198]\ttraining's multi_logloss: 0.150569\tvalid_1's multi_logloss: 0.28483        \n",
      "[199]\ttraining's multi_logloss: 0.149806\tvalid_1's multi_logloss: 0.28469        \n",
      "[200]\ttraining's multi_logloss: 0.14905\tvalid_1's multi_logloss: 0.284614        \n",
      "[201]\ttraining's multi_logloss: 0.148301\tvalid_1's multi_logloss: 0.284551       \n",
      "[202]\ttraining's multi_logloss: 0.147564\tvalid_1's multi_logloss: 0.284394       \n",
      "[203]\ttraining's multi_logloss: 0.146859\tvalid_1's multi_logloss: 0.284337       \n",
      "[204]\ttraining's multi_logloss: 0.146128\tvalid_1's multi_logloss: 0.284258       \n",
      "[205]\ttraining's multi_logloss: 0.145429\tvalid_1's multi_logloss: 0.28421        \n",
      "[206]\ttraining's multi_logloss: 0.144729\tvalid_1's multi_logloss: 0.284054       \n",
      "[207]\ttraining's multi_logloss: 0.144039\tvalid_1's multi_logloss: 0.284053       \n",
      "[208]\ttraining's multi_logloss: 0.143317\tvalid_1's multi_logloss: 0.283924       \n",
      "[209]\ttraining's multi_logloss: 0.142625\tvalid_1's multi_logloss: 0.283822       \n",
      "[210]\ttraining's multi_logloss: 0.141873\tvalid_1's multi_logloss: 0.283733       \n",
      "[211]\ttraining's multi_logloss: 0.141184\tvalid_1's multi_logloss: 0.28373        \n",
      "[212]\ttraining's multi_logloss: 0.140518\tvalid_1's multi_logloss: 0.283633       \n",
      "[213]\ttraining's multi_logloss: 0.139809\tvalid_1's multi_logloss: 0.283549       \n",
      "[214]\ttraining's multi_logloss: 0.139156\tvalid_1's multi_logloss: 0.283483       \n",
      "[215]\ttraining's multi_logloss: 0.13848\tvalid_1's multi_logloss: 0.283404        \n",
      "[216]\ttraining's multi_logloss: 0.137827\tvalid_1's multi_logloss: 0.283314       \n",
      "[217]\ttraining's multi_logloss: 0.13719\tvalid_1's multi_logloss: 0.283259        \n",
      "[218]\ttraining's multi_logloss: 0.1365\tvalid_1's multi_logloss: 0.283093         \n",
      "[219]\ttraining's multi_logloss: 0.13589\tvalid_1's multi_logloss: 0.283023        \n",
      "[220]\ttraining's multi_logloss: 0.135222\tvalid_1's multi_logloss: 0.282942       \n",
      "[221]\ttraining's multi_logloss: 0.134604\tvalid_1's multi_logloss: 0.282803       \n",
      "[222]\ttraining's multi_logloss: 0.13399\tvalid_1's multi_logloss: 0.282724        \n",
      "[223]\ttraining's multi_logloss: 0.133394\tvalid_1's multi_logloss: 0.282669       \n",
      "[224]\ttraining's multi_logloss: 0.132751\tvalid_1's multi_logloss: 0.282675       \n",
      "[225]\ttraining's multi_logloss: 0.132138\tvalid_1's multi_logloss: 0.282716       \n",
      "[226]\ttraining's multi_logloss: 0.131563\tvalid_1's multi_logloss: 0.282737       \n",
      "[227]\ttraining's multi_logloss: 0.130938\tvalid_1's multi_logloss: 0.282685       \n",
      "[228]\ttraining's multi_logloss: 0.130384\tvalid_1's multi_logloss: 0.282712       \n",
      "[229]\ttraining's multi_logloss: 0.129783\tvalid_1's multi_logloss: 0.282686       \n",
      "[230]\ttraining's multi_logloss: 0.129181\tvalid_1's multi_logloss: 0.282726       \n",
      "[231]\ttraining's multi_logloss: 0.128628\tvalid_1's multi_logloss: 0.282717       \n",
      "[232]\ttraining's multi_logloss: 0.12803\tvalid_1's multi_logloss: 0.282644        \n",
      "[233]\ttraining's multi_logloss: 0.127468\tvalid_1's multi_logloss: 0.282598       \n",
      "[234]\ttraining's multi_logloss: 0.126864\tvalid_1's multi_logloss: 0.282608       \n",
      "[235]\ttraining's multi_logloss: 0.12631\tvalid_1's multi_logloss: 0.282584        \n",
      "[236]\ttraining's multi_logloss: 0.125664\tvalid_1's multi_logloss: 0.282541       \n",
      "[237]\ttraining's multi_logloss: 0.125077\tvalid_1's multi_logloss: 0.282428       \n",
      "[238]\ttraining's multi_logloss: 0.124511\tvalid_1's multi_logloss: 0.282485       \n",
      "[239]\ttraining's multi_logloss: 0.123933\tvalid_1's multi_logloss: 0.282462       \n",
      "[240]\ttraining's multi_logloss: 0.123384\tvalid_1's multi_logloss: 0.282478       \n",
      "[241]\ttraining's multi_logloss: 0.122839\tvalid_1's multi_logloss: 0.282504       \n",
      "[242]\ttraining's multi_logloss: 0.122275\tvalid_1's multi_logloss: 0.28251        \n",
      "[243]\ttraining's multi_logloss: 0.121748\tvalid_1's multi_logloss: 0.282533       \n",
      "[244]\ttraining's multi_logloss: 0.121191\tvalid_1's multi_logloss: 0.282418       \n",
      "[245]\ttraining's multi_logloss: 0.120652\tvalid_1's multi_logloss: 0.282343       \n",
      "[246]\ttraining's multi_logloss: 0.120121\tvalid_1's multi_logloss: 0.282261       \n",
      "[247]\ttraining's multi_logloss: 0.119544\tvalid_1's multi_logloss: 0.282297       \n",
      "[248]\ttraining's multi_logloss: 0.119041\tvalid_1's multi_logloss: 0.282286       \n",
      "[249]\ttraining's multi_logloss: 0.118494\tvalid_1's multi_logloss: 0.282235       \n",
      "[250]\ttraining's multi_logloss: 0.117997\tvalid_1's multi_logloss: 0.282256       \n",
      "[251]\ttraining's multi_logloss: 0.11745\tvalid_1's multi_logloss: 0.282212        \n",
      "[252]\ttraining's multi_logloss: 0.11691\tvalid_1's multi_logloss: 0.282229        \n",
      "[253]\ttraining's multi_logloss: 0.11643\tvalid_1's multi_logloss: 0.282249        \n",
      "[254]\ttraining's multi_logloss: 0.115891\tvalid_1's multi_logloss: 0.282247       \n",
      "[255]\ttraining's multi_logloss: 0.115358\tvalid_1's multi_logloss: 0.282327       \n",
      "[256]\ttraining's multi_logloss: 0.114803\tvalid_1's multi_logloss: 0.282345       \n",
      "[257]\ttraining's multi_logloss: 0.114291\tvalid_1's multi_logloss: 0.282344       \n",
      "[258]\ttraining's multi_logloss: 0.11375\tvalid_1's multi_logloss: 0.282388        \n",
      "[259]\ttraining's multi_logloss: 0.113235\tvalid_1's multi_logloss: 0.282463       \n",
      "[260]\ttraining's multi_logloss: 0.112771\tvalid_1's multi_logloss: 0.282482       \n",
      "[261]\ttraining's multi_logloss: 0.112247\tvalid_1's multi_logloss: 0.282562       \n",
      "[262]\ttraining's multi_logloss: 0.11172\tvalid_1's multi_logloss: 0.282637        \n",
      "[263]\ttraining's multi_logloss: 0.111238\tvalid_1's multi_logloss: 0.282704       \n",
      "[264]\ttraining's multi_logloss: 0.110761\tvalid_1's multi_logloss: 0.282681       \n",
      "[265]\ttraining's multi_logloss: 0.110245\tvalid_1's multi_logloss: 0.282801       \n",
      "[266]\ttraining's multi_logloss: 0.109714\tvalid_1's multi_logloss: 0.282743       \n",
      "[267]\ttraining's multi_logloss: 0.109256\tvalid_1's multi_logloss: 0.282802       \n",
      "[268]\ttraining's multi_logloss: 0.108742\tvalid_1's multi_logloss: 0.282859       \n",
      "[269]\ttraining's multi_logloss: 0.108303\tvalid_1's multi_logloss: 0.282916       \n",
      "[270]\ttraining's multi_logloss: 0.107799\tvalid_1's multi_logloss: 0.282945       \n",
      "[271]\ttraining's multi_logloss: 0.10731\tvalid_1's multi_logloss: 0.283033        \n",
      "[272]\ttraining's multi_logloss: 0.106832\tvalid_1's multi_logloss: 0.28307        \n",
      "[273]\ttraining's multi_logloss: 0.106347\tvalid_1's multi_logloss: 0.283195       \n",
      "[274]\ttraining's multi_logloss: 0.105843\tvalid_1's multi_logloss: 0.283233       \n",
      "[275]\ttraining's multi_logloss: 0.105359\tvalid_1's multi_logloss: 0.283259       \n",
      "[276]\ttraining's multi_logloss: 0.104914\tvalid_1's multi_logloss: 0.28326        \n",
      "[277]\ttraining's multi_logloss: 0.104453\tvalid_1's multi_logloss: 0.2832         \n",
      "[278]\ttraining's multi_logloss: 0.103966\tvalid_1's multi_logloss: 0.283271       \n",
      "[279]\ttraining's multi_logloss: 0.1035\tvalid_1's multi_logloss: 0.283378         \n",
      "[280]\ttraining's multi_logloss: 0.103059\tvalid_1's multi_logloss: 0.283461       \n",
      "[281]\ttraining's multi_logloss: 0.102602\tvalid_1's multi_logloss: 0.283606       \n",
      "Early stopping, best iteration is:                                               \n",
      "[251]\ttraining's multi_logloss: 0.11745\tvalid_1's multi_logloss: 0.282212\n",
      "[1]\ttraining's multi_logloss: 1.83573\tvalid_1's multi_logloss: 1.83837           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.75154\tvalid_1's multi_logloss: 1.75481           \n",
      "[3]\ttraining's multi_logloss: 1.67568\tvalid_1's multi_logloss: 1.67953           \n",
      "[4]\ttraining's multi_logloss: 1.60654\tvalid_1's multi_logloss: 1.61097           \n",
      "[5]\ttraining's multi_logloss: 1.54304\tvalid_1's multi_logloss: 1.5479            \n",
      "[6]\ttraining's multi_logloss: 1.48409\tvalid_1's multi_logloss: 1.48936           \n",
      "[7]\ttraining's multi_logloss: 1.42963\tvalid_1's multi_logloss: 1.43537           \n",
      "[8]\ttraining's multi_logloss: 1.37896\tvalid_1's multi_logloss: 1.38515           \n",
      "[9]\ttraining's multi_logloss: 1.33131\tvalid_1's multi_logloss: 1.33816           \n",
      "[10]\ttraining's multi_logloss: 1.28654\tvalid_1's multi_logloss: 1.29384          \n",
      "[11]\ttraining's multi_logloss: 1.24496\tvalid_1's multi_logloss: 1.2529           \n",
      "[12]\ttraining's multi_logloss: 1.20589\tvalid_1's multi_logloss: 1.2142           \n",
      "[13]\ttraining's multi_logloss: 1.16885\tvalid_1's multi_logloss: 1.17758          \n",
      "[14]\ttraining's multi_logloss: 1.13378\tvalid_1's multi_logloss: 1.14291          \n",
      "[15]\ttraining's multi_logloss: 1.10048\tvalid_1's multi_logloss: 1.11009          \n",
      "[16]\ttraining's multi_logloss: 1.06879\tvalid_1's multi_logloss: 1.07869          \n",
      "[17]\ttraining's multi_logloss: 1.03864\tvalid_1's multi_logloss: 1.04892          \n",
      "[18]\ttraining's multi_logloss: 1.00994\tvalid_1's multi_logloss: 1.02059          \n",
      "[19]\ttraining's multi_logloss: 0.982739\tvalid_1's multi_logloss: 0.993604        \n",
      "[20]\ttraining's multi_logloss: 0.956476\tvalid_1's multi_logloss: 0.967644        \n",
      "[21]\ttraining's multi_logloss: 0.931297\tvalid_1's multi_logloss: 0.942871        \n",
      "[22]\ttraining's multi_logloss: 0.907628\tvalid_1's multi_logloss: 0.919418        \n",
      "[23]\ttraining's multi_logloss: 0.884567\tvalid_1's multi_logloss: 0.896745        \n",
      "[24]\ttraining's multi_logloss: 0.862481\tvalid_1's multi_logloss: 0.874893        \n",
      "[25]\ttraining's multi_logloss: 0.841333\tvalid_1's multi_logloss: 0.854188        \n",
      "[26]\ttraining's multi_logloss: 0.821111\tvalid_1's multi_logloss: 0.834472        \n",
      "[27]\ttraining's multi_logloss: 0.801822\tvalid_1's multi_logloss: 0.815537        \n",
      "[28]\ttraining's multi_logloss: 0.782987\tvalid_1's multi_logloss: 0.797018        \n",
      "[29]\ttraining's multi_logloss: 0.765201\tvalid_1's multi_logloss: 0.779698        \n",
      "[30]\ttraining's multi_logloss: 0.748067\tvalid_1's multi_logloss: 0.76291         \n",
      "[31]\ttraining's multi_logloss: 0.731611\tvalid_1's multi_logloss: 0.746883        \n",
      "[32]\ttraining's multi_logloss: 0.715685\tvalid_1's multi_logloss: 0.731311        \n",
      "[33]\ttraining's multi_logloss: 0.700273\tvalid_1's multi_logloss: 0.716457        \n",
      "[34]\ttraining's multi_logloss: 0.68548\tvalid_1's multi_logloss: 0.702162         \n",
      "[35]\ttraining's multi_logloss: 0.671159\tvalid_1's multi_logloss: 0.688469        \n",
      "[36]\ttraining's multi_logloss: 0.657502\tvalid_1's multi_logloss: 0.675327        \n",
      "[37]\ttraining's multi_logloss: 0.644134\tvalid_1's multi_logloss: 0.662416        \n",
      "[38]\ttraining's multi_logloss: 0.631418\tvalid_1's multi_logloss: 0.650239        \n",
      "[39]\ttraining's multi_logloss: 0.619044\tvalid_1's multi_logloss: 0.638344        \n",
      "[40]\ttraining's multi_logloss: 0.607263\tvalid_1's multi_logloss: 0.627108        \n",
      "[41]\ttraining's multi_logloss: 0.595924\tvalid_1's multi_logloss: 0.61628         \n",
      "[42]\ttraining's multi_logloss: 0.584765\tvalid_1's multi_logloss: 0.605556        \n",
      "[43]\ttraining's multi_logloss: 0.57416\tvalid_1's multi_logloss: 0.595577         \n",
      "[44]\ttraining's multi_logloss: 0.563851\tvalid_1's multi_logloss: 0.585896        \n",
      "[45]\ttraining's multi_logloss: 0.553906\tvalid_1's multi_logloss: 0.576463        \n",
      "[46]\ttraining's multi_logloss: 0.544232\tvalid_1's multi_logloss: 0.567399        \n",
      "[47]\ttraining's multi_logloss: 0.534879\tvalid_1's multi_logloss: 0.558627        \n",
      "[48]\ttraining's multi_logloss: 0.525772\tvalid_1's multi_logloss: 0.549988        \n",
      "[49]\ttraining's multi_logloss: 0.517103\tvalid_1's multi_logloss: 0.541879        \n",
      "[50]\ttraining's multi_logloss: 0.50861\tvalid_1's multi_logloss: 0.533889         \n",
      "[51]\ttraining's multi_logloss: 0.500414\tvalid_1's multi_logloss: 0.52627         \n",
      "[52]\ttraining's multi_logloss: 0.492476\tvalid_1's multi_logloss: 0.518649        \n",
      "[53]\ttraining's multi_logloss: 0.484798\tvalid_1's multi_logloss: 0.511425        \n",
      "[54]\ttraining's multi_logloss: 0.477347\tvalid_1's multi_logloss: 0.504503        \n",
      "[55]\ttraining's multi_logloss: 0.470135\tvalid_1's multi_logloss: 0.497748        \n",
      "[56]\ttraining's multi_logloss: 0.463183\tvalid_1's multi_logloss: 0.491278        \n",
      "[57]\ttraining's multi_logloss: 0.456391\tvalid_1's multi_logloss: 0.484978        \n",
      "[58]\ttraining's multi_logloss: 0.449823\tvalid_1's multi_logloss: 0.478985        \n",
      "[59]\ttraining's multi_logloss: 0.443469\tvalid_1's multi_logloss: 0.473167        \n",
      "[60]\ttraining's multi_logloss: 0.43724\tvalid_1's multi_logloss: 0.467477         \n",
      "[61]\ttraining's multi_logloss: 0.431162\tvalid_1's multi_logloss: 0.46191         \n",
      "[62]\ttraining's multi_logloss: 0.425211\tvalid_1's multi_logloss: 0.456529        \n",
      "[63]\ttraining's multi_logloss: 0.419467\tvalid_1's multi_logloss: 0.451295        \n",
      "[64]\ttraining's multi_logloss: 0.413971\tvalid_1's multi_logloss: 0.44627         \n",
      "[65]\ttraining's multi_logloss: 0.408379\tvalid_1's multi_logloss: 0.441101        \n",
      "[66]\ttraining's multi_logloss: 0.403062\tvalid_1's multi_logloss: 0.436255        \n",
      "[67]\ttraining's multi_logloss: 0.397763\tvalid_1's multi_logloss: 0.431325        \n",
      "[68]\ttraining's multi_logloss: 0.392761\tvalid_1's multi_logloss: 0.426849        \n",
      "[69]\ttraining's multi_logloss: 0.387841\tvalid_1's multi_logloss: 0.422423        \n",
      "[70]\ttraining's multi_logloss: 0.383064\tvalid_1's multi_logloss: 0.418066        \n",
      "[71]\ttraining's multi_logloss: 0.378427\tvalid_1's multi_logloss: 0.41385         \n",
      "[72]\ttraining's multi_logloss: 0.373859\tvalid_1's multi_logloss: 0.409843        \n",
      "[73]\ttraining's multi_logloss: 0.369438\tvalid_1's multi_logloss: 0.40589         \n",
      "[74]\ttraining's multi_logloss: 0.365159\tvalid_1's multi_logloss: 0.402192        \n",
      "[75]\ttraining's multi_logloss: 0.360854\tvalid_1's multi_logloss: 0.398482        \n",
      "[76]\ttraining's multi_logloss: 0.356726\tvalid_1's multi_logloss: 0.394743        \n",
      "[77]\ttraining's multi_logloss: 0.352717\tvalid_1's multi_logloss: 0.391188        \n",
      "[78]\ttraining's multi_logloss: 0.348879\tvalid_1's multi_logloss: 0.387782        \n",
      "[79]\ttraining's multi_logloss: 0.345078\tvalid_1's multi_logloss: 0.38448         \n",
      "[80]\ttraining's multi_logloss: 0.3414\tvalid_1's multi_logloss: 0.381341          \n",
      "[81]\ttraining's multi_logloss: 0.337871\tvalid_1's multi_logloss: 0.378288        \n",
      "[82]\ttraining's multi_logloss: 0.334367\tvalid_1's multi_logloss: 0.375261        \n",
      "[83]\ttraining's multi_logloss: 0.330943\tvalid_1's multi_logloss: 0.372334        \n",
      "[84]\ttraining's multi_logloss: 0.32756\tvalid_1's multi_logloss: 0.369446         \n",
      "[85]\ttraining's multi_logloss: 0.324305\tvalid_1's multi_logloss: 0.366778        \n",
      "[86]\ttraining's multi_logloss: 0.32102\tvalid_1's multi_logloss: 0.364019         \n",
      "[87]\ttraining's multi_logloss: 0.317855\tvalid_1's multi_logloss: 0.361476        \n",
      "[88]\ttraining's multi_logloss: 0.314788\tvalid_1's multi_logloss: 0.35895         \n",
      "[89]\ttraining's multi_logloss: 0.311695\tvalid_1's multi_logloss: 0.35644         \n",
      "[90]\ttraining's multi_logloss: 0.308778\tvalid_1's multi_logloss: 0.354137        \n",
      "[91]\ttraining's multi_logloss: 0.305928\tvalid_1's multi_logloss: 0.35183         \n",
      "[92]\ttraining's multi_logloss: 0.303016\tvalid_1's multi_logloss: 0.349495        \n",
      "[93]\ttraining's multi_logloss: 0.300309\tvalid_1's multi_logloss: 0.347269        \n",
      "[94]\ttraining's multi_logloss: 0.297559\tvalid_1's multi_logloss: 0.345149        \n",
      "[95]\ttraining's multi_logloss: 0.294989\tvalid_1's multi_logloss: 0.343124        \n",
      "[96]\ttraining's multi_logloss: 0.292401\tvalid_1's multi_logloss: 0.341208        \n",
      "[97]\ttraining's multi_logloss: 0.2899\tvalid_1's multi_logloss: 0.339289          \n",
      "[98]\ttraining's multi_logloss: 0.287372\tvalid_1's multi_logloss: 0.337364        \n",
      "[99]\ttraining's multi_logloss: 0.284914\tvalid_1's multi_logloss: 0.335548        \n",
      "[100]\ttraining's multi_logloss: 0.282484\tvalid_1's multi_logloss: 0.333721       \n",
      "[101]\ttraining's multi_logloss: 0.280161\tvalid_1's multi_logloss: 0.331913       \n",
      "[102]\ttraining's multi_logloss: 0.277787\tvalid_1's multi_logloss: 0.330163       \n",
      "[103]\ttraining's multi_logloss: 0.27558\tvalid_1's multi_logloss: 0.328568        \n",
      "[104]\ttraining's multi_logloss: 0.273396\tvalid_1's multi_logloss: 0.327048       \n",
      "[105]\ttraining's multi_logloss: 0.271211\tvalid_1's multi_logloss: 0.325534       \n",
      "[106]\ttraining's multi_logloss: 0.269108\tvalid_1's multi_logloss: 0.324042       \n",
      "[107]\ttraining's multi_logloss: 0.267061\tvalid_1's multi_logloss: 0.322645       \n",
      "[108]\ttraining's multi_logloss: 0.264967\tvalid_1's multi_logloss: 0.321204       \n",
      "[109]\ttraining's multi_logloss: 0.263024\tvalid_1's multi_logloss: 0.319887       \n",
      "[110]\ttraining's multi_logloss: 0.261035\tvalid_1's multi_logloss: 0.318489       \n",
      "[111]\ttraining's multi_logloss: 0.259135\tvalid_1's multi_logloss: 0.317173       \n",
      "[112]\ttraining's multi_logloss: 0.257258\tvalid_1's multi_logloss: 0.31589        \n",
      "[113]\ttraining's multi_logloss: 0.255397\tvalid_1's multi_logloss: 0.314648       \n",
      "[114]\ttraining's multi_logloss: 0.253626\tvalid_1's multi_logloss: 0.313512       \n",
      "[115]\ttraining's multi_logloss: 0.251775\tvalid_1's multi_logloss: 0.312381       \n",
      "[116]\ttraining's multi_logloss: 0.250061\tvalid_1's multi_logloss: 0.311311       \n",
      "[117]\ttraining's multi_logloss: 0.248383\tvalid_1's multi_logloss: 0.310233       \n",
      "[118]\ttraining's multi_logloss: 0.246713\tvalid_1's multi_logloss: 0.309151       \n",
      "[119]\ttraining's multi_logloss: 0.245009\tvalid_1's multi_logloss: 0.308151       \n",
      "[120]\ttraining's multi_logloss: 0.243316\tvalid_1's multi_logloss: 0.307172       \n",
      "[121]\ttraining's multi_logloss: 0.241689\tvalid_1's multi_logloss: 0.306164       \n",
      "[122]\ttraining's multi_logloss: 0.240033\tvalid_1's multi_logloss: 0.305137       \n",
      "[123]\ttraining's multi_logloss: 0.238421\tvalid_1's multi_logloss: 0.304285       \n",
      "[124]\ttraining's multi_logloss: 0.236875\tvalid_1's multi_logloss: 0.303353       \n",
      "[125]\ttraining's multi_logloss: 0.235311\tvalid_1's multi_logloss: 0.30238        \n",
      "[126]\ttraining's multi_logloss: 0.233772\tvalid_1's multi_logloss: 0.3015         \n",
      "[127]\ttraining's multi_logloss: 0.232289\tvalid_1's multi_logloss: 0.300686       \n",
      "[128]\ttraining's multi_logloss: 0.230808\tvalid_1's multi_logloss: 0.299836       \n",
      "[129]\ttraining's multi_logloss: 0.229303\tvalid_1's multi_logloss: 0.298952       \n",
      "[130]\ttraining's multi_logloss: 0.227892\tvalid_1's multi_logloss: 0.298222       \n",
      "[131]\ttraining's multi_logloss: 0.226463\tvalid_1's multi_logloss: 0.297482       \n",
      "[132]\ttraining's multi_logloss: 0.225054\tvalid_1's multi_logloss: 0.296728       \n",
      "[133]\ttraining's multi_logloss: 0.223665\tvalid_1's multi_logloss: 0.296024       \n",
      "[134]\ttraining's multi_logloss: 0.222361\tvalid_1's multi_logloss: 0.295489       \n",
      "[135]\ttraining's multi_logloss: 0.220965\tvalid_1's multi_logloss: 0.294804       \n",
      "[136]\ttraining's multi_logloss: 0.219598\tvalid_1's multi_logloss: 0.294155       \n",
      "[137]\ttraining's multi_logloss: 0.218264\tvalid_1's multi_logloss: 0.293443       \n",
      "[138]\ttraining's multi_logloss: 0.216896\tvalid_1's multi_logloss: 0.292755       \n",
      "[139]\ttraining's multi_logloss: 0.215602\tvalid_1's multi_logloss: 0.292144       \n",
      "[140]\ttraining's multi_logloss: 0.214342\tvalid_1's multi_logloss: 0.291479       \n",
      "[141]\ttraining's multi_logloss: 0.213052\tvalid_1's multi_logloss: 0.290848       \n",
      "[142]\ttraining's multi_logloss: 0.211849\tvalid_1's multi_logloss: 0.290312       \n",
      "[143]\ttraining's multi_logloss: 0.210624\tvalid_1's multi_logloss: 0.289732       \n",
      "[144]\ttraining's multi_logloss: 0.20942\tvalid_1's multi_logloss: 0.28909         \n",
      "[145]\ttraining's multi_logloss: 0.208264\tvalid_1's multi_logloss: 0.28859        \n",
      "[146]\ttraining's multi_logloss: 0.207094\tvalid_1's multi_logloss: 0.288143       \n",
      "[147]\ttraining's multi_logloss: 0.205949\tvalid_1's multi_logloss: 0.287712       \n",
      "[148]\ttraining's multi_logloss: 0.204774\tvalid_1's multi_logloss: 0.287221       \n",
      "[149]\ttraining's multi_logloss: 0.20364\tvalid_1's multi_logloss: 0.286863        \n",
      "[150]\ttraining's multi_logloss: 0.202472\tvalid_1's multi_logloss: 0.286324       \n",
      "[151]\ttraining's multi_logloss: 0.201334\tvalid_1's multi_logloss: 0.285872       \n",
      "[152]\ttraining's multi_logloss: 0.200236\tvalid_1's multi_logloss: 0.285414       \n",
      "[153]\ttraining's multi_logloss: 0.199066\tvalid_1's multi_logloss: 0.284944       \n",
      "[154]\ttraining's multi_logloss: 0.197967\tvalid_1's multi_logloss: 0.284518       \n",
      "[155]\ttraining's multi_logloss: 0.19692\tvalid_1's multi_logloss: 0.284139        \n",
      "[156]\ttraining's multi_logloss: 0.195866\tvalid_1's multi_logloss: 0.283792       \n",
      "[157]\ttraining's multi_logloss: 0.194743\tvalid_1's multi_logloss: 0.283414       \n",
      "[158]\ttraining's multi_logloss: 0.193636\tvalid_1's multi_logloss: 0.283003       \n",
      "[159]\ttraining's multi_logloss: 0.192534\tvalid_1's multi_logloss: 0.28263        \n",
      "[160]\ttraining's multi_logloss: 0.191474\tvalid_1's multi_logloss: 0.282261       \n",
      "[161]\ttraining's multi_logloss: 0.190397\tvalid_1's multi_logloss: 0.281917       \n",
      "[162]\ttraining's multi_logloss: 0.189373\tvalid_1's multi_logloss: 0.281553       \n",
      "[163]\ttraining's multi_logloss: 0.188343\tvalid_1's multi_logloss: 0.281203       \n",
      "[164]\ttraining's multi_logloss: 0.18728\tvalid_1's multi_logloss: 0.280846        \n",
      "[165]\ttraining's multi_logloss: 0.186281\tvalid_1's multi_logloss: 0.280465       \n",
      "[166]\ttraining's multi_logloss: 0.185266\tvalid_1's multi_logloss: 0.280235       \n",
      "[167]\ttraining's multi_logloss: 0.184327\tvalid_1's multi_logloss: 0.279885       \n",
      "[168]\ttraining's multi_logloss: 0.183334\tvalid_1's multi_logloss: 0.279602       \n",
      "[169]\ttraining's multi_logloss: 0.182367\tvalid_1's multi_logloss: 0.279395       \n",
      "[170]\ttraining's multi_logloss: 0.18146\tvalid_1's multi_logloss: 0.27919         \n",
      "[171]\ttraining's multi_logloss: 0.180538\tvalid_1's multi_logloss: 0.278943       \n",
      "[172]\ttraining's multi_logloss: 0.179565\tvalid_1's multi_logloss: 0.278744       \n",
      "[173]\ttraining's multi_logloss: 0.17861\tvalid_1's multi_logloss: 0.278482        \n",
      "[174]\ttraining's multi_logloss: 0.177702\tvalid_1's multi_logloss: 0.27829        \n",
      "[175]\ttraining's multi_logloss: 0.176781\tvalid_1's multi_logloss: 0.278065       \n",
      "[176]\ttraining's multi_logloss: 0.175868\tvalid_1's multi_logloss: 0.277933       \n",
      "[177]\ttraining's multi_logloss: 0.174961\tvalid_1's multi_logloss: 0.277744       \n",
      "[178]\ttraining's multi_logloss: 0.174075\tvalid_1's multi_logloss: 0.277541       \n",
      "[179]\ttraining's multi_logloss: 0.17325\tvalid_1's multi_logloss: 0.277366        \n",
      "[180]\ttraining's multi_logloss: 0.172374\tvalid_1's multi_logloss: 0.27716        \n",
      "[181]\ttraining's multi_logloss: 0.171545\tvalid_1's multi_logloss: 0.276937       \n",
      "[182]\ttraining's multi_logloss: 0.170706\tvalid_1's multi_logloss: 0.276691       \n",
      "[183]\ttraining's multi_logloss: 0.169829\tvalid_1's multi_logloss: 0.276537       \n",
      "[184]\ttraining's multi_logloss: 0.16898\tvalid_1's multi_logloss: 0.276378        \n",
      "[185]\ttraining's multi_logloss: 0.16812\tvalid_1's multi_logloss: 0.276112        \n",
      "[186]\ttraining's multi_logloss: 0.167243\tvalid_1's multi_logloss: 0.275886       \n",
      "[187]\ttraining's multi_logloss: 0.166408\tvalid_1's multi_logloss: 0.275726       \n",
      "[188]\ttraining's multi_logloss: 0.165545\tvalid_1's multi_logloss: 0.275526       \n",
      "[189]\ttraining's multi_logloss: 0.164717\tvalid_1's multi_logloss: 0.275341       \n",
      "[190]\ttraining's multi_logloss: 0.163872\tvalid_1's multi_logloss: 0.275142       \n",
      "[191]\ttraining's multi_logloss: 0.163102\tvalid_1's multi_logloss: 0.275071       \n",
      "[192]\ttraining's multi_logloss: 0.162296\tvalid_1's multi_logloss: 0.274921       \n",
      "[193]\ttraining's multi_logloss: 0.161492\tvalid_1's multi_logloss: 0.274838       \n",
      "[194]\ttraining's multi_logloss: 0.160724\tvalid_1's multi_logloss: 0.274756       \n",
      "[195]\ttraining's multi_logloss: 0.159949\tvalid_1's multi_logloss: 0.274639       \n",
      "[196]\ttraining's multi_logloss: 0.159177\tvalid_1's multi_logloss: 0.274541       \n",
      "[197]\ttraining's multi_logloss: 0.158416\tvalid_1's multi_logloss: 0.274439       \n",
      "[198]\ttraining's multi_logloss: 0.157637\tvalid_1's multi_logloss: 0.274257       \n",
      "[199]\ttraining's multi_logloss: 0.156881\tvalid_1's multi_logloss: 0.274083       \n",
      "[200]\ttraining's multi_logloss: 0.156179\tvalid_1's multi_logloss: 0.273879       \n",
      "[201]\ttraining's multi_logloss: 0.155426\tvalid_1's multi_logloss: 0.273759       \n",
      "[202]\ttraining's multi_logloss: 0.15469\tvalid_1's multi_logloss: 0.273619        \n",
      "[203]\ttraining's multi_logloss: 0.153913\tvalid_1's multi_logloss: 0.273557       \n",
      "[204]\ttraining's multi_logloss: 0.153188\tvalid_1's multi_logloss: 0.273446       \n",
      "[205]\ttraining's multi_logloss: 0.152487\tvalid_1's multi_logloss: 0.273347       \n",
      "[206]\ttraining's multi_logloss: 0.151743\tvalid_1's multi_logloss: 0.273173       \n",
      "[207]\ttraining's multi_logloss: 0.151066\tvalid_1's multi_logloss: 0.273089       \n",
      "[208]\ttraining's multi_logloss: 0.150323\tvalid_1's multi_logloss: 0.273015       \n",
      "[209]\ttraining's multi_logloss: 0.149582\tvalid_1's multi_logloss: 0.27285        \n",
      "[210]\ttraining's multi_logloss: 0.1489\tvalid_1's multi_logloss: 0.272823         \n",
      "[211]\ttraining's multi_logloss: 0.148161\tvalid_1's multi_logloss: 0.272774       \n",
      "[212]\ttraining's multi_logloss: 0.147406\tvalid_1's multi_logloss: 0.27269        \n",
      "[213]\ttraining's multi_logloss: 0.146717\tvalid_1's multi_logloss: 0.272577       \n",
      "[214]\ttraining's multi_logloss: 0.146033\tvalid_1's multi_logloss: 0.272472       \n",
      "[215]\ttraining's multi_logloss: 0.145388\tvalid_1's multi_logloss: 0.272325       \n",
      "[216]\ttraining's multi_logloss: 0.144701\tvalid_1's multi_logloss: 0.272266       \n",
      "[217]\ttraining's multi_logloss: 0.143999\tvalid_1's multi_logloss: 0.272122       \n",
      "[218]\ttraining's multi_logloss: 0.143283\tvalid_1's multi_logloss: 0.272024       \n",
      "[219]\ttraining's multi_logloss: 0.1426\tvalid_1's multi_logloss: 0.271907         \n",
      "[220]\ttraining's multi_logloss: 0.14186\tvalid_1's multi_logloss: 0.271745        \n",
      "[221]\ttraining's multi_logloss: 0.141208\tvalid_1's multi_logloss: 0.271625       \n",
      "[222]\ttraining's multi_logloss: 0.140548\tvalid_1's multi_logloss: 0.271532       \n",
      "[223]\ttraining's multi_logloss: 0.139886\tvalid_1's multi_logloss: 0.271438       \n",
      "[224]\ttraining's multi_logloss: 0.139226\tvalid_1's multi_logloss: 0.271383       \n",
      "[225]\ttraining's multi_logloss: 0.138532\tvalid_1's multi_logloss: 0.271287       \n",
      "[226]\ttraining's multi_logloss: 0.137898\tvalid_1's multi_logloss: 0.271095       \n",
      "[227]\ttraining's multi_logloss: 0.137252\tvalid_1's multi_logloss: 0.271053       \n",
      "[228]\ttraining's multi_logloss: 0.136625\tvalid_1's multi_logloss: 0.270943       \n",
      "[229]\ttraining's multi_logloss: 0.136021\tvalid_1's multi_logloss: 0.270822       \n",
      "[230]\ttraining's multi_logloss: 0.135366\tvalid_1's multi_logloss: 0.270751       \n",
      "[231]\ttraining's multi_logloss: 0.13473\tvalid_1's multi_logloss: 0.270717        \n",
      "[232]\ttraining's multi_logloss: 0.134125\tvalid_1's multi_logloss: 0.270611       \n",
      "[233]\ttraining's multi_logloss: 0.13349\tvalid_1's multi_logloss: 0.270479        \n",
      "[234]\ttraining's multi_logloss: 0.132859\tvalid_1's multi_logloss: 0.270389       \n",
      "[235]\ttraining's multi_logloss: 0.132249\tvalid_1's multi_logloss: 0.270331       \n",
      "[236]\ttraining's multi_logloss: 0.131609\tvalid_1's multi_logloss: 0.270173       \n",
      "[237]\ttraining's multi_logloss: 0.13104\tvalid_1's multi_logloss: 0.270138        \n",
      "[238]\ttraining's multi_logloss: 0.130436\tvalid_1's multi_logloss: 0.270139       \n",
      "[239]\ttraining's multi_logloss: 0.129839\tvalid_1's multi_logloss: 0.270122       \n",
      "[240]\ttraining's multi_logloss: 0.129282\tvalid_1's multi_logloss: 0.270088       \n",
      "[241]\ttraining's multi_logloss: 0.128684\tvalid_1's multi_logloss: 0.270011       \n",
      "[242]\ttraining's multi_logloss: 0.128114\tvalid_1's multi_logloss: 0.269933       \n",
      "[243]\ttraining's multi_logloss: 0.127567\tvalid_1's multi_logloss: 0.269903       \n",
      "[244]\ttraining's multi_logloss: 0.12703\tvalid_1's multi_logloss: 0.269904        \n",
      "[245]\ttraining's multi_logloss: 0.126491\tvalid_1's multi_logloss: 0.269888       \n",
      "[246]\ttraining's multi_logloss: 0.125935\tvalid_1's multi_logloss: 0.269936       \n",
      "[247]\ttraining's multi_logloss: 0.125397\tvalid_1's multi_logloss: 0.269903       \n",
      "[248]\ttraining's multi_logloss: 0.124881\tvalid_1's multi_logloss: 0.269834       \n",
      "[249]\ttraining's multi_logloss: 0.124359\tvalid_1's multi_logloss: 0.269779       \n",
      "[250]\ttraining's multi_logloss: 0.123846\tvalid_1's multi_logloss: 0.269744       \n",
      "[251]\ttraining's multi_logloss: 0.123279\tvalid_1's multi_logloss: 0.269757       \n",
      "[252]\ttraining's multi_logloss: 0.122734\tvalid_1's multi_logloss: 0.269732       \n",
      "[253]\ttraining's multi_logloss: 0.122197\tvalid_1's multi_logloss: 0.269718       \n",
      "[254]\ttraining's multi_logloss: 0.121712\tvalid_1's multi_logloss: 0.269678       \n",
      "[255]\ttraining's multi_logloss: 0.12117\tvalid_1's multi_logloss: 0.269664        \n",
      "[256]\ttraining's multi_logloss: 0.120635\tvalid_1's multi_logloss: 0.269728       \n",
      "[257]\ttraining's multi_logloss: 0.120113\tvalid_1's multi_logloss: 0.269804       \n",
      "[258]\ttraining's multi_logloss: 0.119584\tvalid_1's multi_logloss: 0.269809       \n",
      "[259]\ttraining's multi_logloss: 0.119064\tvalid_1's multi_logloss: 0.269818       \n",
      "[260]\ttraining's multi_logloss: 0.11856\tvalid_1's multi_logloss: 0.269843        \n",
      "[261]\ttraining's multi_logloss: 0.118079\tvalid_1's multi_logloss: 0.269847       \n",
      "[262]\ttraining's multi_logloss: 0.117539\tvalid_1's multi_logloss: 0.269806       \n",
      "[263]\ttraining's multi_logloss: 0.117024\tvalid_1's multi_logloss: 0.269904       \n",
      "[264]\ttraining's multi_logloss: 0.116475\tvalid_1's multi_logloss: 0.269953       \n",
      "[265]\ttraining's multi_logloss: 0.115967\tvalid_1's multi_logloss: 0.270035       \n",
      "[266]\ttraining's multi_logloss: 0.115483\tvalid_1's multi_logloss: 0.270021       \n",
      "[267]\ttraining's multi_logloss: 0.114987\tvalid_1's multi_logloss: 0.270106       \n",
      "[268]\ttraining's multi_logloss: 0.114448\tvalid_1's multi_logloss: 0.270132       \n",
      "[269]\ttraining's multi_logloss: 0.113982\tvalid_1's multi_logloss: 0.270198       \n",
      "[270]\ttraining's multi_logloss: 0.113501\tvalid_1's multi_logloss: 0.270266       \n",
      "[271]\ttraining's multi_logloss: 0.11304\tvalid_1's multi_logloss: 0.270322        \n",
      "[272]\ttraining's multi_logloss: 0.112559\tvalid_1's multi_logloss: 0.27038        \n",
      "[273]\ttraining's multi_logloss: 0.112116\tvalid_1's multi_logloss: 0.270425       \n",
      "[274]\ttraining's multi_logloss: 0.111654\tvalid_1's multi_logloss: 0.270474       \n",
      "[275]\ttraining's multi_logloss: 0.111164\tvalid_1's multi_logloss: 0.27042        \n",
      "[276]\ttraining's multi_logloss: 0.110716\tvalid_1's multi_logloss: 0.270449       \n",
      "[277]\ttraining's multi_logloss: 0.110243\tvalid_1's multi_logloss: 0.270446       \n",
      "[278]\ttraining's multi_logloss: 0.109765\tvalid_1's multi_logloss: 0.270582       \n",
      "[279]\ttraining's multi_logloss: 0.109332\tvalid_1's multi_logloss: 0.270593       \n",
      "[280]\ttraining's multi_logloss: 0.108899\tvalid_1's multi_logloss: 0.270599       \n",
      "[281]\ttraining's multi_logloss: 0.108439\tvalid_1's multi_logloss: 0.270649       \n",
      "[282]\ttraining's multi_logloss: 0.107976\tvalid_1's multi_logloss: 0.270652       \n",
      "[283]\ttraining's multi_logloss: 0.107543\tvalid_1's multi_logloss: 0.270637       \n",
      "[284]\ttraining's multi_logloss: 0.107068\tvalid_1's multi_logloss: 0.270792       \n",
      "[285]\ttraining's multi_logloss: 0.106632\tvalid_1's multi_logloss: 0.270904       \n",
      "Early stopping, best iteration is:                                               \n",
      "[255]\ttraining's multi_logloss: 0.12117\tvalid_1's multi_logloss: 0.269664\n",
      "[1]\ttraining's multi_logloss: 1.79145\tvalid_1's multi_logloss: 1.79209           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.6721\tvalid_1's multi_logloss: 1.67572            \n",
      "[3]\ttraining's multi_logloss: 1.56845\tvalid_1's multi_logloss: 1.57459           \n",
      "[4]\ttraining's multi_logloss: 1.47753\tvalid_1's multi_logloss: 1.48622           \n",
      "[5]\ttraining's multi_logloss: 1.39636\tvalid_1's multi_logloss: 1.4075            \n",
      "[6]\ttraining's multi_logloss: 1.32328\tvalid_1's multi_logloss: 1.33608           \n",
      "[7]\ttraining's multi_logloss: 1.25751\tvalid_1's multi_logloss: 1.27216           \n",
      "[8]\ttraining's multi_logloss: 1.19722\tvalid_1's multi_logloss: 1.21367           \n",
      "[9]\ttraining's multi_logloss: 1.14226\tvalid_1's multi_logloss: 1.16028           \n",
      "[10]\ttraining's multi_logloss: 1.0915\tvalid_1's multi_logloss: 1.11138           \n",
      "[11]\ttraining's multi_logloss: 1.04469\tvalid_1's multi_logloss: 1.06605          \n",
      "[12]\ttraining's multi_logloss: 1.0013\tvalid_1's multi_logloss: 1.02431           \n",
      "[13]\ttraining's multi_logloss: 0.960826\tvalid_1's multi_logloss: 0.985376        \n",
      "[14]\ttraining's multi_logloss: 0.923038\tvalid_1's multi_logloss: 0.949017        \n",
      "[15]\ttraining's multi_logloss: 0.88772\tvalid_1's multi_logloss: 0.914984         \n",
      "[16]\ttraining's multi_logloss: 0.854425\tvalid_1's multi_logloss: 0.882948        \n",
      "[17]\ttraining's multi_logloss: 0.823256\tvalid_1's multi_logloss: 0.852798        \n",
      "[18]\ttraining's multi_logloss: 0.793857\tvalid_1's multi_logloss: 0.824466        \n",
      "[19]\ttraining's multi_logloss: 0.766137\tvalid_1's multi_logloss: 0.797758        \n",
      "[20]\ttraining's multi_logloss: 0.740299\tvalid_1's multi_logloss: 0.772905        \n",
      "[21]\ttraining's multi_logloss: 0.715623\tvalid_1's multi_logloss: 0.749176        \n",
      "[22]\ttraining's multi_logloss: 0.692541\tvalid_1's multi_logloss: 0.727047        \n",
      "[23]\ttraining's multi_logloss: 0.67055\tvalid_1's multi_logloss: 0.706026         \n",
      "[24]\ttraining's multi_logloss: 0.649663\tvalid_1's multi_logloss: 0.686128        \n",
      "[25]\ttraining's multi_logloss: 0.629974\tvalid_1's multi_logloss: 0.667402        \n",
      "[26]\ttraining's multi_logloss: 0.611382\tvalid_1's multi_logloss: 0.649857        \n",
      "[27]\ttraining's multi_logloss: 0.593318\tvalid_1's multi_logloss: 0.632825        \n",
      "[28]\ttraining's multi_logloss: 0.576197\tvalid_1's multi_logloss: 0.616551        \n",
      "[29]\ttraining's multi_logloss: 0.560277\tvalid_1's multi_logloss: 0.601433        \n",
      "[30]\ttraining's multi_logloss: 0.545286\tvalid_1's multi_logloss: 0.5874          \n",
      "[31]\ttraining's multi_logloss: 0.530714\tvalid_1's multi_logloss: 0.573728        \n",
      "[32]\ttraining's multi_logloss: 0.517083\tvalid_1's multi_logloss: 0.560979        \n",
      "[33]\ttraining's multi_logloss: 0.503985\tvalid_1's multi_logloss: 0.548884        \n",
      "[34]\ttraining's multi_logloss: 0.49154\tvalid_1's multi_logloss: 0.537257         \n",
      "[35]\ttraining's multi_logloss: 0.479675\tvalid_1's multi_logloss: 0.5262          \n",
      "[36]\ttraining's multi_logloss: 0.468332\tvalid_1's multi_logloss: 0.515726        \n",
      "[37]\ttraining's multi_logloss: 0.45749\tvalid_1's multi_logloss: 0.505765         \n",
      "[38]\ttraining's multi_logloss: 0.447094\tvalid_1's multi_logloss: 0.496165        \n",
      "[39]\ttraining's multi_logloss: 0.437274\tvalid_1's multi_logloss: 0.487121        \n",
      "[40]\ttraining's multi_logloss: 0.427824\tvalid_1's multi_logloss: 0.478513        \n",
      "[41]\ttraining's multi_logloss: 0.41871\tvalid_1's multi_logloss: 0.470281         \n",
      "[42]\ttraining's multi_logloss: 0.410017\tvalid_1's multi_logloss: 0.462471        \n",
      "[43]\ttraining's multi_logloss: 0.401578\tvalid_1's multi_logloss: 0.454747        \n",
      "[44]\ttraining's multi_logloss: 0.393651\tvalid_1's multi_logloss: 0.447504        \n",
      "[45]\ttraining's multi_logloss: 0.385986\tvalid_1's multi_logloss: 0.440533        \n",
      "[46]\ttraining's multi_logloss: 0.378715\tvalid_1's multi_logloss: 0.43407         \n",
      "[47]\ttraining's multi_logloss: 0.371804\tvalid_1's multi_logloss: 0.427874        \n",
      "[48]\ttraining's multi_logloss: 0.365244\tvalid_1's multi_logloss: 0.422146        \n",
      "[49]\ttraining's multi_logloss: 0.358885\tvalid_1's multi_logloss: 0.416664        \n",
      "[50]\ttraining's multi_logloss: 0.352847\tvalid_1's multi_logloss: 0.411598        \n",
      "[51]\ttraining's multi_logloss: 0.346941\tvalid_1's multi_logloss: 0.40657         \n",
      "[52]\ttraining's multi_logloss: 0.341201\tvalid_1's multi_logloss: 0.401884        \n",
      "[53]\ttraining's multi_logloss: 0.335659\tvalid_1's multi_logloss: 0.397148        \n",
      "[54]\ttraining's multi_logloss: 0.33031\tvalid_1's multi_logloss: 0.392712         \n",
      "[55]\ttraining's multi_logloss: 0.325228\tvalid_1's multi_logloss: 0.388517        \n",
      "[56]\ttraining's multi_logloss: 0.320199\tvalid_1's multi_logloss: 0.384332        \n",
      "[57]\ttraining's multi_logloss: 0.31552\tvalid_1's multi_logloss: 0.380516         \n",
      "[58]\ttraining's multi_logloss: 0.310945\tvalid_1's multi_logloss: 0.376723        \n",
      "[59]\ttraining's multi_logloss: 0.306514\tvalid_1's multi_logloss: 0.373221        \n",
      "[60]\ttraining's multi_logloss: 0.302269\tvalid_1's multi_logloss: 0.369756        \n",
      "[61]\ttraining's multi_logloss: 0.298186\tvalid_1's multi_logloss: 0.366545        \n",
      "[62]\ttraining's multi_logloss: 0.294235\tvalid_1's multi_logloss: 0.363451        \n",
      "[63]\ttraining's multi_logloss: 0.290345\tvalid_1's multi_logloss: 0.360466        \n",
      "[64]\ttraining's multi_logloss: 0.286651\tvalid_1's multi_logloss: 0.357811        \n",
      "[65]\ttraining's multi_logloss: 0.283081\tvalid_1's multi_logloss: 0.355183        \n",
      "[66]\ttraining's multi_logloss: 0.279509\tvalid_1's multi_logloss: 0.352559        \n",
      "[67]\ttraining's multi_logloss: 0.276215\tvalid_1's multi_logloss: 0.350257        \n",
      "[68]\ttraining's multi_logloss: 0.272791\tvalid_1's multi_logloss: 0.347682        \n",
      "[69]\ttraining's multi_logloss: 0.269601\tvalid_1's multi_logloss: 0.345288        \n",
      "[70]\ttraining's multi_logloss: 0.266372\tvalid_1's multi_logloss: 0.343074        \n",
      "[71]\ttraining's multi_logloss: 0.263282\tvalid_1's multi_logloss: 0.340903        \n",
      "[72]\ttraining's multi_logloss: 0.2603\tvalid_1's multi_logloss: 0.338798          \n",
      "[73]\ttraining's multi_logloss: 0.257449\tvalid_1's multi_logloss: 0.336796        \n",
      "[74]\ttraining's multi_logloss: 0.25454\tvalid_1's multi_logloss: 0.33486          \n",
      "[75]\ttraining's multi_logloss: 0.251798\tvalid_1's multi_logloss: 0.333149        \n",
      "[76]\ttraining's multi_logloss: 0.249074\tvalid_1's multi_logloss: 0.331358        \n",
      "[77]\ttraining's multi_logloss: 0.246555\tvalid_1's multi_logloss: 0.329739        \n",
      "[78]\ttraining's multi_logloss: 0.244041\tvalid_1's multi_logloss: 0.328267        \n",
      "[79]\ttraining's multi_logloss: 0.241542\tvalid_1's multi_logloss: 0.326747        \n",
      "[80]\ttraining's multi_logloss: 0.239133\tvalid_1's multi_logloss: 0.325376        \n",
      "[81]\ttraining's multi_logloss: 0.236724\tvalid_1's multi_logloss: 0.323923        \n",
      "[82]\ttraining's multi_logloss: 0.234431\tvalid_1's multi_logloss: 0.322615        \n",
      "[83]\ttraining's multi_logloss: 0.232046\tvalid_1's multi_logloss: 0.321252        \n",
      "[84]\ttraining's multi_logloss: 0.229774\tvalid_1's multi_logloss: 0.319703        \n",
      "[85]\ttraining's multi_logloss: 0.227552\tvalid_1's multi_logloss: 0.318444        \n",
      "[86]\ttraining's multi_logloss: 0.225436\tvalid_1's multi_logloss: 0.317308        \n",
      "[87]\ttraining's multi_logloss: 0.223313\tvalid_1's multi_logloss: 0.316166        \n",
      "[88]\ttraining's multi_logloss: 0.221279\tvalid_1's multi_logloss: 0.314991        \n",
      "[89]\ttraining's multi_logloss: 0.219274\tvalid_1's multi_logloss: 0.314038        \n",
      "[90]\ttraining's multi_logloss: 0.21729\tvalid_1's multi_logloss: 0.313071         \n",
      "[91]\ttraining's multi_logloss: 0.215394\tvalid_1's multi_logloss: 0.31213         \n",
      "[92]\ttraining's multi_logloss: 0.213519\tvalid_1's multi_logloss: 0.311207        \n",
      "[93]\ttraining's multi_logloss: 0.211721\tvalid_1's multi_logloss: 0.31028         \n",
      "[94]\ttraining's multi_logloss: 0.209875\tvalid_1's multi_logloss: 0.309566        \n",
      "[95]\ttraining's multi_logloss: 0.208099\tvalid_1's multi_logloss: 0.308824        \n",
      "[96]\ttraining's multi_logloss: 0.206314\tvalid_1's multi_logloss: 0.308026        \n",
      "[97]\ttraining's multi_logloss: 0.204559\tvalid_1's multi_logloss: 0.3073          \n",
      "[98]\ttraining's multi_logloss: 0.202885\tvalid_1's multi_logloss: 0.306505        \n",
      "[99]\ttraining's multi_logloss: 0.201218\tvalid_1's multi_logloss: 0.305778        \n",
      "[100]\ttraining's multi_logloss: 0.199585\tvalid_1's multi_logloss: 0.305091       \n",
      "[101]\ttraining's multi_logloss: 0.197938\tvalid_1's multi_logloss: 0.304374       \n",
      "[102]\ttraining's multi_logloss: 0.196334\tvalid_1's multi_logloss: 0.303746       \n",
      "[103]\ttraining's multi_logloss: 0.19479\tvalid_1's multi_logloss: 0.303222        \n",
      "[104]\ttraining's multi_logloss: 0.193284\tvalid_1's multi_logloss: 0.302655       \n",
      "[105]\ttraining's multi_logloss: 0.191795\tvalid_1's multi_logloss: 0.30221        \n",
      "[106]\ttraining's multi_logloss: 0.190352\tvalid_1's multi_logloss: 0.301755       \n",
      "[107]\ttraining's multi_logloss: 0.1888\tvalid_1's multi_logloss: 0.301345         \n",
      "[108]\ttraining's multi_logloss: 0.187293\tvalid_1's multi_logloss: 0.300822       \n",
      "[109]\ttraining's multi_logloss: 0.185842\tvalid_1's multi_logloss: 0.300318       \n",
      "[110]\ttraining's multi_logloss: 0.184325\tvalid_1's multi_logloss: 0.299884       \n",
      "[111]\ttraining's multi_logloss: 0.182904\tvalid_1's multi_logloss: 0.299291       \n",
      "[112]\ttraining's multi_logloss: 0.181565\tvalid_1's multi_logloss: 0.298928       \n",
      "[113]\ttraining's multi_logloss: 0.180235\tvalid_1's multi_logloss: 0.298476       \n",
      "[114]\ttraining's multi_logloss: 0.178983\tvalid_1's multi_logloss: 0.298169       \n",
      "[115]\ttraining's multi_logloss: 0.177663\tvalid_1's multi_logloss: 0.297828       \n",
      "[116]\ttraining's multi_logloss: 0.176447\tvalid_1's multi_logloss: 0.29743        \n",
      "[117]\ttraining's multi_logloss: 0.175172\tvalid_1's multi_logloss: 0.297094       \n",
      "[118]\ttraining's multi_logloss: 0.17394\tvalid_1's multi_logloss: 0.296671        \n",
      "[119]\ttraining's multi_logloss: 0.172639\tvalid_1's multi_logloss: 0.296374       \n",
      "[120]\ttraining's multi_logloss: 0.171395\tvalid_1's multi_logloss: 0.296062       \n",
      "[121]\ttraining's multi_logloss: 0.17011\tvalid_1's multi_logloss: 0.295668        \n",
      "[122]\ttraining's multi_logloss: 0.168838\tvalid_1's multi_logloss: 0.295396       \n",
      "[123]\ttraining's multi_logloss: 0.167638\tvalid_1's multi_logloss: 0.294998       \n",
      "[124]\ttraining's multi_logloss: 0.166414\tvalid_1's multi_logloss: 0.294745       \n",
      "[125]\ttraining's multi_logloss: 0.165128\tvalid_1's multi_logloss: 0.294443       \n",
      "[126]\ttraining's multi_logloss: 0.163918\tvalid_1's multi_logloss: 0.294038       \n",
      "[127]\ttraining's multi_logloss: 0.16275\tvalid_1's multi_logloss: 0.293695        \n",
      "[128]\ttraining's multi_logloss: 0.161562\tvalid_1's multi_logloss: 0.293435       \n",
      "[129]\ttraining's multi_logloss: 0.160423\tvalid_1's multi_logloss: 0.293231       \n",
      "[130]\ttraining's multi_logloss: 0.159328\tvalid_1's multi_logloss: 0.292844       \n",
      "[131]\ttraining's multi_logloss: 0.158155\tvalid_1's multi_logloss: 0.292533       \n",
      "[132]\ttraining's multi_logloss: 0.157024\tvalid_1's multi_logloss: 0.292324       \n",
      "[133]\ttraining's multi_logloss: 0.156019\tvalid_1's multi_logloss: 0.29204        \n",
      "[134]\ttraining's multi_logloss: 0.155003\tvalid_1's multi_logloss: 0.2919         \n",
      "[135]\ttraining's multi_logloss: 0.153964\tvalid_1's multi_logloss: 0.291774       \n",
      "[136]\ttraining's multi_logloss: 0.152893\tvalid_1's multi_logloss: 0.291503       \n",
      "[137]\ttraining's multi_logloss: 0.151875\tvalid_1's multi_logloss: 0.291257       \n",
      "[138]\ttraining's multi_logloss: 0.150852\tvalid_1's multi_logloss: 0.291178       \n",
      "[139]\ttraining's multi_logloss: 0.149845\tvalid_1's multi_logloss: 0.290956       \n",
      "[140]\ttraining's multi_logloss: 0.148807\tvalid_1's multi_logloss: 0.290708       \n",
      "[141]\ttraining's multi_logloss: 0.147766\tvalid_1's multi_logloss: 0.290631       \n",
      "[142]\ttraining's multi_logloss: 0.146773\tvalid_1's multi_logloss: 0.290489       \n",
      "[143]\ttraining's multi_logloss: 0.145754\tvalid_1's multi_logloss: 0.290377       \n",
      "[144]\ttraining's multi_logloss: 0.144781\tvalid_1's multi_logloss: 0.290391       \n",
      "[145]\ttraining's multi_logloss: 0.143832\tvalid_1's multi_logloss: 0.290089       \n",
      "[146]\ttraining's multi_logloss: 0.142903\tvalid_1's multi_logloss: 0.289898       \n",
      "[147]\ttraining's multi_logloss: 0.141929\tvalid_1's multi_logloss: 0.289785       \n",
      "[148]\ttraining's multi_logloss: 0.141017\tvalid_1's multi_logloss: 0.289737       \n",
      "[149]\ttraining's multi_logloss: 0.14011\tvalid_1's multi_logloss: 0.289607        \n",
      "[150]\ttraining's multi_logloss: 0.139171\tvalid_1's multi_logloss: 0.289621       \n",
      "[151]\ttraining's multi_logloss: 0.138295\tvalid_1's multi_logloss: 0.28962        \n",
      "[152]\ttraining's multi_logloss: 0.13747\tvalid_1's multi_logloss: 0.289491        \n",
      "[153]\ttraining's multi_logloss: 0.136619\tvalid_1's multi_logloss: 0.289452       \n",
      "[154]\ttraining's multi_logloss: 0.135807\tvalid_1's multi_logloss: 0.28939        \n",
      "[155]\ttraining's multi_logloss: 0.134933\tvalid_1's multi_logloss: 0.289153       \n",
      "[156]\ttraining's multi_logloss: 0.134117\tvalid_1's multi_logloss: 0.289136       \n",
      "[157]\ttraining's multi_logloss: 0.133236\tvalid_1's multi_logloss: 0.289065       \n",
      "[158]\ttraining's multi_logloss: 0.132359\tvalid_1's multi_logloss: 0.289157       \n",
      "[159]\ttraining's multi_logloss: 0.131594\tvalid_1's multi_logloss: 0.289072       \n",
      "[160]\ttraining's multi_logloss: 0.130763\tvalid_1's multi_logloss: 0.289039       \n",
      "[161]\ttraining's multi_logloss: 0.12989\tvalid_1's multi_logloss: 0.288984        \n",
      "[162]\ttraining's multi_logloss: 0.129106\tvalid_1's multi_logloss: 0.288947       \n",
      "[163]\ttraining's multi_logloss: 0.128328\tvalid_1's multi_logloss: 0.288864       \n",
      "[164]\ttraining's multi_logloss: 0.127539\tvalid_1's multi_logloss: 0.288806       \n",
      "[165]\ttraining's multi_logloss: 0.126745\tvalid_1's multi_logloss: 0.288833       \n",
      "[166]\ttraining's multi_logloss: 0.125973\tvalid_1's multi_logloss: 0.288687       \n",
      "[167]\ttraining's multi_logloss: 0.125226\tvalid_1's multi_logloss: 0.288559       \n",
      "[168]\ttraining's multi_logloss: 0.124506\tvalid_1's multi_logloss: 0.288449       \n",
      "[169]\ttraining's multi_logloss: 0.123729\tvalid_1's multi_logloss: 0.288399       \n",
      "[170]\ttraining's multi_logloss: 0.123012\tvalid_1's multi_logloss: 0.288471       \n",
      "[171]\ttraining's multi_logloss: 0.122256\tvalid_1's multi_logloss: 0.288461       \n",
      "[172]\ttraining's multi_logloss: 0.121519\tvalid_1's multi_logloss: 0.288447       \n",
      "[173]\ttraining's multi_logloss: 0.120838\tvalid_1's multi_logloss: 0.288439       \n",
      "[174]\ttraining's multi_logloss: 0.120143\tvalid_1's multi_logloss: 0.288484       \n",
      "[175]\ttraining's multi_logloss: 0.119426\tvalid_1's multi_logloss: 0.288535       \n",
      "[176]\ttraining's multi_logloss: 0.118714\tvalid_1's multi_logloss: 0.288489       \n",
      "[177]\ttraining's multi_logloss: 0.118039\tvalid_1's multi_logloss: 0.288465       \n",
      "[178]\ttraining's multi_logloss: 0.117345\tvalid_1's multi_logloss: 0.288343       \n",
      "[179]\ttraining's multi_logloss: 0.11667\tvalid_1's multi_logloss: 0.288296        \n",
      "[180]\ttraining's multi_logloss: 0.116012\tvalid_1's multi_logloss: 0.288277       \n",
      "[181]\ttraining's multi_logloss: 0.115314\tvalid_1's multi_logloss: 0.288342       \n",
      "[182]\ttraining's multi_logloss: 0.114656\tvalid_1's multi_logloss: 0.288214       \n",
      "[183]\ttraining's multi_logloss: 0.113965\tvalid_1's multi_logloss: 0.288267       \n",
      "[184]\ttraining's multi_logloss: 0.113324\tvalid_1's multi_logloss: 0.288382       \n",
      "[185]\ttraining's multi_logloss: 0.112703\tvalid_1's multi_logloss: 0.288451       \n",
      "[186]\ttraining's multi_logloss: 0.11207\tvalid_1's multi_logloss: 0.288478        \n",
      "[187]\ttraining's multi_logloss: 0.111414\tvalid_1's multi_logloss: 0.288543       \n",
      "[188]\ttraining's multi_logloss: 0.110806\tvalid_1's multi_logloss: 0.288448       \n",
      "[189]\ttraining's multi_logloss: 0.110147\tvalid_1's multi_logloss: 0.288437       \n",
      "[190]\ttraining's multi_logloss: 0.109521\tvalid_1's multi_logloss: 0.288506       \n",
      "[191]\ttraining's multi_logloss: 0.108891\tvalid_1's multi_logloss: 0.288491       \n",
      "[192]\ttraining's multi_logloss: 0.108293\tvalid_1's multi_logloss: 0.288609       \n",
      "[193]\ttraining's multi_logloss: 0.10769\tvalid_1's multi_logloss: 0.288638        \n",
      "[194]\ttraining's multi_logloss: 0.107084\tvalid_1's multi_logloss: 0.288652       \n",
      "[195]\ttraining's multi_logloss: 0.106505\tvalid_1's multi_logloss: 0.288722       \n",
      "[196]\ttraining's multi_logloss: 0.105896\tvalid_1's multi_logloss: 0.288828       \n",
      "[197]\ttraining's multi_logloss: 0.10531\tvalid_1's multi_logloss: 0.288913        \n",
      "[198]\ttraining's multi_logloss: 0.104702\tvalid_1's multi_logloss: 0.28883        \n",
      "[199]\ttraining's multi_logloss: 0.104133\tvalid_1's multi_logloss: 0.288862       \n",
      "[200]\ttraining's multi_logloss: 0.103566\tvalid_1's multi_logloss: 0.288909       \n",
      "[201]\ttraining's multi_logloss: 0.103055\tvalid_1's multi_logloss: 0.288883       \n",
      "[202]\ttraining's multi_logloss: 0.102509\tvalid_1's multi_logloss: 0.288979       \n",
      "[203]\ttraining's multi_logloss: 0.101993\tvalid_1's multi_logloss: 0.28902        \n",
      "[204]\ttraining's multi_logloss: 0.101446\tvalid_1's multi_logloss: 0.289172       \n",
      "[205]\ttraining's multi_logloss: 0.10094\tvalid_1's multi_logloss: 0.289178        \n",
      "[206]\ttraining's multi_logloss: 0.100432\tvalid_1's multi_logloss: 0.289331       \n",
      "[207]\ttraining's multi_logloss: 0.0998879\tvalid_1's multi_logloss: 0.289327      \n",
      "[208]\ttraining's multi_logloss: 0.0994025\tvalid_1's multi_logloss: 0.289397      \n",
      "[209]\ttraining's multi_logloss: 0.0989327\tvalid_1's multi_logloss: 0.289412      \n",
      "[210]\ttraining's multi_logloss: 0.0984263\tvalid_1's multi_logloss: 0.289462      \n",
      "[211]\ttraining's multi_logloss: 0.0979676\tvalid_1's multi_logloss: 0.28953       \n",
      "[212]\ttraining's multi_logloss: 0.097453\tvalid_1's multi_logloss: 0.289579       \n",
      "Early stopping, best iteration is:                                               \n",
      "[182]\ttraining's multi_logloss: 0.114656\tvalid_1's multi_logloss: 0.288214\n",
      "[1]\ttraining's multi_logloss: 1.78992\tvalid_1's multi_logloss: 1.79261           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.67213\tvalid_1's multi_logloss: 1.67573           \n",
      "[3]\ttraining's multi_logloss: 1.57001\tvalid_1's multi_logloss: 1.57456           \n",
      "[4]\ttraining's multi_logloss: 1.48001\tvalid_1's multi_logloss: 1.48511           \n",
      "[5]\ttraining's multi_logloss: 1.39982\tvalid_1's multi_logloss: 1.40587           \n",
      "[6]\ttraining's multi_logloss: 1.32786\tvalid_1's multi_logloss: 1.33498           \n",
      "[7]\ttraining's multi_logloss: 1.26268\tvalid_1's multi_logloss: 1.27093           \n",
      "[8]\ttraining's multi_logloss: 1.2026\tvalid_1's multi_logloss: 1.21156            \n",
      "[9]\ttraining's multi_logloss: 1.14771\tvalid_1's multi_logloss: 1.15743           \n",
      "[10]\ttraining's multi_logloss: 1.0973\tvalid_1's multi_logloss: 1.10818           \n",
      "[11]\ttraining's multi_logloss: 1.05091\tvalid_1's multi_logloss: 1.06273          \n",
      "[12]\ttraining's multi_logloss: 1.00712\tvalid_1's multi_logloss: 1.01995          \n",
      "[13]\ttraining's multi_logloss: 0.966873\tvalid_1's multi_logloss: 0.980739        \n",
      "[14]\ttraining's multi_logloss: 0.929194\tvalid_1's multi_logloss: 0.944065        \n",
      "[15]\ttraining's multi_logloss: 0.894164\tvalid_1's multi_logloss: 0.909953        \n",
      "[16]\ttraining's multi_logloss: 0.861026\tvalid_1's multi_logloss: 0.877687        \n",
      "[17]\ttraining's multi_logloss: 0.830154\tvalid_1's multi_logloss: 0.847807        \n",
      "[18]\ttraining's multi_logloss: 0.80096\tvalid_1's multi_logloss: 0.819483         \n",
      "[19]\ttraining's multi_logloss: 0.77336\tvalid_1's multi_logloss: 0.792801         \n",
      "[20]\ttraining's multi_logloss: 0.747292\tvalid_1's multi_logloss: 0.767698        \n",
      "[21]\ttraining's multi_logloss: 0.722702\tvalid_1's multi_logloss: 0.744236        \n",
      "[22]\ttraining's multi_logloss: 0.699276\tvalid_1's multi_logloss: 0.721752        \n",
      "[23]\ttraining's multi_logloss: 0.677115\tvalid_1's multi_logloss: 0.700469        \n",
      "[24]\ttraining's multi_logloss: 0.656248\tvalid_1's multi_logloss: 0.680559        \n",
      "[25]\ttraining's multi_logloss: 0.636507\tvalid_1's multi_logloss: 0.661854        \n",
      "[26]\ttraining's multi_logloss: 0.617672\tvalid_1's multi_logloss: 0.643876        \n",
      "[27]\ttraining's multi_logloss: 0.599549\tvalid_1's multi_logloss: 0.626477        \n",
      "[28]\ttraining's multi_logloss: 0.582651\tvalid_1's multi_logloss: 0.610374        \n",
      "[29]\ttraining's multi_logloss: 0.566532\tvalid_1's multi_logloss: 0.594961        \n",
      "[30]\ttraining's multi_logloss: 0.551326\tvalid_1's multi_logloss: 0.580639        \n",
      "[31]\ttraining's multi_logloss: 0.537017\tvalid_1's multi_logloss: 0.567195        \n",
      "[32]\ttraining's multi_logloss: 0.523168\tvalid_1's multi_logloss: 0.554242        \n",
      "[33]\ttraining's multi_logloss: 0.510099\tvalid_1's multi_logloss: 0.541944        \n",
      "[34]\ttraining's multi_logloss: 0.497847\tvalid_1's multi_logloss: 0.530499        \n",
      "[35]\ttraining's multi_logloss: 0.485956\tvalid_1's multi_logloss: 0.51949         \n",
      "[36]\ttraining's multi_logloss: 0.474695\tvalid_1's multi_logloss: 0.509129        \n",
      "[37]\ttraining's multi_logloss: 0.463816\tvalid_1's multi_logloss: 0.499302        \n",
      "[38]\ttraining's multi_logloss: 0.453439\tvalid_1's multi_logloss: 0.489855        \n",
      "[39]\ttraining's multi_logloss: 0.443441\tvalid_1's multi_logloss: 0.480938        \n",
      "[40]\ttraining's multi_logloss: 0.433837\tvalid_1's multi_logloss: 0.472363        \n",
      "[41]\ttraining's multi_logloss: 0.424795\tvalid_1's multi_logloss: 0.464227        \n",
      "[42]\ttraining's multi_logloss: 0.416123\tvalid_1's multi_logloss: 0.456421        \n",
      "[43]\ttraining's multi_logloss: 0.407858\tvalid_1's multi_logloss: 0.449161        \n",
      "[44]\ttraining's multi_logloss: 0.3998\tvalid_1's multi_logloss: 0.442248          \n",
      "[45]\ttraining's multi_logloss: 0.392178\tvalid_1's multi_logloss: 0.435526        \n",
      "[46]\ttraining's multi_logloss: 0.384843\tvalid_1's multi_logloss: 0.429221        \n",
      "[47]\ttraining's multi_logloss: 0.377866\tvalid_1's multi_logloss: 0.423133        \n",
      "[48]\ttraining's multi_logloss: 0.371112\tvalid_1's multi_logloss: 0.417254        \n",
      "[49]\ttraining's multi_logloss: 0.364647\tvalid_1's multi_logloss: 0.411743        \n",
      "[50]\ttraining's multi_logloss: 0.358481\tvalid_1's multi_logloss: 0.40643         \n",
      "[51]\ttraining's multi_logloss: 0.352349\tvalid_1's multi_logloss: 0.401128        \n",
      "[52]\ttraining's multi_logloss: 0.346453\tvalid_1's multi_logloss: 0.396101        \n",
      "[53]\ttraining's multi_logloss: 0.340883\tvalid_1's multi_logloss: 0.391393        \n",
      "[54]\ttraining's multi_logloss: 0.335416\tvalid_1's multi_logloss: 0.386871        \n",
      "[55]\ttraining's multi_logloss: 0.33018\tvalid_1's multi_logloss: 0.38249          \n",
      "[56]\ttraining's multi_logloss: 0.32517\tvalid_1's multi_logloss: 0.378374         \n",
      "[57]\ttraining's multi_logloss: 0.320338\tvalid_1's multi_logloss: 0.374431        \n",
      "[58]\ttraining's multi_logloss: 0.315571\tvalid_1's multi_logloss: 0.370548        \n",
      "[59]\ttraining's multi_logloss: 0.310759\tvalid_1's multi_logloss: 0.366727        \n",
      "[60]\ttraining's multi_logloss: 0.306421\tvalid_1's multi_logloss: 0.363278        \n",
      "[61]\ttraining's multi_logloss: 0.302034\tvalid_1's multi_logloss: 0.359845        \n",
      "[62]\ttraining's multi_logloss: 0.298077\tvalid_1's multi_logloss: 0.356833        \n",
      "[63]\ttraining's multi_logloss: 0.293993\tvalid_1's multi_logloss: 0.353739        \n",
      "[64]\ttraining's multi_logloss: 0.290128\tvalid_1's multi_logloss: 0.350864        \n",
      "[65]\ttraining's multi_logloss: 0.286242\tvalid_1's multi_logloss: 0.3479          \n",
      "[66]\ttraining's multi_logloss: 0.282564\tvalid_1's multi_logloss: 0.345232        \n",
      "[67]\ttraining's multi_logloss: 0.278849\tvalid_1's multi_logloss: 0.34244         \n",
      "[68]\ttraining's multi_logloss: 0.275443\tvalid_1's multi_logloss: 0.34003         \n",
      "[69]\ttraining's multi_logloss: 0.272039\tvalid_1's multi_logloss: 0.337694        \n",
      "[70]\ttraining's multi_logloss: 0.268794\tvalid_1's multi_logloss: 0.335433        \n",
      "[71]\ttraining's multi_logloss: 0.265716\tvalid_1's multi_logloss: 0.333471        \n",
      "[72]\ttraining's multi_logloss: 0.262591\tvalid_1's multi_logloss: 0.331343        \n",
      "[73]\ttraining's multi_logloss: 0.259634\tvalid_1's multi_logloss: 0.329376        \n",
      "[74]\ttraining's multi_logloss: 0.256736\tvalid_1's multi_logloss: 0.327485        \n",
      "[75]\ttraining's multi_logloss: 0.25392\tvalid_1's multi_logloss: 0.325815         \n",
      "[76]\ttraining's multi_logloss: 0.251196\tvalid_1's multi_logloss: 0.324111        \n",
      "[77]\ttraining's multi_logloss: 0.24856\tvalid_1's multi_logloss: 0.322439         \n",
      "[78]\ttraining's multi_logloss: 0.245905\tvalid_1's multi_logloss: 0.320894        \n",
      "[79]\ttraining's multi_logloss: 0.243343\tvalid_1's multi_logloss: 0.319455        \n",
      "[80]\ttraining's multi_logloss: 0.240864\tvalid_1's multi_logloss: 0.31814         \n",
      "[81]\ttraining's multi_logloss: 0.23849\tvalid_1's multi_logloss: 0.316731         \n",
      "[82]\ttraining's multi_logloss: 0.236035\tvalid_1's multi_logloss: 0.31534         \n",
      "[83]\ttraining's multi_logloss: 0.233727\tvalid_1's multi_logloss: 0.314142        \n",
      "[84]\ttraining's multi_logloss: 0.231461\tvalid_1's multi_logloss: 0.31298         \n",
      "[85]\ttraining's multi_logloss: 0.229159\tvalid_1's multi_logloss: 0.311737        \n",
      "[86]\ttraining's multi_logloss: 0.226995\tvalid_1's multi_logloss: 0.310617        \n",
      "[87]\ttraining's multi_logloss: 0.224866\tvalid_1's multi_logloss: 0.309529        \n",
      "[88]\ttraining's multi_logloss: 0.222716\tvalid_1's multi_logloss: 0.30844         \n",
      "[89]\ttraining's multi_logloss: 0.220771\tvalid_1's multi_logloss: 0.307361        \n",
      "[90]\ttraining's multi_logloss: 0.218704\tvalid_1's multi_logloss: 0.306425        \n",
      "[91]\ttraining's multi_logloss: 0.216772\tvalid_1's multi_logloss: 0.305514        \n",
      "[92]\ttraining's multi_logloss: 0.214843\tvalid_1's multi_logloss: 0.304595        \n",
      "[93]\ttraining's multi_logloss: 0.213003\tvalid_1's multi_logloss: 0.303684        \n",
      "[94]\ttraining's multi_logloss: 0.211157\tvalid_1's multi_logloss: 0.302883        \n",
      "[95]\ttraining's multi_logloss: 0.209279\tvalid_1's multi_logloss: 0.302149        \n",
      "[96]\ttraining's multi_logloss: 0.207505\tvalid_1's multi_logloss: 0.301364        \n",
      "[97]\ttraining's multi_logloss: 0.205788\tvalid_1's multi_logloss: 0.300751        \n",
      "[98]\ttraining's multi_logloss: 0.204098\tvalid_1's multi_logloss: 0.30012         \n",
      "[99]\ttraining's multi_logloss: 0.202381\tvalid_1's multi_logloss: 0.299546        \n",
      "[100]\ttraining's multi_logloss: 0.200735\tvalid_1's multi_logloss: 0.298918       \n",
      "[101]\ttraining's multi_logloss: 0.199091\tvalid_1's multi_logloss: 0.298402       \n",
      "[102]\ttraining's multi_logloss: 0.197515\tvalid_1's multi_logloss: 0.297757       \n",
      "[103]\ttraining's multi_logloss: 0.195841\tvalid_1's multi_logloss: 0.297093       \n",
      "[104]\ttraining's multi_logloss: 0.194197\tvalid_1's multi_logloss: 0.296524       \n",
      "[105]\ttraining's multi_logloss: 0.192729\tvalid_1's multi_logloss: 0.295998       \n",
      "[106]\ttraining's multi_logloss: 0.1912\tvalid_1's multi_logloss: 0.295309         \n",
      "[107]\ttraining's multi_logloss: 0.18966\tvalid_1's multi_logloss: 0.294891        \n",
      "[108]\ttraining's multi_logloss: 0.188184\tvalid_1's multi_logloss: 0.294411       \n",
      "[109]\ttraining's multi_logloss: 0.186716\tvalid_1's multi_logloss: 0.293911       \n",
      "[110]\ttraining's multi_logloss: 0.185193\tvalid_1's multi_logloss: 0.293439       \n",
      "[111]\ttraining's multi_logloss: 0.183713\tvalid_1's multi_logloss: 0.292991       \n",
      "[112]\ttraining's multi_logloss: 0.182301\tvalid_1's multi_logloss: 0.292589       \n",
      "[113]\ttraining's multi_logloss: 0.180909\tvalid_1's multi_logloss: 0.29225        \n",
      "[114]\ttraining's multi_logloss: 0.179508\tvalid_1's multi_logloss: 0.291751       \n",
      "[115]\ttraining's multi_logloss: 0.178195\tvalid_1's multi_logloss: 0.291317       \n",
      "[116]\ttraining's multi_logloss: 0.176801\tvalid_1's multi_logloss: 0.291001       \n",
      "[117]\ttraining's multi_logloss: 0.175375\tvalid_1's multi_logloss: 0.29054        \n",
      "[118]\ttraining's multi_logloss: 0.174012\tvalid_1's multi_logloss: 0.290079       \n",
      "[119]\ttraining's multi_logloss: 0.172663\tvalid_1's multi_logloss: 0.289834       \n",
      "[120]\ttraining's multi_logloss: 0.171369\tvalid_1's multi_logloss: 0.289607       \n",
      "[121]\ttraining's multi_logloss: 0.170102\tvalid_1's multi_logloss: 0.289393       \n",
      "[122]\ttraining's multi_logloss: 0.168916\tvalid_1's multi_logloss: 0.289248       \n",
      "[123]\ttraining's multi_logloss: 0.167687\tvalid_1's multi_logloss: 0.289065       \n",
      "[124]\ttraining's multi_logloss: 0.166443\tvalid_1's multi_logloss: 0.288752       \n",
      "[125]\ttraining's multi_logloss: 0.165186\tvalid_1's multi_logloss: 0.288472       \n",
      "[126]\ttraining's multi_logloss: 0.163944\tvalid_1's multi_logloss: 0.2881         \n",
      "[127]\ttraining's multi_logloss: 0.162748\tvalid_1's multi_logloss: 0.287867       \n",
      "[128]\ttraining's multi_logloss: 0.16152\tvalid_1's multi_logloss: 0.287572        \n",
      "[129]\ttraining's multi_logloss: 0.160333\tvalid_1's multi_logloss: 0.287299       \n",
      "[130]\ttraining's multi_logloss: 0.159222\tvalid_1's multi_logloss: 0.287092       \n",
      "[131]\ttraining's multi_logloss: 0.158119\tvalid_1's multi_logloss: 0.287014       \n",
      "[132]\ttraining's multi_logloss: 0.156971\tvalid_1's multi_logloss: 0.286831       \n",
      "[133]\ttraining's multi_logloss: 0.155817\tvalid_1's multi_logloss: 0.286623       \n",
      "[134]\ttraining's multi_logloss: 0.154685\tvalid_1's multi_logloss: 0.286646       \n",
      "[135]\ttraining's multi_logloss: 0.1536\tvalid_1's multi_logloss: 0.286445         \n",
      "[136]\ttraining's multi_logloss: 0.152476\tvalid_1's multi_logloss: 0.286369       \n",
      "[137]\ttraining's multi_logloss: 0.151373\tvalid_1's multi_logloss: 0.286347       \n",
      "[138]\ttraining's multi_logloss: 0.15029\tvalid_1's multi_logloss: 0.286127        \n",
      "[139]\ttraining's multi_logloss: 0.149207\tvalid_1's multi_logloss: 0.286059       \n",
      "[140]\ttraining's multi_logloss: 0.148122\tvalid_1's multi_logloss: 0.285921       \n",
      "[141]\ttraining's multi_logloss: 0.147101\tvalid_1's multi_logloss: 0.285716       \n",
      "[142]\ttraining's multi_logloss: 0.14605\tvalid_1's multi_logloss: 0.285515        \n",
      "[143]\ttraining's multi_logloss: 0.145098\tvalid_1's multi_logloss: 0.285589       \n",
      "[144]\ttraining's multi_logloss: 0.144119\tvalid_1's multi_logloss: 0.28553        \n",
      "[145]\ttraining's multi_logloss: 0.143096\tvalid_1's multi_logloss: 0.285439       \n",
      "[146]\ttraining's multi_logloss: 0.142141\tvalid_1's multi_logloss: 0.285334       \n",
      "[147]\ttraining's multi_logloss: 0.141173\tvalid_1's multi_logloss: 0.285376       \n",
      "[148]\ttraining's multi_logloss: 0.140285\tvalid_1's multi_logloss: 0.285344       \n",
      "[149]\ttraining's multi_logloss: 0.139404\tvalid_1's multi_logloss: 0.285379       \n",
      "[150]\ttraining's multi_logloss: 0.138471\tvalid_1's multi_logloss: 0.285324       \n",
      "[151]\ttraining's multi_logloss: 0.137533\tvalid_1's multi_logloss: 0.285223       \n",
      "[152]\ttraining's multi_logloss: 0.136565\tvalid_1's multi_logloss: 0.285296       \n",
      "[153]\ttraining's multi_logloss: 0.135691\tvalid_1's multi_logloss: 0.285267       \n",
      "[154]\ttraining's multi_logloss: 0.134814\tvalid_1's multi_logloss: 0.285178       \n",
      "[155]\ttraining's multi_logloss: 0.133924\tvalid_1's multi_logloss: 0.285243       \n",
      "[156]\ttraining's multi_logloss: 0.132983\tvalid_1's multi_logloss: 0.285238       \n",
      "[157]\ttraining's multi_logloss: 0.132141\tvalid_1's multi_logloss: 0.285153       \n",
      "[158]\ttraining's multi_logloss: 0.131297\tvalid_1's multi_logloss: 0.285164       \n",
      "[159]\ttraining's multi_logloss: 0.130458\tvalid_1's multi_logloss: 0.285043       \n",
      "[160]\ttraining's multi_logloss: 0.129718\tvalid_1's multi_logloss: 0.284948       \n",
      "[161]\ttraining's multi_logloss: 0.128883\tvalid_1's multi_logloss: 0.284852       \n",
      "[162]\ttraining's multi_logloss: 0.128056\tvalid_1's multi_logloss: 0.284723       \n",
      "[163]\ttraining's multi_logloss: 0.127211\tvalid_1's multi_logloss: 0.28472        \n",
      "[164]\ttraining's multi_logloss: 0.126428\tvalid_1's multi_logloss: 0.284643       \n",
      "[165]\ttraining's multi_logloss: 0.125626\tvalid_1's multi_logloss: 0.284586       \n",
      "[166]\ttraining's multi_logloss: 0.124785\tvalid_1's multi_logloss: 0.284649       \n",
      "[167]\ttraining's multi_logloss: 0.12402\tvalid_1's multi_logloss: 0.284548        \n",
      "[168]\ttraining's multi_logloss: 0.123217\tvalid_1's multi_logloss: 0.284492       \n",
      "[169]\ttraining's multi_logloss: 0.122445\tvalid_1's multi_logloss: 0.284522       \n",
      "[170]\ttraining's multi_logloss: 0.121689\tvalid_1's multi_logloss: 0.284454       \n",
      "[171]\ttraining's multi_logloss: 0.120933\tvalid_1's multi_logloss: 0.284445       \n",
      "[172]\ttraining's multi_logloss: 0.120147\tvalid_1's multi_logloss: 0.284352       \n",
      "[173]\ttraining's multi_logloss: 0.119416\tvalid_1's multi_logloss: 0.284336       \n",
      "[174]\ttraining's multi_logloss: 0.11873\tvalid_1's multi_logloss: 0.284284        \n",
      "[175]\ttraining's multi_logloss: 0.11805\tvalid_1's multi_logloss: 0.284291        \n",
      "[176]\ttraining's multi_logloss: 0.117377\tvalid_1's multi_logloss: 0.284305       \n",
      "[177]\ttraining's multi_logloss: 0.116632\tvalid_1's multi_logloss: 0.284426       \n",
      "[178]\ttraining's multi_logloss: 0.115949\tvalid_1's multi_logloss: 0.284587       \n",
      "[179]\ttraining's multi_logloss: 0.115235\tvalid_1's multi_logloss: 0.28457        \n",
      "[180]\ttraining's multi_logloss: 0.114582\tvalid_1's multi_logloss: 0.284568       \n",
      "[181]\ttraining's multi_logloss: 0.113886\tvalid_1's multi_logloss: 0.284727       \n",
      "[182]\ttraining's multi_logloss: 0.113178\tvalid_1's multi_logloss: 0.284732       \n",
      "[183]\ttraining's multi_logloss: 0.11246\tvalid_1's multi_logloss: 0.284782        \n",
      "[184]\ttraining's multi_logloss: 0.111802\tvalid_1's multi_logloss: 0.284798       \n",
      "[185]\ttraining's multi_logloss: 0.111178\tvalid_1's multi_logloss: 0.284879       \n",
      "[186]\ttraining's multi_logloss: 0.110505\tvalid_1's multi_logloss: 0.285048       \n",
      "[187]\ttraining's multi_logloss: 0.109843\tvalid_1's multi_logloss: 0.285011       \n",
      "[188]\ttraining's multi_logloss: 0.109197\tvalid_1's multi_logloss: 0.284978       \n",
      "[189]\ttraining's multi_logloss: 0.108555\tvalid_1's multi_logloss: 0.285053       \n",
      "[190]\ttraining's multi_logloss: 0.107964\tvalid_1's multi_logloss: 0.285078       \n",
      "[191]\ttraining's multi_logloss: 0.107318\tvalid_1's multi_logloss: 0.285077       \n",
      "[192]\ttraining's multi_logloss: 0.106697\tvalid_1's multi_logloss: 0.285177       \n",
      "[193]\ttraining's multi_logloss: 0.106108\tvalid_1's multi_logloss: 0.285321       \n",
      "[194]\ttraining's multi_logloss: 0.105472\tvalid_1's multi_logloss: 0.28543        \n",
      "[195]\ttraining's multi_logloss: 0.104883\tvalid_1's multi_logloss: 0.285471       \n",
      "[196]\ttraining's multi_logloss: 0.104287\tvalid_1's multi_logloss: 0.285615       \n",
      "[197]\ttraining's multi_logloss: 0.10374\tvalid_1's multi_logloss: 0.285708        \n",
      "[198]\ttraining's multi_logloss: 0.103153\tvalid_1's multi_logloss: 0.285802       \n",
      "[199]\ttraining's multi_logloss: 0.102574\tvalid_1's multi_logloss: 0.285897       \n",
      "[200]\ttraining's multi_logloss: 0.101974\tvalid_1's multi_logloss: 0.28602        \n",
      "[201]\ttraining's multi_logloss: 0.101432\tvalid_1's multi_logloss: 0.28613        \n",
      "[202]\ttraining's multi_logloss: 0.100839\tvalid_1's multi_logloss: 0.286147       \n",
      "[203]\ttraining's multi_logloss: 0.100288\tvalid_1's multi_logloss: 0.286318       \n",
      "[204]\ttraining's multi_logloss: 0.0997551\tvalid_1's multi_logloss: 0.286506      \n",
      "Early stopping, best iteration is:                                               \n",
      "[174]\ttraining's multi_logloss: 0.11873\tvalid_1's multi_logloss: 0.284284\n",
      "[1]\ttraining's multi_logloss: 1.79078\tvalid_1's multi_logloss: 1.79382           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.67287\tvalid_1's multi_logloss: 1.67697           \n",
      "[3]\ttraining's multi_logloss: 1.57112\tvalid_1's multi_logloss: 1.57611           \n",
      "[4]\ttraining's multi_logloss: 1.48109\tvalid_1's multi_logloss: 1.48655           \n",
      "[5]\ttraining's multi_logloss: 1.40099\tvalid_1's multi_logloss: 1.40724           \n",
      "[6]\ttraining's multi_logloss: 1.32859\tvalid_1's multi_logloss: 1.33537           \n",
      "[7]\ttraining's multi_logloss: 1.26289\tvalid_1's multi_logloss: 1.27027           \n",
      "[8]\ttraining's multi_logloss: 1.20332\tvalid_1's multi_logloss: 1.21161           \n",
      "[9]\ttraining's multi_logloss: 1.14894\tvalid_1's multi_logloss: 1.15764           \n",
      "[10]\ttraining's multi_logloss: 1.09865\tvalid_1's multi_logloss: 1.10807          \n",
      "[11]\ttraining's multi_logloss: 1.05189\tvalid_1's multi_logloss: 1.06174          \n",
      "[12]\ttraining's multi_logloss: 1.00836\tvalid_1's multi_logloss: 1.01866          \n",
      "[13]\ttraining's multi_logloss: 0.968184\tvalid_1's multi_logloss: 0.978785        \n",
      "[14]\ttraining's multi_logloss: 0.930505\tvalid_1's multi_logloss: 0.941344        \n",
      "[15]\ttraining's multi_logloss: 0.89503\tvalid_1's multi_logloss: 0.906378         \n",
      "[16]\ttraining's multi_logloss: 0.861848\tvalid_1's multi_logloss: 0.873813        \n",
      "[17]\ttraining's multi_logloss: 0.830953\tvalid_1's multi_logloss: 0.843568        \n",
      "[18]\ttraining's multi_logloss: 0.80179\tvalid_1's multi_logloss: 0.814718         \n",
      "[19]\ttraining's multi_logloss: 0.774188\tvalid_1's multi_logloss: 0.787771        \n",
      "[20]\ttraining's multi_logloss: 0.748198\tvalid_1's multi_logloss: 0.762507        \n",
      "[21]\ttraining's multi_logloss: 0.723797\tvalid_1's multi_logloss: 0.738734        \n",
      "[22]\ttraining's multi_logloss: 0.70056\tvalid_1's multi_logloss: 0.716205         \n",
      "[23]\ttraining's multi_logloss: 0.678636\tvalid_1's multi_logloss: 0.694882        \n",
      "[24]\ttraining's multi_logloss: 0.657798\tvalid_1's multi_logloss: 0.674695        \n",
      "[25]\ttraining's multi_logloss: 0.63828\tvalid_1's multi_logloss: 0.655909         \n",
      "[26]\ttraining's multi_logloss: 0.619623\tvalid_1's multi_logloss: 0.638209        \n",
      "[27]\ttraining's multi_logloss: 0.602202\tvalid_1's multi_logloss: 0.621561        \n",
      "[28]\ttraining's multi_logloss: 0.585689\tvalid_1's multi_logloss: 0.605974        \n",
      "[29]\ttraining's multi_logloss: 0.569943\tvalid_1's multi_logloss: 0.591196        \n",
      "[30]\ttraining's multi_logloss: 0.55495\tvalid_1's multi_logloss: 0.576806         \n",
      "[31]\ttraining's multi_logloss: 0.540745\tvalid_1's multi_logloss: 0.563393        \n",
      "[32]\ttraining's multi_logloss: 0.527175\tvalid_1's multi_logloss: 0.550527        \n",
      "[33]\ttraining's multi_logloss: 0.51436\tvalid_1's multi_logloss: 0.538423         \n",
      "[34]\ttraining's multi_logloss: 0.50205\tvalid_1's multi_logloss: 0.526846         \n",
      "[35]\ttraining's multi_logloss: 0.490166\tvalid_1's multi_logloss: 0.515665        \n",
      "[36]\ttraining's multi_logloss: 0.478884\tvalid_1's multi_logloss: 0.504971        \n",
      "[37]\ttraining's multi_logloss: 0.468311\tvalid_1's multi_logloss: 0.495027        \n",
      "[38]\ttraining's multi_logloss: 0.458195\tvalid_1's multi_logloss: 0.485664        \n",
      "[39]\ttraining's multi_logloss: 0.448494\tvalid_1's multi_logloss: 0.476612        \n",
      "[40]\ttraining's multi_logloss: 0.439184\tvalid_1's multi_logloss: 0.467996        \n",
      "[41]\ttraining's multi_logloss: 0.430083\tvalid_1's multi_logloss: 0.45967         \n",
      "[42]\ttraining's multi_logloss: 0.421509\tvalid_1's multi_logloss: 0.451786        \n",
      "[43]\ttraining's multi_logloss: 0.412951\tvalid_1's multi_logloss: 0.44385         \n",
      "[44]\ttraining's multi_logloss: 0.404989\tvalid_1's multi_logloss: 0.436678        \n",
      "[45]\ttraining's multi_logloss: 0.397156\tvalid_1's multi_logloss: 0.429583        \n",
      "[46]\ttraining's multi_logloss: 0.389828\tvalid_1's multi_logloss: 0.422934        \n",
      "[47]\ttraining's multi_logloss: 0.382934\tvalid_1's multi_logloss: 0.416667        \n",
      "[48]\ttraining's multi_logloss: 0.376092\tvalid_1's multi_logloss: 0.410493        \n",
      "[49]\ttraining's multi_logloss: 0.369257\tvalid_1's multi_logloss: 0.40433         \n",
      "[50]\ttraining's multi_logloss: 0.362916\tvalid_1's multi_logloss: 0.398873        \n",
      "[51]\ttraining's multi_logloss: 0.356898\tvalid_1's multi_logloss: 0.393603        \n",
      "[52]\ttraining's multi_logloss: 0.350996\tvalid_1's multi_logloss: 0.38829         \n",
      "[53]\ttraining's multi_logloss: 0.345381\tvalid_1's multi_logloss: 0.383237        \n",
      "[54]\ttraining's multi_logloss: 0.340056\tvalid_1's multi_logloss: 0.378555        \n",
      "[55]\ttraining's multi_logloss: 0.334819\tvalid_1's multi_logloss: 0.373999        \n",
      "[56]\ttraining's multi_logloss: 0.329936\tvalid_1's multi_logloss: 0.369846        \n",
      "[57]\ttraining's multi_logloss: 0.325218\tvalid_1's multi_logloss: 0.365892        \n",
      "[58]\ttraining's multi_logloss: 0.320564\tvalid_1's multi_logloss: 0.362012        \n",
      "[59]\ttraining's multi_logloss: 0.31602\tvalid_1's multi_logloss: 0.358278         \n",
      "[60]\ttraining's multi_logloss: 0.311561\tvalid_1's multi_logloss: 0.354536        \n",
      "[61]\ttraining's multi_logloss: 0.307181\tvalid_1's multi_logloss: 0.351041        \n",
      "[62]\ttraining's multi_logloss: 0.303084\tvalid_1's multi_logloss: 0.347878        \n",
      "[63]\ttraining's multi_logloss: 0.29913\tvalid_1's multi_logloss: 0.344696         \n",
      "[64]\ttraining's multi_logloss: 0.295322\tvalid_1's multi_logloss: 0.34165         \n",
      "[65]\ttraining's multi_logloss: 0.291575\tvalid_1's multi_logloss: 0.338774        \n",
      "[66]\ttraining's multi_logloss: 0.288062\tvalid_1's multi_logloss: 0.336041        \n",
      "[67]\ttraining's multi_logloss: 0.284534\tvalid_1's multi_logloss: 0.333377        \n",
      "[68]\ttraining's multi_logloss: 0.281075\tvalid_1's multi_logloss: 0.330746        \n",
      "[69]\ttraining's multi_logloss: 0.277726\tvalid_1's multi_logloss: 0.328248        \n",
      "[70]\ttraining's multi_logloss: 0.274555\tvalid_1's multi_logloss: 0.325874        \n",
      "[71]\ttraining's multi_logloss: 0.271454\tvalid_1's multi_logloss: 0.323551        \n",
      "[72]\ttraining's multi_logloss: 0.268413\tvalid_1's multi_logloss: 0.321434        \n",
      "[73]\ttraining's multi_logloss: 0.265387\tvalid_1's multi_logloss: 0.31932         \n",
      "[74]\ttraining's multi_logloss: 0.262516\tvalid_1's multi_logloss: 0.317378        \n",
      "[75]\ttraining's multi_logloss: 0.25967\tvalid_1's multi_logloss: 0.315377         \n",
      "[76]\ttraining's multi_logloss: 0.256959\tvalid_1's multi_logloss: 0.313624        \n",
      "[77]\ttraining's multi_logloss: 0.254278\tvalid_1's multi_logloss: 0.311812        \n",
      "[78]\ttraining's multi_logloss: 0.251806\tvalid_1's multi_logloss: 0.310151        \n",
      "[79]\ttraining's multi_logloss: 0.249327\tvalid_1's multi_logloss: 0.308481        \n",
      "[80]\ttraining's multi_logloss: 0.246866\tvalid_1's multi_logloss: 0.307089        \n",
      "[81]\ttraining's multi_logloss: 0.244389\tvalid_1's multi_logloss: 0.305723        \n",
      "[82]\ttraining's multi_logloss: 0.242042\tvalid_1's multi_logloss: 0.304231        \n",
      "[83]\ttraining's multi_logloss: 0.239799\tvalid_1's multi_logloss: 0.302892        \n",
      "[84]\ttraining's multi_logloss: 0.237569\tvalid_1's multi_logloss: 0.301725        \n",
      "[85]\ttraining's multi_logloss: 0.235331\tvalid_1's multi_logloss: 0.300297        \n",
      "[86]\ttraining's multi_logloss: 0.23329\tvalid_1's multi_logloss: 0.299169         \n",
      "[87]\ttraining's multi_logloss: 0.231118\tvalid_1's multi_logloss: 0.297955        \n",
      "[88]\ttraining's multi_logloss: 0.229057\tvalid_1's multi_logloss: 0.29696         \n",
      "[89]\ttraining's multi_logloss: 0.226928\tvalid_1's multi_logloss: 0.295825        \n",
      "[90]\ttraining's multi_logloss: 0.224863\tvalid_1's multi_logloss: 0.294608        \n",
      "[91]\ttraining's multi_logloss: 0.22294\tvalid_1's multi_logloss: 0.293776         \n",
      "[92]\ttraining's multi_logloss: 0.221007\tvalid_1's multi_logloss: 0.292761        \n",
      "[93]\ttraining's multi_logloss: 0.219158\tvalid_1's multi_logloss: 0.291893        \n",
      "[94]\ttraining's multi_logloss: 0.217318\tvalid_1's multi_logloss: 0.29093         \n",
      "[95]\ttraining's multi_logloss: 0.215453\tvalid_1's multi_logloss: 0.289917        \n",
      "[96]\ttraining's multi_logloss: 0.213649\tvalid_1's multi_logloss: 0.289137        \n",
      "[97]\ttraining's multi_logloss: 0.211845\tvalid_1's multi_logloss: 0.288303        \n",
      "[98]\ttraining's multi_logloss: 0.210232\tvalid_1's multi_logloss: 0.28756         \n",
      "[99]\ttraining's multi_logloss: 0.208609\tvalid_1's multi_logloss: 0.286889        \n",
      "[100]\ttraining's multi_logloss: 0.206902\tvalid_1's multi_logloss: 0.286227       \n",
      "[101]\ttraining's multi_logloss: 0.205233\tvalid_1's multi_logloss: 0.285615       \n",
      "[102]\ttraining's multi_logloss: 0.203604\tvalid_1's multi_logloss: 0.285005       \n",
      "[103]\ttraining's multi_logloss: 0.202027\tvalid_1's multi_logloss: 0.284489       \n",
      "[104]\ttraining's multi_logloss: 0.200391\tvalid_1's multi_logloss: 0.28383        \n",
      "[105]\ttraining's multi_logloss: 0.19882\tvalid_1's multi_logloss: 0.283368        \n",
      "[106]\ttraining's multi_logloss: 0.197155\tvalid_1's multi_logloss: 0.282619       \n",
      "[107]\ttraining's multi_logloss: 0.195692\tvalid_1's multi_logloss: 0.282156       \n",
      "[108]\ttraining's multi_logloss: 0.194102\tvalid_1's multi_logloss: 0.281508       \n",
      "[109]\ttraining's multi_logloss: 0.192656\tvalid_1's multi_logloss: 0.281197       \n",
      "[110]\ttraining's multi_logloss: 0.191147\tvalid_1's multi_logloss: 0.280614       \n",
      "[111]\ttraining's multi_logloss: 0.189743\tvalid_1's multi_logloss: 0.280156       \n",
      "[112]\ttraining's multi_logloss: 0.188259\tvalid_1's multi_logloss: 0.279595       \n",
      "[113]\ttraining's multi_logloss: 0.186811\tvalid_1's multi_logloss: 0.27918        \n",
      "[114]\ttraining's multi_logloss: 0.185454\tvalid_1's multi_logloss: 0.27871        \n",
      "[115]\ttraining's multi_logloss: 0.184152\tvalid_1's multi_logloss: 0.278447       \n",
      "[116]\ttraining's multi_logloss: 0.182713\tvalid_1's multi_logloss: 0.277996       \n",
      "[117]\ttraining's multi_logloss: 0.181437\tvalid_1's multi_logloss: 0.277731       \n",
      "[118]\ttraining's multi_logloss: 0.180088\tvalid_1's multi_logloss: 0.277327       \n",
      "[119]\ttraining's multi_logloss: 0.178735\tvalid_1's multi_logloss: 0.277094       \n",
      "[120]\ttraining's multi_logloss: 0.177462\tvalid_1's multi_logloss: 0.276684       \n",
      "[121]\ttraining's multi_logloss: 0.176181\tvalid_1's multi_logloss: 0.276429       \n",
      "[122]\ttraining's multi_logloss: 0.17491\tvalid_1's multi_logloss: 0.276079        \n",
      "[123]\ttraining's multi_logloss: 0.173697\tvalid_1's multi_logloss: 0.275789       \n",
      "[124]\ttraining's multi_logloss: 0.172497\tvalid_1's multi_logloss: 0.275565       \n",
      "[125]\ttraining's multi_logloss: 0.171312\tvalid_1's multi_logloss: 0.275185       \n",
      "[126]\ttraining's multi_logloss: 0.170059\tvalid_1's multi_logloss: 0.275087       \n",
      "[127]\ttraining's multi_logloss: 0.16889\tvalid_1's multi_logloss: 0.274901        \n",
      "[128]\ttraining's multi_logloss: 0.167746\tvalid_1's multi_logloss: 0.274621       \n",
      "[129]\ttraining's multi_logloss: 0.166555\tvalid_1's multi_logloss: 0.274308       \n",
      "[130]\ttraining's multi_logloss: 0.165458\tvalid_1's multi_logloss: 0.274186       \n",
      "[131]\ttraining's multi_logloss: 0.164273\tvalid_1's multi_logloss: 0.273935       \n",
      "[132]\ttraining's multi_logloss: 0.163097\tvalid_1's multi_logloss: 0.273672       \n",
      "[133]\ttraining's multi_logloss: 0.162032\tvalid_1's multi_logloss: 0.273389       \n",
      "[134]\ttraining's multi_logloss: 0.160958\tvalid_1's multi_logloss: 0.273236       \n",
      "[135]\ttraining's multi_logloss: 0.159837\tvalid_1's multi_logloss: 0.272969       \n",
      "[136]\ttraining's multi_logloss: 0.158683\tvalid_1's multi_logloss: 0.272801       \n",
      "[137]\ttraining's multi_logloss: 0.157581\tvalid_1's multi_logloss: 0.272486       \n",
      "[138]\ttraining's multi_logloss: 0.156544\tvalid_1's multi_logloss: 0.272246       \n",
      "[139]\ttraining's multi_logloss: 0.155571\tvalid_1's multi_logloss: 0.272159       \n",
      "[140]\ttraining's multi_logloss: 0.154524\tvalid_1's multi_logloss: 0.272036       \n",
      "[141]\ttraining's multi_logloss: 0.153461\tvalid_1's multi_logloss: 0.271869       \n",
      "[142]\ttraining's multi_logloss: 0.152414\tvalid_1's multi_logloss: 0.271817       \n",
      "[143]\ttraining's multi_logloss: 0.151503\tvalid_1's multi_logloss: 0.271744       \n",
      "[144]\ttraining's multi_logloss: 0.150508\tvalid_1's multi_logloss: 0.271554       \n",
      "[145]\ttraining's multi_logloss: 0.149559\tvalid_1's multi_logloss: 0.271464       \n",
      "[146]\ttraining's multi_logloss: 0.148562\tvalid_1's multi_logloss: 0.27123        \n",
      "[147]\ttraining's multi_logloss: 0.147583\tvalid_1's multi_logloss: 0.271097       \n",
      "[148]\ttraining's multi_logloss: 0.146625\tvalid_1's multi_logloss: 0.270974       \n",
      "[149]\ttraining's multi_logloss: 0.145627\tvalid_1's multi_logloss: 0.270819       \n",
      "[150]\ttraining's multi_logloss: 0.14466\tvalid_1's multi_logloss: 0.270622        \n",
      "[151]\ttraining's multi_logloss: 0.143766\tvalid_1's multi_logloss: 0.270503       \n",
      "[152]\ttraining's multi_logloss: 0.14283\tvalid_1's multi_logloss: 0.270353        \n",
      "[153]\ttraining's multi_logloss: 0.1419\tvalid_1's multi_logloss: 0.270165         \n",
      "[154]\ttraining's multi_logloss: 0.141003\tvalid_1's multi_logloss: 0.269946       \n",
      "[155]\ttraining's multi_logloss: 0.140127\tvalid_1's multi_logloss: 0.269797       \n",
      "[156]\ttraining's multi_logloss: 0.13925\tvalid_1's multi_logloss: 0.269639        \n",
      "[157]\ttraining's multi_logloss: 0.138373\tvalid_1's multi_logloss: 0.269559       \n",
      "[158]\ttraining's multi_logloss: 0.137548\tvalid_1's multi_logloss: 0.269568       \n",
      "[159]\ttraining's multi_logloss: 0.13664\tvalid_1's multi_logloss: 0.269421        \n",
      "[160]\ttraining's multi_logloss: 0.135828\tvalid_1's multi_logloss: 0.269244       \n",
      "[161]\ttraining's multi_logloss: 0.134965\tvalid_1's multi_logloss: 0.269083       \n",
      "[162]\ttraining's multi_logloss: 0.134167\tvalid_1's multi_logloss: 0.269015       \n",
      "[163]\ttraining's multi_logloss: 0.133415\tvalid_1's multi_logloss: 0.268973       \n",
      "[164]\ttraining's multi_logloss: 0.132644\tvalid_1's multi_logloss: 0.268911       \n",
      "[165]\ttraining's multi_logloss: 0.1319\tvalid_1's multi_logloss: 0.268837         \n",
      "[166]\ttraining's multi_logloss: 0.131177\tvalid_1's multi_logloss: 0.268676       \n",
      "[167]\ttraining's multi_logloss: 0.130441\tvalid_1's multi_logloss: 0.268677       \n",
      "[168]\ttraining's multi_logloss: 0.129683\tvalid_1's multi_logloss: 0.268749       \n",
      "[169]\ttraining's multi_logloss: 0.12894\tvalid_1's multi_logloss: 0.268572        \n",
      "[170]\ttraining's multi_logloss: 0.128202\tvalid_1's multi_logloss: 0.268514       \n",
      "[171]\ttraining's multi_logloss: 0.127488\tvalid_1's multi_logloss: 0.268473       \n",
      "[172]\ttraining's multi_logloss: 0.126715\tvalid_1's multi_logloss: 0.26829        \n",
      "[173]\ttraining's multi_logloss: 0.126027\tvalid_1's multi_logloss: 0.268225       \n",
      "[174]\ttraining's multi_logloss: 0.125283\tvalid_1's multi_logloss: 0.268159       \n",
      "[175]\ttraining's multi_logloss: 0.124592\tvalid_1's multi_logloss: 0.268081       \n",
      "[176]\ttraining's multi_logloss: 0.12388\tvalid_1's multi_logloss: 0.268096        \n",
      "[177]\ttraining's multi_logloss: 0.123235\tvalid_1's multi_logloss: 0.268122       \n",
      "[178]\ttraining's multi_logloss: 0.122514\tvalid_1's multi_logloss: 0.268078       \n",
      "[179]\ttraining's multi_logloss: 0.121863\tvalid_1's multi_logloss: 0.268112       \n",
      "[180]\ttraining's multi_logloss: 0.121182\tvalid_1's multi_logloss: 0.268198       \n",
      "[181]\ttraining's multi_logloss: 0.120521\tvalid_1's multi_logloss: 0.268151       \n",
      "[182]\ttraining's multi_logloss: 0.119865\tvalid_1's multi_logloss: 0.268181       \n",
      "[183]\ttraining's multi_logloss: 0.119249\tvalid_1's multi_logloss: 0.268167       \n",
      "[184]\ttraining's multi_logloss: 0.118616\tvalid_1's multi_logloss: 0.268284       \n",
      "[185]\ttraining's multi_logloss: 0.117904\tvalid_1's multi_logloss: 0.268328       \n",
      "[186]\ttraining's multi_logloss: 0.117226\tvalid_1's multi_logloss: 0.268381       \n",
      "[187]\ttraining's multi_logloss: 0.116604\tvalid_1's multi_logloss: 0.268532       \n",
      "[188]\ttraining's multi_logloss: 0.115917\tvalid_1's multi_logloss: 0.268516       \n",
      "[189]\ttraining's multi_logloss: 0.115289\tvalid_1's multi_logloss: 0.268476       \n",
      "[190]\ttraining's multi_logloss: 0.11465\tvalid_1's multi_logloss: 0.268475        \n",
      "[191]\ttraining's multi_logloss: 0.113991\tvalid_1's multi_logloss: 0.268624       \n",
      "[192]\ttraining's multi_logloss: 0.113282\tvalid_1's multi_logloss: 0.268709       \n",
      "[193]\ttraining's multi_logloss: 0.112696\tvalid_1's multi_logloss: 0.268798       \n",
      "[194]\ttraining's multi_logloss: 0.112056\tvalid_1's multi_logloss: 0.268831       \n",
      "[195]\ttraining's multi_logloss: 0.111433\tvalid_1's multi_logloss: 0.268851       \n",
      "[196]\ttraining's multi_logloss: 0.110874\tvalid_1's multi_logloss: 0.268871       \n",
      "[197]\ttraining's multi_logloss: 0.11028\tvalid_1's multi_logloss: 0.268899        \n",
      "[198]\ttraining's multi_logloss: 0.109724\tvalid_1's multi_logloss: 0.269036       \n",
      "[199]\ttraining's multi_logloss: 0.109091\tvalid_1's multi_logloss: 0.269031       \n",
      "[200]\ttraining's multi_logloss: 0.108427\tvalid_1's multi_logloss: 0.26904        \n",
      "[201]\ttraining's multi_logloss: 0.107863\tvalid_1's multi_logloss: 0.269173       \n",
      "[202]\ttraining's multi_logloss: 0.10731\tvalid_1's multi_logloss: 0.269107        \n",
      "[203]\ttraining's multi_logloss: 0.106708\tvalid_1's multi_logloss: 0.269146       \n",
      "[204]\ttraining's multi_logloss: 0.106037\tvalid_1's multi_logloss: 0.269075       \n",
      "[205]\ttraining's multi_logloss: 0.10546\tvalid_1's multi_logloss: 0.269146        \n",
      "[206]\ttraining's multi_logloss: 0.104869\tvalid_1's multi_logloss: 0.26907        \n",
      "[207]\ttraining's multi_logloss: 0.104301\tvalid_1's multi_logloss: 0.268943       \n",
      "[208]\ttraining's multi_logloss: 0.103781\tvalid_1's multi_logloss: 0.269077       \n",
      "Early stopping, best iteration is:                                               \n",
      "[178]\ttraining's multi_logloss: 0.122514\tvalid_1's multi_logloss: 0.268078\n",
      "[1]\ttraining's multi_logloss: 1.36333\tvalid_1's multi_logloss: 1.37663           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.07623\tvalid_1's multi_logloss: 1.09925           \n",
      "[3]\ttraining's multi_logloss: 0.887211\tvalid_1's multi_logloss: 0.917784         \n",
      "[4]\ttraining's multi_logloss: 0.750743\tvalid_1's multi_logloss: 0.786803         \n",
      "[5]\ttraining's multi_logloss: 0.646022\tvalid_1's multi_logloss: 0.686747         \n",
      "[6]\ttraining's multi_logloss: 0.564702\tvalid_1's multi_logloss: 0.610199         \n",
      "[7]\ttraining's multi_logloss: 0.49969\tvalid_1's multi_logloss: 0.551072          \n",
      "[8]\ttraining's multi_logloss: 0.446904\tvalid_1's multi_logloss: 0.50301          \n",
      "[9]\ttraining's multi_logloss: 0.403788\tvalid_1's multi_logloss: 0.46455          \n",
      "[10]\ttraining's multi_logloss: 0.368422\tvalid_1's multi_logloss: 0.433467        \n",
      "[11]\ttraining's multi_logloss: 0.339355\tvalid_1's multi_logloss: 0.409298        \n",
      "[12]\ttraining's multi_logloss: 0.314046\tvalid_1's multi_logloss: 0.388896        \n",
      "[13]\ttraining's multi_logloss: 0.292781\tvalid_1's multi_logloss: 0.373257        \n",
      "[14]\ttraining's multi_logloss: 0.27426\tvalid_1's multi_logloss: 0.359285         \n",
      "[15]\ttraining's multi_logloss: 0.257657\tvalid_1's multi_logloss: 0.347523        \n",
      "[16]\ttraining's multi_logloss: 0.243101\tvalid_1's multi_logloss: 0.338952        \n",
      "[17]\ttraining's multi_logloss: 0.230579\tvalid_1's multi_logloss: 0.33177         \n",
      "[18]\ttraining's multi_logloss: 0.218907\tvalid_1's multi_logloss: 0.324397        \n",
      "[19]\ttraining's multi_logloss: 0.208498\tvalid_1's multi_logloss: 0.318874        \n",
      "[20]\ttraining's multi_logloss: 0.198567\tvalid_1's multi_logloss: 0.314132        \n",
      "[21]\ttraining's multi_logloss: 0.189187\tvalid_1's multi_logloss: 0.310151        \n",
      "[22]\ttraining's multi_logloss: 0.180728\tvalid_1's multi_logloss: 0.307171        \n",
      "[23]\ttraining's multi_logloss: 0.172713\tvalid_1's multi_logloss: 0.3041          \n",
      "[24]\ttraining's multi_logloss: 0.16553\tvalid_1's multi_logloss: 0.301878         \n",
      "[25]\ttraining's multi_logloss: 0.158538\tvalid_1's multi_logloss: 0.300537        \n",
      "[26]\ttraining's multi_logloss: 0.151803\tvalid_1's multi_logloss: 0.298921        \n",
      "[27]\ttraining's multi_logloss: 0.145686\tvalid_1's multi_logloss: 0.298069        \n",
      "[28]\ttraining's multi_logloss: 0.139811\tvalid_1's multi_logloss: 0.297391        \n",
      "[29]\ttraining's multi_logloss: 0.13414\tvalid_1's multi_logloss: 0.296741         \n",
      "[30]\ttraining's multi_logloss: 0.128716\tvalid_1's multi_logloss: 0.29708         \n",
      "[31]\ttraining's multi_logloss: 0.12394\tvalid_1's multi_logloss: 0.296919         \n",
      "[32]\ttraining's multi_logloss: 0.119486\tvalid_1's multi_logloss: 0.296593        \n",
      "[33]\ttraining's multi_logloss: 0.114964\tvalid_1's multi_logloss: 0.296281        \n",
      "[34]\ttraining's multi_logloss: 0.110627\tvalid_1's multi_logloss: 0.296588        \n",
      "[35]\ttraining's multi_logloss: 0.106265\tvalid_1's multi_logloss: 0.296094        \n",
      "[36]\ttraining's multi_logloss: 0.10194\tvalid_1's multi_logloss: 0.295861         \n",
      "[37]\ttraining's multi_logloss: 0.0984867\tvalid_1's multi_logloss: 0.295995       \n",
      "[38]\ttraining's multi_logloss: 0.0947897\tvalid_1's multi_logloss: 0.296182       \n",
      "[39]\ttraining's multi_logloss: 0.0912298\tvalid_1's multi_logloss: 0.296753       \n",
      "[40]\ttraining's multi_logloss: 0.0882249\tvalid_1's multi_logloss: 0.297405       \n",
      "[41]\ttraining's multi_logloss: 0.0852148\tvalid_1's multi_logloss: 0.297721       \n",
      "[42]\ttraining's multi_logloss: 0.0823122\tvalid_1's multi_logloss: 0.29866        \n",
      "[43]\ttraining's multi_logloss: 0.0793783\tvalid_1's multi_logloss: 0.2987         \n",
      "[44]\ttraining's multi_logloss: 0.0768252\tvalid_1's multi_logloss: 0.29942        \n",
      "[45]\ttraining's multi_logloss: 0.0741476\tvalid_1's multi_logloss: 0.300172       \n",
      "[46]\ttraining's multi_logloss: 0.0716143\tvalid_1's multi_logloss: 0.30103        \n",
      "[47]\ttraining's multi_logloss: 0.0691893\tvalid_1's multi_logloss: 0.302082       \n",
      "[48]\ttraining's multi_logloss: 0.0668006\tvalid_1's multi_logloss: 0.303514       \n",
      "[49]\ttraining's multi_logloss: 0.0646069\tvalid_1's multi_logloss: 0.304532       \n",
      "[50]\ttraining's multi_logloss: 0.0624773\tvalid_1's multi_logloss: 0.305348       \n",
      "[51]\ttraining's multi_logloss: 0.0605124\tvalid_1's multi_logloss: 0.307212       \n",
      "[52]\ttraining's multi_logloss: 0.0586923\tvalid_1's multi_logloss: 0.308323       \n",
      "[53]\ttraining's multi_logloss: 0.0569723\tvalid_1's multi_logloss: 0.309521       \n",
      "[54]\ttraining's multi_logloss: 0.0551309\tvalid_1's multi_logloss: 0.310102       \n",
      "[55]\ttraining's multi_logloss: 0.0535525\tvalid_1's multi_logloss: 0.311116       \n",
      "[56]\ttraining's multi_logloss: 0.0518584\tvalid_1's multi_logloss: 0.312016       \n",
      "[57]\ttraining's multi_logloss: 0.0502732\tvalid_1's multi_logloss: 0.313204       \n",
      "[58]\ttraining's multi_logloss: 0.048555\tvalid_1's multi_logloss: 0.314509        \n",
      "[59]\ttraining's multi_logloss: 0.0470742\tvalid_1's multi_logloss: 0.315544       \n",
      "[60]\ttraining's multi_logloss: 0.0456747\tvalid_1's multi_logloss: 0.317011       \n",
      "[61]\ttraining's multi_logloss: 0.0441782\tvalid_1's multi_logloss: 0.317629       \n",
      "[62]\ttraining's multi_logloss: 0.0425026\tvalid_1's multi_logloss: 0.319304       \n",
      "[63]\ttraining's multi_logloss: 0.0412876\tvalid_1's multi_logloss: 0.320798       \n",
      "[64]\ttraining's multi_logloss: 0.0398467\tvalid_1's multi_logloss: 0.321791       \n",
      "[65]\ttraining's multi_logloss: 0.0384636\tvalid_1's multi_logloss: 0.323304       \n",
      "[66]\ttraining's multi_logloss: 0.0372834\tvalid_1's multi_logloss: 0.324278       \n",
      "Early stopping, best iteration is:                                               \n",
      "[36]\ttraining's multi_logloss: 0.10194\tvalid_1's multi_logloss: 0.295861\n",
      "[1]\ttraining's multi_logloss: 1.36051\tvalid_1's multi_logloss: 1.36758           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.07813\tvalid_1's multi_logloss: 1.09071           \n",
      "[3]\ttraining's multi_logloss: 0.890076\tvalid_1's multi_logloss: 0.908203         \n",
      "[4]\ttraining's multi_logloss: 0.753408\tvalid_1's multi_logloss: 0.775931         \n",
      "[5]\ttraining's multi_logloss: 0.650554\tvalid_1's multi_logloss: 0.67803          \n",
      "[6]\ttraining's multi_logloss: 0.56831\tvalid_1's multi_logloss: 0.600499          \n",
      "[7]\ttraining's multi_logloss: 0.50429\tvalid_1's multi_logloss: 0.540809          \n",
      "[8]\ttraining's multi_logloss: 0.451533\tvalid_1's multi_logloss: 0.493094         \n",
      "[9]\ttraining's multi_logloss: 0.408448\tvalid_1's multi_logloss: 0.45564          \n",
      "[10]\ttraining's multi_logloss: 0.372805\tvalid_1's multi_logloss: 0.425717        \n",
      "[11]\ttraining's multi_logloss: 0.343074\tvalid_1's multi_logloss: 0.401106        \n",
      "[12]\ttraining's multi_logloss: 0.317836\tvalid_1's multi_logloss: 0.381506        \n",
      "[13]\ttraining's multi_logloss: 0.296306\tvalid_1's multi_logloss: 0.365378        \n",
      "[14]\ttraining's multi_logloss: 0.277219\tvalid_1's multi_logloss: 0.351146        \n",
      "[15]\ttraining's multi_logloss: 0.260275\tvalid_1's multi_logloss: 0.33933         \n",
      "[16]\ttraining's multi_logloss: 0.245119\tvalid_1's multi_logloss: 0.330633        \n",
      "[17]\ttraining's multi_logloss: 0.231618\tvalid_1's multi_logloss: 0.321953        \n",
      "[18]\ttraining's multi_logloss: 0.219474\tvalid_1's multi_logloss: 0.31622         \n",
      "[19]\ttraining's multi_logloss: 0.208458\tvalid_1's multi_logloss: 0.31125         \n",
      "[20]\ttraining's multi_logloss: 0.198061\tvalid_1's multi_logloss: 0.30665         \n",
      "[21]\ttraining's multi_logloss: 0.188595\tvalid_1's multi_logloss: 0.302894        \n",
      "[22]\ttraining's multi_logloss: 0.180253\tvalid_1's multi_logloss: 0.300463        \n",
      "[23]\ttraining's multi_logloss: 0.172247\tvalid_1's multi_logloss: 0.298781        \n",
      "[24]\ttraining's multi_logloss: 0.165339\tvalid_1's multi_logloss: 0.297907        \n",
      "[25]\ttraining's multi_logloss: 0.158171\tvalid_1's multi_logloss: 0.296211        \n",
      "[26]\ttraining's multi_logloss: 0.151295\tvalid_1's multi_logloss: 0.295127        \n",
      "[27]\ttraining's multi_logloss: 0.145102\tvalid_1's multi_logloss: 0.294128        \n",
      "[28]\ttraining's multi_logloss: 0.138969\tvalid_1's multi_logloss: 0.293307        \n",
      "[29]\ttraining's multi_logloss: 0.133224\tvalid_1's multi_logloss: 0.292633        \n",
      "[30]\ttraining's multi_logloss: 0.127902\tvalid_1's multi_logloss: 0.292466        \n",
      "[31]\ttraining's multi_logloss: 0.122494\tvalid_1's multi_logloss: 0.292552        \n",
      "[32]\ttraining's multi_logloss: 0.117707\tvalid_1's multi_logloss: 0.292172        \n",
      "[33]\ttraining's multi_logloss: 0.112985\tvalid_1's multi_logloss: 0.291926        \n",
      "[34]\ttraining's multi_logloss: 0.10837\tvalid_1's multi_logloss: 0.292388         \n",
      "[35]\ttraining's multi_logloss: 0.104235\tvalid_1's multi_logloss: 0.291969        \n",
      "[36]\ttraining's multi_logloss: 0.100291\tvalid_1's multi_logloss: 0.292749        \n",
      "[37]\ttraining's multi_logloss: 0.0966801\tvalid_1's multi_logloss: 0.293032       \n",
      "[38]\ttraining's multi_logloss: 0.0928798\tvalid_1's multi_logloss: 0.293808       \n",
      "[39]\ttraining's multi_logloss: 0.0891272\tvalid_1's multi_logloss: 0.294655       \n",
      "[40]\ttraining's multi_logloss: 0.0859218\tvalid_1's multi_logloss: 0.295146       \n",
      "[41]\ttraining's multi_logloss: 0.0826426\tvalid_1's multi_logloss: 0.295503       \n",
      "[42]\ttraining's multi_logloss: 0.0798357\tvalid_1's multi_logloss: 0.295962       \n",
      "[43]\ttraining's multi_logloss: 0.076983\tvalid_1's multi_logloss: 0.296735        \n",
      "[44]\ttraining's multi_logloss: 0.0744358\tvalid_1's multi_logloss: 0.297753       \n",
      "[45]\ttraining's multi_logloss: 0.0717776\tvalid_1's multi_logloss: 0.298699       \n",
      "[46]\ttraining's multi_logloss: 0.069347\tvalid_1's multi_logloss: 0.300208        \n",
      "[47]\ttraining's multi_logloss: 0.0668495\tvalid_1's multi_logloss: 0.300566       \n",
      "[48]\ttraining's multi_logloss: 0.0643988\tvalid_1's multi_logloss: 0.301639       \n",
      "[49]\ttraining's multi_logloss: 0.0623295\tvalid_1's multi_logloss: 0.302555       \n",
      "[50]\ttraining's multi_logloss: 0.060333\tvalid_1's multi_logloss: 0.303801        \n",
      "[51]\ttraining's multi_logloss: 0.058496\tvalid_1's multi_logloss: 0.304889        \n",
      "[52]\ttraining's multi_logloss: 0.0563792\tvalid_1's multi_logloss: 0.305537       \n",
      "[53]\ttraining's multi_logloss: 0.0545048\tvalid_1's multi_logloss: 0.306556       \n",
      "[54]\ttraining's multi_logloss: 0.0528344\tvalid_1's multi_logloss: 0.307849       \n",
      "[55]\ttraining's multi_logloss: 0.0511945\tvalid_1's multi_logloss: 0.309401       \n",
      "[56]\ttraining's multi_logloss: 0.0495907\tvalid_1's multi_logloss: 0.310472       \n",
      "[57]\ttraining's multi_logloss: 0.0479347\tvalid_1's multi_logloss: 0.310988       \n",
      "[58]\ttraining's multi_logloss: 0.0463281\tvalid_1's multi_logloss: 0.312087       \n",
      "[59]\ttraining's multi_logloss: 0.0447932\tvalid_1's multi_logloss: 0.313964       \n",
      "[60]\ttraining's multi_logloss: 0.0434323\tvalid_1's multi_logloss: 0.314969       \n",
      "[61]\ttraining's multi_logloss: 0.0421998\tvalid_1's multi_logloss: 0.316126       \n",
      "[62]\ttraining's multi_logloss: 0.0407441\tvalid_1's multi_logloss: 0.317661       \n",
      "[63]\ttraining's multi_logloss: 0.0393213\tvalid_1's multi_logloss: 0.318863       \n",
      "Early stopping, best iteration is:                                               \n",
      "[33]\ttraining's multi_logloss: 0.112985\tvalid_1's multi_logloss: 0.291926\n",
      "[1]\ttraining's multi_logloss: 1.36318\tvalid_1's multi_logloss: 1.3697            \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.08139\tvalid_1's multi_logloss: 1.09161           \n",
      "[3]\ttraining's multi_logloss: 0.892866\tvalid_1's multi_logloss: 0.906477         \n",
      "[4]\ttraining's multi_logloss: 0.756741\tvalid_1's multi_logloss: 0.773208         \n",
      "[5]\ttraining's multi_logloss: 0.653346\tvalid_1's multi_logloss: 0.673576         \n",
      "[6]\ttraining's multi_logloss: 0.572766\tvalid_1's multi_logloss: 0.596985         \n",
      "[7]\ttraining's multi_logloss: 0.507388\tvalid_1's multi_logloss: 0.535283         \n",
      "[8]\ttraining's multi_logloss: 0.455768\tvalid_1's multi_logloss: 0.487131         \n",
      "[9]\ttraining's multi_logloss: 0.413612\tvalid_1's multi_logloss: 0.449528         \n",
      "[10]\ttraining's multi_logloss: 0.377953\tvalid_1's multi_logloss: 0.418057        \n",
      "[11]\ttraining's multi_logloss: 0.348624\tvalid_1's multi_logloss: 0.393583        \n",
      "[12]\ttraining's multi_logloss: 0.322363\tvalid_1's multi_logloss: 0.371179        \n",
      "[13]\ttraining's multi_logloss: 0.300711\tvalid_1's multi_logloss: 0.353327        \n",
      "[14]\ttraining's multi_logloss: 0.281748\tvalid_1's multi_logloss: 0.340382        \n",
      "[15]\ttraining's multi_logloss: 0.264997\tvalid_1's multi_logloss: 0.328681        \n",
      "[16]\ttraining's multi_logloss: 0.250232\tvalid_1's multi_logloss: 0.318631        \n",
      "[17]\ttraining's multi_logloss: 0.236938\tvalid_1's multi_logloss: 0.310949        \n",
      "[18]\ttraining's multi_logloss: 0.225048\tvalid_1's multi_logloss: 0.304062        \n",
      "[19]\ttraining's multi_logloss: 0.213958\tvalid_1's multi_logloss: 0.298753        \n",
      "[20]\ttraining's multi_logloss: 0.204244\tvalid_1's multi_logloss: 0.294182        \n",
      "[21]\ttraining's multi_logloss: 0.195212\tvalid_1's multi_logloss: 0.290333        \n",
      "[22]\ttraining's multi_logloss: 0.186321\tvalid_1's multi_logloss: 0.287626        \n",
      "[23]\ttraining's multi_logloss: 0.178321\tvalid_1's multi_logloss: 0.285126        \n",
      "[24]\ttraining's multi_logloss: 0.171085\tvalid_1's multi_logloss: 0.283564        \n",
      "[25]\ttraining's multi_logloss: 0.163849\tvalid_1's multi_logloss: 0.281986        \n",
      "[26]\ttraining's multi_logloss: 0.157224\tvalid_1's multi_logloss: 0.280505        \n",
      "[27]\ttraining's multi_logloss: 0.151\tvalid_1's multi_logloss: 0.279734           \n",
      "[28]\ttraining's multi_logloss: 0.144685\tvalid_1's multi_logloss: 0.27828         \n",
      "[29]\ttraining's multi_logloss: 0.139077\tvalid_1's multi_logloss: 0.27749         \n",
      "[30]\ttraining's multi_logloss: 0.133732\tvalid_1's multi_logloss: 0.277002        \n",
      "[31]\ttraining's multi_logloss: 0.128344\tvalid_1's multi_logloss: 0.276677        \n",
      "[32]\ttraining's multi_logloss: 0.12309\tvalid_1's multi_logloss: 0.275844         \n",
      "[33]\ttraining's multi_logloss: 0.118457\tvalid_1's multi_logloss: 0.275512        \n",
      "[34]\ttraining's multi_logloss: 0.113754\tvalid_1's multi_logloss: 0.274541        \n",
      "[35]\ttraining's multi_logloss: 0.109136\tvalid_1's multi_logloss: 0.274119        \n",
      "[36]\ttraining's multi_logloss: 0.104794\tvalid_1's multi_logloss: 0.273904        \n",
      "[37]\ttraining's multi_logloss: 0.100896\tvalid_1's multi_logloss: 0.273829        \n",
      "[38]\ttraining's multi_logloss: 0.0971762\tvalid_1's multi_logloss: 0.274506       \n",
      "[39]\ttraining's multi_logloss: 0.093712\tvalid_1's multi_logloss: 0.274687        \n",
      "[40]\ttraining's multi_logloss: 0.0903061\tvalid_1's multi_logloss: 0.275607       \n",
      "[41]\ttraining's multi_logloss: 0.0870307\tvalid_1's multi_logloss: 0.275797       \n",
      "[42]\ttraining's multi_logloss: 0.0840232\tvalid_1's multi_logloss: 0.276498       \n",
      "[43]\ttraining's multi_logloss: 0.0812266\tvalid_1's multi_logloss: 0.276805       \n",
      "[44]\ttraining's multi_logloss: 0.0783509\tvalid_1's multi_logloss: 0.277026       \n",
      "[45]\ttraining's multi_logloss: 0.0756563\tvalid_1's multi_logloss: 0.277893       \n",
      "[46]\ttraining's multi_logloss: 0.0732138\tvalid_1's multi_logloss: 0.279117       \n",
      "[47]\ttraining's multi_logloss: 0.0708053\tvalid_1's multi_logloss: 0.279199       \n",
      "[48]\ttraining's multi_logloss: 0.0685981\tvalid_1's multi_logloss: 0.279956       \n",
      "[49]\ttraining's multi_logloss: 0.0663171\tvalid_1's multi_logloss: 0.280312       \n",
      "[50]\ttraining's multi_logloss: 0.0642965\tvalid_1's multi_logloss: 0.28035        \n",
      "[51]\ttraining's multi_logloss: 0.0621946\tvalid_1's multi_logloss: 0.280943       \n",
      "[52]\ttraining's multi_logloss: 0.060202\tvalid_1's multi_logloss: 0.282135        \n",
      "[53]\ttraining's multi_logloss: 0.0582869\tvalid_1's multi_logloss: 0.28293        \n",
      "[54]\ttraining's multi_logloss: 0.0564824\tvalid_1's multi_logloss: 0.283257       \n",
      "[55]\ttraining's multi_logloss: 0.0547511\tvalid_1's multi_logloss: 0.284275       \n",
      "[56]\ttraining's multi_logloss: 0.0530134\tvalid_1's multi_logloss: 0.285031       \n",
      "[57]\ttraining's multi_logloss: 0.0514811\tvalid_1's multi_logloss: 0.28631        \n",
      "[58]\ttraining's multi_logloss: 0.0499798\tvalid_1's multi_logloss: 0.287403       \n",
      "[59]\ttraining's multi_logloss: 0.0482975\tvalid_1's multi_logloss: 0.288317       \n",
      "[60]\ttraining's multi_logloss: 0.0468683\tvalid_1's multi_logloss: 0.289006       \n",
      "[61]\ttraining's multi_logloss: 0.0453538\tvalid_1's multi_logloss: 0.290054       \n",
      "[62]\ttraining's multi_logloss: 0.043932\tvalid_1's multi_logloss: 0.291591        \n",
      "[63]\ttraining's multi_logloss: 0.0424981\tvalid_1's multi_logloss: 0.292106       \n",
      "[64]\ttraining's multi_logloss: 0.041177\tvalid_1's multi_logloss: 0.293322        \n",
      "[65]\ttraining's multi_logloss: 0.0398417\tvalid_1's multi_logloss: 0.29406        \n",
      "[66]\ttraining's multi_logloss: 0.0386665\tvalid_1's multi_logloss: 0.294704       \n",
      "[67]\ttraining's multi_logloss: 0.0375868\tvalid_1's multi_logloss: 0.296291       \n",
      "Early stopping, best iteration is:                                               \n",
      "[37]\ttraining's multi_logloss: 0.100896\tvalid_1's multi_logloss: 0.273829\n",
      "[1]\ttraining's multi_logloss: 1.88096\tvalid_1's multi_logloss: 1.87956           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.83305\tvalid_1's multi_logloss: 1.83295           \n",
      "[3]\ttraining's multi_logloss: 1.78779\tvalid_1's multi_logloss: 1.78894           \n",
      "[4]\ttraining's multi_logloss: 1.74494\tvalid_1's multi_logloss: 1.74721           \n",
      "[5]\ttraining's multi_logloss: 1.70414\tvalid_1's multi_logloss: 1.70757           \n",
      "[6]\ttraining's multi_logloss: 1.66527\tvalid_1's multi_logloss: 1.66975           \n",
      "[7]\ttraining's multi_logloss: 1.62832\tvalid_1's multi_logloss: 1.6338            \n",
      "[8]\ttraining's multi_logloss: 1.59298\tvalid_1's multi_logloss: 1.59941           \n",
      "[9]\ttraining's multi_logloss: 1.5591\tvalid_1's multi_logloss: 1.56659            \n",
      "[10]\ttraining's multi_logloss: 1.52652\tvalid_1's multi_logloss: 1.53494          \n",
      "[11]\ttraining's multi_logloss: 1.49531\tvalid_1's multi_logloss: 1.50461          \n",
      "[12]\ttraining's multi_logloss: 1.46528\tvalid_1's multi_logloss: 1.47549          \n",
      "[13]\ttraining's multi_logloss: 1.43654\tvalid_1's multi_logloss: 1.44746          \n",
      "[14]\ttraining's multi_logloss: 1.4087\tvalid_1's multi_logloss: 1.42046           \n",
      "[15]\ttraining's multi_logloss: 1.38177\tvalid_1's multi_logloss: 1.39424          \n",
      "[16]\ttraining's multi_logloss: 1.35584\tvalid_1's multi_logloss: 1.36903          \n",
      "[17]\ttraining's multi_logloss: 1.3307\tvalid_1's multi_logloss: 1.34456           \n",
      "[18]\ttraining's multi_logloss: 1.3065\tvalid_1's multi_logloss: 1.32107           \n",
      "[19]\ttraining's multi_logloss: 1.28297\tvalid_1's multi_logloss: 1.29828          \n",
      "[20]\ttraining's multi_logloss: 1.26036\tvalid_1's multi_logloss: 1.27632          \n",
      "[21]\ttraining's multi_logloss: 1.23833\tvalid_1's multi_logloss: 1.255            \n",
      "[22]\ttraining's multi_logloss: 1.21702\tvalid_1's multi_logloss: 1.23443          \n",
      "[23]\ttraining's multi_logloss: 1.19641\tvalid_1's multi_logloss: 1.21444          \n",
      "[24]\ttraining's multi_logloss: 1.17643\tvalid_1's multi_logloss: 1.19515          \n",
      "[25]\ttraining's multi_logloss: 1.15714\tvalid_1's multi_logloss: 1.17643          \n",
      "[26]\ttraining's multi_logloss: 1.13827\tvalid_1's multi_logloss: 1.15824          \n",
      "[27]\ttraining's multi_logloss: 1.11999\tvalid_1's multi_logloss: 1.14061          \n",
      "[28]\ttraining's multi_logloss: 1.10223\tvalid_1's multi_logloss: 1.12346          \n",
      "[29]\ttraining's multi_logloss: 1.0849\tvalid_1's multi_logloss: 1.10674           \n",
      "[30]\ttraining's multi_logloss: 1.0681\tvalid_1's multi_logloss: 1.09055           \n",
      "[31]\ttraining's multi_logloss: 1.05167\tvalid_1's multi_logloss: 1.07474          \n",
      "[32]\ttraining's multi_logloss: 1.03572\tvalid_1's multi_logloss: 1.0594           \n",
      "[33]\ttraining's multi_logloss: 1.02017\tvalid_1's multi_logloss: 1.04439          \n",
      "[34]\ttraining's multi_logloss: 1.00501\tvalid_1's multi_logloss: 1.02978          \n",
      "[35]\ttraining's multi_logloss: 0.990272\tvalid_1's multi_logloss: 1.01553         \n",
      "[36]\ttraining's multi_logloss: 0.975853\tvalid_1's multi_logloss: 1.00167         \n",
      "[37]\ttraining's multi_logloss: 0.961752\tvalid_1's multi_logloss: 0.988123        \n",
      "[38]\ttraining's multi_logloss: 0.947997\tvalid_1's multi_logloss: 0.974856        \n",
      "[39]\ttraining's multi_logloss: 0.93457\tvalid_1's multi_logloss: 0.961995         \n",
      "[40]\ttraining's multi_logloss: 0.921435\tvalid_1's multi_logloss: 0.949308        \n",
      "[41]\ttraining's multi_logloss: 0.908573\tvalid_1's multi_logloss: 0.936898        \n",
      "[42]\ttraining's multi_logloss: 0.896057\tvalid_1's multi_logloss: 0.924861        \n",
      "[43]\ttraining's multi_logloss: 0.883788\tvalid_1's multi_logloss: 0.913071        \n",
      "[44]\ttraining's multi_logloss: 0.87186\tvalid_1's multi_logloss: 0.901591         \n",
      "[45]\ttraining's multi_logloss: 0.860103\tvalid_1's multi_logloss: 0.890279        \n",
      "[46]\ttraining's multi_logloss: 0.848556\tvalid_1's multi_logloss: 0.879189        \n",
      "[47]\ttraining's multi_logloss: 0.837258\tvalid_1's multi_logloss: 0.868317        \n",
      "[48]\ttraining's multi_logloss: 0.826218\tvalid_1's multi_logloss: 0.857688        \n",
      "[49]\ttraining's multi_logloss: 0.815346\tvalid_1's multi_logloss: 0.847202        \n",
      "[50]\ttraining's multi_logloss: 0.80479\tvalid_1's multi_logloss: 0.837039         \n",
      "[51]\ttraining's multi_logloss: 0.794477\tvalid_1's multi_logloss: 0.827136        \n",
      "[52]\ttraining's multi_logloss: 0.784298\tvalid_1's multi_logloss: 0.817344        \n",
      "[53]\ttraining's multi_logloss: 0.774409\tvalid_1's multi_logloss: 0.80784         \n",
      "[54]\ttraining's multi_logloss: 0.764578\tvalid_1's multi_logloss: 0.798388        \n",
      "[55]\ttraining's multi_logloss: 0.755075\tvalid_1's multi_logloss: 0.78929         \n",
      "[56]\ttraining's multi_logloss: 0.745745\tvalid_1's multi_logloss: 0.780333        \n",
      "[57]\ttraining's multi_logloss: 0.736603\tvalid_1's multi_logloss: 0.771567        \n",
      "[58]\ttraining's multi_logloss: 0.727569\tvalid_1's multi_logloss: 0.762884        \n",
      "[59]\ttraining's multi_logloss: 0.718839\tvalid_1's multi_logloss: 0.754532        \n",
      "[60]\ttraining's multi_logloss: 0.710312\tvalid_1's multi_logloss: 0.746393        \n",
      "[61]\ttraining's multi_logloss: 0.701941\tvalid_1's multi_logloss: 0.738383        \n",
      "[62]\ttraining's multi_logloss: 0.69367\tvalid_1's multi_logloss: 0.730473         \n",
      "[63]\ttraining's multi_logloss: 0.685601\tvalid_1's multi_logloss: 0.722793        \n",
      "[64]\ttraining's multi_logloss: 0.677697\tvalid_1's multi_logloss: 0.715244        \n",
      "[65]\ttraining's multi_logloss: 0.669998\tvalid_1's multi_logloss: 0.7079          \n",
      "[66]\ttraining's multi_logloss: 0.662381\tvalid_1's multi_logloss: 0.700714        \n",
      "[67]\ttraining's multi_logloss: 0.654957\tvalid_1's multi_logloss: 0.693655        \n",
      "[68]\ttraining's multi_logloss: 0.647656\tvalid_1's multi_logloss: 0.686726        \n",
      "[69]\ttraining's multi_logloss: 0.64045\tvalid_1's multi_logloss: 0.67991          \n",
      "[70]\ttraining's multi_logloss: 0.633425\tvalid_1's multi_logloss: 0.673265        \n",
      "[71]\ttraining's multi_logloss: 0.62654\tvalid_1's multi_logloss: 0.666757         \n",
      "[72]\ttraining's multi_logloss: 0.619687\tvalid_1's multi_logloss: 0.660297        \n",
      "[73]\ttraining's multi_logloss: 0.613035\tvalid_1's multi_logloss: 0.654041        \n",
      "[74]\ttraining's multi_logloss: 0.606508\tvalid_1's multi_logloss: 0.647872        \n",
      "[75]\ttraining's multi_logloss: 0.599974\tvalid_1's multi_logloss: 0.641735        \n",
      "[76]\ttraining's multi_logloss: 0.593644\tvalid_1's multi_logloss: 0.635769        \n",
      "[77]\ttraining's multi_logloss: 0.587388\tvalid_1's multi_logloss: 0.629892        \n",
      "[78]\ttraining's multi_logloss: 0.581237\tvalid_1's multi_logloss: 0.624123        \n",
      "[79]\ttraining's multi_logloss: 0.5753\tvalid_1's multi_logloss: 0.61857           \n",
      "[80]\ttraining's multi_logloss: 0.569385\tvalid_1's multi_logloss: 0.613066        \n",
      "[81]\ttraining's multi_logloss: 0.563558\tvalid_1's multi_logloss: 0.607596        \n",
      "[82]\ttraining's multi_logloss: 0.557857\tvalid_1's multi_logloss: 0.602247        \n",
      "[83]\ttraining's multi_logloss: 0.552353\tvalid_1's multi_logloss: 0.597068        \n",
      "[84]\ttraining's multi_logloss: 0.546929\tvalid_1's multi_logloss: 0.592009        \n",
      "[85]\ttraining's multi_logloss: 0.541555\tvalid_1's multi_logloss: 0.586981        \n",
      "[86]\ttraining's multi_logloss: 0.53633\tvalid_1's multi_logloss: 0.582139         \n",
      "[87]\ttraining's multi_logloss: 0.531203\tvalid_1's multi_logloss: 0.57738         \n",
      "[88]\ttraining's multi_logloss: 0.526139\tvalid_1's multi_logloss: 0.572699        \n",
      "[89]\ttraining's multi_logloss: 0.521213\tvalid_1's multi_logloss: 0.568072        \n",
      "[90]\ttraining's multi_logloss: 0.516341\tvalid_1's multi_logloss: 0.563546        \n",
      "[91]\ttraining's multi_logloss: 0.51151\tvalid_1's multi_logloss: 0.559081         \n",
      "[92]\ttraining's multi_logloss: 0.50684\tvalid_1's multi_logloss: 0.554789         \n",
      "[93]\ttraining's multi_logloss: 0.502156\tvalid_1's multi_logloss: 0.550523        \n",
      "[94]\ttraining's multi_logloss: 0.497505\tvalid_1's multi_logloss: 0.546211        \n",
      "[95]\ttraining's multi_logloss: 0.492937\tvalid_1's multi_logloss: 0.541984        \n",
      "[96]\ttraining's multi_logloss: 0.488458\tvalid_1's multi_logloss: 0.537886        \n",
      "[97]\ttraining's multi_logloss: 0.484091\tvalid_1's multi_logloss: 0.533851        \n",
      "[98]\ttraining's multi_logloss: 0.479781\tvalid_1's multi_logloss: 0.529895        \n",
      "[99]\ttraining's multi_logloss: 0.47557\tvalid_1's multi_logloss: 0.526027         \n",
      "[100]\ttraining's multi_logloss: 0.471425\tvalid_1's multi_logloss: 0.522255       \n",
      "[101]\ttraining's multi_logloss: 0.467365\tvalid_1's multi_logloss: 0.518614       \n",
      "[102]\ttraining's multi_logloss: 0.463248\tvalid_1's multi_logloss: 0.514837       \n",
      "[103]\ttraining's multi_logloss: 0.459281\tvalid_1's multi_logloss: 0.511227       \n",
      "[104]\ttraining's multi_logloss: 0.455337\tvalid_1's multi_logloss: 0.507618       \n",
      "[105]\ttraining's multi_logloss: 0.451489\tvalid_1's multi_logloss: 0.504103       \n",
      "[106]\ttraining's multi_logloss: 0.447697\tvalid_1's multi_logloss: 0.500669       \n",
      "[107]\ttraining's multi_logloss: 0.443918\tvalid_1's multi_logloss: 0.49727        \n",
      "[108]\ttraining's multi_logloss: 0.440209\tvalid_1's multi_logloss: 0.493932       \n",
      "[109]\ttraining's multi_logloss: 0.436513\tvalid_1's multi_logloss: 0.49063        \n",
      "[110]\ttraining's multi_logloss: 0.432923\tvalid_1's multi_logloss: 0.487422       \n",
      "[111]\ttraining's multi_logloss: 0.429344\tvalid_1's multi_logloss: 0.48425        \n",
      "[112]\ttraining's multi_logloss: 0.425859\tvalid_1's multi_logloss: 0.481134       \n",
      "[113]\ttraining's multi_logloss: 0.422393\tvalid_1's multi_logloss: 0.47806        \n",
      "[114]\ttraining's multi_logloss: 0.41905\tvalid_1's multi_logloss: 0.475029        \n",
      "[115]\ttraining's multi_logloss: 0.415722\tvalid_1's multi_logloss: 0.472091       \n",
      "[116]\ttraining's multi_logloss: 0.412479\tvalid_1's multi_logloss: 0.469194       \n",
      "[117]\ttraining's multi_logloss: 0.409261\tvalid_1's multi_logloss: 0.466327       \n",
      "[118]\ttraining's multi_logloss: 0.406144\tvalid_1's multi_logloss: 0.463543       \n",
      "[119]\ttraining's multi_logloss: 0.403054\tvalid_1's multi_logloss: 0.460789       \n",
      "[120]\ttraining's multi_logloss: 0.399979\tvalid_1's multi_logloss: 0.458047       \n",
      "[121]\ttraining's multi_logloss: 0.396988\tvalid_1's multi_logloss: 0.455415       \n",
      "[122]\ttraining's multi_logloss: 0.394026\tvalid_1's multi_logloss: 0.452851       \n",
      "[123]\ttraining's multi_logloss: 0.391138\tvalid_1's multi_logloss: 0.450303       \n",
      "[124]\ttraining's multi_logloss: 0.388269\tvalid_1's multi_logloss: 0.447705       \n",
      "[125]\ttraining's multi_logloss: 0.385468\tvalid_1's multi_logloss: 0.445286       \n",
      "[126]\ttraining's multi_logloss: 0.382691\tvalid_1's multi_logloss: 0.442804       \n",
      "[127]\ttraining's multi_logloss: 0.379982\tvalid_1's multi_logloss: 0.440417       \n",
      "[128]\ttraining's multi_logloss: 0.377291\tvalid_1's multi_logloss: 0.438057       \n",
      "[129]\ttraining's multi_logloss: 0.3746\tvalid_1's multi_logloss: 0.435667         \n",
      "[130]\ttraining's multi_logloss: 0.371944\tvalid_1's multi_logloss: 0.433372       \n",
      "[131]\ttraining's multi_logloss: 0.369371\tvalid_1's multi_logloss: 0.43111        \n",
      "[132]\ttraining's multi_logloss: 0.366822\tvalid_1's multi_logloss: 0.428891       \n",
      "[133]\ttraining's multi_logloss: 0.364289\tvalid_1's multi_logloss: 0.426689       \n",
      "[134]\ttraining's multi_logloss: 0.361831\tvalid_1's multi_logloss: 0.424542       \n",
      "[135]\ttraining's multi_logloss: 0.359396\tvalid_1's multi_logloss: 0.42244        \n",
      "[136]\ttraining's multi_logloss: 0.35697\tvalid_1's multi_logloss: 0.420331        \n",
      "[137]\ttraining's multi_logloss: 0.354581\tvalid_1's multi_logloss: 0.418312       \n",
      "[138]\ttraining's multi_logloss: 0.352271\tvalid_1's multi_logloss: 0.416317       \n",
      "[139]\ttraining's multi_logloss: 0.349992\tvalid_1's multi_logloss: 0.41436        \n",
      "[140]\ttraining's multi_logloss: 0.347748\tvalid_1's multi_logloss: 0.412445       \n",
      "[141]\ttraining's multi_logloss: 0.345538\tvalid_1's multi_logloss: 0.410568       \n",
      "[142]\ttraining's multi_logloss: 0.343369\tvalid_1's multi_logloss: 0.408769       \n",
      "[143]\ttraining's multi_logloss: 0.341232\tvalid_1's multi_logloss: 0.40702        \n",
      "[144]\ttraining's multi_logloss: 0.339105\tvalid_1's multi_logloss: 0.405281       \n",
      "[145]\ttraining's multi_logloss: 0.336998\tvalid_1's multi_logloss: 0.40353        \n",
      "[146]\ttraining's multi_logloss: 0.334938\tvalid_1's multi_logloss: 0.401842       \n",
      "[147]\ttraining's multi_logloss: 0.332879\tvalid_1's multi_logloss: 0.400162       \n",
      "[148]\ttraining's multi_logloss: 0.330874\tvalid_1's multi_logloss: 0.398507       \n",
      "[149]\ttraining's multi_logloss: 0.328835\tvalid_1's multi_logloss: 0.396879       \n",
      "[150]\ttraining's multi_logloss: 0.326878\tvalid_1's multi_logloss: 0.395278       \n",
      "[151]\ttraining's multi_logloss: 0.32489\tvalid_1's multi_logloss: 0.393648        \n",
      "[152]\ttraining's multi_logloss: 0.32299\tvalid_1's multi_logloss: 0.392102        \n",
      "[153]\ttraining's multi_logloss: 0.321061\tvalid_1's multi_logloss: 0.390541       \n",
      "[154]\ttraining's multi_logloss: 0.319206\tvalid_1's multi_logloss: 0.389078       \n",
      "[155]\ttraining's multi_logloss: 0.317329\tvalid_1's multi_logloss: 0.387549       \n",
      "[156]\ttraining's multi_logloss: 0.315452\tvalid_1's multi_logloss: 0.386002       \n",
      "[157]\ttraining's multi_logloss: 0.313643\tvalid_1's multi_logloss: 0.384537       \n",
      "[158]\ttraining's multi_logloss: 0.311817\tvalid_1's multi_logloss: 0.383057       \n",
      "[159]\ttraining's multi_logloss: 0.31006\tvalid_1's multi_logloss: 0.381679        \n",
      "[160]\ttraining's multi_logloss: 0.308291\tvalid_1's multi_logloss: 0.380277       \n",
      "[161]\ttraining's multi_logloss: 0.306539\tvalid_1's multi_logloss: 0.378923       \n",
      "[162]\ttraining's multi_logloss: 0.304831\tvalid_1's multi_logloss: 0.377579       \n",
      "[163]\ttraining's multi_logloss: 0.303118\tvalid_1's multi_logloss: 0.376265       \n",
      "[164]\ttraining's multi_logloss: 0.301428\tvalid_1's multi_logloss: 0.374937       \n",
      "[165]\ttraining's multi_logloss: 0.299804\tvalid_1's multi_logloss: 0.373654       \n",
      "[166]\ttraining's multi_logloss: 0.29815\tvalid_1's multi_logloss: 0.372393        \n",
      "[167]\ttraining's multi_logloss: 0.296586\tvalid_1's multi_logloss: 0.371164       \n",
      "[168]\ttraining's multi_logloss: 0.294988\tvalid_1's multi_logloss: 0.369883       \n",
      "[169]\ttraining's multi_logloss: 0.293427\tvalid_1's multi_logloss: 0.368694       \n",
      "[170]\ttraining's multi_logloss: 0.2919\tvalid_1's multi_logloss: 0.367472         \n",
      "[171]\ttraining's multi_logloss: 0.290376\tvalid_1's multi_logloss: 0.366323       \n",
      "[172]\ttraining's multi_logloss: 0.288895\tvalid_1's multi_logloss: 0.365161       \n",
      "[173]\ttraining's multi_logloss: 0.287351\tvalid_1's multi_logloss: 0.363947       \n",
      "[174]\ttraining's multi_logloss: 0.285843\tvalid_1's multi_logloss: 0.362847       \n",
      "[175]\ttraining's multi_logloss: 0.284339\tvalid_1's multi_logloss: 0.361707       \n",
      "[176]\ttraining's multi_logloss: 0.282883\tvalid_1's multi_logloss: 0.360615       \n",
      "[177]\ttraining's multi_logloss: 0.281463\tvalid_1's multi_logloss: 0.359525       \n",
      "[178]\ttraining's multi_logloss: 0.280057\tvalid_1's multi_logloss: 0.358496       \n",
      "[179]\ttraining's multi_logloss: 0.278679\tvalid_1's multi_logloss: 0.357464       \n",
      "[180]\ttraining's multi_logloss: 0.277277\tvalid_1's multi_logloss: 0.356465       \n",
      "[181]\ttraining's multi_logloss: 0.275852\tvalid_1's multi_logloss: 0.355459       \n",
      "[182]\ttraining's multi_logloss: 0.2745\tvalid_1's multi_logloss: 0.354501         \n",
      "[183]\ttraining's multi_logloss: 0.273172\tvalid_1's multi_logloss: 0.353574       \n",
      "[184]\ttraining's multi_logloss: 0.271849\tvalid_1's multi_logloss: 0.352627       \n",
      "[185]\ttraining's multi_logloss: 0.270565\tvalid_1's multi_logloss: 0.351721       \n",
      "[186]\ttraining's multi_logloss: 0.269214\tvalid_1's multi_logloss: 0.350762       \n",
      "[187]\ttraining's multi_logloss: 0.267914\tvalid_1's multi_logloss: 0.34985        \n",
      "[188]\ttraining's multi_logloss: 0.266617\tvalid_1's multi_logloss: 0.348984       \n",
      "[189]\ttraining's multi_logloss: 0.265299\tvalid_1's multi_logloss: 0.348082       \n",
      "[190]\ttraining's multi_logloss: 0.264016\tvalid_1's multi_logloss: 0.3472         \n",
      "[191]\ttraining's multi_logloss: 0.262722\tvalid_1's multi_logloss: 0.346359       \n",
      "[192]\ttraining's multi_logloss: 0.261506\tvalid_1's multi_logloss: 0.345598       \n",
      "[193]\ttraining's multi_logloss: 0.260288\tvalid_1's multi_logloss: 0.344805       \n",
      "[194]\ttraining's multi_logloss: 0.2591\tvalid_1's multi_logloss: 0.344075         \n",
      "[195]\ttraining's multi_logloss: 0.257883\tvalid_1's multi_logloss: 0.343282       \n",
      "[196]\ttraining's multi_logloss: 0.256691\tvalid_1's multi_logloss: 0.342478       \n",
      "[197]\ttraining's multi_logloss: 0.255501\tvalid_1's multi_logloss: 0.341755       \n",
      "[198]\ttraining's multi_logloss: 0.254361\tvalid_1's multi_logloss: 0.340991       \n",
      "[199]\ttraining's multi_logloss: 0.25321\tvalid_1's multi_logloss: 0.340244        \n",
      "[200]\ttraining's multi_logloss: 0.252064\tvalid_1's multi_logloss: 0.339478       \n",
      "[201]\ttraining's multi_logloss: 0.250935\tvalid_1's multi_logloss: 0.338753       \n",
      "[202]\ttraining's multi_logloss: 0.249836\tvalid_1's multi_logloss: 0.338045       \n",
      "[203]\ttraining's multi_logloss: 0.248733\tvalid_1's multi_logloss: 0.337328       \n",
      "[204]\ttraining's multi_logloss: 0.247648\tvalid_1's multi_logloss: 0.336615       \n",
      "[205]\ttraining's multi_logloss: 0.246572\tvalid_1's multi_logloss: 0.335893       \n",
      "[206]\ttraining's multi_logloss: 0.245497\tvalid_1's multi_logloss: 0.335224       \n",
      "[207]\ttraining's multi_logloss: 0.244456\tvalid_1's multi_logloss: 0.334534       \n",
      "[208]\ttraining's multi_logloss: 0.243381\tvalid_1's multi_logloss: 0.333907       \n",
      "[209]\ttraining's multi_logloss: 0.242354\tvalid_1's multi_logloss: 0.333289       \n",
      "[210]\ttraining's multi_logloss: 0.241304\tvalid_1's multi_logloss: 0.332641       \n",
      "[211]\ttraining's multi_logloss: 0.240253\tvalid_1's multi_logloss: 0.332039       \n",
      "[212]\ttraining's multi_logloss: 0.23923\tvalid_1's multi_logloss: 0.33142         \n",
      "[213]\ttraining's multi_logloss: 0.23822\tvalid_1's multi_logloss: 0.330799        \n",
      "[214]\ttraining's multi_logloss: 0.237244\tvalid_1's multi_logloss: 0.330207       \n",
      "[215]\ttraining's multi_logloss: 0.236225\tvalid_1's multi_logloss: 0.329624       \n",
      "[216]\ttraining's multi_logloss: 0.235197\tvalid_1's multi_logloss: 0.329062       \n",
      "[217]\ttraining's multi_logloss: 0.234236\tvalid_1's multi_logloss: 0.328503       \n",
      "[218]\ttraining's multi_logloss: 0.233222\tvalid_1's multi_logloss: 0.327935       \n",
      "[219]\ttraining's multi_logloss: 0.232214\tvalid_1's multi_logloss: 0.327387       \n",
      "[220]\ttraining's multi_logloss: 0.231226\tvalid_1's multi_logloss: 0.326875       \n",
      "[221]\ttraining's multi_logloss: 0.230246\tvalid_1's multi_logloss: 0.326336       \n",
      "[222]\ttraining's multi_logloss: 0.229283\tvalid_1's multi_logloss: 0.325841       \n",
      "[223]\ttraining's multi_logloss: 0.228336\tvalid_1's multi_logloss: 0.325296       \n",
      "[224]\ttraining's multi_logloss: 0.227403\tvalid_1's multi_logloss: 0.324805       \n",
      "[225]\ttraining's multi_logloss: 0.226467\tvalid_1's multi_logloss: 0.324299       \n",
      "[226]\ttraining's multi_logloss: 0.225557\tvalid_1's multi_logloss: 0.323806       \n",
      "[227]\ttraining's multi_logloss: 0.224624\tvalid_1's multi_logloss: 0.323339       \n",
      "[228]\ttraining's multi_logloss: 0.223722\tvalid_1's multi_logloss: 0.322879       \n",
      "[229]\ttraining's multi_logloss: 0.222802\tvalid_1's multi_logloss: 0.322394       \n",
      "[230]\ttraining's multi_logloss: 0.221922\tvalid_1's multi_logloss: 0.32198        \n",
      "[231]\ttraining's multi_logloss: 0.221017\tvalid_1's multi_logloss: 0.321497       \n",
      "[232]\ttraining's multi_logloss: 0.220141\tvalid_1's multi_logloss: 0.32107        \n",
      "[233]\ttraining's multi_logloss: 0.219258\tvalid_1's multi_logloss: 0.320658       \n",
      "[234]\ttraining's multi_logloss: 0.218379\tvalid_1's multi_logloss: 0.320207       \n",
      "[235]\ttraining's multi_logloss: 0.217549\tvalid_1's multi_logloss: 0.319794       \n",
      "[236]\ttraining's multi_logloss: 0.216687\tvalid_1's multi_logloss: 0.319387       \n",
      "[237]\ttraining's multi_logloss: 0.21584\tvalid_1's multi_logloss: 0.318967        \n",
      "[238]\ttraining's multi_logloss: 0.215009\tvalid_1's multi_logloss: 0.318522       \n",
      "[239]\ttraining's multi_logloss: 0.214152\tvalid_1's multi_logloss: 0.318102       \n",
      "[240]\ttraining's multi_logloss: 0.213336\tvalid_1's multi_logloss: 0.317719       \n",
      "[241]\ttraining's multi_logloss: 0.212495\tvalid_1's multi_logloss: 0.317291       \n",
      "[242]\ttraining's multi_logloss: 0.211689\tvalid_1's multi_logloss: 0.31691        \n",
      "[243]\ttraining's multi_logloss: 0.210885\tvalid_1's multi_logloss: 0.316504       \n",
      "[244]\ttraining's multi_logloss: 0.210088\tvalid_1's multi_logloss: 0.316165       \n",
      "[245]\ttraining's multi_logloss: 0.209276\tvalid_1's multi_logloss: 0.315805       \n",
      "[246]\ttraining's multi_logloss: 0.208493\tvalid_1's multi_logloss: 0.315453       \n",
      "[247]\ttraining's multi_logloss: 0.207686\tvalid_1's multi_logloss: 0.315098       \n",
      "[248]\ttraining's multi_logloss: 0.206898\tvalid_1's multi_logloss: 0.314782       \n",
      "[249]\ttraining's multi_logloss: 0.206117\tvalid_1's multi_logloss: 0.314414       \n",
      "[250]\ttraining's multi_logloss: 0.205343\tvalid_1's multi_logloss: 0.314054       \n",
      "[251]\ttraining's multi_logloss: 0.204587\tvalid_1's multi_logloss: 0.313705       \n",
      "[252]\ttraining's multi_logloss: 0.203844\tvalid_1's multi_logloss: 0.313337       \n",
      "[253]\ttraining's multi_logloss: 0.203087\tvalid_1's multi_logloss: 0.313019       \n",
      "[254]\ttraining's multi_logloss: 0.202343\tvalid_1's multi_logloss: 0.312719       \n",
      "[255]\ttraining's multi_logloss: 0.201593\tvalid_1's multi_logloss: 0.312351       \n",
      "[256]\ttraining's multi_logloss: 0.200849\tvalid_1's multi_logloss: 0.312041       \n",
      "[257]\ttraining's multi_logloss: 0.200126\tvalid_1's multi_logloss: 0.31176        \n",
      "[258]\ttraining's multi_logloss: 0.199374\tvalid_1's multi_logloss: 0.311481       \n",
      "[259]\ttraining's multi_logloss: 0.198674\tvalid_1's multi_logloss: 0.3112         \n",
      "[260]\ttraining's multi_logloss: 0.197925\tvalid_1's multi_logloss: 0.310898       \n",
      "[261]\ttraining's multi_logloss: 0.197184\tvalid_1's multi_logloss: 0.31058        \n",
      "[262]\ttraining's multi_logloss: 0.196469\tvalid_1's multi_logloss: 0.310325       \n",
      "[263]\ttraining's multi_logloss: 0.195744\tvalid_1's multi_logloss: 0.310061       \n",
      "[264]\ttraining's multi_logloss: 0.195038\tvalid_1's multi_logloss: 0.309781       \n",
      "[265]\ttraining's multi_logloss: 0.194317\tvalid_1's multi_logloss: 0.309536       \n",
      "[266]\ttraining's multi_logloss: 0.193597\tvalid_1's multi_logloss: 0.309237       \n",
      "[267]\ttraining's multi_logloss: 0.192897\tvalid_1's multi_logloss: 0.308928       \n",
      "[268]\ttraining's multi_logloss: 0.192186\tvalid_1's multi_logloss: 0.308648       \n",
      "[269]\ttraining's multi_logloss: 0.191515\tvalid_1's multi_logloss: 0.308375       \n",
      "[270]\ttraining's multi_logloss: 0.190818\tvalid_1's multi_logloss: 0.308103       \n",
      "[271]\ttraining's multi_logloss: 0.190141\tvalid_1's multi_logloss: 0.307842       \n",
      "[272]\ttraining's multi_logloss: 0.189467\tvalid_1's multi_logloss: 0.307565       \n",
      "[273]\ttraining's multi_logloss: 0.18881\tvalid_1's multi_logloss: 0.307312        \n",
      "[274]\ttraining's multi_logloss: 0.188142\tvalid_1's multi_logloss: 0.307068       \n",
      "[275]\ttraining's multi_logloss: 0.187468\tvalid_1's multi_logloss: 0.306855       \n",
      "[276]\ttraining's multi_logloss: 0.186766\tvalid_1's multi_logloss: 0.30659        \n",
      "[277]\ttraining's multi_logloss: 0.186094\tvalid_1's multi_logloss: 0.30634        \n",
      "[278]\ttraining's multi_logloss: 0.185411\tvalid_1's multi_logloss: 0.30611        \n",
      "[279]\ttraining's multi_logloss: 0.184745\tvalid_1's multi_logloss: 0.305907       \n",
      "[280]\ttraining's multi_logloss: 0.184093\tvalid_1's multi_logloss: 0.30564        \n",
      "[281]\ttraining's multi_logloss: 0.183429\tvalid_1's multi_logloss: 0.305411       \n",
      "[282]\ttraining's multi_logloss: 0.182785\tvalid_1's multi_logloss: 0.305187       \n",
      "[283]\ttraining's multi_logloss: 0.182166\tvalid_1's multi_logloss: 0.304986       \n",
      "[284]\ttraining's multi_logloss: 0.181497\tvalid_1's multi_logloss: 0.304688       \n",
      "[285]\ttraining's multi_logloss: 0.180876\tvalid_1's multi_logloss: 0.30451        \n",
      "[286]\ttraining's multi_logloss: 0.18021\tvalid_1's multi_logloss: 0.304252        \n",
      "[287]\ttraining's multi_logloss: 0.17959\tvalid_1's multi_logloss: 0.304063        \n",
      "[288]\ttraining's multi_logloss: 0.178953\tvalid_1's multi_logloss: 0.303868       \n",
      "[289]\ttraining's multi_logloss: 0.178311\tvalid_1's multi_logloss: 0.303636       \n",
      "[290]\ttraining's multi_logloss: 0.177672\tvalid_1's multi_logloss: 0.303438       \n",
      "[291]\ttraining's multi_logloss: 0.177068\tvalid_1's multi_logloss: 0.303194       \n",
      "[292]\ttraining's multi_logloss: 0.17644\tvalid_1's multi_logloss: 0.303003        \n",
      "[293]\ttraining's multi_logloss: 0.175863\tvalid_1's multi_logloss: 0.302813       \n",
      "[294]\ttraining's multi_logloss: 0.175246\tvalid_1's multi_logloss: 0.302629       \n",
      "[295]\ttraining's multi_logloss: 0.174656\tvalid_1's multi_logloss: 0.302427       \n",
      "[296]\ttraining's multi_logloss: 0.174078\tvalid_1's multi_logloss: 0.302243       \n",
      "[297]\ttraining's multi_logloss: 0.173488\tvalid_1's multi_logloss: 0.302089       \n",
      "[298]\ttraining's multi_logloss: 0.172935\tvalid_1's multi_logloss: 0.301958       \n",
      "[299]\ttraining's multi_logloss: 0.172354\tvalid_1's multi_logloss: 0.301749       \n",
      "[300]\ttraining's multi_logloss: 0.171801\tvalid_1's multi_logloss: 0.3016         \n",
      "[301]\ttraining's multi_logloss: 0.171222\tvalid_1's multi_logloss: 0.301409       \n",
      "[302]\ttraining's multi_logloss: 0.170673\tvalid_1's multi_logloss: 0.301294       \n",
      "[303]\ttraining's multi_logloss: 0.170088\tvalid_1's multi_logloss: 0.301098       \n",
      "[304]\ttraining's multi_logloss: 0.169501\tvalid_1's multi_logloss: 0.300895       \n",
      "[305]\ttraining's multi_logloss: 0.168962\tvalid_1's multi_logloss: 0.300727       \n",
      "[306]\ttraining's multi_logloss: 0.168394\tvalid_1's multi_logloss: 0.300558       \n",
      "[307]\ttraining's multi_logloss: 0.167839\tvalid_1's multi_logloss: 0.300416       \n",
      "[308]\ttraining's multi_logloss: 0.167285\tvalid_1's multi_logloss: 0.300262       \n",
      "[309]\ttraining's multi_logloss: 0.166721\tvalid_1's multi_logloss: 0.30006        \n",
      "[310]\ttraining's multi_logloss: 0.166172\tvalid_1's multi_logloss: 0.299923       \n",
      "[311]\ttraining's multi_logloss: 0.165619\tvalid_1's multi_logloss: 0.299775       \n",
      "[312]\ttraining's multi_logloss: 0.165078\tvalid_1's multi_logloss: 0.299653       \n",
      "[313]\ttraining's multi_logloss: 0.164542\tvalid_1's multi_logloss: 0.299444       \n",
      "[314]\ttraining's multi_logloss: 0.164011\tvalid_1's multi_logloss: 0.299299       \n",
      "[315]\ttraining's multi_logloss: 0.16346\tvalid_1's multi_logloss: 0.299119        \n",
      "[316]\ttraining's multi_logloss: 0.162945\tvalid_1's multi_logloss: 0.299009       \n",
      "[317]\ttraining's multi_logloss: 0.162404\tvalid_1's multi_logloss: 0.298897       \n",
      "[318]\ttraining's multi_logloss: 0.161857\tvalid_1's multi_logloss: 0.298792       \n",
      "[319]\ttraining's multi_logloss: 0.161367\tvalid_1's multi_logloss: 0.298644       \n",
      "[320]\ttraining's multi_logloss: 0.160843\tvalid_1's multi_logloss: 0.298529       \n",
      "[321]\ttraining's multi_logloss: 0.16035\tvalid_1's multi_logloss: 0.298394        \n",
      "[322]\ttraining's multi_logloss: 0.159832\tvalid_1's multi_logloss: 0.298281       \n",
      "[323]\ttraining's multi_logloss: 0.159303\tvalid_1's multi_logloss: 0.298128       \n",
      "[324]\ttraining's multi_logloss: 0.158772\tvalid_1's multi_logloss: 0.297991       \n",
      "[325]\ttraining's multi_logloss: 0.158255\tvalid_1's multi_logloss: 0.297864       \n",
      "[326]\ttraining's multi_logloss: 0.15775\tvalid_1's multi_logloss: 0.297763        \n",
      "[327]\ttraining's multi_logloss: 0.157225\tvalid_1's multi_logloss: 0.297624       \n",
      "[328]\ttraining's multi_logloss: 0.156732\tvalid_1's multi_logloss: 0.297508       \n",
      "[329]\ttraining's multi_logloss: 0.156229\tvalid_1's multi_logloss: 0.29742        \n",
      "[330]\ttraining's multi_logloss: 0.155734\tvalid_1's multi_logloss: 0.297325       \n",
      "[331]\ttraining's multi_logloss: 0.15521\tvalid_1's multi_logloss: 0.297235        \n",
      "[332]\ttraining's multi_logloss: 0.154722\tvalid_1's multi_logloss: 0.297145       \n",
      "[333]\ttraining's multi_logloss: 0.154241\tvalid_1's multi_logloss: 0.297056       \n",
      "[334]\ttraining's multi_logloss: 0.153744\tvalid_1's multi_logloss: 0.296976       \n",
      "[335]\ttraining's multi_logloss: 0.153244\tvalid_1's multi_logloss: 0.296915       \n",
      "[336]\ttraining's multi_logloss: 0.152749\tvalid_1's multi_logloss: 0.296813       \n",
      "[337]\ttraining's multi_logloss: 0.15229\tvalid_1's multi_logloss: 0.296719        \n",
      "[338]\ttraining's multi_logloss: 0.151782\tvalid_1's multi_logloss: 0.296596       \n",
      "[339]\ttraining's multi_logloss: 0.151305\tvalid_1's multi_logloss: 0.296558       \n",
      "[340]\ttraining's multi_logloss: 0.150826\tvalid_1's multi_logloss: 0.296482       \n",
      "[341]\ttraining's multi_logloss: 0.150333\tvalid_1's multi_logloss: 0.296417       \n",
      "[342]\ttraining's multi_logloss: 0.14986\tvalid_1's multi_logloss: 0.296309        \n",
      "[343]\ttraining's multi_logloss: 0.14938\tvalid_1's multi_logloss: 0.296243        \n",
      "[344]\ttraining's multi_logloss: 0.148919\tvalid_1's multi_logloss: 0.29616        \n",
      "[345]\ttraining's multi_logloss: 0.148467\tvalid_1's multi_logloss: 0.296112       \n",
      "[346]\ttraining's multi_logloss: 0.147992\tvalid_1's multi_logloss: 0.296016       \n",
      "[347]\ttraining's multi_logloss: 0.147549\tvalid_1's multi_logloss: 0.295942       \n",
      "[348]\ttraining's multi_logloss: 0.147098\tvalid_1's multi_logloss: 0.295836       \n",
      "[349]\ttraining's multi_logloss: 0.146608\tvalid_1's multi_logloss: 0.295704       \n",
      "[350]\ttraining's multi_logloss: 0.146164\tvalid_1's multi_logloss: 0.295649       \n",
      "[351]\ttraining's multi_logloss: 0.145694\tvalid_1's multi_logloss: 0.295594       \n",
      "[352]\ttraining's multi_logloss: 0.145218\tvalid_1's multi_logloss: 0.295495       \n",
      "[353]\ttraining's multi_logloss: 0.144741\tvalid_1's multi_logloss: 0.29542        \n",
      "[354]\ttraining's multi_logloss: 0.144242\tvalid_1's multi_logloss: 0.295307       \n",
      "[355]\ttraining's multi_logloss: 0.143759\tvalid_1's multi_logloss: 0.295195       \n",
      "[356]\ttraining's multi_logloss: 0.143295\tvalid_1's multi_logloss: 0.295114       \n",
      "[357]\ttraining's multi_logloss: 0.142836\tvalid_1's multi_logloss: 0.29503        \n",
      "[358]\ttraining's multi_logloss: 0.142382\tvalid_1's multi_logloss: 0.29495        \n",
      "[359]\ttraining's multi_logloss: 0.141928\tvalid_1's multi_logloss: 0.294893       \n",
      "[360]\ttraining's multi_logloss: 0.141493\tvalid_1's multi_logloss: 0.294874       \n",
      "[361]\ttraining's multi_logloss: 0.141037\tvalid_1's multi_logloss: 0.294817       \n",
      "[362]\ttraining's multi_logloss: 0.140612\tvalid_1's multi_logloss: 0.294799       \n",
      "[363]\ttraining's multi_logloss: 0.140174\tvalid_1's multi_logloss: 0.294722       \n",
      "[364]\ttraining's multi_logloss: 0.139737\tvalid_1's multi_logloss: 0.294655       \n",
      "[365]\ttraining's multi_logloss: 0.139309\tvalid_1's multi_logloss: 0.294634       \n",
      "[366]\ttraining's multi_logloss: 0.138875\tvalid_1's multi_logloss: 0.294617       \n",
      "[367]\ttraining's multi_logloss: 0.13844\tvalid_1's multi_logloss: 0.294583        \n",
      "[368]\ttraining's multi_logloss: 0.137992\tvalid_1's multi_logloss: 0.294437       \n",
      "[369]\ttraining's multi_logloss: 0.137557\tvalid_1's multi_logloss: 0.294397       \n",
      "[370]\ttraining's multi_logloss: 0.137108\tvalid_1's multi_logloss: 0.294318       \n",
      "[371]\ttraining's multi_logloss: 0.136684\tvalid_1's multi_logloss: 0.294248       \n",
      "[372]\ttraining's multi_logloss: 0.136245\tvalid_1's multi_logloss: 0.294188       \n",
      "[373]\ttraining's multi_logloss: 0.135831\tvalid_1's multi_logloss: 0.294135       \n",
      "[374]\ttraining's multi_logloss: 0.135389\tvalid_1's multi_logloss: 0.294068       \n",
      "[375]\ttraining's multi_logloss: 0.13498\tvalid_1's multi_logloss: 0.293986        \n",
      "[376]\ttraining's multi_logloss: 0.134585\tvalid_1's multi_logloss: 0.293953       \n",
      "[377]\ttraining's multi_logloss: 0.134178\tvalid_1's multi_logloss: 0.293943       \n",
      "[378]\ttraining's multi_logloss: 0.133776\tvalid_1's multi_logloss: 0.293875       \n",
      "[379]\ttraining's multi_logloss: 0.133383\tvalid_1's multi_logloss: 0.293836       \n",
      "[380]\ttraining's multi_logloss: 0.132964\tvalid_1's multi_logloss: 0.293766       \n",
      "[381]\ttraining's multi_logloss: 0.132559\tvalid_1's multi_logloss: 0.293685       \n",
      "[382]\ttraining's multi_logloss: 0.132146\tvalid_1's multi_logloss: 0.293587       \n",
      "[383]\ttraining's multi_logloss: 0.131761\tvalid_1's multi_logloss: 0.293521       \n",
      "[384]\ttraining's multi_logloss: 0.131325\tvalid_1's multi_logloss: 0.293428       \n",
      "[385]\ttraining's multi_logloss: 0.130929\tvalid_1's multi_logloss: 0.293354       \n",
      "[386]\ttraining's multi_logloss: 0.130501\tvalid_1's multi_logloss: 0.293333       \n",
      "[387]\ttraining's multi_logloss: 0.130106\tvalid_1's multi_logloss: 0.293287       \n",
      "[388]\ttraining's multi_logloss: 0.129708\tvalid_1's multi_logloss: 0.293248       \n",
      "[389]\ttraining's multi_logloss: 0.129326\tvalid_1's multi_logloss: 0.293223       \n",
      "[390]\ttraining's multi_logloss: 0.128948\tvalid_1's multi_logloss: 0.293198       \n",
      "[391]\ttraining's multi_logloss: 0.128561\tvalid_1's multi_logloss: 0.293152       \n",
      "[392]\ttraining's multi_logloss: 0.128169\tvalid_1's multi_logloss: 0.293102       \n",
      "[393]\ttraining's multi_logloss: 0.127788\tvalid_1's multi_logloss: 0.29308        \n",
      "[394]\ttraining's multi_logloss: 0.127413\tvalid_1's multi_logloss: 0.293049       \n",
      "[395]\ttraining's multi_logloss: 0.127018\tvalid_1's multi_logloss: 0.293025       \n",
      "[396]\ttraining's multi_logloss: 0.126664\tvalid_1's multi_logloss: 0.293018       \n",
      "[397]\ttraining's multi_logloss: 0.126263\tvalid_1's multi_logloss: 0.29301        \n",
      "[398]\ttraining's multi_logloss: 0.125884\tvalid_1's multi_logloss: 0.292997       \n",
      "[399]\ttraining's multi_logloss: 0.125517\tvalid_1's multi_logloss: 0.292977       \n",
      "[400]\ttraining's multi_logloss: 0.125138\tvalid_1's multi_logloss: 0.292942       \n",
      "Did not meet early stopping. Best iteration is:                                  \n",
      "[400]\ttraining's multi_logloss: 0.125138\tvalid_1's multi_logloss: 0.292942\n",
      "[1]\ttraining's multi_logloss: 1.87931\tvalid_1's multi_logloss: 1.88137           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.83166\tvalid_1's multi_logloss: 1.8341            \n",
      "[3]\ttraining's multi_logloss: 1.78672\tvalid_1's multi_logloss: 1.78949           \n",
      "[4]\ttraining's multi_logloss: 1.74423\tvalid_1's multi_logloss: 1.7473            \n",
      "[5]\ttraining's multi_logloss: 1.70369\tvalid_1's multi_logloss: 1.70701           \n",
      "[6]\ttraining's multi_logloss: 1.66518\tvalid_1's multi_logloss: 1.66874           \n",
      "[7]\ttraining's multi_logloss: 1.62833\tvalid_1's multi_logloss: 1.63207           \n",
      "[8]\ttraining's multi_logloss: 1.59323\tvalid_1's multi_logloss: 1.59718           \n",
      "[9]\ttraining's multi_logloss: 1.55959\tvalid_1's multi_logloss: 1.56376           \n",
      "[10]\ttraining's multi_logloss: 1.52745\tvalid_1's multi_logloss: 1.53193          \n",
      "[11]\ttraining's multi_logloss: 1.49645\tvalid_1's multi_logloss: 1.50131          \n",
      "[12]\ttraining's multi_logloss: 1.4668\tvalid_1's multi_logloss: 1.47215           \n",
      "[13]\ttraining's multi_logloss: 1.4383\tvalid_1's multi_logloss: 1.44405           \n",
      "[14]\ttraining's multi_logloss: 1.41078\tvalid_1's multi_logloss: 1.41699          \n",
      "[15]\ttraining's multi_logloss: 1.38428\tvalid_1's multi_logloss: 1.39095          \n",
      "[16]\ttraining's multi_logloss: 1.3587\tvalid_1's multi_logloss: 1.36564           \n",
      "[17]\ttraining's multi_logloss: 1.33406\tvalid_1's multi_logloss: 1.34147          \n",
      "[18]\ttraining's multi_logloss: 1.31015\tvalid_1's multi_logloss: 1.31788          \n",
      "[19]\ttraining's multi_logloss: 1.28709\tvalid_1's multi_logloss: 1.29528          \n",
      "[20]\ttraining's multi_logloss: 1.26462\tvalid_1's multi_logloss: 1.27314          \n",
      "[21]\ttraining's multi_logloss: 1.24293\tvalid_1's multi_logloss: 1.25185          \n",
      "[22]\ttraining's multi_logloss: 1.2218\tvalid_1's multi_logloss: 1.23107           \n",
      "[23]\ttraining's multi_logloss: 1.20134\tvalid_1's multi_logloss: 1.21104          \n",
      "[24]\ttraining's multi_logloss: 1.1814\tvalid_1's multi_logloss: 1.19144           \n",
      "[25]\ttraining's multi_logloss: 1.16204\tvalid_1's multi_logloss: 1.17245          \n",
      "[26]\ttraining's multi_logloss: 1.14324\tvalid_1's multi_logloss: 1.15399          \n",
      "[27]\ttraining's multi_logloss: 1.12498\tvalid_1's multi_logloss: 1.13616          \n",
      "[28]\ttraining's multi_logloss: 1.1072\tvalid_1's multi_logloss: 1.11868           \n",
      "[29]\ttraining's multi_logloss: 1.08988\tvalid_1's multi_logloss: 1.10176          \n",
      "[30]\ttraining's multi_logloss: 1.07299\tvalid_1's multi_logloss: 1.08514          \n",
      "[31]\ttraining's multi_logloss: 1.05667\tvalid_1's multi_logloss: 1.06922          \n",
      "[32]\ttraining's multi_logloss: 1.04068\tvalid_1's multi_logloss: 1.0536           \n",
      "[33]\ttraining's multi_logloss: 1.02504\tvalid_1's multi_logloss: 1.03836          \n",
      "[34]\ttraining's multi_logloss: 1.0099\tvalid_1's multi_logloss: 1.02358           \n",
      "[35]\ttraining's multi_logloss: 0.995087\tvalid_1's multi_logloss: 1.00909         \n",
      "[36]\ttraining's multi_logloss: 0.980557\tvalid_1's multi_logloss: 0.995003        \n",
      "[37]\ttraining's multi_logloss: 0.966421\tvalid_1's multi_logloss: 0.981235        \n",
      "[38]\ttraining's multi_logloss: 0.952709\tvalid_1's multi_logloss: 0.967871        \n",
      "[39]\ttraining's multi_logloss: 0.939292\tvalid_1's multi_logloss: 0.954825        \n",
      "[40]\ttraining's multi_logloss: 0.926237\tvalid_1's multi_logloss: 0.942155        \n",
      "[41]\ttraining's multi_logloss: 0.913422\tvalid_1's multi_logloss: 0.929719        \n",
      "[42]\ttraining's multi_logloss: 0.900855\tvalid_1's multi_logloss: 0.917548        \n",
      "[43]\ttraining's multi_logloss: 0.888668\tvalid_1's multi_logloss: 0.905717        \n",
      "[44]\ttraining's multi_logloss: 0.876761\tvalid_1's multi_logloss: 0.894221        \n",
      "[45]\ttraining's multi_logloss: 0.865085\tvalid_1's multi_logloss: 0.882854        \n",
      "[46]\ttraining's multi_logloss: 0.853698\tvalid_1's multi_logloss: 0.871766        \n",
      "[47]\ttraining's multi_logloss: 0.842485\tvalid_1's multi_logloss: 0.860891        \n",
      "[48]\ttraining's multi_logloss: 0.831531\tvalid_1's multi_logloss: 0.850312        \n",
      "[49]\ttraining's multi_logloss: 0.820763\tvalid_1's multi_logloss: 0.839879        \n",
      "[50]\ttraining's multi_logloss: 0.81038\tvalid_1's multi_logloss: 0.829854         \n",
      "[51]\ttraining's multi_logloss: 0.80008\tvalid_1's multi_logloss: 0.819863         \n",
      "[52]\ttraining's multi_logloss: 0.789983\tvalid_1's multi_logloss: 0.810173        \n",
      "[53]\ttraining's multi_logloss: 0.780144\tvalid_1's multi_logloss: 0.800727        \n",
      "[54]\ttraining's multi_logloss: 0.770442\tvalid_1's multi_logloss: 0.791431        \n",
      "[55]\ttraining's multi_logloss: 0.760929\tvalid_1's multi_logloss: 0.782287        \n",
      "[56]\ttraining's multi_logloss: 0.751653\tvalid_1's multi_logloss: 0.773357        \n",
      "[57]\ttraining's multi_logloss: 0.742543\tvalid_1's multi_logloss: 0.764583        \n",
      "[58]\ttraining's multi_logloss: 0.733603\tvalid_1's multi_logloss: 0.756062        \n",
      "[59]\ttraining's multi_logloss: 0.724838\tvalid_1's multi_logloss: 0.74773         \n",
      "[60]\ttraining's multi_logloss: 0.71625\tvalid_1's multi_logloss: 0.739569         \n",
      "[61]\ttraining's multi_logloss: 0.707745\tvalid_1's multi_logloss: 0.73148         \n",
      "[62]\ttraining's multi_logloss: 0.69946\tvalid_1's multi_logloss: 0.723621         \n",
      "[63]\ttraining's multi_logloss: 0.691382\tvalid_1's multi_logloss: 0.71596         \n",
      "[64]\ttraining's multi_logloss: 0.683383\tvalid_1's multi_logloss: 0.708424        \n",
      "[65]\ttraining's multi_logloss: 0.675555\tvalid_1's multi_logloss: 0.701038        \n",
      "[66]\ttraining's multi_logloss: 0.667879\tvalid_1's multi_logloss: 0.693789        \n",
      "[67]\ttraining's multi_logloss: 0.660354\tvalid_1's multi_logloss: 0.686688        \n",
      "[68]\ttraining's multi_logloss: 0.652921\tvalid_1's multi_logloss: 0.679662        \n",
      "[69]\ttraining's multi_logloss: 0.64564\tvalid_1's multi_logloss: 0.672815         \n",
      "[70]\ttraining's multi_logloss: 0.638533\tvalid_1's multi_logloss: 0.666124        \n",
      "[71]\ttraining's multi_logloss: 0.631524\tvalid_1's multi_logloss: 0.659448        \n",
      "[72]\ttraining's multi_logloss: 0.624696\tvalid_1's multi_logloss: 0.653035        \n",
      "[73]\ttraining's multi_logloss: 0.618019\tvalid_1's multi_logloss: 0.646665        \n",
      "[74]\ttraining's multi_logloss: 0.611465\tvalid_1's multi_logloss: 0.64047         \n",
      "[75]\ttraining's multi_logloss: 0.605028\tvalid_1's multi_logloss: 0.634434        \n",
      "[76]\ttraining's multi_logloss: 0.598649\tvalid_1's multi_logloss: 0.628305        \n",
      "[77]\ttraining's multi_logloss: 0.592401\tvalid_1's multi_logloss: 0.622368        \n",
      "[78]\ttraining's multi_logloss: 0.586245\tvalid_1's multi_logloss: 0.616526        \n",
      "[79]\ttraining's multi_logloss: 0.58022\tvalid_1's multi_logloss: 0.610796         \n",
      "[80]\ttraining's multi_logloss: 0.574351\tvalid_1's multi_logloss: 0.605296        \n",
      "[81]\ttraining's multi_logloss: 0.568573\tvalid_1's multi_logloss: 0.59985         \n",
      "[82]\ttraining's multi_logloss: 0.562932\tvalid_1's multi_logloss: 0.594555        \n",
      "[83]\ttraining's multi_logloss: 0.55736\tvalid_1's multi_logloss: 0.589325         \n",
      "[84]\ttraining's multi_logloss: 0.551857\tvalid_1's multi_logloss: 0.584149        \n",
      "[85]\ttraining's multi_logloss: 0.546499\tvalid_1's multi_logloss: 0.579145        \n",
      "[86]\ttraining's multi_logloss: 0.541226\tvalid_1's multi_logloss: 0.574219        \n",
      "[87]\ttraining's multi_logloss: 0.536013\tvalid_1's multi_logloss: 0.569345        \n",
      "[88]\ttraining's multi_logloss: 0.530855\tvalid_1's multi_logloss: 0.564558        \n",
      "[89]\ttraining's multi_logloss: 0.525863\tvalid_1's multi_logloss: 0.559907        \n",
      "[90]\ttraining's multi_logloss: 0.520907\tvalid_1's multi_logloss: 0.555366        \n",
      "[91]\ttraining's multi_logloss: 0.516111\tvalid_1's multi_logloss: 0.550905        \n",
      "[92]\ttraining's multi_logloss: 0.511332\tvalid_1's multi_logloss: 0.546476        \n",
      "[93]\ttraining's multi_logloss: 0.5067\tvalid_1's multi_logloss: 0.542241          \n",
      "[94]\ttraining's multi_logloss: 0.502089\tvalid_1's multi_logloss: 0.537967        \n",
      "[95]\ttraining's multi_logloss: 0.497611\tvalid_1's multi_logloss: 0.533886        \n",
      "[96]\ttraining's multi_logloss: 0.493218\tvalid_1's multi_logloss: 0.529831        \n",
      "[97]\ttraining's multi_logloss: 0.488895\tvalid_1's multi_logloss: 0.525878        \n",
      "[98]\ttraining's multi_logloss: 0.484637\tvalid_1's multi_logloss: 0.522002        \n",
      "[99]\ttraining's multi_logloss: 0.480452\tvalid_1's multi_logloss: 0.518116        \n",
      "[100]\ttraining's multi_logloss: 0.476349\tvalid_1's multi_logloss: 0.514403       \n",
      "[101]\ttraining's multi_logloss: 0.472294\tvalid_1's multi_logloss: 0.510622       \n",
      "[102]\ttraining's multi_logloss: 0.468217\tvalid_1's multi_logloss: 0.506843       \n",
      "[103]\ttraining's multi_logloss: 0.464302\tvalid_1's multi_logloss: 0.503295       \n",
      "[104]\ttraining's multi_logloss: 0.460458\tvalid_1's multi_logloss: 0.499801       \n",
      "[105]\ttraining's multi_logloss: 0.456657\tvalid_1's multi_logloss: 0.496318       \n",
      "[106]\ttraining's multi_logloss: 0.452892\tvalid_1's multi_logloss: 0.492863       \n",
      "[107]\ttraining's multi_logloss: 0.44919\tvalid_1's multi_logloss: 0.489515        \n",
      "[108]\ttraining's multi_logloss: 0.445556\tvalid_1's multi_logloss: 0.486254       \n",
      "[109]\ttraining's multi_logloss: 0.441934\tvalid_1's multi_logloss: 0.483039       \n",
      "[110]\ttraining's multi_logloss: 0.43841\tvalid_1's multi_logloss: 0.47987         \n",
      "[111]\ttraining's multi_logloss: 0.434924\tvalid_1's multi_logloss: 0.476797       \n",
      "[112]\ttraining's multi_logloss: 0.431517\tvalid_1's multi_logloss: 0.473823       \n",
      "[113]\ttraining's multi_logloss: 0.428094\tvalid_1's multi_logloss: 0.47081        \n",
      "[114]\ttraining's multi_logloss: 0.42473\tvalid_1's multi_logloss: 0.467877        \n",
      "[115]\ttraining's multi_logloss: 0.421417\tvalid_1's multi_logloss: 0.464998       \n",
      "[116]\ttraining's multi_logloss: 0.418126\tvalid_1's multi_logloss: 0.462125       \n",
      "[117]\ttraining's multi_logloss: 0.414938\tvalid_1's multi_logloss: 0.459296       \n",
      "[118]\ttraining's multi_logloss: 0.411787\tvalid_1's multi_logloss: 0.456513       \n",
      "[119]\ttraining's multi_logloss: 0.40864\tvalid_1's multi_logloss: 0.453722        \n",
      "[120]\ttraining's multi_logloss: 0.405526\tvalid_1's multi_logloss: 0.450959       \n",
      "[121]\ttraining's multi_logloss: 0.402493\tvalid_1's multi_logloss: 0.448293       \n",
      "[122]\ttraining's multi_logloss: 0.399522\tvalid_1's multi_logloss: 0.445736       \n",
      "[123]\ttraining's multi_logloss: 0.396618\tvalid_1's multi_logloss: 0.443224       \n",
      "[124]\ttraining's multi_logloss: 0.393734\tvalid_1's multi_logloss: 0.440732       \n",
      "[125]\ttraining's multi_logloss: 0.390898\tvalid_1's multi_logloss: 0.438286       \n",
      "[126]\ttraining's multi_logloss: 0.388095\tvalid_1's multi_logloss: 0.435939       \n",
      "[127]\ttraining's multi_logloss: 0.385327\tvalid_1's multi_logloss: 0.433586       \n",
      "[128]\ttraining's multi_logloss: 0.382586\tvalid_1's multi_logloss: 0.431309       \n",
      "[129]\ttraining's multi_logloss: 0.379898\tvalid_1's multi_logloss: 0.429003       \n",
      "[130]\ttraining's multi_logloss: 0.377283\tvalid_1's multi_logloss: 0.426802       \n",
      "[131]\ttraining's multi_logloss: 0.374656\tvalid_1's multi_logloss: 0.42459        \n",
      "[132]\ttraining's multi_logloss: 0.372082\tvalid_1's multi_logloss: 0.422444       \n",
      "[133]\ttraining's multi_logloss: 0.369561\tvalid_1's multi_logloss: 0.420284       \n",
      "[134]\ttraining's multi_logloss: 0.366937\tvalid_1's multi_logloss: 0.418125       \n",
      "[135]\ttraining's multi_logloss: 0.364405\tvalid_1's multi_logloss: 0.416017       \n",
      "[136]\ttraining's multi_logloss: 0.361899\tvalid_1's multi_logloss: 0.413944       \n",
      "[137]\ttraining's multi_logloss: 0.359528\tvalid_1's multi_logloss: 0.411924       \n",
      "[138]\ttraining's multi_logloss: 0.357109\tvalid_1's multi_logloss: 0.409955       \n",
      "[139]\ttraining's multi_logloss: 0.354734\tvalid_1's multi_logloss: 0.407974       \n",
      "[140]\ttraining's multi_logloss: 0.352418\tvalid_1's multi_logloss: 0.406086       \n",
      "[141]\ttraining's multi_logloss: 0.350129\tvalid_1's multi_logloss: 0.404257       \n",
      "[142]\ttraining's multi_logloss: 0.347878\tvalid_1's multi_logloss: 0.40244        \n",
      "[143]\ttraining's multi_logloss: 0.345616\tvalid_1's multi_logloss: 0.400655       \n",
      "[144]\ttraining's multi_logloss: 0.343399\tvalid_1's multi_logloss: 0.398914       \n",
      "[145]\ttraining's multi_logloss: 0.341241\tvalid_1's multi_logloss: 0.397185       \n",
      "[146]\ttraining's multi_logloss: 0.339094\tvalid_1's multi_logloss: 0.395499       \n",
      "[147]\ttraining's multi_logloss: 0.336988\tvalid_1's multi_logloss: 0.393828       \n",
      "[148]\ttraining's multi_logloss: 0.334914\tvalid_1's multi_logloss: 0.392146       \n",
      "[149]\ttraining's multi_logloss: 0.332856\tvalid_1's multi_logloss: 0.390482       \n",
      "[150]\ttraining's multi_logloss: 0.330828\tvalid_1's multi_logloss: 0.388898       \n",
      "[151]\ttraining's multi_logloss: 0.328797\tvalid_1's multi_logloss: 0.387268       \n",
      "[152]\ttraining's multi_logloss: 0.326744\tvalid_1's multi_logloss: 0.385589       \n",
      "[153]\ttraining's multi_logloss: 0.324761\tvalid_1's multi_logloss: 0.38398        \n",
      "[154]\ttraining's multi_logloss: 0.322795\tvalid_1's multi_logloss: 0.382344       \n",
      "[155]\ttraining's multi_logloss: 0.320846\tvalid_1's multi_logloss: 0.380835       \n",
      "[156]\ttraining's multi_logloss: 0.31899\tvalid_1's multi_logloss: 0.379384        \n",
      "[157]\ttraining's multi_logloss: 0.317109\tvalid_1's multi_logloss: 0.377921       \n",
      "[158]\ttraining's multi_logloss: 0.315276\tvalid_1's multi_logloss: 0.376478       \n",
      "[159]\ttraining's multi_logloss: 0.313444\tvalid_1's multi_logloss: 0.375056       \n",
      "[160]\ttraining's multi_logloss: 0.311646\tvalid_1's multi_logloss: 0.373697       \n",
      "[161]\ttraining's multi_logloss: 0.309863\tvalid_1's multi_logloss: 0.372318       \n",
      "[162]\ttraining's multi_logloss: 0.308119\tvalid_1's multi_logloss: 0.371013       \n",
      "[163]\ttraining's multi_logloss: 0.306358\tvalid_1's multi_logloss: 0.369672       \n",
      "[164]\ttraining's multi_logloss: 0.304653\tvalid_1's multi_logloss: 0.368385       \n",
      "[165]\ttraining's multi_logloss: 0.302952\tvalid_1's multi_logloss: 0.367098       \n",
      "[166]\ttraining's multi_logloss: 0.301319\tvalid_1's multi_logloss: 0.365921       \n",
      "[167]\ttraining's multi_logloss: 0.299703\tvalid_1's multi_logloss: 0.364788       \n",
      "[168]\ttraining's multi_logloss: 0.298056\tvalid_1's multi_logloss: 0.363577       \n",
      "[169]\ttraining's multi_logloss: 0.29645\tvalid_1's multi_logloss: 0.36232         \n",
      "[170]\ttraining's multi_logloss: 0.294834\tvalid_1's multi_logloss: 0.361108       \n",
      "[171]\ttraining's multi_logloss: 0.29328\tvalid_1's multi_logloss: 0.359982        \n",
      "[172]\ttraining's multi_logloss: 0.291725\tvalid_1's multi_logloss: 0.358792       \n",
      "[173]\ttraining's multi_logloss: 0.290189\tvalid_1's multi_logloss: 0.3577         \n",
      "[174]\ttraining's multi_logloss: 0.288641\tvalid_1's multi_logloss: 0.356583       \n",
      "[175]\ttraining's multi_logloss: 0.287156\tvalid_1's multi_logloss: 0.355481       \n",
      "[176]\ttraining's multi_logloss: 0.285642\tvalid_1's multi_logloss: 0.354355       \n",
      "[177]\ttraining's multi_logloss: 0.284186\tvalid_1's multi_logloss: 0.353291       \n",
      "[178]\ttraining's multi_logloss: 0.282679\tvalid_1's multi_logloss: 0.352142       \n",
      "[179]\ttraining's multi_logloss: 0.281255\tvalid_1's multi_logloss: 0.351076       \n",
      "[180]\ttraining's multi_logloss: 0.279847\tvalid_1's multi_logloss: 0.350091       \n",
      "[181]\ttraining's multi_logloss: 0.278363\tvalid_1's multi_logloss: 0.348963       \n",
      "[182]\ttraining's multi_logloss: 0.276956\tvalid_1's multi_logloss: 0.347954       \n",
      "[183]\ttraining's multi_logloss: 0.275559\tvalid_1's multi_logloss: 0.346915       \n",
      "[184]\ttraining's multi_logloss: 0.274139\tvalid_1's multi_logloss: 0.345833       \n",
      "[185]\ttraining's multi_logloss: 0.272772\tvalid_1's multi_logloss: 0.344842       \n",
      "[186]\ttraining's multi_logloss: 0.271391\tvalid_1's multi_logloss: 0.34386        \n",
      "[187]\ttraining's multi_logloss: 0.27008\tvalid_1's multi_logloss: 0.342928        \n",
      "[188]\ttraining's multi_logloss: 0.268777\tvalid_1's multi_logloss: 0.341959       \n",
      "[189]\ttraining's multi_logloss: 0.267433\tvalid_1's multi_logloss: 0.340986       \n",
      "[190]\ttraining's multi_logloss: 0.266093\tvalid_1's multi_logloss: 0.340093       \n",
      "[191]\ttraining's multi_logloss: 0.264856\tvalid_1's multi_logloss: 0.339213       \n",
      "[192]\ttraining's multi_logloss: 0.263593\tvalid_1's multi_logloss: 0.338321       \n",
      "[193]\ttraining's multi_logloss: 0.262293\tvalid_1's multi_logloss: 0.337438       \n",
      "[194]\ttraining's multi_logloss: 0.261033\tvalid_1's multi_logloss: 0.336585       \n",
      "[195]\ttraining's multi_logloss: 0.259783\tvalid_1's multi_logloss: 0.335756       \n",
      "[196]\ttraining's multi_logloss: 0.258528\tvalid_1's multi_logloss: 0.33494        \n",
      "[197]\ttraining's multi_logloss: 0.257309\tvalid_1's multi_logloss: 0.334118       \n",
      "[198]\ttraining's multi_logloss: 0.25611\tvalid_1's multi_logloss: 0.333381        \n",
      "[199]\ttraining's multi_logloss: 0.254898\tvalid_1's multi_logloss: 0.332633       \n",
      "[200]\ttraining's multi_logloss: 0.253711\tvalid_1's multi_logloss: 0.331894       \n",
      "[201]\ttraining's multi_logloss: 0.25251\tvalid_1's multi_logloss: 0.331153        \n",
      "[202]\ttraining's multi_logloss: 0.251322\tvalid_1's multi_logloss: 0.330436       \n",
      "[203]\ttraining's multi_logloss: 0.250205\tvalid_1's multi_logloss: 0.329717       \n",
      "[204]\ttraining's multi_logloss: 0.249063\tvalid_1's multi_logloss: 0.329012       \n",
      "[205]\ttraining's multi_logloss: 0.247936\tvalid_1's multi_logloss: 0.328308       \n",
      "[206]\ttraining's multi_logloss: 0.246842\tvalid_1's multi_logloss: 0.327597       \n",
      "[207]\ttraining's multi_logloss: 0.245713\tvalid_1's multi_logloss: 0.326952       \n",
      "[208]\ttraining's multi_logloss: 0.244598\tvalid_1's multi_logloss: 0.326298       \n",
      "[209]\ttraining's multi_logloss: 0.243531\tvalid_1's multi_logloss: 0.325658       \n",
      "[210]\ttraining's multi_logloss: 0.242455\tvalid_1's multi_logloss: 0.32501        \n",
      "[211]\ttraining's multi_logloss: 0.241412\tvalid_1's multi_logloss: 0.324447       \n",
      "[212]\ttraining's multi_logloss: 0.240305\tvalid_1's multi_logloss: 0.323802       \n",
      "[213]\ttraining's multi_logloss: 0.23927\tvalid_1's multi_logloss: 0.323201        \n",
      "[214]\ttraining's multi_logloss: 0.238234\tvalid_1's multi_logloss: 0.322602       \n",
      "[215]\ttraining's multi_logloss: 0.237224\tvalid_1's multi_logloss: 0.322035       \n",
      "[216]\ttraining's multi_logloss: 0.236233\tvalid_1's multi_logloss: 0.321467       \n",
      "[217]\ttraining's multi_logloss: 0.235202\tvalid_1's multi_logloss: 0.320857       \n",
      "[218]\ttraining's multi_logloss: 0.234216\tvalid_1's multi_logloss: 0.320288       \n",
      "[219]\ttraining's multi_logloss: 0.233216\tvalid_1's multi_logloss: 0.319716       \n",
      "[220]\ttraining's multi_logloss: 0.232281\tvalid_1's multi_logloss: 0.319184       \n",
      "[221]\ttraining's multi_logloss: 0.231303\tvalid_1's multi_logloss: 0.318679       \n",
      "[222]\ttraining's multi_logloss: 0.230371\tvalid_1's multi_logloss: 0.318153       \n",
      "[223]\ttraining's multi_logloss: 0.229431\tvalid_1's multi_logloss: 0.317615       \n",
      "[224]\ttraining's multi_logloss: 0.228479\tvalid_1's multi_logloss: 0.317108       \n",
      "[225]\ttraining's multi_logloss: 0.227552\tvalid_1's multi_logloss: 0.316625       \n",
      "[226]\ttraining's multi_logloss: 0.226625\tvalid_1's multi_logloss: 0.31614        \n",
      "[227]\ttraining's multi_logloss: 0.225712\tvalid_1's multi_logloss: 0.315676       \n",
      "[228]\ttraining's multi_logloss: 0.224834\tvalid_1's multi_logloss: 0.315229       \n",
      "[229]\ttraining's multi_logloss: 0.223942\tvalid_1's multi_logloss: 0.314787       \n",
      "[230]\ttraining's multi_logloss: 0.223026\tvalid_1's multi_logloss: 0.314323       \n",
      "[231]\ttraining's multi_logloss: 0.222133\tvalid_1's multi_logloss: 0.313871       \n",
      "[232]\ttraining's multi_logloss: 0.221223\tvalid_1's multi_logloss: 0.313483       \n",
      "[233]\ttraining's multi_logloss: 0.220346\tvalid_1's multi_logloss: 0.312984       \n",
      "[234]\ttraining's multi_logloss: 0.219443\tvalid_1's multi_logloss: 0.312559       \n",
      "[235]\ttraining's multi_logloss: 0.218585\tvalid_1's multi_logloss: 0.312117       \n",
      "[236]\ttraining's multi_logloss: 0.217701\tvalid_1's multi_logloss: 0.311669       \n",
      "[237]\ttraining's multi_logloss: 0.216842\tvalid_1's multi_logloss: 0.311244       \n",
      "[238]\ttraining's multi_logloss: 0.215985\tvalid_1's multi_logloss: 0.310789       \n",
      "[239]\ttraining's multi_logloss: 0.215121\tvalid_1's multi_logloss: 0.310376       \n",
      "[240]\ttraining's multi_logloss: 0.214265\tvalid_1's multi_logloss: 0.310021       \n",
      "[241]\ttraining's multi_logloss: 0.213456\tvalid_1's multi_logloss: 0.3096         \n",
      "[242]\ttraining's multi_logloss: 0.21266\tvalid_1's multi_logloss: 0.309207        \n",
      "[243]\ttraining's multi_logloss: 0.211832\tvalid_1's multi_logloss: 0.308834       \n",
      "[244]\ttraining's multi_logloss: 0.211038\tvalid_1's multi_logloss: 0.308445       \n",
      "[245]\ttraining's multi_logloss: 0.210186\tvalid_1's multi_logloss: 0.308043       \n",
      "[246]\ttraining's multi_logloss: 0.209391\tvalid_1's multi_logloss: 0.307715       \n",
      "[247]\ttraining's multi_logloss: 0.2086\tvalid_1's multi_logloss: 0.307346         \n",
      "[248]\ttraining's multi_logloss: 0.207805\tvalid_1's multi_logloss: 0.306984       \n",
      "[249]\ttraining's multi_logloss: 0.207022\tvalid_1's multi_logloss: 0.306633       \n",
      "[250]\ttraining's multi_logloss: 0.206253\tvalid_1's multi_logloss: 0.306342       \n",
      "[251]\ttraining's multi_logloss: 0.205442\tvalid_1's multi_logloss: 0.305989       \n",
      "[252]\ttraining's multi_logloss: 0.204715\tvalid_1's multi_logloss: 0.30567        \n",
      "[253]\ttraining's multi_logloss: 0.20395\tvalid_1's multi_logloss: 0.305325        \n",
      "[254]\ttraining's multi_logloss: 0.203207\tvalid_1's multi_logloss: 0.305019       \n",
      "[255]\ttraining's multi_logloss: 0.20244\tvalid_1's multi_logloss: 0.304716        \n",
      "[256]\ttraining's multi_logloss: 0.201689\tvalid_1's multi_logloss: 0.304401       \n",
      "[257]\ttraining's multi_logloss: 0.200909\tvalid_1's multi_logloss: 0.304059       \n",
      "[258]\ttraining's multi_logloss: 0.200186\tvalid_1's multi_logloss: 0.303808       \n",
      "[259]\ttraining's multi_logloss: 0.199444\tvalid_1's multi_logloss: 0.303516       \n",
      "[260]\ttraining's multi_logloss: 0.198745\tvalid_1's multi_logloss: 0.303231       \n",
      "[261]\ttraining's multi_logloss: 0.198014\tvalid_1's multi_logloss: 0.30293        \n",
      "[262]\ttraining's multi_logloss: 0.197301\tvalid_1's multi_logloss: 0.302642       \n",
      "[263]\ttraining's multi_logloss: 0.196562\tvalid_1's multi_logloss: 0.302337       \n",
      "[264]\ttraining's multi_logloss: 0.19588\tvalid_1's multi_logloss: 0.302084        \n",
      "[265]\ttraining's multi_logloss: 0.195168\tvalid_1's multi_logloss: 0.301733       \n",
      "[266]\ttraining's multi_logloss: 0.1945\tvalid_1's multi_logloss: 0.301534         \n",
      "[267]\ttraining's multi_logloss: 0.193789\tvalid_1's multi_logloss: 0.301214       \n",
      "[268]\ttraining's multi_logloss: 0.193097\tvalid_1's multi_logloss: 0.300998       \n",
      "[269]\ttraining's multi_logloss: 0.192398\tvalid_1's multi_logloss: 0.300724       \n",
      "[270]\ttraining's multi_logloss: 0.191685\tvalid_1's multi_logloss: 0.300405       \n",
      "[271]\ttraining's multi_logloss: 0.191\tvalid_1's multi_logloss: 0.300139          \n",
      "[272]\ttraining's multi_logloss: 0.19028\tvalid_1's multi_logloss: 0.299838        \n",
      "[273]\ttraining's multi_logloss: 0.189595\tvalid_1's multi_logloss: 0.299522       \n",
      "[274]\ttraining's multi_logloss: 0.188897\tvalid_1's multi_logloss: 0.299259       \n",
      "[275]\ttraining's multi_logloss: 0.188226\tvalid_1's multi_logloss: 0.299025       \n",
      "[276]\ttraining's multi_logloss: 0.187533\tvalid_1's multi_logloss: 0.298741       \n",
      "[277]\ttraining's multi_logloss: 0.186881\tvalid_1's multi_logloss: 0.298499       \n",
      "[278]\ttraining's multi_logloss: 0.186226\tvalid_1's multi_logloss: 0.298244       \n",
      "[279]\ttraining's multi_logloss: 0.185548\tvalid_1's multi_logloss: 0.29804        \n",
      "[280]\ttraining's multi_logloss: 0.184876\tvalid_1's multi_logloss: 0.297851       \n",
      "[281]\ttraining's multi_logloss: 0.184216\tvalid_1's multi_logloss: 0.297588       \n",
      "[282]\ttraining's multi_logloss: 0.183566\tvalid_1's multi_logloss: 0.297381       \n",
      "[283]\ttraining's multi_logloss: 0.182955\tvalid_1's multi_logloss: 0.297234       \n",
      "[284]\ttraining's multi_logloss: 0.182305\tvalid_1's multi_logloss: 0.297049       \n",
      "[285]\ttraining's multi_logloss: 0.181669\tvalid_1's multi_logloss: 0.296794       \n",
      "[286]\ttraining's multi_logloss: 0.18105\tvalid_1's multi_logloss: 0.296658        \n",
      "[287]\ttraining's multi_logloss: 0.180422\tvalid_1's multi_logloss: 0.296477       \n",
      "[288]\ttraining's multi_logloss: 0.179819\tvalid_1's multi_logloss: 0.296337       \n",
      "[289]\ttraining's multi_logloss: 0.17921\tvalid_1's multi_logloss: 0.296132        \n",
      "[290]\ttraining's multi_logloss: 0.178586\tvalid_1's multi_logloss: 0.295952       \n",
      "[291]\ttraining's multi_logloss: 0.177971\tvalid_1's multi_logloss: 0.295782       \n",
      "[292]\ttraining's multi_logloss: 0.177362\tvalid_1's multi_logloss: 0.29555        \n",
      "[293]\ttraining's multi_logloss: 0.176749\tvalid_1's multi_logloss: 0.295394       \n",
      "[294]\ttraining's multi_logloss: 0.176156\tvalid_1's multi_logloss: 0.295222       \n",
      "[295]\ttraining's multi_logloss: 0.175546\tvalid_1's multi_logloss: 0.295055       \n",
      "[296]\ttraining's multi_logloss: 0.174925\tvalid_1's multi_logloss: 0.294906       \n",
      "[297]\ttraining's multi_logloss: 0.174313\tvalid_1's multi_logloss: 0.294711       \n",
      "[298]\ttraining's multi_logloss: 0.173719\tvalid_1's multi_logloss: 0.294583       \n",
      "[299]\ttraining's multi_logloss: 0.173123\tvalid_1's multi_logloss: 0.294399       \n",
      "[300]\ttraining's multi_logloss: 0.172509\tvalid_1's multi_logloss: 0.294217       \n",
      "[301]\ttraining's multi_logloss: 0.171912\tvalid_1's multi_logloss: 0.294043       \n",
      "[302]\ttraining's multi_logloss: 0.171313\tvalid_1's multi_logloss: 0.293834       \n",
      "[303]\ttraining's multi_logloss: 0.170726\tvalid_1's multi_logloss: 0.293685       \n",
      "[304]\ttraining's multi_logloss: 0.170124\tvalid_1's multi_logloss: 0.293444       \n",
      "[305]\ttraining's multi_logloss: 0.169531\tvalid_1's multi_logloss: 0.293257       \n",
      "[306]\ttraining's multi_logloss: 0.168947\tvalid_1's multi_logloss: 0.293123       \n",
      "[307]\ttraining's multi_logloss: 0.168359\tvalid_1's multi_logloss: 0.292923       \n",
      "[308]\ttraining's multi_logloss: 0.167757\tvalid_1's multi_logloss: 0.292741       \n",
      "[309]\ttraining's multi_logloss: 0.167214\tvalid_1's multi_logloss: 0.292566       \n",
      "[310]\ttraining's multi_logloss: 0.166634\tvalid_1's multi_logloss: 0.292416       \n",
      "[311]\ttraining's multi_logloss: 0.166075\tvalid_1's multi_logloss: 0.292292       \n",
      "[312]\ttraining's multi_logloss: 0.165492\tvalid_1's multi_logloss: 0.292123       \n",
      "[313]\ttraining's multi_logloss: 0.164939\tvalid_1's multi_logloss: 0.291957       \n",
      "[314]\ttraining's multi_logloss: 0.164379\tvalid_1's multi_logloss: 0.291777       \n",
      "[315]\ttraining's multi_logloss: 0.163823\tvalid_1's multi_logloss: 0.291627       \n",
      "[316]\ttraining's multi_logloss: 0.163268\tvalid_1's multi_logloss: 0.291476       \n",
      "[317]\ttraining's multi_logloss: 0.162735\tvalid_1's multi_logloss: 0.291356       \n",
      "[318]\ttraining's multi_logloss: 0.162173\tvalid_1's multi_logloss: 0.2912         \n",
      "[319]\ttraining's multi_logloss: 0.161609\tvalid_1's multi_logloss: 0.291052       \n",
      "[320]\ttraining's multi_logloss: 0.161078\tvalid_1's multi_logloss: 0.290897       \n",
      "[321]\ttraining's multi_logloss: 0.160533\tvalid_1's multi_logloss: 0.290792       \n",
      "[322]\ttraining's multi_logloss: 0.160018\tvalid_1's multi_logloss: 0.290706       \n",
      "[323]\ttraining's multi_logloss: 0.159441\tvalid_1's multi_logloss: 0.290513       \n",
      "[324]\ttraining's multi_logloss: 0.158909\tvalid_1's multi_logloss: 0.290393       \n",
      "[325]\ttraining's multi_logloss: 0.158387\tvalid_1's multi_logloss: 0.290237       \n",
      "[326]\ttraining's multi_logloss: 0.15786\tvalid_1's multi_logloss: 0.290112        \n",
      "[327]\ttraining's multi_logloss: 0.157355\tvalid_1's multi_logloss: 0.289965       \n",
      "[328]\ttraining's multi_logloss: 0.156823\tvalid_1's multi_logloss: 0.289852       \n",
      "[329]\ttraining's multi_logloss: 0.156316\tvalid_1's multi_logloss: 0.289734       \n",
      "[330]\ttraining's multi_logloss: 0.15578\tvalid_1's multi_logloss: 0.289598        \n",
      "[331]\ttraining's multi_logloss: 0.155298\tvalid_1's multi_logloss: 0.289523       \n",
      "[332]\ttraining's multi_logloss: 0.154774\tvalid_1's multi_logloss: 0.289444       \n",
      "[333]\ttraining's multi_logloss: 0.154273\tvalid_1's multi_logloss: 0.289336       \n",
      "[334]\ttraining's multi_logloss: 0.153752\tvalid_1's multi_logloss: 0.289209       \n",
      "[335]\ttraining's multi_logloss: 0.153248\tvalid_1's multi_logloss: 0.289089       \n",
      "[336]\ttraining's multi_logloss: 0.152741\tvalid_1's multi_logloss: 0.288953       \n",
      "[337]\ttraining's multi_logloss: 0.152248\tvalid_1's multi_logloss: 0.288856       \n",
      "[338]\ttraining's multi_logloss: 0.151758\tvalid_1's multi_logloss: 0.288706       \n",
      "[339]\ttraining's multi_logloss: 0.15124\tvalid_1's multi_logloss: 0.288665        \n",
      "[340]\ttraining's multi_logloss: 0.150735\tvalid_1's multi_logloss: 0.288586       \n",
      "[341]\ttraining's multi_logloss: 0.150231\tvalid_1's multi_logloss: 0.288438       \n",
      "[342]\ttraining's multi_logloss: 0.149747\tvalid_1's multi_logloss: 0.288333       \n",
      "[343]\ttraining's multi_logloss: 0.149258\tvalid_1's multi_logloss: 0.288207       \n",
      "[344]\ttraining's multi_logloss: 0.148761\tvalid_1's multi_logloss: 0.288109       \n",
      "[345]\ttraining's multi_logloss: 0.148298\tvalid_1's multi_logloss: 0.287998       \n",
      "[346]\ttraining's multi_logloss: 0.147802\tvalid_1's multi_logloss: 0.28788        \n",
      "[347]\ttraining's multi_logloss: 0.147309\tvalid_1's multi_logloss: 0.2878         \n",
      "[348]\ttraining's multi_logloss: 0.146833\tvalid_1's multi_logloss: 0.287698       \n",
      "[349]\ttraining's multi_logloss: 0.146365\tvalid_1's multi_logloss: 0.287614       \n",
      "[350]\ttraining's multi_logloss: 0.14589\tvalid_1's multi_logloss: 0.287491        \n",
      "[351]\ttraining's multi_logloss: 0.145419\tvalid_1's multi_logloss: 0.287388       \n",
      "[352]\ttraining's multi_logloss: 0.144959\tvalid_1's multi_logloss: 0.287313       \n",
      "[353]\ttraining's multi_logloss: 0.144495\tvalid_1's multi_logloss: 0.287196       \n",
      "[354]\ttraining's multi_logloss: 0.144021\tvalid_1's multi_logloss: 0.287117       \n",
      "[355]\ttraining's multi_logloss: 0.143547\tvalid_1's multi_logloss: 0.287004       \n",
      "[356]\ttraining's multi_logloss: 0.143074\tvalid_1's multi_logloss: 0.286998       \n",
      "[357]\ttraining's multi_logloss: 0.142635\tvalid_1's multi_logloss: 0.286895       \n",
      "[358]\ttraining's multi_logloss: 0.142173\tvalid_1's multi_logloss: 0.286789       \n",
      "[359]\ttraining's multi_logloss: 0.141711\tvalid_1's multi_logloss: 0.286718       \n",
      "[360]\ttraining's multi_logloss: 0.141251\tvalid_1's multi_logloss: 0.286677       \n",
      "[361]\ttraining's multi_logloss: 0.140814\tvalid_1's multi_logloss: 0.286662       \n",
      "[362]\ttraining's multi_logloss: 0.140349\tvalid_1's multi_logloss: 0.286549       \n",
      "[363]\ttraining's multi_logloss: 0.13993\tvalid_1's multi_logloss: 0.286526        \n",
      "[364]\ttraining's multi_logloss: 0.139494\tvalid_1's multi_logloss: 0.286453       \n",
      "[365]\ttraining's multi_logloss: 0.139052\tvalid_1's multi_logloss: 0.286376       \n",
      "[366]\ttraining's multi_logloss: 0.138621\tvalid_1's multi_logloss: 0.286278       \n",
      "[367]\ttraining's multi_logloss: 0.138191\tvalid_1's multi_logloss: 0.286217       \n",
      "[368]\ttraining's multi_logloss: 0.137771\tvalid_1's multi_logloss: 0.286149       \n",
      "[369]\ttraining's multi_logloss: 0.137353\tvalid_1's multi_logloss: 0.286103       \n",
      "[370]\ttraining's multi_logloss: 0.136933\tvalid_1's multi_logloss: 0.286056       \n",
      "[371]\ttraining's multi_logloss: 0.136484\tvalid_1's multi_logloss: 0.285943       \n",
      "[372]\ttraining's multi_logloss: 0.136059\tvalid_1's multi_logloss: 0.285875       \n",
      "[373]\ttraining's multi_logloss: 0.135591\tvalid_1's multi_logloss: 0.285831       \n",
      "[374]\ttraining's multi_logloss: 0.13516\tvalid_1's multi_logloss: 0.285782        \n",
      "[375]\ttraining's multi_logloss: 0.134732\tvalid_1's multi_logloss: 0.28572        \n",
      "[376]\ttraining's multi_logloss: 0.134296\tvalid_1's multi_logloss: 0.285662       \n",
      "[377]\ttraining's multi_logloss: 0.133846\tvalid_1's multi_logloss: 0.285627       \n",
      "[378]\ttraining's multi_logloss: 0.133397\tvalid_1's multi_logloss: 0.285642       \n",
      "[379]\ttraining's multi_logloss: 0.132948\tvalid_1's multi_logloss: 0.285595       \n",
      "[380]\ttraining's multi_logloss: 0.132511\tvalid_1's multi_logloss: 0.28556        \n",
      "[381]\ttraining's multi_logloss: 0.132077\tvalid_1's multi_logloss: 0.285549       \n",
      "[382]\ttraining's multi_logloss: 0.131672\tvalid_1's multi_logloss: 0.285476       \n",
      "[383]\ttraining's multi_logloss: 0.131254\tvalid_1's multi_logloss: 0.285442       \n",
      "[384]\ttraining's multi_logloss: 0.130852\tvalid_1's multi_logloss: 0.285421       \n",
      "[385]\ttraining's multi_logloss: 0.130427\tvalid_1's multi_logloss: 0.285365       \n",
      "[386]\ttraining's multi_logloss: 0.130022\tvalid_1's multi_logloss: 0.28534        \n",
      "[387]\ttraining's multi_logloss: 0.129603\tvalid_1's multi_logloss: 0.285306       \n",
      "[388]\ttraining's multi_logloss: 0.129212\tvalid_1's multi_logloss: 0.285288       \n",
      "[389]\ttraining's multi_logloss: 0.128823\tvalid_1's multi_logloss: 0.285267       \n",
      "[390]\ttraining's multi_logloss: 0.128445\tvalid_1's multi_logloss: 0.285261       \n",
      "[391]\ttraining's multi_logloss: 0.128064\tvalid_1's multi_logloss: 0.285255       \n",
      "[392]\ttraining's multi_logloss: 0.127683\tvalid_1's multi_logloss: 0.285224       \n",
      "[393]\ttraining's multi_logloss: 0.127311\tvalid_1's multi_logloss: 0.28522        \n",
      "[394]\ttraining's multi_logloss: 0.126937\tvalid_1's multi_logloss: 0.285154       \n",
      "[395]\ttraining's multi_logloss: 0.126554\tvalid_1's multi_logloss: 0.285168       \n",
      "[396]\ttraining's multi_logloss: 0.12617\tvalid_1's multi_logloss: 0.285208        \n",
      "[397]\ttraining's multi_logloss: 0.125776\tvalid_1's multi_logloss: 0.285211       \n",
      "[398]\ttraining's multi_logloss: 0.125382\tvalid_1's multi_logloss: 0.285192       \n",
      "[399]\ttraining's multi_logloss: 0.125003\tvalid_1's multi_logloss: 0.285138       \n",
      "[400]\ttraining's multi_logloss: 0.124602\tvalid_1's multi_logloss: 0.285116       \n",
      "Did not meet early stopping. Best iteration is:                                  \n",
      "[400]\ttraining's multi_logloss: 0.124602\tvalid_1's multi_logloss: 0.285116\n",
      "[1]\ttraining's multi_logloss: 1.87944\tvalid_1's multi_logloss: 1.88177           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.83195\tvalid_1's multi_logloss: 1.8347            \n",
      "[3]\ttraining's multi_logloss: 1.78716\tvalid_1's multi_logloss: 1.79033           \n",
      "[4]\ttraining's multi_logloss: 1.74482\tvalid_1's multi_logloss: 1.74838           \n",
      "[5]\ttraining's multi_logloss: 1.70465\tvalid_1's multi_logloss: 1.70865           \n",
      "[6]\ttraining's multi_logloss: 1.66632\tvalid_1's multi_logloss: 1.67073           \n",
      "[7]\ttraining's multi_logloss: 1.62966\tvalid_1's multi_logloss: 1.63443           \n",
      "[8]\ttraining's multi_logloss: 1.59476\tvalid_1's multi_logloss: 1.59985           \n",
      "[9]\ttraining's multi_logloss: 1.56142\tvalid_1's multi_logloss: 1.56682           \n",
      "[10]\ttraining's multi_logloss: 1.52941\tvalid_1's multi_logloss: 1.53512          \n",
      "[11]\ttraining's multi_logloss: 1.49852\tvalid_1's multi_logloss: 1.50453          \n",
      "[12]\ttraining's multi_logloss: 1.46878\tvalid_1's multi_logloss: 1.47503          \n",
      "[13]\ttraining's multi_logloss: 1.44009\tvalid_1's multi_logloss: 1.44665          \n",
      "[14]\ttraining's multi_logloss: 1.41257\tvalid_1's multi_logloss: 1.41939          \n",
      "[15]\ttraining's multi_logloss: 1.38595\tvalid_1's multi_logloss: 1.39297          \n",
      "[16]\ttraining's multi_logloss: 1.36022\tvalid_1's multi_logloss: 1.36744          \n",
      "[17]\ttraining's multi_logloss: 1.33536\tvalid_1's multi_logloss: 1.34279          \n",
      "[18]\ttraining's multi_logloss: 1.31145\tvalid_1's multi_logloss: 1.31908          \n",
      "[19]\ttraining's multi_logloss: 1.28817\tvalid_1's multi_logloss: 1.29605          \n",
      "[20]\ttraining's multi_logloss: 1.26569\tvalid_1's multi_logloss: 1.27376          \n",
      "[21]\ttraining's multi_logloss: 1.24395\tvalid_1's multi_logloss: 1.25232          \n",
      "[22]\ttraining's multi_logloss: 1.22283\tvalid_1's multi_logloss: 1.23147          \n",
      "[23]\ttraining's multi_logloss: 1.20232\tvalid_1's multi_logloss: 1.21118          \n",
      "[24]\ttraining's multi_logloss: 1.18248\tvalid_1's multi_logloss: 1.19157          \n",
      "[25]\ttraining's multi_logloss: 1.16313\tvalid_1's multi_logloss: 1.17235          \n",
      "[26]\ttraining's multi_logloss: 1.14438\tvalid_1's multi_logloss: 1.15383          \n",
      "[27]\ttraining's multi_logloss: 1.12608\tvalid_1's multi_logloss: 1.13577          \n",
      "[28]\ttraining's multi_logloss: 1.10816\tvalid_1's multi_logloss: 1.11801          \n",
      "[29]\ttraining's multi_logloss: 1.09082\tvalid_1's multi_logloss: 1.10094          \n",
      "[30]\ttraining's multi_logloss: 1.07405\tvalid_1's multi_logloss: 1.08441          \n",
      "[31]\ttraining's multi_logloss: 1.05767\tvalid_1's multi_logloss: 1.06824          \n",
      "[32]\ttraining's multi_logloss: 1.04169\tvalid_1's multi_logloss: 1.05247          \n",
      "[33]\ttraining's multi_logloss: 1.02619\tvalid_1's multi_logloss: 1.03722          \n",
      "[34]\ttraining's multi_logloss: 1.01105\tvalid_1's multi_logloss: 1.02221          \n",
      "[35]\ttraining's multi_logloss: 0.996257\tvalid_1's multi_logloss: 1.00762         \n",
      "[36]\ttraining's multi_logloss: 0.98182\tvalid_1's multi_logloss: 0.993347         \n",
      "[37]\ttraining's multi_logloss: 0.967782\tvalid_1's multi_logloss: 0.97953         \n",
      "[38]\ttraining's multi_logloss: 0.95389\tvalid_1's multi_logloss: 0.965816         \n",
      "[39]\ttraining's multi_logloss: 0.940481\tvalid_1's multi_logloss: 0.952585        \n",
      "[40]\ttraining's multi_logloss: 0.927417\tvalid_1's multi_logloss: 0.939774        \n",
      "[41]\ttraining's multi_logloss: 0.914705\tvalid_1's multi_logloss: 0.927193        \n",
      "[42]\ttraining's multi_logloss: 0.902155\tvalid_1's multi_logloss: 0.914892        \n",
      "[43]\ttraining's multi_logloss: 0.889794\tvalid_1's multi_logloss: 0.902741        \n",
      "[44]\ttraining's multi_logloss: 0.877863\tvalid_1's multi_logloss: 0.891021        \n",
      "[45]\ttraining's multi_logloss: 0.8661\tvalid_1's multi_logloss: 0.879553          \n",
      "[46]\ttraining's multi_logloss: 0.854615\tvalid_1's multi_logloss: 0.86829         \n",
      "[47]\ttraining's multi_logloss: 0.84338\tvalid_1's multi_logloss: 0.857366         \n",
      "[48]\ttraining's multi_logloss: 0.832393\tvalid_1's multi_logloss: 0.846635        \n",
      "[49]\ttraining's multi_logloss: 0.821623\tvalid_1's multi_logloss: 0.836087        \n",
      "[50]\ttraining's multi_logloss: 0.811138\tvalid_1's multi_logloss: 0.82579         \n",
      "[51]\ttraining's multi_logloss: 0.800832\tvalid_1's multi_logloss: 0.815721        \n",
      "[52]\ttraining's multi_logloss: 0.790718\tvalid_1's multi_logloss: 0.80585         \n",
      "[53]\ttraining's multi_logloss: 0.780789\tvalid_1's multi_logloss: 0.796134        \n",
      "[54]\ttraining's multi_logloss: 0.771092\tvalid_1's multi_logloss: 0.786676        \n",
      "[55]\ttraining's multi_logloss: 0.761664\tvalid_1's multi_logloss: 0.777516        \n",
      "[56]\ttraining's multi_logloss: 0.752398\tvalid_1's multi_logloss: 0.768493        \n",
      "[57]\ttraining's multi_logloss: 0.74329\tvalid_1's multi_logloss: 0.759642         \n",
      "[58]\ttraining's multi_logloss: 0.734443\tvalid_1's multi_logloss: 0.75103         \n",
      "[59]\ttraining's multi_logloss: 0.725763\tvalid_1's multi_logloss: 0.742615        \n",
      "[60]\ttraining's multi_logloss: 0.717236\tvalid_1's multi_logloss: 0.734282        \n",
      "[61]\ttraining's multi_logloss: 0.708876\tvalid_1's multi_logloss: 0.726167        \n",
      "[62]\ttraining's multi_logloss: 0.70074\tvalid_1's multi_logloss: 0.718317         \n",
      "[63]\ttraining's multi_logloss: 0.692614\tvalid_1's multi_logloss: 0.71044         \n",
      "[64]\ttraining's multi_logloss: 0.684705\tvalid_1's multi_logloss: 0.702821        \n",
      "[65]\ttraining's multi_logloss: 0.676886\tvalid_1's multi_logloss: 0.695217        \n",
      "[66]\ttraining's multi_logloss: 0.669277\tvalid_1's multi_logloss: 0.687914        \n",
      "[67]\ttraining's multi_logloss: 0.66185\tvalid_1's multi_logloss: 0.68075          \n",
      "[68]\ttraining's multi_logloss: 0.654606\tvalid_1's multi_logloss: 0.673792        \n",
      "[69]\ttraining's multi_logloss: 0.647404\tvalid_1's multi_logloss: 0.666806        \n",
      "[70]\ttraining's multi_logloss: 0.640387\tvalid_1's multi_logloss: 0.660017        \n",
      "[71]\ttraining's multi_logloss: 0.633537\tvalid_1's multi_logloss: 0.653477        \n",
      "[72]\ttraining's multi_logloss: 0.626699\tvalid_1's multi_logloss: 0.646854        \n",
      "[73]\ttraining's multi_logloss: 0.620096\tvalid_1's multi_logloss: 0.640547        \n",
      "[74]\ttraining's multi_logloss: 0.613577\tvalid_1's multi_logloss: 0.634266        \n",
      "[75]\ttraining's multi_logloss: 0.607265\tvalid_1's multi_logloss: 0.628291        \n",
      "[76]\ttraining's multi_logloss: 0.601023\tvalid_1's multi_logloss: 0.622408        \n",
      "[77]\ttraining's multi_logloss: 0.594829\tvalid_1's multi_logloss: 0.616444        \n",
      "[78]\ttraining's multi_logloss: 0.588846\tvalid_1's multi_logloss: 0.610765        \n",
      "[79]\ttraining's multi_logloss: 0.582937\tvalid_1's multi_logloss: 0.605147        \n",
      "[80]\ttraining's multi_logloss: 0.577167\tvalid_1's multi_logloss: 0.599673        \n",
      "[81]\ttraining's multi_logloss: 0.571528\tvalid_1's multi_logloss: 0.59439         \n",
      "[82]\ttraining's multi_logloss: 0.565965\tvalid_1's multi_logloss: 0.589125        \n",
      "[83]\ttraining's multi_logloss: 0.560457\tvalid_1's multi_logloss: 0.583937        \n",
      "[84]\ttraining's multi_logloss: 0.555109\tvalid_1's multi_logloss: 0.578898        \n",
      "[85]\ttraining's multi_logloss: 0.54987\tvalid_1's multi_logloss: 0.573983         \n",
      "[86]\ttraining's multi_logloss: 0.544648\tvalid_1's multi_logloss: 0.56905         \n",
      "[87]\ttraining's multi_logloss: 0.539545\tvalid_1's multi_logloss: 0.564299        \n",
      "[88]\ttraining's multi_logloss: 0.53451\tvalid_1's multi_logloss: 0.559592         \n",
      "[89]\ttraining's multi_logloss: 0.529581\tvalid_1's multi_logloss: 0.554968        \n",
      "[90]\ttraining's multi_logloss: 0.52472\tvalid_1's multi_logloss: 0.550396         \n",
      "[91]\ttraining's multi_logloss: 0.520023\tvalid_1's multi_logloss: 0.546035        \n",
      "[92]\ttraining's multi_logloss: 0.515293\tvalid_1's multi_logloss: 0.541659        \n",
      "[93]\ttraining's multi_logloss: 0.510697\tvalid_1's multi_logloss: 0.53738         \n",
      "[94]\ttraining's multi_logloss: 0.506126\tvalid_1's multi_logloss: 0.533097        \n",
      "[95]\ttraining's multi_logloss: 0.501604\tvalid_1's multi_logloss: 0.528875        \n",
      "[96]\ttraining's multi_logloss: 0.497204\tvalid_1's multi_logloss: 0.524802        \n",
      "[97]\ttraining's multi_logloss: 0.492931\tvalid_1's multi_logloss: 0.520874        \n",
      "[98]\ttraining's multi_logloss: 0.488696\tvalid_1's multi_logloss: 0.516972        \n",
      "[99]\ttraining's multi_logloss: 0.484512\tvalid_1's multi_logloss: 0.51309         \n",
      "[100]\ttraining's multi_logloss: 0.480369\tvalid_1's multi_logloss: 0.509236       \n",
      "[101]\ttraining's multi_logloss: 0.476293\tvalid_1's multi_logloss: 0.505449       \n",
      "[102]\ttraining's multi_logloss: 0.472277\tvalid_1's multi_logloss: 0.501742       \n",
      "[103]\ttraining's multi_logloss: 0.468306\tvalid_1's multi_logloss: 0.498093       \n",
      "[104]\ttraining's multi_logloss: 0.464446\tvalid_1's multi_logloss: 0.494542       \n",
      "[105]\ttraining's multi_logloss: 0.460673\tvalid_1's multi_logloss: 0.491099       \n",
      "[106]\ttraining's multi_logloss: 0.456925\tvalid_1's multi_logloss: 0.487625       \n",
      "[107]\ttraining's multi_logloss: 0.4532\tvalid_1's multi_logloss: 0.48421          \n",
      "[108]\ttraining's multi_logloss: 0.44957\tvalid_1's multi_logloss: 0.480917        \n",
      "[109]\ttraining's multi_logloss: 0.445983\tvalid_1's multi_logloss: 0.477663       \n",
      "[110]\ttraining's multi_logloss: 0.442457\tvalid_1's multi_logloss: 0.474464       \n",
      "[111]\ttraining's multi_logloss: 0.438957\tvalid_1's multi_logloss: 0.4713         \n",
      "[112]\ttraining's multi_logloss: 0.43555\tvalid_1's multi_logloss: 0.468216        \n",
      "[113]\ttraining's multi_logloss: 0.432199\tvalid_1's multi_logloss: 0.465183       \n",
      "[114]\ttraining's multi_logloss: 0.428877\tvalid_1's multi_logloss: 0.462172       \n",
      "[115]\ttraining's multi_logloss: 0.425622\tvalid_1's multi_logloss: 0.459232       \n",
      "[116]\ttraining's multi_logloss: 0.422441\tvalid_1's multi_logloss: 0.456354       \n",
      "[117]\ttraining's multi_logloss: 0.419307\tvalid_1's multi_logloss: 0.453498       \n",
      "[118]\ttraining's multi_logloss: 0.41616\tvalid_1's multi_logloss: 0.450689        \n",
      "[119]\ttraining's multi_logloss: 0.413098\tvalid_1's multi_logloss: 0.447925       \n",
      "[120]\ttraining's multi_logloss: 0.410083\tvalid_1's multi_logloss: 0.445178       \n",
      "[121]\ttraining's multi_logloss: 0.407123\tvalid_1's multi_logloss: 0.442502       \n",
      "[122]\ttraining's multi_logloss: 0.404153\tvalid_1's multi_logloss: 0.439778       \n",
      "[123]\ttraining's multi_logloss: 0.401232\tvalid_1's multi_logloss: 0.437136       \n",
      "[124]\ttraining's multi_logloss: 0.398406\tvalid_1's multi_logloss: 0.434585       \n",
      "[125]\ttraining's multi_logloss: 0.395598\tvalid_1's multi_logloss: 0.432053       \n",
      "[126]\ttraining's multi_logloss: 0.392726\tvalid_1's multi_logloss: 0.429471       \n",
      "[127]\ttraining's multi_logloss: 0.389975\tvalid_1's multi_logloss: 0.427022       \n",
      "[128]\ttraining's multi_logloss: 0.387201\tvalid_1's multi_logloss: 0.424549       \n",
      "[129]\ttraining's multi_logloss: 0.384537\tvalid_1's multi_logloss: 0.422203       \n",
      "[130]\ttraining's multi_logloss: 0.381835\tvalid_1's multi_logloss: 0.419825       \n",
      "[131]\ttraining's multi_logloss: 0.379296\tvalid_1's multi_logloss: 0.41759        \n",
      "[132]\ttraining's multi_logloss: 0.376747\tvalid_1's multi_logloss: 0.415357       \n",
      "[133]\ttraining's multi_logloss: 0.374196\tvalid_1's multi_logloss: 0.413089       \n",
      "[134]\ttraining's multi_logloss: 0.371731\tvalid_1's multi_logloss: 0.410944       \n",
      "[135]\ttraining's multi_logloss: 0.369288\tvalid_1's multi_logloss: 0.408868       \n",
      "[136]\ttraining's multi_logloss: 0.366855\tvalid_1's multi_logloss: 0.406761       \n",
      "[137]\ttraining's multi_logloss: 0.364527\tvalid_1's multi_logloss: 0.404782       \n",
      "[138]\ttraining's multi_logloss: 0.362144\tvalid_1's multi_logloss: 0.402729       \n",
      "[139]\ttraining's multi_logloss: 0.359812\tvalid_1's multi_logloss: 0.400692       \n",
      "[140]\ttraining's multi_logloss: 0.357548\tvalid_1's multi_logloss: 0.398718       \n",
      "[141]\ttraining's multi_logloss: 0.355206\tvalid_1's multi_logloss: 0.396691       \n",
      "[142]\ttraining's multi_logloss: 0.352984\tvalid_1's multi_logloss: 0.394846       \n",
      "[143]\ttraining's multi_logloss: 0.350722\tvalid_1's multi_logloss: 0.392924       \n",
      "[144]\ttraining's multi_logloss: 0.348473\tvalid_1's multi_logloss: 0.390928       \n",
      "[145]\ttraining's multi_logloss: 0.346321\tvalid_1's multi_logloss: 0.389138       \n",
      "[146]\ttraining's multi_logloss: 0.344133\tvalid_1's multi_logloss: 0.387282       \n",
      "[147]\ttraining's multi_logloss: 0.342021\tvalid_1's multi_logloss: 0.385517       \n",
      "[148]\ttraining's multi_logloss: 0.339991\tvalid_1's multi_logloss: 0.38376        \n",
      "[149]\ttraining's multi_logloss: 0.337928\tvalid_1's multi_logloss: 0.382003       \n",
      "[150]\ttraining's multi_logloss: 0.335913\tvalid_1's multi_logloss: 0.38025        \n",
      "[151]\ttraining's multi_logloss: 0.333912\tvalid_1's multi_logloss: 0.378573       \n",
      "[152]\ttraining's multi_logloss: 0.331976\tvalid_1's multi_logloss: 0.376939       \n",
      "[153]\ttraining's multi_logloss: 0.33001\tvalid_1's multi_logloss: 0.375245        \n",
      "[154]\ttraining's multi_logloss: 0.328111\tvalid_1's multi_logloss: 0.373664       \n",
      "[155]\ttraining's multi_logloss: 0.326216\tvalid_1's multi_logloss: 0.372138       \n",
      "[156]\ttraining's multi_logloss: 0.324339\tvalid_1's multi_logloss: 0.370592       \n",
      "[157]\ttraining's multi_logloss: 0.322503\tvalid_1's multi_logloss: 0.369116       \n",
      "[158]\ttraining's multi_logloss: 0.32065\tvalid_1's multi_logloss: 0.367569        \n",
      "[159]\ttraining's multi_logloss: 0.318839\tvalid_1's multi_logloss: 0.366086       \n",
      "[160]\ttraining's multi_logloss: 0.317048\tvalid_1's multi_logloss: 0.364608       \n",
      "[161]\ttraining's multi_logloss: 0.315283\tvalid_1's multi_logloss: 0.363178       \n",
      "[162]\ttraining's multi_logloss: 0.313556\tvalid_1's multi_logloss: 0.361806       \n",
      "[163]\ttraining's multi_logloss: 0.311845\tvalid_1's multi_logloss: 0.360435       \n",
      "[164]\ttraining's multi_logloss: 0.310158\tvalid_1's multi_logloss: 0.359083       \n",
      "[165]\ttraining's multi_logloss: 0.308478\tvalid_1's multi_logloss: 0.357764       \n",
      "[166]\ttraining's multi_logloss: 0.30683\tvalid_1's multi_logloss: 0.356479        \n",
      "[167]\ttraining's multi_logloss: 0.305169\tvalid_1's multi_logloss: 0.355178       \n",
      "[168]\ttraining's multi_logloss: 0.30354\tvalid_1's multi_logloss: 0.35396         \n",
      "[169]\ttraining's multi_logloss: 0.301893\tvalid_1's multi_logloss: 0.352684       \n",
      "[170]\ttraining's multi_logloss: 0.300282\tvalid_1's multi_logloss: 0.351412       \n",
      "[171]\ttraining's multi_logloss: 0.298707\tvalid_1's multi_logloss: 0.350206       \n",
      "[172]\ttraining's multi_logloss: 0.29711\tvalid_1's multi_logloss: 0.34898         \n",
      "[173]\ttraining's multi_logloss: 0.295555\tvalid_1's multi_logloss: 0.347723       \n",
      "[174]\ttraining's multi_logloss: 0.294021\tvalid_1's multi_logloss: 0.346507       \n",
      "[175]\ttraining's multi_logloss: 0.292492\tvalid_1's multi_logloss: 0.345321       \n",
      "[176]\ttraining's multi_logloss: 0.290985\tvalid_1's multi_logloss: 0.344159       \n",
      "[177]\ttraining's multi_logloss: 0.28947\tvalid_1's multi_logloss: 0.343053        \n",
      "[178]\ttraining's multi_logloss: 0.287993\tvalid_1's multi_logloss: 0.34193        \n",
      "[179]\ttraining's multi_logloss: 0.286486\tvalid_1's multi_logloss: 0.340844       \n",
      "[180]\ttraining's multi_logloss: 0.28502\tvalid_1's multi_logloss: 0.339757        \n",
      "[181]\ttraining's multi_logloss: 0.28358\tvalid_1's multi_logloss: 0.3387          \n",
      "[182]\ttraining's multi_logloss: 0.28214\tvalid_1's multi_logloss: 0.337697        \n",
      "[183]\ttraining's multi_logloss: 0.28072\tvalid_1's multi_logloss: 0.336747        \n",
      "[184]\ttraining's multi_logloss: 0.279354\tvalid_1's multi_logloss: 0.335763       \n",
      "[185]\ttraining's multi_logloss: 0.278057\tvalid_1's multi_logloss: 0.334797       \n",
      "[186]\ttraining's multi_logloss: 0.276703\tvalid_1's multi_logloss: 0.333868       \n",
      "[187]\ttraining's multi_logloss: 0.275361\tvalid_1's multi_logloss: 0.332888       \n",
      "[188]\ttraining's multi_logloss: 0.274097\tvalid_1's multi_logloss: 0.331946       \n",
      "[189]\ttraining's multi_logloss: 0.272791\tvalid_1's multi_logloss: 0.331014       \n",
      "[190]\ttraining's multi_logloss: 0.271552\tvalid_1's multi_logloss: 0.330174       \n",
      "[191]\ttraining's multi_logloss: 0.270243\tvalid_1's multi_logloss: 0.329287       \n",
      "[192]\ttraining's multi_logloss: 0.268956\tvalid_1's multi_logloss: 0.328436       \n",
      "[193]\ttraining's multi_logloss: 0.267701\tvalid_1's multi_logloss: 0.327569       \n",
      "[194]\ttraining's multi_logloss: 0.266482\tvalid_1's multi_logloss: 0.326752       \n",
      "[195]\ttraining's multi_logloss: 0.265238\tvalid_1's multi_logloss: 0.32593        \n",
      "[196]\ttraining's multi_logloss: 0.264048\tvalid_1's multi_logloss: 0.325156       \n",
      "[197]\ttraining's multi_logloss: 0.26283\tvalid_1's multi_logloss: 0.324302        \n",
      "[198]\ttraining's multi_logloss: 0.261648\tvalid_1's multi_logloss: 0.323505       \n",
      "[199]\ttraining's multi_logloss: 0.260434\tvalid_1's multi_logloss: 0.322674       \n",
      "[200]\ttraining's multi_logloss: 0.259248\tvalid_1's multi_logloss: 0.321871       \n",
      "[201]\ttraining's multi_logloss: 0.258091\tvalid_1's multi_logloss: 0.321082       \n",
      "[202]\ttraining's multi_logloss: 0.256919\tvalid_1's multi_logloss: 0.320281       \n",
      "[203]\ttraining's multi_logloss: 0.255778\tvalid_1's multi_logloss: 0.319548       \n",
      "[204]\ttraining's multi_logloss: 0.254681\tvalid_1's multi_logloss: 0.318858       \n",
      "[205]\ttraining's multi_logloss: 0.25357\tvalid_1's multi_logloss: 0.318222        \n",
      "[206]\ttraining's multi_logloss: 0.252466\tvalid_1's multi_logloss: 0.317506       \n",
      "[207]\ttraining's multi_logloss: 0.251366\tvalid_1's multi_logloss: 0.316814       \n",
      "[208]\ttraining's multi_logloss: 0.250294\tvalid_1's multi_logloss: 0.316114       \n",
      "[209]\ttraining's multi_logloss: 0.249204\tvalid_1's multi_logloss: 0.3154         \n",
      "[210]\ttraining's multi_logloss: 0.248152\tvalid_1's multi_logloss: 0.314738       \n",
      "[211]\ttraining's multi_logloss: 0.247109\tvalid_1's multi_logloss: 0.314127       \n",
      "[212]\ttraining's multi_logloss: 0.246051\tvalid_1's multi_logloss: 0.313485       \n",
      "[213]\ttraining's multi_logloss: 0.245038\tvalid_1's multi_logloss: 0.312823       \n",
      "[214]\ttraining's multi_logloss: 0.243991\tvalid_1's multi_logloss: 0.312185       \n",
      "[215]\ttraining's multi_logloss: 0.242993\tvalid_1's multi_logloss: 0.311591       \n",
      "[216]\ttraining's multi_logloss: 0.241981\tvalid_1's multi_logloss: 0.310937       \n",
      "[217]\ttraining's multi_logloss: 0.240982\tvalid_1's multi_logloss: 0.310347       \n",
      "[218]\ttraining's multi_logloss: 0.24001\tvalid_1's multi_logloss: 0.309697        \n",
      "[219]\ttraining's multi_logloss: 0.239019\tvalid_1's multi_logloss: 0.309115       \n",
      "[220]\ttraining's multi_logloss: 0.238056\tvalid_1's multi_logloss: 0.308501       \n",
      "[221]\ttraining's multi_logloss: 0.237081\tvalid_1's multi_logloss: 0.30795        \n",
      "[222]\ttraining's multi_logloss: 0.236117\tvalid_1's multi_logloss: 0.307359       \n",
      "[223]\ttraining's multi_logloss: 0.23516\tvalid_1's multi_logloss: 0.306803        \n",
      "[224]\ttraining's multi_logloss: 0.234175\tvalid_1's multi_logloss: 0.306171       \n",
      "[225]\ttraining's multi_logloss: 0.233219\tvalid_1's multi_logloss: 0.305591       \n",
      "[226]\ttraining's multi_logloss: 0.232288\tvalid_1's multi_logloss: 0.305051       \n",
      "[227]\ttraining's multi_logloss: 0.231342\tvalid_1's multi_logloss: 0.304516       \n",
      "[228]\ttraining's multi_logloss: 0.230414\tvalid_1's multi_logloss: 0.304035       \n",
      "[229]\ttraining's multi_logloss: 0.229492\tvalid_1's multi_logloss: 0.303516       \n",
      "[230]\ttraining's multi_logloss: 0.228616\tvalid_1's multi_logloss: 0.303001       \n",
      "[231]\ttraining's multi_logloss: 0.227744\tvalid_1's multi_logloss: 0.302583       \n",
      "[232]\ttraining's multi_logloss: 0.226864\tvalid_1's multi_logloss: 0.302096       \n",
      "[233]\ttraining's multi_logloss: 0.225992\tvalid_1's multi_logloss: 0.301632       \n",
      "[234]\ttraining's multi_logloss: 0.225097\tvalid_1's multi_logloss: 0.301113       \n",
      "[235]\ttraining's multi_logloss: 0.224227\tvalid_1's multi_logloss: 0.300641       \n",
      "[236]\ttraining's multi_logloss: 0.223368\tvalid_1's multi_logloss: 0.300181       \n",
      "[237]\ttraining's multi_logloss: 0.222532\tvalid_1's multi_logloss: 0.29972        \n",
      "[238]\ttraining's multi_logloss: 0.221715\tvalid_1's multi_logloss: 0.299327       \n",
      "[239]\ttraining's multi_logloss: 0.220893\tvalid_1's multi_logloss: 0.298902       \n",
      "[240]\ttraining's multi_logloss: 0.220034\tvalid_1's multi_logloss: 0.298439       \n",
      "[241]\ttraining's multi_logloss: 0.219196\tvalid_1's multi_logloss: 0.298016       \n",
      "[242]\ttraining's multi_logloss: 0.218357\tvalid_1's multi_logloss: 0.297611       \n",
      "[243]\ttraining's multi_logloss: 0.217564\tvalid_1's multi_logloss: 0.297241       \n",
      "[244]\ttraining's multi_logloss: 0.21675\tvalid_1's multi_logloss: 0.29684         \n",
      "[245]\ttraining's multi_logloss: 0.21594\tvalid_1's multi_logloss: 0.296437        \n",
      "[246]\ttraining's multi_logloss: 0.215136\tvalid_1's multi_logloss: 0.296042       \n",
      "[247]\ttraining's multi_logloss: 0.214332\tvalid_1's multi_logloss: 0.295687       \n",
      "[248]\ttraining's multi_logloss: 0.213558\tvalid_1's multi_logloss: 0.29528        \n",
      "[249]\ttraining's multi_logloss: 0.212763\tvalid_1's multi_logloss: 0.294892       \n",
      "[250]\ttraining's multi_logloss: 0.211971\tvalid_1's multi_logloss: 0.294537       \n",
      "[251]\ttraining's multi_logloss: 0.211171\tvalid_1's multi_logloss: 0.294167       \n",
      "[252]\ttraining's multi_logloss: 0.210408\tvalid_1's multi_logloss: 0.293751       \n",
      "[253]\ttraining's multi_logloss: 0.209637\tvalid_1's multi_logloss: 0.293411       \n",
      "[254]\ttraining's multi_logloss: 0.208847\tvalid_1's multi_logloss: 0.292981       \n",
      "[255]\ttraining's multi_logloss: 0.208072\tvalid_1's multi_logloss: 0.292691       \n",
      "[256]\ttraining's multi_logloss: 0.207314\tvalid_1's multi_logloss: 0.292325       \n",
      "[257]\ttraining's multi_logloss: 0.206577\tvalid_1's multi_logloss: 0.292059       \n",
      "[258]\ttraining's multi_logloss: 0.205867\tvalid_1's multi_logloss: 0.291779       \n",
      "[259]\ttraining's multi_logloss: 0.205125\tvalid_1's multi_logloss: 0.29146        \n",
      "[260]\ttraining's multi_logloss: 0.204397\tvalid_1's multi_logloss: 0.29108        \n",
      "[261]\ttraining's multi_logloss: 0.203659\tvalid_1's multi_logloss: 0.290803       \n",
      "[262]\ttraining's multi_logloss: 0.202934\tvalid_1's multi_logloss: 0.290495       \n",
      "[263]\ttraining's multi_logloss: 0.202215\tvalid_1's multi_logloss: 0.29025        \n",
      "[264]\ttraining's multi_logloss: 0.20153\tvalid_1's multi_logloss: 0.289971        \n",
      "[265]\ttraining's multi_logloss: 0.200808\tvalid_1's multi_logloss: 0.289711       \n",
      "[266]\ttraining's multi_logloss: 0.2001\tvalid_1's multi_logloss: 0.289422         \n",
      "[267]\ttraining's multi_logloss: 0.19938\tvalid_1's multi_logloss: 0.289142        \n",
      "[268]\ttraining's multi_logloss: 0.198694\tvalid_1's multi_logloss: 0.288873       \n",
      "[269]\ttraining's multi_logloss: 0.198022\tvalid_1's multi_logloss: 0.288598       \n",
      "[270]\ttraining's multi_logloss: 0.197316\tvalid_1's multi_logloss: 0.288319       \n",
      "[271]\ttraining's multi_logloss: 0.196621\tvalid_1's multi_logloss: 0.288051       \n",
      "[272]\ttraining's multi_logloss: 0.195932\tvalid_1's multi_logloss: 0.287757       \n",
      "[273]\ttraining's multi_logloss: 0.195273\tvalid_1's multi_logloss: 0.287483       \n",
      "[274]\ttraining's multi_logloss: 0.194615\tvalid_1's multi_logloss: 0.287231       \n",
      "[275]\ttraining's multi_logloss: 0.193954\tvalid_1's multi_logloss: 0.286978       \n",
      "[276]\ttraining's multi_logloss: 0.193301\tvalid_1's multi_logloss: 0.286696       \n",
      "[277]\ttraining's multi_logloss: 0.192645\tvalid_1's multi_logloss: 0.286475       \n",
      "[278]\ttraining's multi_logloss: 0.191956\tvalid_1's multi_logloss: 0.286164       \n",
      "[279]\ttraining's multi_logloss: 0.191312\tvalid_1's multi_logloss: 0.285903       \n",
      "[280]\ttraining's multi_logloss: 0.190652\tvalid_1's multi_logloss: 0.285679       \n",
      "[281]\ttraining's multi_logloss: 0.189998\tvalid_1's multi_logloss: 0.285473       \n",
      "[282]\ttraining's multi_logloss: 0.189351\tvalid_1's multi_logloss: 0.285196       \n",
      "[283]\ttraining's multi_logloss: 0.188729\tvalid_1's multi_logloss: 0.284968       \n",
      "[284]\ttraining's multi_logloss: 0.188095\tvalid_1's multi_logloss: 0.284692       \n",
      "[285]\ttraining's multi_logloss: 0.187446\tvalid_1's multi_logloss: 0.284491       \n",
      "[286]\ttraining's multi_logloss: 0.186826\tvalid_1's multi_logloss: 0.284237       \n",
      "[287]\ttraining's multi_logloss: 0.186185\tvalid_1's multi_logloss: 0.284012       \n",
      "[288]\ttraining's multi_logloss: 0.18557\tvalid_1's multi_logloss: 0.283798        \n",
      "[289]\ttraining's multi_logloss: 0.18495\tvalid_1's multi_logloss: 0.2836          \n",
      "[290]\ttraining's multi_logloss: 0.184304\tvalid_1's multi_logloss: 0.283343       \n",
      "[291]\ttraining's multi_logloss: 0.183705\tvalid_1's multi_logloss: 0.283139       \n",
      "[292]\ttraining's multi_logloss: 0.183104\tvalid_1's multi_logloss: 0.282947       \n",
      "[293]\ttraining's multi_logloss: 0.18247\tvalid_1's multi_logloss: 0.282726        \n",
      "[294]\ttraining's multi_logloss: 0.181874\tvalid_1's multi_logloss: 0.282502       \n",
      "[295]\ttraining's multi_logloss: 0.181289\tvalid_1's multi_logloss: 0.28232        \n",
      "[296]\ttraining's multi_logloss: 0.180691\tvalid_1's multi_logloss: 0.282145       \n",
      "[297]\ttraining's multi_logloss: 0.180086\tvalid_1's multi_logloss: 0.281928       \n",
      "[298]\ttraining's multi_logloss: 0.17949\tvalid_1's multi_logloss: 0.281697        \n",
      "[299]\ttraining's multi_logloss: 0.178891\tvalid_1's multi_logloss: 0.281534       \n",
      "[300]\ttraining's multi_logloss: 0.178286\tvalid_1's multi_logloss: 0.281409       \n",
      "[301]\ttraining's multi_logloss: 0.177674\tvalid_1's multi_logloss: 0.281225       \n",
      "[302]\ttraining's multi_logloss: 0.177074\tvalid_1's multi_logloss: 0.281083       \n",
      "[303]\ttraining's multi_logloss: 0.176497\tvalid_1's multi_logloss: 0.280927       \n",
      "[304]\ttraining's multi_logloss: 0.175928\tvalid_1's multi_logloss: 0.280741       \n",
      "[305]\ttraining's multi_logloss: 0.175346\tvalid_1's multi_logloss: 0.280633       \n",
      "[306]\ttraining's multi_logloss: 0.174764\tvalid_1's multi_logloss: 0.280474       \n",
      "[307]\ttraining's multi_logloss: 0.174199\tvalid_1's multi_logloss: 0.28028        \n",
      "[308]\ttraining's multi_logloss: 0.173631\tvalid_1's multi_logloss: 0.280101       \n",
      "[309]\ttraining's multi_logloss: 0.173045\tvalid_1's multi_logloss: 0.279968       \n",
      "[310]\ttraining's multi_logloss: 0.172482\tvalid_1's multi_logloss: 0.27979        \n",
      "[311]\ttraining's multi_logloss: 0.171904\tvalid_1's multi_logloss: 0.279617       \n",
      "[312]\ttraining's multi_logloss: 0.171342\tvalid_1's multi_logloss: 0.279442       \n",
      "[313]\ttraining's multi_logloss: 0.170766\tvalid_1's multi_logloss: 0.279298       \n",
      "[314]\ttraining's multi_logloss: 0.170227\tvalid_1's multi_logloss: 0.279215       \n",
      "[315]\ttraining's multi_logloss: 0.169656\tvalid_1's multi_logloss: 0.279064       \n",
      "[316]\ttraining's multi_logloss: 0.169085\tvalid_1's multi_logloss: 0.279012       \n",
      "[317]\ttraining's multi_logloss: 0.168518\tvalid_1's multi_logloss: 0.27886        \n",
      "[318]\ttraining's multi_logloss: 0.167952\tvalid_1's multi_logloss: 0.278735       \n",
      "[319]\ttraining's multi_logloss: 0.167394\tvalid_1's multi_logloss: 0.278635       \n",
      "[320]\ttraining's multi_logloss: 0.166832\tvalid_1's multi_logloss: 0.278503       \n",
      "[321]\ttraining's multi_logloss: 0.166271\tvalid_1's multi_logloss: 0.278413       \n",
      "[322]\ttraining's multi_logloss: 0.165734\tvalid_1's multi_logloss: 0.27833        \n",
      "[323]\ttraining's multi_logloss: 0.165171\tvalid_1's multi_logloss: 0.278175       \n",
      "[324]\ttraining's multi_logloss: 0.164617\tvalid_1's multi_logloss: 0.278133       \n",
      "[325]\ttraining's multi_logloss: 0.164096\tvalid_1's multi_logloss: 0.278042       \n",
      "[326]\ttraining's multi_logloss: 0.163562\tvalid_1's multi_logloss: 0.277955       \n",
      "[327]\ttraining's multi_logloss: 0.163015\tvalid_1's multi_logloss: 0.277833       \n",
      "[328]\ttraining's multi_logloss: 0.162474\tvalid_1's multi_logloss: 0.277754       \n",
      "[329]\ttraining's multi_logloss: 0.161967\tvalid_1's multi_logloss: 0.277594       \n",
      "[330]\ttraining's multi_logloss: 0.161433\tvalid_1's multi_logloss: 0.277507       \n",
      "[331]\ttraining's multi_logloss: 0.1609\tvalid_1's multi_logloss: 0.277382         \n",
      "[332]\ttraining's multi_logloss: 0.160405\tvalid_1's multi_logloss: 0.277315       \n",
      "[333]\ttraining's multi_logloss: 0.159894\tvalid_1's multi_logloss: 0.277286       \n",
      "[334]\ttraining's multi_logloss: 0.159365\tvalid_1's multi_logloss: 0.277227       \n",
      "[335]\ttraining's multi_logloss: 0.158862\tvalid_1's multi_logloss: 0.277142       \n",
      "[336]\ttraining's multi_logloss: 0.158393\tvalid_1's multi_logloss: 0.277036       \n",
      "[337]\ttraining's multi_logloss: 0.157895\tvalid_1's multi_logloss: 0.276988       \n",
      "[338]\ttraining's multi_logloss: 0.157373\tvalid_1's multi_logloss: 0.276864       \n",
      "[339]\ttraining's multi_logloss: 0.156865\tvalid_1's multi_logloss: 0.2767         \n",
      "[340]\ttraining's multi_logloss: 0.156385\tvalid_1's multi_logloss: 0.276659       \n",
      "[341]\ttraining's multi_logloss: 0.155891\tvalid_1's multi_logloss: 0.27656        \n",
      "[342]\ttraining's multi_logloss: 0.155386\tvalid_1's multi_logloss: 0.276437       \n",
      "[343]\ttraining's multi_logloss: 0.154873\tvalid_1's multi_logloss: 0.276343       \n",
      "[344]\ttraining's multi_logloss: 0.154393\tvalid_1's multi_logloss: 0.276228       \n",
      "[345]\ttraining's multi_logloss: 0.153926\tvalid_1's multi_logloss: 0.276141       \n",
      "[346]\ttraining's multi_logloss: 0.153442\tvalid_1's multi_logloss: 0.276036       \n",
      "[347]\ttraining's multi_logloss: 0.152973\tvalid_1's multi_logloss: 0.275948       \n",
      "[348]\ttraining's multi_logloss: 0.152485\tvalid_1's multi_logloss: 0.275816       \n",
      "[349]\ttraining's multi_logloss: 0.152017\tvalid_1's multi_logloss: 0.275751       \n",
      "[350]\ttraining's multi_logloss: 0.151524\tvalid_1's multi_logloss: 0.275681       \n",
      "[351]\ttraining's multi_logloss: 0.15106\tvalid_1's multi_logloss: 0.27565         \n",
      "[352]\ttraining's multi_logloss: 0.150582\tvalid_1's multi_logloss: 0.275527       \n",
      "[353]\ttraining's multi_logloss: 0.150117\tvalid_1's multi_logloss: 0.275407       \n",
      "[354]\ttraining's multi_logloss: 0.149642\tvalid_1's multi_logloss: 0.275349       \n",
      "[355]\ttraining's multi_logloss: 0.149194\tvalid_1's multi_logloss: 0.275291       \n",
      "[356]\ttraining's multi_logloss: 0.148734\tvalid_1's multi_logloss: 0.275239       \n",
      "[357]\ttraining's multi_logloss: 0.148275\tvalid_1's multi_logloss: 0.275151       \n",
      "[358]\ttraining's multi_logloss: 0.147835\tvalid_1's multi_logloss: 0.275093       \n",
      "[359]\ttraining's multi_logloss: 0.147367\tvalid_1's multi_logloss: 0.275018       \n",
      "[360]\ttraining's multi_logloss: 0.146915\tvalid_1's multi_logloss: 0.274943       \n",
      "[361]\ttraining's multi_logloss: 0.146478\tvalid_1's multi_logloss: 0.274864       \n",
      "[362]\ttraining's multi_logloss: 0.146033\tvalid_1's multi_logloss: 0.274765       \n",
      "[363]\ttraining's multi_logloss: 0.145594\tvalid_1's multi_logloss: 0.274737       \n",
      "[364]\ttraining's multi_logloss: 0.145137\tvalid_1's multi_logloss: 0.274654       \n",
      "[365]\ttraining's multi_logloss: 0.144676\tvalid_1's multi_logloss: 0.274589       \n",
      "[366]\ttraining's multi_logloss: 0.14424\tvalid_1's multi_logloss: 0.274554        \n",
      "[367]\ttraining's multi_logloss: 0.143823\tvalid_1's multi_logloss: 0.274525       \n",
      "[368]\ttraining's multi_logloss: 0.143378\tvalid_1's multi_logloss: 0.274494       \n",
      "[369]\ttraining's multi_logloss: 0.142935\tvalid_1's multi_logloss: 0.274389       \n",
      "[370]\ttraining's multi_logloss: 0.14251\tvalid_1's multi_logloss: 0.274397        \n",
      "[371]\ttraining's multi_logloss: 0.14207\tvalid_1's multi_logloss: 0.274359        \n",
      "[372]\ttraining's multi_logloss: 0.141647\tvalid_1's multi_logloss: 0.274314       \n",
      "[373]\ttraining's multi_logloss: 0.141211\tvalid_1's multi_logloss: 0.274271       \n",
      "[374]\ttraining's multi_logloss: 0.140766\tvalid_1's multi_logloss: 0.27424        \n",
      "[375]\ttraining's multi_logloss: 0.140355\tvalid_1's multi_logloss: 0.274232       \n",
      "[376]\ttraining's multi_logloss: 0.139913\tvalid_1's multi_logloss: 0.274104       \n",
      "[377]\ttraining's multi_logloss: 0.139456\tvalid_1's multi_logloss: 0.274069       \n",
      "[378]\ttraining's multi_logloss: 0.139016\tvalid_1's multi_logloss: 0.27402        \n",
      "[379]\ttraining's multi_logloss: 0.138569\tvalid_1's multi_logloss: 0.273978       \n",
      "[380]\ttraining's multi_logloss: 0.138147\tvalid_1's multi_logloss: 0.273912       \n",
      "[381]\ttraining's multi_logloss: 0.137713\tvalid_1's multi_logloss: 0.273835       \n",
      "[382]\ttraining's multi_logloss: 0.137274\tvalid_1's multi_logloss: 0.273773       \n",
      "[383]\ttraining's multi_logloss: 0.136822\tvalid_1's multi_logloss: 0.273732       \n",
      "[384]\ttraining's multi_logloss: 0.136413\tvalid_1's multi_logloss: 0.273702       \n",
      "[385]\ttraining's multi_logloss: 0.135968\tvalid_1's multi_logloss: 0.273615       \n",
      "[386]\ttraining's multi_logloss: 0.135545\tvalid_1's multi_logloss: 0.273612       \n",
      "[387]\ttraining's multi_logloss: 0.135115\tvalid_1's multi_logloss: 0.273539       \n",
      "[388]\ttraining's multi_logloss: 0.134701\tvalid_1's multi_logloss: 0.273466       \n",
      "[389]\ttraining's multi_logloss: 0.134263\tvalid_1's multi_logloss: 0.27344        \n",
      "[390]\ttraining's multi_logloss: 0.133849\tvalid_1's multi_logloss: 0.273364       \n",
      "[391]\ttraining's multi_logloss: 0.133451\tvalid_1's multi_logloss: 0.273357       \n",
      "[392]\ttraining's multi_logloss: 0.133045\tvalid_1's multi_logloss: 0.273297       \n",
      "[393]\ttraining's multi_logloss: 0.132643\tvalid_1's multi_logloss: 0.273242       \n",
      "[394]\ttraining's multi_logloss: 0.132245\tvalid_1's multi_logloss: 0.273209       \n",
      "[395]\ttraining's multi_logloss: 0.131856\tvalid_1's multi_logloss: 0.27321        \n",
      "[396]\ttraining's multi_logloss: 0.131456\tvalid_1's multi_logloss: 0.273145       \n",
      "[397]\ttraining's multi_logloss: 0.131063\tvalid_1's multi_logloss: 0.273106       \n",
      "[398]\ttraining's multi_logloss: 0.130674\tvalid_1's multi_logloss: 0.273074       \n",
      "[399]\ttraining's multi_logloss: 0.13027\tvalid_1's multi_logloss: 0.272968        \n",
      "[400]\ttraining's multi_logloss: 0.129882\tvalid_1's multi_logloss: 0.272898       \n",
      "Did not meet early stopping. Best iteration is:                                  \n",
      "[400]\ttraining's multi_logloss: 0.129882\tvalid_1's multi_logloss: 0.272898\n",
      "[1]\ttraining's multi_logloss: 1.76779\tvalid_1's multi_logloss: 1.76891           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.63264\tvalid_1's multi_logloss: 1.63725           \n",
      "[3]\ttraining's multi_logloss: 1.51788\tvalid_1's multi_logloss: 1.5253            \n",
      "[4]\ttraining's multi_logloss: 1.41867\tvalid_1's multi_logloss: 1.42863           \n",
      "[5]\ttraining's multi_logloss: 1.33091\tvalid_1's multi_logloss: 1.34338           \n",
      "[6]\ttraining's multi_logloss: 1.25321\tvalid_1's multi_logloss: 1.26789           \n",
      "[7]\ttraining's multi_logloss: 1.18335\tvalid_1's multi_logloss: 1.19994           \n",
      "[8]\ttraining's multi_logloss: 1.12056\tvalid_1's multi_logloss: 1.13906           \n",
      "[9]\ttraining's multi_logloss: 1.06323\tvalid_1's multi_logloss: 1.08347           \n",
      "[10]\ttraining's multi_logloss: 1.01118\tvalid_1's multi_logloss: 1.03312          \n",
      "[11]\ttraining's multi_logloss: 0.963443\tvalid_1's multi_logloss: 0.987103        \n",
      "[12]\ttraining's multi_logloss: 0.919506\tvalid_1's multi_logloss: 0.944576        \n",
      "[13]\ttraining's multi_logloss: 0.878703\tvalid_1's multi_logloss: 0.9051          \n",
      "[14]\ttraining's multi_logloss: 0.840771\tvalid_1's multi_logloss: 0.86853         \n",
      "[15]\ttraining's multi_logloss: 0.805648\tvalid_1's multi_logloss: 0.834505        \n",
      "[16]\ttraining's multi_logloss: 0.77316\tvalid_1's multi_logloss: 0.803113         \n",
      "[17]\ttraining's multi_logloss: 0.742774\tvalid_1's multi_logloss: 0.773797        \n",
      "[18]\ttraining's multi_logloss: 0.714562\tvalid_1's multi_logloss: 0.746632        \n",
      "[19]\ttraining's multi_logloss: 0.687948\tvalid_1's multi_logloss: 0.721055        \n",
      "[20]\ttraining's multi_logloss: 0.662898\tvalid_1's multi_logloss: 0.697103        \n",
      "[21]\ttraining's multi_logloss: 0.639683\tvalid_1's multi_logloss: 0.674919        \n",
      "[22]\ttraining's multi_logloss: 0.617494\tvalid_1's multi_logloss: 0.653814        \n",
      "[23]\ttraining's multi_logloss: 0.596521\tvalid_1's multi_logloss: 0.633924        \n",
      "[24]\ttraining's multi_logloss: 0.577101\tvalid_1's multi_logloss: 0.615561        \n",
      "[25]\ttraining's multi_logloss: 0.558737\tvalid_1's multi_logloss: 0.598325        \n",
      "[26]\ttraining's multi_logloss: 0.541552\tvalid_1's multi_logloss: 0.582029        \n",
      "[27]\ttraining's multi_logloss: 0.525284\tvalid_1's multi_logloss: 0.566905        \n",
      "[28]\ttraining's multi_logloss: 0.50988\tvalid_1's multi_logloss: 0.55245          \n",
      "[29]\ttraining's multi_logloss: 0.495196\tvalid_1's multi_logloss: 0.538698        \n",
      "[30]\ttraining's multi_logloss: 0.481536\tvalid_1's multi_logloss: 0.52607         \n",
      "[31]\ttraining's multi_logloss: 0.468384\tvalid_1's multi_logloss: 0.513762        \n",
      "[32]\ttraining's multi_logloss: 0.456187\tvalid_1's multi_logloss: 0.502386        \n",
      "[33]\ttraining's multi_logloss: 0.44433\tvalid_1's multi_logloss: 0.491428         \n",
      "[34]\ttraining's multi_logloss: 0.433237\tvalid_1's multi_logloss: 0.48117         \n",
      "[35]\ttraining's multi_logloss: 0.422675\tvalid_1's multi_logloss: 0.471423        \n",
      "[36]\ttraining's multi_logloss: 0.412581\tvalid_1's multi_logloss: 0.462263        \n",
      "[37]\ttraining's multi_logloss: 0.403091\tvalid_1's multi_logloss: 0.453595        \n",
      "[38]\ttraining's multi_logloss: 0.393923\tvalid_1's multi_logloss: 0.445322        \n",
      "[39]\ttraining's multi_logloss: 0.385293\tvalid_1's multi_logloss: 0.43745         \n",
      "[40]\ttraining's multi_logloss: 0.377356\tvalid_1's multi_logloss: 0.430263        \n",
      "[41]\ttraining's multi_logloss: 0.369582\tvalid_1's multi_logloss: 0.423218        \n",
      "[42]\ttraining's multi_logloss: 0.362075\tvalid_1's multi_logloss: 0.416617        \n",
      "[43]\ttraining's multi_logloss: 0.355002\tvalid_1's multi_logloss: 0.410359        \n",
      "[44]\ttraining's multi_logloss: 0.348247\tvalid_1's multi_logloss: 0.40461         \n",
      "[45]\ttraining's multi_logloss: 0.341895\tvalid_1's multi_logloss: 0.399172        \n",
      "[46]\ttraining's multi_logloss: 0.335679\tvalid_1's multi_logloss: 0.394016        \n",
      "[47]\ttraining's multi_logloss: 0.329941\tvalid_1's multi_logloss: 0.389384        \n",
      "[48]\ttraining's multi_logloss: 0.324453\tvalid_1's multi_logloss: 0.384706        \n",
      "[49]\ttraining's multi_logloss: 0.319216\tvalid_1's multi_logloss: 0.380281        \n",
      "[50]\ttraining's multi_logloss: 0.314094\tvalid_1's multi_logloss: 0.375878        \n",
      "[51]\ttraining's multi_logloss: 0.309128\tvalid_1's multi_logloss: 0.371776        \n",
      "[52]\ttraining's multi_logloss: 0.304388\tvalid_1's multi_logloss: 0.367913        \n",
      "[53]\ttraining's multi_logloss: 0.299613\tvalid_1's multi_logloss: 0.364244        \n",
      "[54]\ttraining's multi_logloss: 0.295053\tvalid_1's multi_logloss: 0.360726        \n",
      "[55]\ttraining's multi_logloss: 0.2907\tvalid_1's multi_logloss: 0.357464          \n",
      "[56]\ttraining's multi_logloss: 0.286394\tvalid_1's multi_logloss: 0.354327        \n",
      "[57]\ttraining's multi_logloss: 0.2823\tvalid_1's multi_logloss: 0.351561          \n",
      "[58]\ttraining's multi_logloss: 0.278482\tvalid_1's multi_logloss: 0.348737        \n",
      "[59]\ttraining's multi_logloss: 0.274662\tvalid_1's multi_logloss: 0.345892        \n",
      "[60]\ttraining's multi_logloss: 0.271043\tvalid_1's multi_logloss: 0.3433          \n",
      "[61]\ttraining's multi_logloss: 0.267619\tvalid_1's multi_logloss: 0.340889        \n",
      "[62]\ttraining's multi_logloss: 0.264188\tvalid_1's multi_logloss: 0.338754        \n",
      "[63]\ttraining's multi_logloss: 0.260894\tvalid_1's multi_logloss: 0.336349        \n",
      "[64]\ttraining's multi_logloss: 0.257715\tvalid_1's multi_logloss: 0.334156        \n",
      "[65]\ttraining's multi_logloss: 0.254695\tvalid_1's multi_logloss: 0.332197        \n",
      "[66]\ttraining's multi_logloss: 0.251724\tvalid_1's multi_logloss: 0.33042         \n",
      "[67]\ttraining's multi_logloss: 0.248831\tvalid_1's multi_logloss: 0.328543        \n",
      "[68]\ttraining's multi_logloss: 0.245903\tvalid_1's multi_logloss: 0.326583        \n",
      "[69]\ttraining's multi_logloss: 0.243143\tvalid_1's multi_logloss: 0.324774        \n",
      "[70]\ttraining's multi_logloss: 0.240497\tvalid_1's multi_logloss: 0.323141        \n",
      "[71]\ttraining's multi_logloss: 0.237903\tvalid_1's multi_logloss: 0.321573        \n",
      "[72]\ttraining's multi_logloss: 0.235395\tvalid_1's multi_logloss: 0.320117        \n",
      "[73]\ttraining's multi_logloss: 0.232995\tvalid_1's multi_logloss: 0.318754        \n",
      "[74]\ttraining's multi_logloss: 0.230634\tvalid_1's multi_logloss: 0.31748         \n",
      "[75]\ttraining's multi_logloss: 0.228233\tvalid_1's multi_logloss: 0.316121        \n",
      "[76]\ttraining's multi_logloss: 0.225961\tvalid_1's multi_logloss: 0.315004        \n",
      "[77]\ttraining's multi_logloss: 0.223691\tvalid_1's multi_logloss: 0.313997        \n",
      "[78]\ttraining's multi_logloss: 0.221512\tvalid_1's multi_logloss: 0.312859        \n",
      "[79]\ttraining's multi_logloss: 0.219417\tvalid_1's multi_logloss: 0.311886        \n",
      "[80]\ttraining's multi_logloss: 0.217325\tvalid_1's multi_logloss: 0.310816        \n",
      "[81]\ttraining's multi_logloss: 0.215312\tvalid_1's multi_logloss: 0.30989         \n",
      "[82]\ttraining's multi_logloss: 0.213311\tvalid_1's multi_logloss: 0.308845        \n",
      "[83]\ttraining's multi_logloss: 0.21139\tvalid_1's multi_logloss: 0.307958         \n",
      "[84]\ttraining's multi_logloss: 0.209469\tvalid_1's multi_logloss: 0.307025        \n",
      "[85]\ttraining's multi_logloss: 0.207594\tvalid_1's multi_logloss: 0.306299        \n",
      "[86]\ttraining's multi_logloss: 0.205736\tvalid_1's multi_logloss: 0.305236        \n",
      "[87]\ttraining's multi_logloss: 0.203905\tvalid_1's multi_logloss: 0.304576        \n",
      "[88]\ttraining's multi_logloss: 0.202092\tvalid_1's multi_logloss: 0.303843        \n",
      "[89]\ttraining's multi_logloss: 0.20032\tvalid_1's multi_logloss: 0.303147         \n",
      "[90]\ttraining's multi_logloss: 0.198574\tvalid_1's multi_logloss: 0.302496        \n",
      "[91]\ttraining's multi_logloss: 0.196915\tvalid_1's multi_logloss: 0.301923        \n",
      "[92]\ttraining's multi_logloss: 0.195243\tvalid_1's multi_logloss: 0.301384        \n",
      "[93]\ttraining's multi_logloss: 0.193567\tvalid_1's multi_logloss: 0.300696        \n",
      "[94]\ttraining's multi_logloss: 0.191935\tvalid_1's multi_logloss: 0.3002          \n",
      "[95]\ttraining's multi_logloss: 0.190351\tvalid_1's multi_logloss: 0.299809        \n",
      "[96]\ttraining's multi_logloss: 0.188825\tvalid_1's multi_logloss: 0.299409        \n",
      "[97]\ttraining's multi_logloss: 0.18728\tvalid_1's multi_logloss: 0.298959         \n",
      "[98]\ttraining's multi_logloss: 0.185776\tvalid_1's multi_logloss: 0.298527        \n",
      "[99]\ttraining's multi_logloss: 0.184278\tvalid_1's multi_logloss: 0.298131        \n",
      "[100]\ttraining's multi_logloss: 0.182759\tvalid_1's multi_logloss: 0.297563       \n",
      "[101]\ttraining's multi_logloss: 0.181343\tvalid_1's multi_logloss: 0.297148       \n",
      "[102]\ttraining's multi_logloss: 0.179918\tvalid_1's multi_logloss: 0.296877       \n",
      "[103]\ttraining's multi_logloss: 0.178456\tvalid_1's multi_logloss: 0.296472       \n",
      "[104]\ttraining's multi_logloss: 0.177018\tvalid_1's multi_logloss: 0.296169       \n",
      "[105]\ttraining's multi_logloss: 0.17564\tvalid_1's multi_logloss: 0.2958          \n",
      "[106]\ttraining's multi_logloss: 0.174234\tvalid_1's multi_logloss: 0.295621       \n",
      "[107]\ttraining's multi_logloss: 0.172871\tvalid_1's multi_logloss: 0.295048       \n",
      "[108]\ttraining's multi_logloss: 0.171605\tvalid_1's multi_logloss: 0.294744       \n",
      "[109]\ttraining's multi_logloss: 0.170256\tvalid_1's multi_logloss: 0.294406       \n",
      "[110]\ttraining's multi_logloss: 0.168961\tvalid_1's multi_logloss: 0.294253       \n",
      "[111]\ttraining's multi_logloss: 0.167677\tvalid_1's multi_logloss: 0.294094       \n",
      "[112]\ttraining's multi_logloss: 0.166408\tvalid_1's multi_logloss: 0.293905       \n",
      "[113]\ttraining's multi_logloss: 0.165202\tvalid_1's multi_logloss: 0.293517       \n",
      "[114]\ttraining's multi_logloss: 0.163925\tvalid_1's multi_logloss: 0.293363       \n",
      "[115]\ttraining's multi_logloss: 0.162758\tvalid_1's multi_logloss: 0.293175       \n",
      "[116]\ttraining's multi_logloss: 0.161483\tvalid_1's multi_logloss: 0.293134       \n",
      "[117]\ttraining's multi_logloss: 0.160341\tvalid_1's multi_logloss: 0.292876       \n",
      "[118]\ttraining's multi_logloss: 0.159138\tvalid_1's multi_logloss: 0.292713       \n",
      "[119]\ttraining's multi_logloss: 0.157974\tvalid_1's multi_logloss: 0.292621       \n",
      "[120]\ttraining's multi_logloss: 0.156777\tvalid_1's multi_logloss: 0.292351       \n",
      "[121]\ttraining's multi_logloss: 0.155608\tvalid_1's multi_logloss: 0.292262       \n",
      "[122]\ttraining's multi_logloss: 0.1545\tvalid_1's multi_logloss: 0.292226         \n",
      "[123]\ttraining's multi_logloss: 0.153412\tvalid_1's multi_logloss: 0.292062       \n",
      "[124]\ttraining's multi_logloss: 0.152342\tvalid_1's multi_logloss: 0.2919         \n",
      "[125]\ttraining's multi_logloss: 0.151273\tvalid_1's multi_logloss: 0.291581       \n",
      "[126]\ttraining's multi_logloss: 0.150207\tvalid_1's multi_logloss: 0.291419       \n",
      "[127]\ttraining's multi_logloss: 0.149247\tvalid_1's multi_logloss: 0.291347       \n",
      "[128]\ttraining's multi_logloss: 0.148133\tvalid_1's multi_logloss: 0.291095       \n",
      "[129]\ttraining's multi_logloss: 0.147135\tvalid_1's multi_logloss: 0.290915       \n",
      "[130]\ttraining's multi_logloss: 0.146137\tvalid_1's multi_logloss: 0.290753       \n",
      "[131]\ttraining's multi_logloss: 0.145186\tvalid_1's multi_logloss: 0.290581       \n",
      "[132]\ttraining's multi_logloss: 0.144259\tvalid_1's multi_logloss: 0.2905         \n",
      "[133]\ttraining's multi_logloss: 0.143302\tvalid_1's multi_logloss: 0.290379       \n",
      "[134]\ttraining's multi_logloss: 0.142362\tvalid_1's multi_logloss: 0.290289       \n",
      "[135]\ttraining's multi_logloss: 0.141396\tvalid_1's multi_logloss: 0.290146       \n",
      "[136]\ttraining's multi_logloss: 0.14041\tvalid_1's multi_logloss: 0.290176        \n",
      "[137]\ttraining's multi_logloss: 0.139402\tvalid_1's multi_logloss: 0.290065       \n",
      "[138]\ttraining's multi_logloss: 0.138437\tvalid_1's multi_logloss: 0.289984       \n",
      "[139]\ttraining's multi_logloss: 0.137473\tvalid_1's multi_logloss: 0.289936       \n",
      "[140]\ttraining's multi_logloss: 0.136522\tvalid_1's multi_logloss: 0.289981       \n",
      "[141]\ttraining's multi_logloss: 0.135657\tvalid_1's multi_logloss: 0.289869       \n",
      "[142]\ttraining's multi_logloss: 0.134719\tvalid_1's multi_logloss: 0.289869       \n",
      "[143]\ttraining's multi_logloss: 0.133814\tvalid_1's multi_logloss: 0.28989        \n",
      "[144]\ttraining's multi_logloss: 0.13298\tvalid_1's multi_logloss: 0.289769        \n",
      "[145]\ttraining's multi_logloss: 0.132092\tvalid_1's multi_logloss: 0.289673       \n",
      "[146]\ttraining's multi_logloss: 0.131257\tvalid_1's multi_logloss: 0.289499       \n",
      "[147]\ttraining's multi_logloss: 0.130421\tvalid_1's multi_logloss: 0.289611       \n",
      "[148]\ttraining's multi_logloss: 0.129547\tvalid_1's multi_logloss: 0.289791       \n",
      "[149]\ttraining's multi_logloss: 0.128658\tvalid_1's multi_logloss: 0.289704       \n",
      "[150]\ttraining's multi_logloss: 0.127818\tvalid_1's multi_logloss: 0.289718       \n",
      "[151]\ttraining's multi_logloss: 0.12697\tvalid_1's multi_logloss: 0.289571        \n",
      "[152]\ttraining's multi_logloss: 0.126157\tvalid_1's multi_logloss: 0.289495       \n",
      "[153]\ttraining's multi_logloss: 0.125397\tvalid_1's multi_logloss: 0.289528       \n",
      "[154]\ttraining's multi_logloss: 0.124548\tvalid_1's multi_logloss: 0.28944        \n",
      "[155]\ttraining's multi_logloss: 0.123728\tvalid_1's multi_logloss: 0.289429       \n",
      "[156]\ttraining's multi_logloss: 0.122983\tvalid_1's multi_logloss: 0.289294       \n",
      "[157]\ttraining's multi_logloss: 0.122181\tvalid_1's multi_logloss: 0.289249       \n",
      "[158]\ttraining's multi_logloss: 0.121446\tvalid_1's multi_logloss: 0.289196       \n",
      "[159]\ttraining's multi_logloss: 0.120713\tvalid_1's multi_logloss: 0.289211       \n",
      "[160]\ttraining's multi_logloss: 0.12002\tvalid_1's multi_logloss: 0.289147        \n",
      "[161]\ttraining's multi_logloss: 0.119279\tvalid_1's multi_logloss: 0.289208       \n",
      "[162]\ttraining's multi_logloss: 0.118504\tvalid_1's multi_logloss: 0.289188       \n",
      "[163]\ttraining's multi_logloss: 0.11778\tvalid_1's multi_logloss: 0.289264        \n",
      "[164]\ttraining's multi_logloss: 0.117066\tvalid_1's multi_logloss: 0.289329       \n",
      "[165]\ttraining's multi_logloss: 0.11634\tvalid_1's multi_logloss: 0.289298        \n",
      "[166]\ttraining's multi_logloss: 0.115669\tvalid_1's multi_logloss: 0.28921        \n",
      "[167]\ttraining's multi_logloss: 0.114972\tvalid_1's multi_logloss: 0.289232       \n",
      "[168]\ttraining's multi_logloss: 0.114316\tvalid_1's multi_logloss: 0.28933        \n",
      "[169]\ttraining's multi_logloss: 0.113614\tvalid_1's multi_logloss: 0.289363       \n",
      "[170]\ttraining's multi_logloss: 0.113021\tvalid_1's multi_logloss: 0.289518       \n",
      "[171]\ttraining's multi_logloss: 0.112299\tvalid_1's multi_logloss: 0.289596       \n",
      "[172]\ttraining's multi_logloss: 0.111676\tvalid_1's multi_logloss: 0.289733       \n",
      "[173]\ttraining's multi_logloss: 0.111037\tvalid_1's multi_logloss: 0.28972        \n",
      "[174]\ttraining's multi_logloss: 0.110478\tvalid_1's multi_logloss: 0.289826       \n",
      "[175]\ttraining's multi_logloss: 0.10981\tvalid_1's multi_logloss: 0.289941        \n",
      "[176]\ttraining's multi_logloss: 0.109154\tvalid_1's multi_logloss: 0.289937       \n",
      "[177]\ttraining's multi_logloss: 0.108545\tvalid_1's multi_logloss: 0.290151       \n",
      "[178]\ttraining's multi_logloss: 0.107931\tvalid_1's multi_logloss: 0.290133       \n",
      "[179]\ttraining's multi_logloss: 0.107291\tvalid_1's multi_logloss: 0.290209       \n",
      "[180]\ttraining's multi_logloss: 0.10673\tvalid_1's multi_logloss: 0.29035         \n",
      "[181]\ttraining's multi_logloss: 0.10614\tvalid_1's multi_logloss: 0.290385        \n",
      "[182]\ttraining's multi_logloss: 0.105549\tvalid_1's multi_logloss: 0.290466       \n",
      "[183]\ttraining's multi_logloss: 0.104892\tvalid_1's multi_logloss: 0.290342       \n",
      "[184]\ttraining's multi_logloss: 0.104295\tvalid_1's multi_logloss: 0.290501       \n",
      "[185]\ttraining's multi_logloss: 0.103724\tvalid_1's multi_logloss: 0.290552       \n",
      "[186]\ttraining's multi_logloss: 0.103097\tvalid_1's multi_logloss: 0.290668       \n",
      "[187]\ttraining's multi_logloss: 0.102512\tvalid_1's multi_logloss: 0.290723       \n",
      "[188]\ttraining's multi_logloss: 0.101924\tvalid_1's multi_logloss: 0.2907         \n",
      "[189]\ttraining's multi_logloss: 0.101307\tvalid_1's multi_logloss: 0.290945       \n",
      "[190]\ttraining's multi_logloss: 0.100738\tvalid_1's multi_logloss: 0.291022       \n",
      "Early stopping, best iteration is:                                               \n",
      "[160]\ttraining's multi_logloss: 0.12002\tvalid_1's multi_logloss: 0.289147\n",
      "[1]\ttraining's multi_logloss: 1.76633\tvalid_1's multi_logloss: 1.76915           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.63243\tvalid_1's multi_logloss: 1.63634           \n",
      "[3]\ttraining's multi_logloss: 1.51944\tvalid_1's multi_logloss: 1.52436           \n",
      "[4]\ttraining's multi_logloss: 1.42103\tvalid_1's multi_logloss: 1.42666           \n",
      "[5]\ttraining's multi_logloss: 1.33459\tvalid_1's multi_logloss: 1.34124           \n",
      "[6]\ttraining's multi_logloss: 1.25767\tvalid_1's multi_logloss: 1.26543           \n",
      "[7]\ttraining's multi_logloss: 1.18883\tvalid_1's multi_logloss: 1.19771           \n",
      "[8]\ttraining's multi_logloss: 1.12688\tvalid_1's multi_logloss: 1.13675           \n",
      "[9]\ttraining's multi_logloss: 1.07042\tvalid_1's multi_logloss: 1.08127           \n",
      "[10]\ttraining's multi_logloss: 1.01844\tvalid_1's multi_logloss: 1.03037          \n",
      "[11]\ttraining's multi_logloss: 0.970515\tvalid_1's multi_logloss: 0.983556        \n",
      "[12]\ttraining's multi_logloss: 0.926422\tvalid_1's multi_logloss: 0.940365        \n",
      "[13]\ttraining's multi_logloss: 0.88606\tvalid_1's multi_logloss: 0.901039         \n",
      "[14]\ttraining's multi_logloss: 0.848007\tvalid_1's multi_logloss: 0.863709        \n",
      "[15]\ttraining's multi_logloss: 0.813084\tvalid_1's multi_logloss: 0.829848        \n",
      "[16]\ttraining's multi_logloss: 0.780013\tvalid_1's multi_logloss: 0.79768         \n",
      "[17]\ttraining's multi_logloss: 0.749548\tvalid_1's multi_logloss: 0.768218        \n",
      "[18]\ttraining's multi_logloss: 0.720925\tvalid_1's multi_logloss: 0.740724        \n",
      "[19]\ttraining's multi_logloss: 0.693976\tvalid_1's multi_logloss: 0.714949        \n",
      "[20]\ttraining's multi_logloss: 0.668994\tvalid_1's multi_logloss: 0.691061        \n",
      "[21]\ttraining's multi_logloss: 0.645711\tvalid_1's multi_logloss: 0.668988        \n",
      "[22]\ttraining's multi_logloss: 0.623581\tvalid_1's multi_logloss: 0.647546        \n",
      "[23]\ttraining's multi_logloss: 0.602813\tvalid_1's multi_logloss: 0.627676        \n",
      "[24]\ttraining's multi_logloss: 0.583427\tvalid_1's multi_logloss: 0.609195        \n",
      "[25]\ttraining's multi_logloss: 0.564847\tvalid_1's multi_logloss: 0.591614        \n",
      "[26]\ttraining's multi_logloss: 0.547288\tvalid_1's multi_logloss: 0.574787        \n",
      "[27]\ttraining's multi_logloss: 0.53102\tvalid_1's multi_logloss: 0.55933          \n",
      "[28]\ttraining's multi_logloss: 0.515532\tvalid_1's multi_logloss: 0.544683        \n",
      "[29]\ttraining's multi_logloss: 0.500944\tvalid_1's multi_logloss: 0.531082        \n",
      "[30]\ttraining's multi_logloss: 0.48721\tvalid_1's multi_logloss: 0.518164         \n",
      "[31]\ttraining's multi_logloss: 0.474174\tvalid_1's multi_logloss: 0.506224        \n",
      "[32]\ttraining's multi_logloss: 0.461654\tvalid_1's multi_logloss: 0.494793        \n",
      "[33]\ttraining's multi_logloss: 0.449829\tvalid_1's multi_logloss: 0.483924        \n",
      "[34]\ttraining's multi_logloss: 0.438788\tvalid_1's multi_logloss: 0.474126        \n",
      "[35]\ttraining's multi_logloss: 0.42816\tvalid_1's multi_logloss: 0.464581         \n",
      "[36]\ttraining's multi_logloss: 0.41831\tvalid_1's multi_logloss: 0.455728         \n",
      "[37]\ttraining's multi_logloss: 0.408711\tvalid_1's multi_logloss: 0.447349        \n",
      "[38]\ttraining's multi_logloss: 0.399511\tvalid_1's multi_logloss: 0.439127        \n",
      "[39]\ttraining's multi_logloss: 0.390899\tvalid_1's multi_logloss: 0.431618        \n",
      "[40]\ttraining's multi_logloss: 0.382564\tvalid_1's multi_logloss: 0.424195        \n",
      "[41]\ttraining's multi_logloss: 0.374712\tvalid_1's multi_logloss: 0.41722         \n",
      "[42]\ttraining's multi_logloss: 0.367299\tvalid_1's multi_logloss: 0.410758        \n",
      "[43]\ttraining's multi_logloss: 0.360125\tvalid_1's multi_logloss: 0.404461        \n",
      "[44]\ttraining's multi_logloss: 0.353317\tvalid_1's multi_logloss: 0.398627        \n",
      "[45]\ttraining's multi_logloss: 0.3468\tvalid_1's multi_logloss: 0.393133          \n",
      "[46]\ttraining's multi_logloss: 0.340501\tvalid_1's multi_logloss: 0.387937        \n",
      "[47]\ttraining's multi_logloss: 0.33447\tvalid_1's multi_logloss: 0.382948         \n",
      "[48]\ttraining's multi_logloss: 0.328857\tvalid_1's multi_logloss: 0.378215        \n",
      "[49]\ttraining's multi_logloss: 0.323436\tvalid_1's multi_logloss: 0.373823        \n",
      "[50]\ttraining's multi_logloss: 0.318124\tvalid_1's multi_logloss: 0.369447        \n",
      "[51]\ttraining's multi_logloss: 0.312816\tvalid_1's multi_logloss: 0.365122        \n",
      "[52]\ttraining's multi_logloss: 0.307903\tvalid_1's multi_logloss: 0.361132        \n",
      "[53]\ttraining's multi_logloss: 0.302857\tvalid_1's multi_logloss: 0.357196        \n",
      "[54]\ttraining's multi_logloss: 0.297896\tvalid_1's multi_logloss: 0.353495        \n",
      "[55]\ttraining's multi_logloss: 0.293333\tvalid_1's multi_logloss: 0.349934        \n",
      "[56]\ttraining's multi_logloss: 0.289054\tvalid_1's multi_logloss: 0.346505        \n",
      "[57]\ttraining's multi_logloss: 0.285007\tvalid_1's multi_logloss: 0.343643        \n",
      "[58]\ttraining's multi_logloss: 0.280922\tvalid_1's multi_logloss: 0.340745        \n",
      "[59]\ttraining's multi_logloss: 0.277142\tvalid_1's multi_logloss: 0.337913        \n",
      "[60]\ttraining's multi_logloss: 0.273469\tvalid_1's multi_logloss: 0.335349        \n",
      "[61]\ttraining's multi_logloss: 0.269981\tvalid_1's multi_logloss: 0.332873        \n",
      "[62]\ttraining's multi_logloss: 0.266449\tvalid_1's multi_logloss: 0.330551        \n",
      "[63]\ttraining's multi_logloss: 0.263044\tvalid_1's multi_logloss: 0.328415        \n",
      "[64]\ttraining's multi_logloss: 0.259846\tvalid_1's multi_logloss: 0.326356        \n",
      "[65]\ttraining's multi_logloss: 0.256743\tvalid_1's multi_logloss: 0.324293        \n",
      "[66]\ttraining's multi_logloss: 0.253577\tvalid_1's multi_logloss: 0.322277        \n",
      "[67]\ttraining's multi_logloss: 0.250544\tvalid_1's multi_logloss: 0.32048         \n",
      "[68]\ttraining's multi_logloss: 0.247692\tvalid_1's multi_logloss: 0.31869         \n",
      "[69]\ttraining's multi_logloss: 0.244803\tvalid_1's multi_logloss: 0.317058        \n",
      "[70]\ttraining's multi_logloss: 0.241998\tvalid_1's multi_logloss: 0.315537        \n",
      "[71]\ttraining's multi_logloss: 0.239326\tvalid_1's multi_logloss: 0.314027        \n",
      "[72]\ttraining's multi_logloss: 0.236696\tvalid_1's multi_logloss: 0.312432        \n",
      "[73]\ttraining's multi_logloss: 0.234185\tvalid_1's multi_logloss: 0.310998        \n",
      "[74]\ttraining's multi_logloss: 0.231646\tvalid_1's multi_logloss: 0.309691        \n",
      "[75]\ttraining's multi_logloss: 0.229265\tvalid_1's multi_logloss: 0.308473        \n",
      "[76]\ttraining's multi_logloss: 0.226842\tvalid_1's multi_logloss: 0.307129        \n",
      "[77]\ttraining's multi_logloss: 0.224515\tvalid_1's multi_logloss: 0.30613         \n",
      "[78]\ttraining's multi_logloss: 0.222309\tvalid_1's multi_logloss: 0.304982        \n",
      "[79]\ttraining's multi_logloss: 0.220157\tvalid_1's multi_logloss: 0.303956        \n",
      "[80]\ttraining's multi_logloss: 0.218089\tvalid_1's multi_logloss: 0.303093        \n",
      "[81]\ttraining's multi_logloss: 0.216057\tvalid_1's multi_logloss: 0.302168        \n",
      "[82]\ttraining's multi_logloss: 0.213963\tvalid_1's multi_logloss: 0.301281        \n",
      "[83]\ttraining's multi_logloss: 0.211982\tvalid_1's multi_logloss: 0.300454        \n",
      "[84]\ttraining's multi_logloss: 0.210011\tvalid_1's multi_logloss: 0.299556        \n",
      "[85]\ttraining's multi_logloss: 0.208052\tvalid_1's multi_logloss: 0.298679        \n",
      "[86]\ttraining's multi_logloss: 0.206216\tvalid_1's multi_logloss: 0.297878        \n",
      "[87]\ttraining's multi_logloss: 0.204381\tvalid_1's multi_logloss: 0.297265        \n",
      "[88]\ttraining's multi_logloss: 0.202521\tvalid_1's multi_logloss: 0.296654        \n",
      "[89]\ttraining's multi_logloss: 0.200713\tvalid_1's multi_logloss: 0.296135        \n",
      "[90]\ttraining's multi_logloss: 0.198968\tvalid_1's multi_logloss: 0.295438        \n",
      "[91]\ttraining's multi_logloss: 0.197189\tvalid_1's multi_logloss: 0.294649        \n",
      "[92]\ttraining's multi_logloss: 0.195474\tvalid_1's multi_logloss: 0.294092        \n",
      "[93]\ttraining's multi_logloss: 0.19384\tvalid_1's multi_logloss: 0.293489         \n",
      "[94]\ttraining's multi_logloss: 0.192129\tvalid_1's multi_logloss: 0.292784        \n",
      "[95]\ttraining's multi_logloss: 0.190502\tvalid_1's multi_logloss: 0.292248        \n",
      "[96]\ttraining's multi_logloss: 0.188868\tvalid_1's multi_logloss: 0.291538        \n",
      "[97]\ttraining's multi_logloss: 0.187268\tvalid_1's multi_logloss: 0.290999        \n",
      "[98]\ttraining's multi_logloss: 0.185627\tvalid_1's multi_logloss: 0.290451        \n",
      "[99]\ttraining's multi_logloss: 0.184002\tvalid_1's multi_logloss: 0.289881        \n",
      "[100]\ttraining's multi_logloss: 0.182461\tvalid_1's multi_logloss: 0.289465       \n",
      "[101]\ttraining's multi_logloss: 0.180911\tvalid_1's multi_logloss: 0.288977       \n",
      "[102]\ttraining's multi_logloss: 0.179368\tvalid_1's multi_logloss: 0.288581       \n",
      "[103]\ttraining's multi_logloss: 0.177914\tvalid_1's multi_logloss: 0.288051       \n",
      "[104]\ttraining's multi_logloss: 0.176483\tvalid_1's multi_logloss: 0.287723       \n",
      "[105]\ttraining's multi_logloss: 0.175019\tvalid_1's multi_logloss: 0.287297       \n",
      "[106]\ttraining's multi_logloss: 0.173536\tvalid_1's multi_logloss: 0.287042       \n",
      "[107]\ttraining's multi_logloss: 0.172112\tvalid_1's multi_logloss: 0.286651       \n",
      "[108]\ttraining's multi_logloss: 0.17074\tvalid_1's multi_logloss: 0.286362        \n",
      "[109]\ttraining's multi_logloss: 0.169354\tvalid_1's multi_logloss: 0.286124       \n",
      "[110]\ttraining's multi_logloss: 0.168035\tvalid_1's multi_logloss: 0.285616       \n",
      "[111]\ttraining's multi_logloss: 0.166626\tvalid_1's multi_logloss: 0.28546        \n",
      "[112]\ttraining's multi_logloss: 0.165332\tvalid_1's multi_logloss: 0.285088       \n",
      "[113]\ttraining's multi_logloss: 0.163982\tvalid_1's multi_logloss: 0.2849         \n",
      "[114]\ttraining's multi_logloss: 0.162781\tvalid_1's multi_logloss: 0.284661       \n",
      "[115]\ttraining's multi_logloss: 0.161563\tvalid_1's multi_logloss: 0.284548       \n",
      "[116]\ttraining's multi_logloss: 0.16029\tvalid_1's multi_logloss: 0.284388        \n",
      "[117]\ttraining's multi_logloss: 0.159104\tvalid_1's multi_logloss: 0.284225       \n",
      "[118]\ttraining's multi_logloss: 0.157987\tvalid_1's multi_logloss: 0.284049       \n",
      "[119]\ttraining's multi_logloss: 0.156814\tvalid_1's multi_logloss: 0.283893       \n",
      "[120]\ttraining's multi_logloss: 0.155695\tvalid_1's multi_logloss: 0.283789       \n",
      "[121]\ttraining's multi_logloss: 0.154562\tvalid_1's multi_logloss: 0.28352        \n",
      "[122]\ttraining's multi_logloss: 0.1534\tvalid_1's multi_logloss: 0.283252         \n",
      "[123]\ttraining's multi_logloss: 0.152313\tvalid_1's multi_logloss: 0.282998       \n",
      "[124]\ttraining's multi_logloss: 0.151105\tvalid_1's multi_logloss: 0.28274        \n",
      "[125]\ttraining's multi_logloss: 0.149933\tvalid_1's multi_logloss: 0.282794       \n",
      "[126]\ttraining's multi_logloss: 0.148912\tvalid_1's multi_logloss: 0.282778       \n",
      "[127]\ttraining's multi_logloss: 0.147831\tvalid_1's multi_logloss: 0.282648       \n",
      "[128]\ttraining's multi_logloss: 0.146812\tvalid_1's multi_logloss: 0.282547       \n",
      "[129]\ttraining's multi_logloss: 0.145791\tvalid_1's multi_logloss: 0.282502       \n",
      "[130]\ttraining's multi_logloss: 0.14476\tvalid_1's multi_logloss: 0.282428        \n",
      "[131]\ttraining's multi_logloss: 0.14378\tvalid_1's multi_logloss: 0.2824          \n",
      "[132]\ttraining's multi_logloss: 0.142808\tvalid_1's multi_logloss: 0.28227        \n",
      "[133]\ttraining's multi_logloss: 0.141821\tvalid_1's multi_logloss: 0.282201       \n",
      "[134]\ttraining's multi_logloss: 0.140872\tvalid_1's multi_logloss: 0.2822         \n",
      "[135]\ttraining's multi_logloss: 0.139943\tvalid_1's multi_logloss: 0.282218       \n",
      "[136]\ttraining's multi_logloss: 0.138961\tvalid_1's multi_logloss: 0.282312       \n",
      "[137]\ttraining's multi_logloss: 0.138093\tvalid_1's multi_logloss: 0.282137       \n",
      "[138]\ttraining's multi_logloss: 0.137054\tvalid_1's multi_logloss: 0.282024       \n",
      "[139]\ttraining's multi_logloss: 0.136071\tvalid_1's multi_logloss: 0.281986       \n",
      "[140]\ttraining's multi_logloss: 0.135134\tvalid_1's multi_logloss: 0.281983       \n",
      "[141]\ttraining's multi_logloss: 0.134108\tvalid_1's multi_logloss: 0.281995       \n",
      "[142]\ttraining's multi_logloss: 0.1332\tvalid_1's multi_logloss: 0.282067         \n",
      "[143]\ttraining's multi_logloss: 0.132293\tvalid_1's multi_logloss: 0.282152       \n",
      "[144]\ttraining's multi_logloss: 0.131346\tvalid_1's multi_logloss: 0.2822         \n",
      "[145]\ttraining's multi_logloss: 0.130495\tvalid_1's multi_logloss: 0.28221        \n",
      "[146]\ttraining's multi_logloss: 0.129568\tvalid_1's multi_logloss: 0.282341       \n",
      "[147]\ttraining's multi_logloss: 0.128748\tvalid_1's multi_logloss: 0.28227        \n",
      "[148]\ttraining's multi_logloss: 0.127895\tvalid_1's multi_logloss: 0.282266       \n",
      "[149]\ttraining's multi_logloss: 0.127065\tvalid_1's multi_logloss: 0.282085       \n",
      "[150]\ttraining's multi_logloss: 0.126235\tvalid_1's multi_logloss: 0.282229       \n",
      "[151]\ttraining's multi_logloss: 0.125368\tvalid_1's multi_logloss: 0.282269       \n",
      "[152]\ttraining's multi_logloss: 0.124571\tvalid_1's multi_logloss: 0.282306       \n",
      "[153]\ttraining's multi_logloss: 0.123767\tvalid_1's multi_logloss: 0.282344       \n",
      "[154]\ttraining's multi_logloss: 0.12298\tvalid_1's multi_logloss: 0.282442        \n",
      "[155]\ttraining's multi_logloss: 0.12224\tvalid_1's multi_logloss: 0.282474        \n",
      "[156]\ttraining's multi_logloss: 0.121465\tvalid_1's multi_logloss: 0.282444       \n",
      "[157]\ttraining's multi_logloss: 0.120716\tvalid_1's multi_logloss: 0.282408       \n",
      "[158]\ttraining's multi_logloss: 0.119944\tvalid_1's multi_logloss: 0.282465       \n",
      "[159]\ttraining's multi_logloss: 0.119181\tvalid_1's multi_logloss: 0.282569       \n",
      "[160]\ttraining's multi_logloss: 0.118381\tvalid_1's multi_logloss: 0.282592       \n",
      "[161]\ttraining's multi_logloss: 0.117673\tvalid_1's multi_logloss: 0.282628       \n",
      "[162]\ttraining's multi_logloss: 0.116904\tvalid_1's multi_logloss: 0.282683       \n",
      "[163]\ttraining's multi_logloss: 0.116211\tvalid_1's multi_logloss: 0.28267        \n",
      "[164]\ttraining's multi_logloss: 0.115487\tvalid_1's multi_logloss: 0.282773       \n",
      "[165]\ttraining's multi_logloss: 0.114792\tvalid_1's multi_logloss: 0.282805       \n",
      "[166]\ttraining's multi_logloss: 0.11413\tvalid_1's multi_logloss: 0.282956        \n",
      "[167]\ttraining's multi_logloss: 0.113458\tvalid_1's multi_logloss: 0.28296        \n",
      "[168]\ttraining's multi_logloss: 0.112784\tvalid_1's multi_logloss: 0.282971       \n",
      "[169]\ttraining's multi_logloss: 0.112083\tvalid_1's multi_logloss: 0.283014       \n",
      "[170]\ttraining's multi_logloss: 0.111455\tvalid_1's multi_logloss: 0.283097       \n",
      "Early stopping, best iteration is:                                               \n",
      "[140]\ttraining's multi_logloss: 0.135134\tvalid_1's multi_logloss: 0.281983\n",
      "[1]\ttraining's multi_logloss: 1.76754\tvalid_1's multi_logloss: 1.77062           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.63399\tvalid_1's multi_logloss: 1.63825           \n",
      "[3]\ttraining's multi_logloss: 1.52069\tvalid_1's multi_logloss: 1.52585           \n",
      "[4]\ttraining's multi_logloss: 1.42216\tvalid_1's multi_logloss: 1.42786           \n",
      "[5]\ttraining's multi_logloss: 1.33549\tvalid_1's multi_logloss: 1.34231           \n",
      "[6]\ttraining's multi_logloss: 1.25846\tvalid_1's multi_logloss: 1.26599           \n",
      "[7]\ttraining's multi_logloss: 1.18985\tvalid_1's multi_logloss: 1.1982            \n",
      "[8]\ttraining's multi_logloss: 1.12758\tvalid_1's multi_logloss: 1.1365            \n",
      "[9]\ttraining's multi_logloss: 1.07125\tvalid_1's multi_logloss: 1.08097           \n",
      "[10]\ttraining's multi_logloss: 1.01942\tvalid_1's multi_logloss: 1.0296           \n",
      "[11]\ttraining's multi_logloss: 0.971344\tvalid_1's multi_logloss: 0.982095        \n",
      "[12]\ttraining's multi_logloss: 0.927602\tvalid_1's multi_logloss: 0.938559        \n",
      "[13]\ttraining's multi_logloss: 0.886833\tvalid_1's multi_logloss: 0.898525        \n",
      "[14]\ttraining's multi_logloss: 0.848534\tvalid_1's multi_logloss: 0.860698        \n",
      "[15]\ttraining's multi_logloss: 0.813107\tvalid_1's multi_logloss: 0.825627        \n",
      "[16]\ttraining's multi_logloss: 0.780179\tvalid_1's multi_logloss: 0.793253        \n",
      "[17]\ttraining's multi_logloss: 0.75012\tvalid_1's multi_logloss: 0.763864         \n",
      "[18]\ttraining's multi_logloss: 0.721589\tvalid_1's multi_logloss: 0.736009        \n",
      "[19]\ttraining's multi_logloss: 0.695168\tvalid_1's multi_logloss: 0.710404        \n",
      "[20]\ttraining's multi_logloss: 0.670087\tvalid_1's multi_logloss: 0.685927        \n",
      "[21]\ttraining's multi_logloss: 0.646976\tvalid_1's multi_logloss: 0.663665        \n",
      "[22]\ttraining's multi_logloss: 0.625023\tvalid_1's multi_logloss: 0.642881        \n",
      "[23]\ttraining's multi_logloss: 0.604406\tvalid_1's multi_logloss: 0.623014        \n",
      "[24]\ttraining's multi_logloss: 0.585278\tvalid_1's multi_logloss: 0.604797        \n",
      "[25]\ttraining's multi_logloss: 0.567084\tvalid_1's multi_logloss: 0.587588        \n",
      "[26]\ttraining's multi_logloss: 0.549961\tvalid_1's multi_logloss: 0.571367        \n",
      "[27]\ttraining's multi_logloss: 0.533884\tvalid_1's multi_logloss: 0.556117        \n",
      "[28]\ttraining's multi_logloss: 0.51894\tvalid_1's multi_logloss: 0.542112         \n",
      "[29]\ttraining's multi_logloss: 0.504434\tvalid_1's multi_logloss: 0.528235        \n",
      "[30]\ttraining's multi_logloss: 0.490847\tvalid_1's multi_logloss: 0.51526         \n",
      "[31]\ttraining's multi_logloss: 0.477821\tvalid_1's multi_logloss: 0.502787        \n",
      "[32]\ttraining's multi_logloss: 0.465825\tvalid_1's multi_logloss: 0.491414        \n",
      "[33]\ttraining's multi_logloss: 0.454569\tvalid_1's multi_logloss: 0.480763        \n",
      "[34]\ttraining's multi_logloss: 0.443589\tvalid_1's multi_logloss: 0.470651        \n",
      "[35]\ttraining's multi_logloss: 0.433057\tvalid_1's multi_logloss: 0.461014        \n",
      "[36]\ttraining's multi_logloss: 0.423147\tvalid_1's multi_logloss: 0.451821        \n",
      "[37]\ttraining's multi_logloss: 0.413304\tvalid_1's multi_logloss: 0.442634        \n",
      "[38]\ttraining's multi_logloss: 0.404324\tvalid_1's multi_logloss: 0.434323        \n",
      "[39]\ttraining's multi_logloss: 0.3956\tvalid_1's multi_logloss: 0.426282          \n",
      "[40]\ttraining's multi_logloss: 0.387242\tvalid_1's multi_logloss: 0.418598        \n",
      "[41]\ttraining's multi_logloss: 0.379508\tvalid_1's multi_logloss: 0.411478        \n",
      "[42]\ttraining's multi_logloss: 0.372064\tvalid_1's multi_logloss: 0.405091        \n",
      "[43]\ttraining's multi_logloss: 0.364812\tvalid_1's multi_logloss: 0.398518        \n",
      "[44]\ttraining's multi_logloss: 0.357724\tvalid_1's multi_logloss: 0.392136        \n",
      "[45]\ttraining's multi_logloss: 0.351192\tvalid_1's multi_logloss: 0.386287        \n",
      "[46]\ttraining's multi_logloss: 0.345029\tvalid_1's multi_logloss: 0.380871        \n",
      "[47]\ttraining's multi_logloss: 0.338993\tvalid_1's multi_logloss: 0.375686        \n",
      "[48]\ttraining's multi_logloss: 0.333233\tvalid_1's multi_logloss: 0.370657        \n",
      "[49]\ttraining's multi_logloss: 0.327601\tvalid_1's multi_logloss: 0.365904        \n",
      "[50]\ttraining's multi_logloss: 0.322203\tvalid_1's multi_logloss: 0.361333        \n",
      "[51]\ttraining's multi_logloss: 0.317022\tvalid_1's multi_logloss: 0.357152        \n",
      "[52]\ttraining's multi_logloss: 0.312056\tvalid_1's multi_logloss: 0.353087        \n",
      "[53]\ttraining's multi_logloss: 0.307431\tvalid_1's multi_logloss: 0.349202        \n",
      "[54]\ttraining's multi_logloss: 0.302722\tvalid_1's multi_logloss: 0.345334        \n",
      "[55]\ttraining's multi_logloss: 0.298262\tvalid_1's multi_logloss: 0.341926        \n",
      "[56]\ttraining's multi_logloss: 0.293928\tvalid_1's multi_logloss: 0.338604        \n",
      "[57]\ttraining's multi_logloss: 0.289705\tvalid_1's multi_logloss: 0.335222        \n",
      "[58]\ttraining's multi_logloss: 0.285643\tvalid_1's multi_logloss: 0.332135        \n",
      "[59]\ttraining's multi_logloss: 0.281794\tvalid_1's multi_logloss: 0.329203        \n",
      "[60]\ttraining's multi_logloss: 0.278101\tvalid_1's multi_logloss: 0.32647         \n",
      "[61]\ttraining's multi_logloss: 0.274543\tvalid_1's multi_logloss: 0.323902        \n",
      "[62]\ttraining's multi_logloss: 0.271133\tvalid_1's multi_logloss: 0.321474        \n",
      "[63]\ttraining's multi_logloss: 0.267879\tvalid_1's multi_logloss: 0.31918         \n",
      "[64]\ttraining's multi_logloss: 0.264626\tvalid_1's multi_logloss: 0.317066        \n",
      "[65]\ttraining's multi_logloss: 0.261553\tvalid_1's multi_logloss: 0.314959        \n",
      "[66]\ttraining's multi_logloss: 0.258661\tvalid_1's multi_logloss: 0.312939        \n",
      "[67]\ttraining's multi_logloss: 0.25576\tvalid_1's multi_logloss: 0.311069         \n",
      "[68]\ttraining's multi_logloss: 0.253107\tvalid_1's multi_logloss: 0.309456        \n",
      "[69]\ttraining's multi_logloss: 0.250365\tvalid_1's multi_logloss: 0.30772         \n",
      "[70]\ttraining's multi_logloss: 0.247776\tvalid_1's multi_logloss: 0.306074        \n",
      "[71]\ttraining's multi_logloss: 0.24508\tvalid_1's multi_logloss: 0.304255         \n",
      "[72]\ttraining's multi_logloss: 0.242581\tvalid_1's multi_logloss: 0.302707        \n",
      "[73]\ttraining's multi_logloss: 0.240082\tvalid_1's multi_logloss: 0.301274        \n",
      "[74]\ttraining's multi_logloss: 0.237707\tvalid_1's multi_logloss: 0.299796        \n",
      "[75]\ttraining's multi_logloss: 0.23542\tvalid_1's multi_logloss: 0.298488         \n",
      "[76]\ttraining's multi_logloss: 0.233133\tvalid_1's multi_logloss: 0.297185        \n",
      "[77]\ttraining's multi_logloss: 0.230851\tvalid_1's multi_logloss: 0.296105        \n",
      "[78]\ttraining's multi_logloss: 0.228737\tvalid_1's multi_logloss: 0.294929        \n",
      "[79]\ttraining's multi_logloss: 0.226505\tvalid_1's multi_logloss: 0.293704        \n",
      "[80]\ttraining's multi_logloss: 0.224479\tvalid_1's multi_logloss: 0.292733        \n",
      "[81]\ttraining's multi_logloss: 0.222405\tvalid_1's multi_logloss: 0.291629        \n",
      "[82]\ttraining's multi_logloss: 0.22042\tvalid_1's multi_logloss: 0.290672         \n",
      "[83]\ttraining's multi_logloss: 0.218474\tvalid_1's multi_logloss: 0.289824        \n",
      "[84]\ttraining's multi_logloss: 0.216379\tvalid_1's multi_logloss: 0.288739        \n",
      "[85]\ttraining's multi_logloss: 0.214462\tvalid_1's multi_logloss: 0.287757        \n",
      "[86]\ttraining's multi_logloss: 0.21261\tvalid_1's multi_logloss: 0.28692          \n",
      "[87]\ttraining's multi_logloss: 0.210799\tvalid_1's multi_logloss: 0.286137        \n",
      "[88]\ttraining's multi_logloss: 0.208978\tvalid_1's multi_logloss: 0.285326        \n",
      "[89]\ttraining's multi_logloss: 0.207097\tvalid_1's multi_logloss: 0.284406        \n",
      "[90]\ttraining's multi_logloss: 0.205269\tvalid_1's multi_logloss: 0.283551        \n",
      "[91]\ttraining's multi_logloss: 0.203438\tvalid_1's multi_logloss: 0.282909        \n",
      "[92]\ttraining's multi_logloss: 0.201624\tvalid_1's multi_logloss: 0.28232         \n",
      "[93]\ttraining's multi_logloss: 0.199919\tvalid_1's multi_logloss: 0.281798        \n",
      "[94]\ttraining's multi_logloss: 0.198278\tvalid_1's multi_logloss: 0.281268        \n",
      "[95]\ttraining's multi_logloss: 0.196656\tvalid_1's multi_logloss: 0.280774        \n",
      "[96]\ttraining's multi_logloss: 0.195059\tvalid_1's multi_logloss: 0.280169        \n",
      "[97]\ttraining's multi_logloss: 0.193425\tvalid_1's multi_logloss: 0.279709        \n",
      "[98]\ttraining's multi_logloss: 0.191828\tvalid_1's multi_logloss: 0.279081        \n",
      "[99]\ttraining's multi_logloss: 0.19023\tvalid_1's multi_logloss: 0.278592         \n",
      "[100]\ttraining's multi_logloss: 0.188727\tvalid_1's multi_logloss: 0.278116       \n",
      "[101]\ttraining's multi_logloss: 0.187246\tvalid_1's multi_logloss: 0.277563       \n",
      "[102]\ttraining's multi_logloss: 0.185721\tvalid_1's multi_logloss: 0.277198       \n",
      "[103]\ttraining's multi_logloss: 0.184287\tvalid_1's multi_logloss: 0.276744       \n",
      "[104]\ttraining's multi_logloss: 0.182888\tvalid_1's multi_logloss: 0.276349       \n",
      "[105]\ttraining's multi_logloss: 0.181476\tvalid_1's multi_logloss: 0.275915       \n",
      "[106]\ttraining's multi_logloss: 0.18009\tvalid_1's multi_logloss: 0.27562         \n",
      "[107]\ttraining's multi_logloss: 0.178703\tvalid_1's multi_logloss: 0.275277       \n",
      "[108]\ttraining's multi_logloss: 0.177262\tvalid_1's multi_logloss: 0.27482        \n",
      "[109]\ttraining's multi_logloss: 0.175954\tvalid_1's multi_logloss: 0.274509       \n",
      "[110]\ttraining's multi_logloss: 0.174604\tvalid_1's multi_logloss: 0.274358       \n",
      "[111]\ttraining's multi_logloss: 0.173314\tvalid_1's multi_logloss: 0.274059       \n",
      "[112]\ttraining's multi_logloss: 0.172038\tvalid_1's multi_logloss: 0.273677       \n",
      "[113]\ttraining's multi_logloss: 0.170803\tvalid_1's multi_logloss: 0.273529       \n",
      "[114]\ttraining's multi_logloss: 0.169593\tvalid_1's multi_logloss: 0.273329       \n",
      "[115]\ttraining's multi_logloss: 0.1683\tvalid_1's multi_logloss: 0.273166         \n",
      "[116]\ttraining's multi_logloss: 0.167003\tvalid_1's multi_logloss: 0.272904       \n",
      "[117]\ttraining's multi_logloss: 0.165776\tvalid_1's multi_logloss: 0.272826       \n",
      "[118]\ttraining's multi_logloss: 0.164674\tvalid_1's multi_logloss: 0.272611       \n",
      "[119]\ttraining's multi_logloss: 0.163519\tvalid_1's multi_logloss: 0.272489       \n",
      "[120]\ttraining's multi_logloss: 0.162367\tvalid_1's multi_logloss: 0.272226       \n",
      "[121]\ttraining's multi_logloss: 0.161267\tvalid_1's multi_logloss: 0.272133       \n",
      "[122]\ttraining's multi_logloss: 0.160112\tvalid_1's multi_logloss: 0.271975       \n",
      "[123]\ttraining's multi_logloss: 0.158981\tvalid_1's multi_logloss: 0.27168        \n",
      "[124]\ttraining's multi_logloss: 0.157802\tvalid_1's multi_logloss: 0.271468       \n",
      "[125]\ttraining's multi_logloss: 0.156673\tvalid_1's multi_logloss: 0.27135        \n",
      "[126]\ttraining's multi_logloss: 0.155548\tvalid_1's multi_logloss: 0.271137       \n",
      "[127]\ttraining's multi_logloss: 0.154434\tvalid_1's multi_logloss: 0.270952       \n",
      "[128]\ttraining's multi_logloss: 0.153282\tvalid_1's multi_logloss: 0.270777       \n",
      "[129]\ttraining's multi_logloss: 0.152179\tvalid_1's multi_logloss: 0.270523       \n",
      "[130]\ttraining's multi_logloss: 0.151104\tvalid_1's multi_logloss: 0.270242       \n",
      "[131]\ttraining's multi_logloss: 0.150045\tvalid_1's multi_logloss: 0.270096       \n",
      "[132]\ttraining's multi_logloss: 0.149005\tvalid_1's multi_logloss: 0.269889       \n",
      "[133]\ttraining's multi_logloss: 0.147978\tvalid_1's multi_logloss: 0.269646       \n",
      "[134]\ttraining's multi_logloss: 0.146997\tvalid_1's multi_logloss: 0.269615       \n",
      "[135]\ttraining's multi_logloss: 0.145993\tvalid_1's multi_logloss: 0.269453       \n",
      "[136]\ttraining's multi_logloss: 0.145035\tvalid_1's multi_logloss: 0.269278       \n",
      "[137]\ttraining's multi_logloss: 0.14413\tvalid_1's multi_logloss: 0.269281        \n",
      "[138]\ttraining's multi_logloss: 0.143174\tvalid_1's multi_logloss: 0.269197       \n",
      "[139]\ttraining's multi_logloss: 0.142267\tvalid_1's multi_logloss: 0.269143       \n",
      "[140]\ttraining's multi_logloss: 0.141313\tvalid_1's multi_logloss: 0.268923       \n",
      "[141]\ttraining's multi_logloss: 0.140289\tvalid_1's multi_logloss: 0.268798       \n",
      "[142]\ttraining's multi_logloss: 0.139394\tvalid_1's multi_logloss: 0.268703       \n",
      "[143]\ttraining's multi_logloss: 0.138483\tvalid_1's multi_logloss: 0.268584       \n",
      "[144]\ttraining's multi_logloss: 0.137636\tvalid_1's multi_logloss: 0.268507       \n",
      "[145]\ttraining's multi_logloss: 0.136851\tvalid_1's multi_logloss: 0.268358       \n",
      "[146]\ttraining's multi_logloss: 0.135981\tvalid_1's multi_logloss: 0.268203       \n",
      "[147]\ttraining's multi_logloss: 0.135129\tvalid_1's multi_logloss: 0.268132       \n",
      "[148]\ttraining's multi_logloss: 0.134261\tvalid_1's multi_logloss: 0.268065       \n",
      "[149]\ttraining's multi_logloss: 0.133471\tvalid_1's multi_logloss: 0.268068       \n",
      "[150]\ttraining's multi_logloss: 0.132609\tvalid_1's multi_logloss: 0.268013       \n",
      "[151]\ttraining's multi_logloss: 0.131739\tvalid_1's multi_logloss: 0.268069       \n",
      "[152]\ttraining's multi_logloss: 0.13091\tvalid_1's multi_logloss: 0.268003        \n",
      "[153]\ttraining's multi_logloss: 0.130083\tvalid_1's multi_logloss: 0.268047       \n",
      "[154]\ttraining's multi_logloss: 0.129382\tvalid_1's multi_logloss: 0.267905       \n",
      "[155]\ttraining's multi_logloss: 0.128583\tvalid_1's multi_logloss: 0.26783        \n",
      "[156]\ttraining's multi_logloss: 0.127822\tvalid_1's multi_logloss: 0.267921       \n",
      "[157]\ttraining's multi_logloss: 0.127127\tvalid_1's multi_logloss: 0.268029       \n",
      "[158]\ttraining's multi_logloss: 0.126383\tvalid_1's multi_logloss: 0.267945       \n",
      "[159]\ttraining's multi_logloss: 0.125612\tvalid_1's multi_logloss: 0.267926       \n",
      "[160]\ttraining's multi_logloss: 0.124844\tvalid_1's multi_logloss: 0.268046       \n",
      "[161]\ttraining's multi_logloss: 0.124106\tvalid_1's multi_logloss: 0.26817        \n",
      "[162]\ttraining's multi_logloss: 0.123352\tvalid_1's multi_logloss: 0.268234       \n",
      "[163]\ttraining's multi_logloss: 0.122661\tvalid_1's multi_logloss: 0.268232       \n",
      "[164]\ttraining's multi_logloss: 0.12195\tvalid_1's multi_logloss: 0.268261        \n",
      "[165]\ttraining's multi_logloss: 0.1212\tvalid_1's multi_logloss: 0.268246         \n",
      "[166]\ttraining's multi_logloss: 0.120551\tvalid_1's multi_logloss: 0.268254       \n",
      "[167]\ttraining's multi_logloss: 0.119818\tvalid_1's multi_logloss: 0.268288       \n",
      "[168]\ttraining's multi_logloss: 0.119133\tvalid_1's multi_logloss: 0.268313       \n",
      "[169]\ttraining's multi_logloss: 0.118374\tvalid_1's multi_logloss: 0.268361       \n",
      "[170]\ttraining's multi_logloss: 0.117643\tvalid_1's multi_logloss: 0.268314       \n",
      "[171]\ttraining's multi_logloss: 0.116993\tvalid_1's multi_logloss: 0.268326       \n",
      "[172]\ttraining's multi_logloss: 0.116324\tvalid_1's multi_logloss: 0.268304       \n",
      "[173]\ttraining's multi_logloss: 0.115615\tvalid_1's multi_logloss: 0.268451       \n",
      "[174]\ttraining's multi_logloss: 0.114956\tvalid_1's multi_logloss: 0.268464       \n",
      "[175]\ttraining's multi_logloss: 0.114303\tvalid_1's multi_logloss: 0.268545       \n",
      "[176]\ttraining's multi_logloss: 0.113599\tvalid_1's multi_logloss: 0.268552       \n",
      "[177]\ttraining's multi_logloss: 0.112974\tvalid_1's multi_logloss: 0.268701       \n",
      "[178]\ttraining's multi_logloss: 0.112331\tvalid_1's multi_logloss: 0.268742       \n",
      "[179]\ttraining's multi_logloss: 0.111691\tvalid_1's multi_logloss: 0.268788       \n",
      "[180]\ttraining's multi_logloss: 0.11105\tvalid_1's multi_logloss: 0.268983        \n",
      "[181]\ttraining's multi_logloss: 0.110389\tvalid_1's multi_logloss: 0.26903        \n",
      "[182]\ttraining's multi_logloss: 0.109708\tvalid_1's multi_logloss: 0.269128       \n",
      "[183]\ttraining's multi_logloss: 0.109138\tvalid_1's multi_logloss: 0.269293       \n",
      "[184]\ttraining's multi_logloss: 0.108499\tvalid_1's multi_logloss: 0.269284       \n",
      "[185]\ttraining's multi_logloss: 0.107886\tvalid_1's multi_logloss: 0.269423       \n",
      "Early stopping, best iteration is:                                               \n",
      "[155]\ttraining's multi_logloss: 0.128583\tvalid_1's multi_logloss: 0.26783\n",
      "[1]\ttraining's multi_logloss: 1.46431\tvalid_1's multi_logloss: 1.47304           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.19827\tvalid_1's multi_logloss: 1.21434           \n",
      "[3]\ttraining's multi_logloss: 1.01197\tvalid_1's multi_logloss: 1.03458           \n",
      "[4]\ttraining's multi_logloss: 0.873095\tvalid_1's multi_logloss: 0.901153         \n",
      "[5]\ttraining's multi_logloss: 0.764373\tvalid_1's multi_logloss: 0.796714         \n",
      "[6]\ttraining's multi_logloss: 0.677742\tvalid_1's multi_logloss: 0.713584         \n",
      "[7]\ttraining's multi_logloss: 0.605863\tvalid_1's multi_logloss: 0.645751         \n",
      "[8]\ttraining's multi_logloss: 0.547095\tvalid_1's multi_logloss: 0.590253         \n",
      "[9]\ttraining's multi_logloss: 0.49805\tvalid_1's multi_logloss: 0.544759          \n",
      "[10]\ttraining's multi_logloss: 0.456241\tvalid_1's multi_logloss: 0.506554        \n",
      "[11]\ttraining's multi_logloss: 0.420772\tvalid_1's multi_logloss: 0.474657        \n",
      "[12]\ttraining's multi_logloss: 0.390413\tvalid_1's multi_logloss: 0.447831        \n",
      "[13]\ttraining's multi_logloss: 0.364303\tvalid_1's multi_logloss: 0.424984        \n",
      "[14]\ttraining's multi_logloss: 0.341886\tvalid_1's multi_logloss: 0.405276        \n",
      "[15]\ttraining's multi_logloss: 0.322102\tvalid_1's multi_logloss: 0.388748        \n",
      "[16]\ttraining's multi_logloss: 0.305053\tvalid_1's multi_logloss: 0.375847        \n",
      "[17]\ttraining's multi_logloss: 0.289962\tvalid_1's multi_logloss: 0.364364        \n",
      "[18]\ttraining's multi_logloss: 0.276045\tvalid_1's multi_logloss: 0.353945        \n",
      "[19]\ttraining's multi_logloss: 0.263328\tvalid_1's multi_logloss: 0.345468        \n",
      "[20]\ttraining's multi_logloss: 0.251948\tvalid_1's multi_logloss: 0.337657        \n",
      "[21]\ttraining's multi_logloss: 0.241425\tvalid_1's multi_logloss: 0.331292        \n",
      "[22]\ttraining's multi_logloss: 0.232242\tvalid_1's multi_logloss: 0.325934        \n",
      "[23]\ttraining's multi_logloss: 0.223531\tvalid_1's multi_logloss: 0.321052        \n",
      "[24]\ttraining's multi_logloss: 0.215149\tvalid_1's multi_logloss: 0.31694         \n",
      "[25]\ttraining's multi_logloss: 0.207457\tvalid_1's multi_logloss: 0.313451        \n",
      "[26]\ttraining's multi_logloss: 0.20017\tvalid_1's multi_logloss: 0.310421         \n",
      "[27]\ttraining's multi_logloss: 0.193321\tvalid_1's multi_logloss: 0.307265        \n",
      "[28]\ttraining's multi_logloss: 0.187013\tvalid_1's multi_logloss: 0.304654        \n",
      "[29]\ttraining's multi_logloss: 0.180666\tvalid_1's multi_logloss: 0.302026        \n",
      "[30]\ttraining's multi_logloss: 0.174871\tvalid_1's multi_logloss: 0.30038         \n",
      "[31]\ttraining's multi_logloss: 0.169207\tvalid_1's multi_logloss: 0.298674        \n",
      "[32]\ttraining's multi_logloss: 0.164123\tvalid_1's multi_logloss: 0.297457        \n",
      "[33]\ttraining's multi_logloss: 0.159007\tvalid_1's multi_logloss: 0.296607        \n",
      "[34]\ttraining's multi_logloss: 0.154145\tvalid_1's multi_logloss: 0.296128        \n",
      "[35]\ttraining's multi_logloss: 0.149695\tvalid_1's multi_logloss: 0.295636        \n",
      "[36]\ttraining's multi_logloss: 0.145011\tvalid_1's multi_logloss: 0.294774        \n",
      "[37]\ttraining's multi_logloss: 0.140701\tvalid_1's multi_logloss: 0.29402         \n",
      "[38]\ttraining's multi_logloss: 0.136557\tvalid_1's multi_logloss: 0.293053        \n",
      "[39]\ttraining's multi_logloss: 0.132617\tvalid_1's multi_logloss: 0.292872        \n",
      "[40]\ttraining's multi_logloss: 0.128842\tvalid_1's multi_logloss: 0.292943        \n",
      "[41]\ttraining's multi_logloss: 0.125136\tvalid_1's multi_logloss: 0.292501        \n",
      "[42]\ttraining's multi_logloss: 0.121677\tvalid_1's multi_logloss: 0.292827        \n",
      "[43]\ttraining's multi_logloss: 0.118258\tvalid_1's multi_logloss: 0.292704        \n",
      "[44]\ttraining's multi_logloss: 0.114964\tvalid_1's multi_logloss: 0.292407        \n",
      "[45]\ttraining's multi_logloss: 0.111591\tvalid_1's multi_logloss: 0.292671        \n",
      "[46]\ttraining's multi_logloss: 0.108309\tvalid_1's multi_logloss: 0.292846        \n",
      "[47]\ttraining's multi_logloss: 0.105255\tvalid_1's multi_logloss: 0.293239        \n",
      "[48]\ttraining's multi_logloss: 0.102463\tvalid_1's multi_logloss: 0.293674        \n",
      "[49]\ttraining's multi_logloss: 0.0995833\tvalid_1's multi_logloss: 0.294104       \n",
      "[50]\ttraining's multi_logloss: 0.0968916\tvalid_1's multi_logloss: 0.294734       \n",
      "[51]\ttraining's multi_logloss: 0.0943537\tvalid_1's multi_logloss: 0.295069       \n",
      "[52]\ttraining's multi_logloss: 0.0917304\tvalid_1's multi_logloss: 0.294849       \n",
      "[53]\ttraining's multi_logloss: 0.0891946\tvalid_1's multi_logloss: 0.295233       \n",
      "[54]\ttraining's multi_logloss: 0.0867739\tvalid_1's multi_logloss: 0.296007       \n",
      "[55]\ttraining's multi_logloss: 0.0844147\tvalid_1's multi_logloss: 0.296462       \n",
      "[56]\ttraining's multi_logloss: 0.0822266\tvalid_1's multi_logloss: 0.296731       \n",
      "[57]\ttraining's multi_logloss: 0.0799981\tvalid_1's multi_logloss: 0.297228       \n",
      "[58]\ttraining's multi_logloss: 0.0779721\tvalid_1's multi_logloss: 0.297987       \n",
      "[59]\ttraining's multi_logloss: 0.075658\tvalid_1's multi_logloss: 0.298107        \n",
      "[60]\ttraining's multi_logloss: 0.0736006\tvalid_1's multi_logloss: 0.298483       \n",
      "[61]\ttraining's multi_logloss: 0.0717167\tvalid_1's multi_logloss: 0.299396       \n",
      "[62]\ttraining's multi_logloss: 0.0698258\tvalid_1's multi_logloss: 0.300071       \n",
      "[63]\ttraining's multi_logloss: 0.0680598\tvalid_1's multi_logloss: 0.301027       \n",
      "[64]\ttraining's multi_logloss: 0.066374\tvalid_1's multi_logloss: 0.302205        \n",
      "[65]\ttraining's multi_logloss: 0.0648389\tvalid_1's multi_logloss: 0.303379       \n",
      "[66]\ttraining's multi_logloss: 0.0632773\tvalid_1's multi_logloss: 0.304514       \n",
      "[67]\ttraining's multi_logloss: 0.0615102\tvalid_1's multi_logloss: 0.305461       \n",
      "[68]\ttraining's multi_logloss: 0.0599243\tvalid_1's multi_logloss: 0.306486       \n",
      "[69]\ttraining's multi_logloss: 0.0584312\tvalid_1's multi_logloss: 0.306964       \n",
      "[70]\ttraining's multi_logloss: 0.0570569\tvalid_1's multi_logloss: 0.307817       \n",
      "[71]\ttraining's multi_logloss: 0.0557632\tvalid_1's multi_logloss: 0.309015       \n",
      "[72]\ttraining's multi_logloss: 0.0543284\tvalid_1's multi_logloss: 0.310016       \n",
      "[73]\ttraining's multi_logloss: 0.0529366\tvalid_1's multi_logloss: 0.310931       \n",
      "[74]\ttraining's multi_logloss: 0.0515909\tvalid_1's multi_logloss: 0.311655       \n",
      "Early stopping, best iteration is:                                               \n",
      "[44]\ttraining's multi_logloss: 0.114964\tvalid_1's multi_logloss: 0.292407\n",
      "[1]\ttraining's multi_logloss: 1.46245\tvalid_1's multi_logloss: 1.46869           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.19928\tvalid_1's multi_logloss: 1.20894           \n",
      "[3]\ttraining's multi_logloss: 1.01697\tvalid_1's multi_logloss: 1.03069           \n",
      "[4]\ttraining's multi_logloss: 0.879651\tvalid_1's multi_logloss: 0.895963         \n",
      "[5]\ttraining's multi_logloss: 0.772385\tvalid_1's multi_logloss: 0.791925         \n",
      "[6]\ttraining's multi_logloss: 0.685034\tvalid_1's multi_logloss: 0.708521         \n",
      "[7]\ttraining's multi_logloss: 0.613489\tvalid_1's multi_logloss: 0.640425         \n",
      "[8]\ttraining's multi_logloss: 0.554371\tvalid_1's multi_logloss: 0.584741         \n",
      "[9]\ttraining's multi_logloss: 0.504427\tvalid_1's multi_logloss: 0.537909         \n",
      "[10]\ttraining's multi_logloss: 0.463422\tvalid_1's multi_logloss: 0.500446        \n",
      "[11]\ttraining's multi_logloss: 0.427921\tvalid_1's multi_logloss: 0.468963        \n",
      "[12]\ttraining's multi_logloss: 0.396724\tvalid_1's multi_logloss: 0.440587        \n",
      "[13]\ttraining's multi_logloss: 0.370664\tvalid_1's multi_logloss: 0.418526        \n",
      "[14]\ttraining's multi_logloss: 0.347391\tvalid_1's multi_logloss: 0.398723        \n",
      "[15]\ttraining's multi_logloss: 0.327324\tvalid_1's multi_logloss: 0.382854        \n",
      "[16]\ttraining's multi_logloss: 0.309914\tvalid_1's multi_logloss: 0.369057        \n",
      "[17]\ttraining's multi_logloss: 0.293849\tvalid_1's multi_logloss: 0.35694         \n",
      "[18]\ttraining's multi_logloss: 0.279442\tvalid_1's multi_logloss: 0.346382        \n",
      "[19]\ttraining's multi_logloss: 0.266506\tvalid_1's multi_logloss: 0.337423        \n",
      "[20]\ttraining's multi_logloss: 0.254717\tvalid_1's multi_logloss: 0.329498        \n",
      "[21]\ttraining's multi_logloss: 0.244059\tvalid_1's multi_logloss: 0.322911        \n",
      "[22]\ttraining's multi_logloss: 0.234278\tvalid_1's multi_logloss: 0.317678        \n",
      "[23]\ttraining's multi_logloss: 0.225034\tvalid_1's multi_logloss: 0.313153        \n",
      "[24]\ttraining's multi_logloss: 0.217014\tvalid_1's multi_logloss: 0.309164        \n",
      "[25]\ttraining's multi_logloss: 0.209206\tvalid_1's multi_logloss: 0.306137        \n",
      "[26]\ttraining's multi_logloss: 0.202048\tvalid_1's multi_logloss: 0.30305         \n",
      "[27]\ttraining's multi_logloss: 0.195142\tvalid_1's multi_logloss: 0.300701        \n",
      "[28]\ttraining's multi_logloss: 0.188567\tvalid_1's multi_logloss: 0.298578        \n",
      "[29]\ttraining's multi_logloss: 0.18206\tvalid_1's multi_logloss: 0.296155         \n",
      "[30]\ttraining's multi_logloss: 0.176058\tvalid_1's multi_logloss: 0.294598        \n",
      "[31]\ttraining's multi_logloss: 0.170326\tvalid_1's multi_logloss: 0.293196        \n",
      "[32]\ttraining's multi_logloss: 0.164704\tvalid_1's multi_logloss: 0.292233        \n",
      "[33]\ttraining's multi_logloss: 0.159096\tvalid_1's multi_logloss: 0.290983        \n",
      "[34]\ttraining's multi_logloss: 0.153864\tvalid_1's multi_logloss: 0.289942        \n",
      "[35]\ttraining's multi_logloss: 0.149032\tvalid_1's multi_logloss: 0.289079        \n",
      "[36]\ttraining's multi_logloss: 0.144332\tvalid_1's multi_logloss: 0.28852         \n",
      "[37]\ttraining's multi_logloss: 0.139556\tvalid_1's multi_logloss: 0.28778         \n",
      "[38]\ttraining's multi_logloss: 0.135489\tvalid_1's multi_logloss: 0.287181        \n",
      "[39]\ttraining's multi_logloss: 0.131287\tvalid_1's multi_logloss: 0.286548        \n",
      "[40]\ttraining's multi_logloss: 0.127349\tvalid_1's multi_logloss: 0.286557        \n",
      "[41]\ttraining's multi_logloss: 0.123663\tvalid_1's multi_logloss: 0.286721        \n",
      "[42]\ttraining's multi_logloss: 0.119971\tvalid_1's multi_logloss: 0.286577        \n",
      "[43]\ttraining's multi_logloss: 0.116258\tvalid_1's multi_logloss: 0.286737        \n",
      "[44]\ttraining's multi_logloss: 0.112944\tvalid_1's multi_logloss: 0.287123        \n",
      "[45]\ttraining's multi_logloss: 0.10984\tvalid_1's multi_logloss: 0.287214         \n",
      "[46]\ttraining's multi_logloss: 0.106798\tvalid_1's multi_logloss: 0.287589        \n",
      "[47]\ttraining's multi_logloss: 0.104009\tvalid_1's multi_logloss: 0.287398        \n",
      "[48]\ttraining's multi_logloss: 0.100988\tvalid_1's multi_logloss: 0.287587        \n",
      "[49]\ttraining's multi_logloss: 0.0979811\tvalid_1's multi_logloss: 0.288045       \n",
      "[50]\ttraining's multi_logloss: 0.0952703\tvalid_1's multi_logloss: 0.288127       \n",
      "[51]\ttraining's multi_logloss: 0.0924234\tvalid_1's multi_logloss: 0.288619       \n",
      "[52]\ttraining's multi_logloss: 0.0898312\tvalid_1's multi_logloss: 0.288925       \n",
      "[53]\ttraining's multi_logloss: 0.0873803\tvalid_1's multi_logloss: 0.289239       \n",
      "[54]\ttraining's multi_logloss: 0.084767\tvalid_1's multi_logloss: 0.28946         \n",
      "[55]\ttraining's multi_logloss: 0.0823253\tvalid_1's multi_logloss: 0.290035       \n",
      "[56]\ttraining's multi_logloss: 0.0802991\tvalid_1's multi_logloss: 0.290372       \n",
      "[57]\ttraining's multi_logloss: 0.0782208\tvalid_1's multi_logloss: 0.291026       \n",
      "[58]\ttraining's multi_logloss: 0.0762221\tvalid_1's multi_logloss: 0.29198        \n",
      "[59]\ttraining's multi_logloss: 0.0741116\tvalid_1's multi_logloss: 0.292588       \n",
      "[60]\ttraining's multi_logloss: 0.0722521\tvalid_1's multi_logloss: 0.293171       \n",
      "[61]\ttraining's multi_logloss: 0.0703854\tvalid_1's multi_logloss: 0.29414        \n",
      "[62]\ttraining's multi_logloss: 0.0684823\tvalid_1's multi_logloss: 0.295269       \n",
      "[63]\ttraining's multi_logloss: 0.0667673\tvalid_1's multi_logloss: 0.296294       \n",
      "[64]\ttraining's multi_logloss: 0.065049\tvalid_1's multi_logloss: 0.297548        \n",
      "[65]\ttraining's multi_logloss: 0.0634012\tvalid_1's multi_logloss: 0.298673       \n",
      "[66]\ttraining's multi_logloss: 0.0619153\tvalid_1's multi_logloss: 0.299365       \n",
      "[67]\ttraining's multi_logloss: 0.0602915\tvalid_1's multi_logloss: 0.300954       \n",
      "[68]\ttraining's multi_logloss: 0.0588793\tvalid_1's multi_logloss: 0.301784       \n",
      "[69]\ttraining's multi_logloss: 0.0574383\tvalid_1's multi_logloss: 0.302786       \n",
      "Early stopping, best iteration is:                                               \n",
      "[39]\ttraining's multi_logloss: 0.131287\tvalid_1's multi_logloss: 0.286548\n",
      "[1]\ttraining's multi_logloss: 1.46531\tvalid_1's multi_logloss: 1.47096           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.20083\tvalid_1's multi_logloss: 1.20882           \n",
      "[3]\ttraining's multi_logloss: 1.01698\tvalid_1's multi_logloss: 1.02761           \n",
      "[4]\ttraining's multi_logloss: 0.87969\tvalid_1's multi_logloss: 0.893279          \n",
      "[5]\ttraining's multi_logloss: 0.771235\tvalid_1's multi_logloss: 0.786466         \n",
      "[6]\ttraining's multi_logloss: 0.68493\tvalid_1's multi_logloss: 0.702236          \n",
      "[7]\ttraining's multi_logloss: 0.614459\tvalid_1's multi_logloss: 0.634362         \n",
      "[8]\ttraining's multi_logloss: 0.555935\tvalid_1's multi_logloss: 0.57904          \n",
      "[9]\ttraining's multi_logloss: 0.507683\tvalid_1's multi_logloss: 0.534072         \n",
      "[10]\ttraining's multi_logloss: 0.46633\tvalid_1's multi_logloss: 0.495522         \n",
      "[11]\ttraining's multi_logloss: 0.431694\tvalid_1's multi_logloss: 0.463903        \n",
      "[12]\ttraining's multi_logloss: 0.401552\tvalid_1's multi_logloss: 0.436274        \n",
      "[13]\ttraining's multi_logloss: 0.374458\tvalid_1's multi_logloss: 0.411512        \n",
      "[14]\ttraining's multi_logloss: 0.351598\tvalid_1's multi_logloss: 0.391987        \n",
      "[15]\ttraining's multi_logloss: 0.330994\tvalid_1's multi_logloss: 0.374654        \n",
      "[16]\ttraining's multi_logloss: 0.313512\tvalid_1's multi_logloss: 0.360558        \n",
      "[17]\ttraining's multi_logloss: 0.297656\tvalid_1's multi_logloss: 0.348443        \n",
      "[18]\ttraining's multi_logloss: 0.283858\tvalid_1's multi_logloss: 0.338696        \n",
      "[19]\ttraining's multi_logloss: 0.27101\tvalid_1's multi_logloss: 0.330018         \n",
      "[20]\ttraining's multi_logloss: 0.259587\tvalid_1's multi_logloss: 0.321797        \n",
      "[21]\ttraining's multi_logloss: 0.24908\tvalid_1's multi_logloss: 0.314766         \n",
      "[22]\ttraining's multi_logloss: 0.239263\tvalid_1's multi_logloss: 0.308863        \n",
      "[23]\ttraining's multi_logloss: 0.230588\tvalid_1's multi_logloss: 0.303591        \n",
      "[24]\ttraining's multi_logloss: 0.221974\tvalid_1's multi_logloss: 0.300007        \n",
      "[25]\ttraining's multi_logloss: 0.214026\tvalid_1's multi_logloss: 0.296035        \n",
      "[26]\ttraining's multi_logloss: 0.206243\tvalid_1's multi_logloss: 0.292434        \n",
      "[27]\ttraining's multi_logloss: 0.199656\tvalid_1's multi_logloss: 0.289393        \n",
      "[28]\ttraining's multi_logloss: 0.193056\tvalid_1's multi_logloss: 0.287067        \n",
      "[29]\ttraining's multi_logloss: 0.187147\tvalid_1's multi_logloss: 0.284684        \n",
      "[30]\ttraining's multi_logloss: 0.181105\tvalid_1's multi_logloss: 0.282805        \n",
      "[31]\ttraining's multi_logloss: 0.17536\tvalid_1's multi_logloss: 0.281378         \n",
      "[32]\ttraining's multi_logloss: 0.170012\tvalid_1's multi_logloss: 0.280195        \n",
      "[33]\ttraining's multi_logloss: 0.164642\tvalid_1's multi_logloss: 0.278537        \n",
      "[34]\ttraining's multi_logloss: 0.159505\tvalid_1's multi_logloss: 0.277339        \n",
      "[35]\ttraining's multi_logloss: 0.154697\tvalid_1's multi_logloss: 0.276229        \n",
      "[36]\ttraining's multi_logloss: 0.150129\tvalid_1's multi_logloss: 0.275445        \n",
      "[37]\ttraining's multi_logloss: 0.145754\tvalid_1's multi_logloss: 0.275064        \n",
      "[38]\ttraining's multi_logloss: 0.141475\tvalid_1's multi_logloss: 0.274272        \n",
      "[39]\ttraining's multi_logloss: 0.137235\tvalid_1's multi_logloss: 0.274233        \n",
      "[40]\ttraining's multi_logloss: 0.132986\tvalid_1's multi_logloss: 0.273659        \n",
      "[41]\ttraining's multi_logloss: 0.129343\tvalid_1's multi_logloss: 0.27332         \n",
      "[42]\ttraining's multi_logloss: 0.125311\tvalid_1's multi_logloss: 0.27303         \n",
      "[43]\ttraining's multi_logloss: 0.1216\tvalid_1's multi_logloss: 0.273137          \n",
      "[44]\ttraining's multi_logloss: 0.118185\tvalid_1's multi_logloss: 0.273297        \n",
      "[45]\ttraining's multi_logloss: 0.114821\tvalid_1's multi_logloss: 0.273019        \n",
      "[46]\ttraining's multi_logloss: 0.111186\tvalid_1's multi_logloss: 0.272811        \n",
      "[47]\ttraining's multi_logloss: 0.10793\tvalid_1's multi_logloss: 0.272966         \n",
      "[48]\ttraining's multi_logloss: 0.104962\tvalid_1's multi_logloss: 0.273425        \n",
      "[49]\ttraining's multi_logloss: 0.102084\tvalid_1's multi_logloss: 0.274062        \n",
      "[50]\ttraining's multi_logloss: 0.0992709\tvalid_1's multi_logloss: 0.274207       \n",
      "[51]\ttraining's multi_logloss: 0.0968595\tvalid_1's multi_logloss: 0.274474       \n",
      "[52]\ttraining's multi_logloss: 0.094198\tvalid_1's multi_logloss: 0.274519        \n",
      "[53]\ttraining's multi_logloss: 0.0917793\tvalid_1's multi_logloss: 0.274421       \n",
      "[54]\ttraining's multi_logloss: 0.0892664\tvalid_1's multi_logloss: 0.274391       \n",
      "[55]\ttraining's multi_logloss: 0.0867719\tvalid_1's multi_logloss: 0.274917       \n",
      "[56]\ttraining's multi_logloss: 0.0846644\tvalid_1's multi_logloss: 0.274964       \n",
      "[57]\ttraining's multi_logloss: 0.0824638\tvalid_1's multi_logloss: 0.275675       \n",
      "[58]\ttraining's multi_logloss: 0.0804265\tvalid_1's multi_logloss: 0.275643       \n",
      "[59]\ttraining's multi_logloss: 0.0783887\tvalid_1's multi_logloss: 0.276299       \n",
      "[60]\ttraining's multi_logloss: 0.0760592\tvalid_1's multi_logloss: 0.277098       \n",
      "[61]\ttraining's multi_logloss: 0.0740534\tvalid_1's multi_logloss: 0.277637       \n",
      "[62]\ttraining's multi_logloss: 0.0721518\tvalid_1's multi_logloss: 0.277918       \n",
      "[63]\ttraining's multi_logloss: 0.0701467\tvalid_1's multi_logloss: 0.278287       \n",
      "[64]\ttraining's multi_logloss: 0.0684708\tvalid_1's multi_logloss: 0.279138       \n",
      "[65]\ttraining's multi_logloss: 0.0668248\tvalid_1's multi_logloss: 0.279851       \n",
      "[66]\ttraining's multi_logloss: 0.0651486\tvalid_1's multi_logloss: 0.280248       \n",
      "[67]\ttraining's multi_logloss: 0.0635149\tvalid_1's multi_logloss: 0.280663       \n",
      "[68]\ttraining's multi_logloss: 0.0618555\tvalid_1's multi_logloss: 0.280959       \n",
      "[69]\ttraining's multi_logloss: 0.0602768\tvalid_1's multi_logloss: 0.281587       \n",
      "[70]\ttraining's multi_logloss: 0.0587442\tvalid_1's multi_logloss: 0.28221        \n",
      "[71]\ttraining's multi_logloss: 0.0573911\tvalid_1's multi_logloss: 0.282434       \n",
      "[72]\ttraining's multi_logloss: 0.0559342\tvalid_1's multi_logloss: 0.283043       \n",
      "[73]\ttraining's multi_logloss: 0.0545527\tvalid_1's multi_logloss: 0.28366        \n",
      "[74]\ttraining's multi_logloss: 0.0533646\tvalid_1's multi_logloss: 0.28454        \n",
      "[75]\ttraining's multi_logloss: 0.0520918\tvalid_1's multi_logloss: 0.285214       \n",
      "[76]\ttraining's multi_logloss: 0.0507215\tvalid_1's multi_logloss: 0.285595       \n",
      "Early stopping, best iteration is:                                               \n",
      "[46]\ttraining's multi_logloss: 0.111186\tvalid_1's multi_logloss: 0.272811\n",
      "[1]\ttraining's multi_logloss: 1.53938\tvalid_1's multi_logloss: 1.54591           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.294\tvalid_1's multi_logloss: 1.30674             \n",
      "[3]\ttraining's multi_logloss: 1.11628\tvalid_1's multi_logloss: 1.13438           \n",
      "[4]\ttraining's multi_logloss: 0.979255\tvalid_1's multi_logloss: 1.00196          \n",
      "[5]\ttraining's multi_logloss: 0.869978\tvalid_1's multi_logloss: 0.896575         \n",
      "[6]\ttraining's multi_logloss: 0.781166\tvalid_1's multi_logloss: 0.811088         \n",
      "[7]\ttraining's multi_logloss: 0.706521\tvalid_1's multi_logloss: 0.739707         \n",
      "[8]\ttraining's multi_logloss: 0.643898\tvalid_1's multi_logloss: 0.679376         \n",
      "[9]\ttraining's multi_logloss: 0.590362\tvalid_1's multi_logloss: 0.628941         \n",
      "[10]\ttraining's multi_logloss: 0.544018\tvalid_1's multi_logloss: 0.585308        \n",
      "[11]\ttraining's multi_logloss: 0.504313\tvalid_1's multi_logloss: 0.548333        \n",
      "[12]\ttraining's multi_logloss: 0.469538\tvalid_1's multi_logloss: 0.515696        \n",
      "[13]\ttraining's multi_logloss: 0.439118\tvalid_1's multi_logloss: 0.488038        \n",
      "[14]\ttraining's multi_logloss: 0.413023\tvalid_1's multi_logloss: 0.464425        \n",
      "[15]\ttraining's multi_logloss: 0.389184\tvalid_1's multi_logloss: 0.442962        \n",
      "[16]\ttraining's multi_logloss: 0.368261\tvalid_1's multi_logloss: 0.424486        \n",
      "[17]\ttraining's multi_logloss: 0.35004\tvalid_1's multi_logloss: 0.409085         \n",
      "[18]\ttraining's multi_logloss: 0.333643\tvalid_1's multi_logloss: 0.394832        \n",
      "[19]\ttraining's multi_logloss: 0.319279\tvalid_1's multi_logloss: 0.383337        \n",
      "[20]\ttraining's multi_logloss: 0.305797\tvalid_1's multi_logloss: 0.372591        \n",
      "[21]\ttraining's multi_logloss: 0.293573\tvalid_1's multi_logloss: 0.363216        \n",
      "[22]\ttraining's multi_logloss: 0.282471\tvalid_1's multi_logloss: 0.354877        \n",
      "[23]\ttraining's multi_logloss: 0.272328\tvalid_1's multi_logloss: 0.347485        \n",
      "[24]\ttraining's multi_logloss: 0.26318\tvalid_1's multi_logloss: 0.34081          \n",
      "[25]\ttraining's multi_logloss: 0.254111\tvalid_1's multi_logloss: 0.334715        \n",
      "[26]\ttraining's multi_logloss: 0.246299\tvalid_1's multi_logloss: 0.329737        \n",
      "[27]\ttraining's multi_logloss: 0.238557\tvalid_1's multi_logloss: 0.325077        \n",
      "[28]\ttraining's multi_logloss: 0.231429\tvalid_1's multi_logloss: 0.320971        \n",
      "[29]\ttraining's multi_logloss: 0.225127\tvalid_1's multi_logloss: 0.317761        \n",
      "[30]\ttraining's multi_logloss: 0.218625\tvalid_1's multi_logloss: 0.314661        \n",
      "[31]\ttraining's multi_logloss: 0.212806\tvalid_1's multi_logloss: 0.312514        \n",
      "[32]\ttraining's multi_logloss: 0.207079\tvalid_1's multi_logloss: 0.309931        \n",
      "[33]\ttraining's multi_logloss: 0.201582\tvalid_1's multi_logloss: 0.307787        \n",
      "[34]\ttraining's multi_logloss: 0.196648\tvalid_1's multi_logloss: 0.30568         \n",
      "[35]\ttraining's multi_logloss: 0.191941\tvalid_1's multi_logloss: 0.303951        \n",
      "[36]\ttraining's multi_logloss: 0.187472\tvalid_1's multi_logloss: 0.302417        \n",
      "[37]\ttraining's multi_logloss: 0.182898\tvalid_1's multi_logloss: 0.301324        \n",
      "[38]\ttraining's multi_logloss: 0.178512\tvalid_1's multi_logloss: 0.299964        \n",
      "[39]\ttraining's multi_logloss: 0.174252\tvalid_1's multi_logloss: 0.298812        \n",
      "[40]\ttraining's multi_logloss: 0.170234\tvalid_1's multi_logloss: 0.298099        \n",
      "[41]\ttraining's multi_logloss: 0.166191\tvalid_1's multi_logloss: 0.297246        \n",
      "[42]\ttraining's multi_logloss: 0.162418\tvalid_1's multi_logloss: 0.296532        \n",
      "[43]\ttraining's multi_logloss: 0.158692\tvalid_1's multi_logloss: 0.296201        \n",
      "[44]\ttraining's multi_logloss: 0.154997\tvalid_1's multi_logloss: 0.296186        \n",
      "[45]\ttraining's multi_logloss: 0.151527\tvalid_1's multi_logloss: 0.295486        \n",
      "[46]\ttraining's multi_logloss: 0.147978\tvalid_1's multi_logloss: 0.294786        \n",
      "[47]\ttraining's multi_logloss: 0.144671\tvalid_1's multi_logloss: 0.294241        \n",
      "[48]\ttraining's multi_logloss: 0.141513\tvalid_1's multi_logloss: 0.29369         \n",
      "[49]\ttraining's multi_logloss: 0.138227\tvalid_1's multi_logloss: 0.293971        \n",
      "[50]\ttraining's multi_logloss: 0.135094\tvalid_1's multi_logloss: 0.293537        \n",
      "[51]\ttraining's multi_logloss: 0.132077\tvalid_1's multi_logloss: 0.293569        \n",
      "[52]\ttraining's multi_logloss: 0.129252\tvalid_1's multi_logloss: 0.293426        \n",
      "[53]\ttraining's multi_logloss: 0.126456\tvalid_1's multi_logloss: 0.293446        \n",
      "[54]\ttraining's multi_logloss: 0.123818\tvalid_1's multi_logloss: 0.293098        \n",
      "[55]\ttraining's multi_logloss: 0.121096\tvalid_1's multi_logloss: 0.293435        \n",
      "[56]\ttraining's multi_logloss: 0.118317\tvalid_1's multi_logloss: 0.293159        \n",
      "[57]\ttraining's multi_logloss: 0.115832\tvalid_1's multi_logloss: 0.293046        \n",
      "[58]\ttraining's multi_logloss: 0.113406\tvalid_1's multi_logloss: 0.29336         \n",
      "[59]\ttraining's multi_logloss: 0.110963\tvalid_1's multi_logloss: 0.293261        \n",
      "[60]\ttraining's multi_logloss: 0.108404\tvalid_1's multi_logloss: 0.293494        \n",
      "[61]\ttraining's multi_logloss: 0.106246\tvalid_1's multi_logloss: 0.293563        \n",
      "[62]\ttraining's multi_logloss: 0.104144\tvalid_1's multi_logloss: 0.293995        \n",
      "[63]\ttraining's multi_logloss: 0.10198\tvalid_1's multi_logloss: 0.294248         \n",
      "[64]\ttraining's multi_logloss: 0.100165\tvalid_1's multi_logloss: 0.294324        \n",
      "[65]\ttraining's multi_logloss: 0.0980093\tvalid_1's multi_logloss: 0.294686       \n",
      "[66]\ttraining's multi_logloss: 0.0960619\tvalid_1's multi_logloss: 0.294921       \n",
      "[67]\ttraining's multi_logloss: 0.0941953\tvalid_1's multi_logloss: 0.295244       \n",
      "[68]\ttraining's multi_logloss: 0.092434\tvalid_1's multi_logloss: 0.295739        \n",
      "[69]\ttraining's multi_logloss: 0.090638\tvalid_1's multi_logloss: 0.295894        \n",
      "[70]\ttraining's multi_logloss: 0.0889775\tvalid_1's multi_logloss: 0.296475       \n",
      "[71]\ttraining's multi_logloss: 0.087333\tvalid_1's multi_logloss: 0.296988        \n",
      "[72]\ttraining's multi_logloss: 0.0856081\tvalid_1's multi_logloss: 0.297235       \n",
      "[73]\ttraining's multi_logloss: 0.0837521\tvalid_1's multi_logloss: 0.297165       \n",
      "[74]\ttraining's multi_logloss: 0.0822811\tvalid_1's multi_logloss: 0.297765       \n",
      "[75]\ttraining's multi_logloss: 0.0806836\tvalid_1's multi_logloss: 0.298095       \n",
      "[76]\ttraining's multi_logloss: 0.0791326\tvalid_1's multi_logloss: 0.298392       \n",
      "[77]\ttraining's multi_logloss: 0.0775083\tvalid_1's multi_logloss: 0.299182       \n",
      "[78]\ttraining's multi_logloss: 0.0760808\tvalid_1's multi_logloss: 0.299517       \n",
      "[79]\ttraining's multi_logloss: 0.0747932\tvalid_1's multi_logloss: 0.300181       \n",
      "[80]\ttraining's multi_logloss: 0.073548\tvalid_1's multi_logloss: 0.300724        \n",
      "[81]\ttraining's multi_logloss: 0.072064\tvalid_1's multi_logloss: 0.301274        \n",
      "[82]\ttraining's multi_logloss: 0.0704761\tvalid_1's multi_logloss: 0.302316       \n",
      "[83]\ttraining's multi_logloss: 0.06919\tvalid_1's multi_logloss: 0.302749         \n",
      "[84]\ttraining's multi_logloss: 0.0680719\tvalid_1's multi_logloss: 0.303676       \n",
      "[85]\ttraining's multi_logloss: 0.0667148\tvalid_1's multi_logloss: 0.304536       \n",
      "[86]\ttraining's multi_logloss: 0.0656406\tvalid_1's multi_logloss: 0.305107       \n",
      "[87]\ttraining's multi_logloss: 0.064343\tvalid_1's multi_logloss: 0.305771        \n",
      "Early stopping, best iteration is:                                               \n",
      "[57]\ttraining's multi_logloss: 0.115832\tvalid_1's multi_logloss: 0.293046\n",
      "[1]\ttraining's multi_logloss: 1.53742\tvalid_1's multi_logloss: 1.54189           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.29469\tvalid_1's multi_logloss: 1.30108           \n",
      "[3]\ttraining's multi_logloss: 1.11961\tvalid_1's multi_logloss: 1.12935           \n",
      "[4]\ttraining's multi_logloss: 0.984802\tvalid_1's multi_logloss: 0.996623         \n",
      "[5]\ttraining's multi_logloss: 0.877213\tvalid_1's multi_logloss: 0.891102         \n",
      "[6]\ttraining's multi_logloss: 0.788538\tvalid_1's multi_logloss: 0.804841         \n",
      "[7]\ttraining's multi_logloss: 0.712897\tvalid_1's multi_logloss: 0.732366         \n",
      "[8]\ttraining's multi_logloss: 0.64924\tvalid_1's multi_logloss: 0.671951          \n",
      "[9]\ttraining's multi_logloss: 0.595911\tvalid_1's multi_logloss: 0.621256         \n",
      "[10]\ttraining's multi_logloss: 0.549998\tvalid_1's multi_logloss: 0.578057        \n",
      "[11]\ttraining's multi_logloss: 0.509481\tvalid_1's multi_logloss: 0.53974         \n",
      "[12]\ttraining's multi_logloss: 0.474505\tvalid_1's multi_logloss: 0.507167        \n",
      "[13]\ttraining's multi_logloss: 0.444318\tvalid_1's multi_logloss: 0.480082        \n",
      "[14]\ttraining's multi_logloss: 0.417572\tvalid_1's multi_logloss: 0.456108        \n",
      "[15]\ttraining's multi_logloss: 0.394227\tvalid_1's multi_logloss: 0.43583         \n",
      "[16]\ttraining's multi_logloss: 0.373096\tvalid_1's multi_logloss: 0.417777        \n",
      "[17]\ttraining's multi_logloss: 0.35484\tvalid_1's multi_logloss: 0.402419         \n",
      "[18]\ttraining's multi_logloss: 0.338078\tvalid_1's multi_logloss: 0.388172        \n",
      "[19]\ttraining's multi_logloss: 0.323395\tvalid_1's multi_logloss: 0.376193        \n",
      "[20]\ttraining's multi_logloss: 0.309923\tvalid_1's multi_logloss: 0.365406        \n",
      "[21]\ttraining's multi_logloss: 0.297112\tvalid_1's multi_logloss: 0.355363        \n",
      "[22]\ttraining's multi_logloss: 0.285675\tvalid_1's multi_logloss: 0.34704         \n",
      "[23]\ttraining's multi_logloss: 0.27475\tvalid_1's multi_logloss: 0.339381         \n",
      "[24]\ttraining's multi_logloss: 0.265133\tvalid_1's multi_logloss: 0.33258         \n",
      "[25]\ttraining's multi_logloss: 0.256263\tvalid_1's multi_logloss: 0.327075        \n",
      "[26]\ttraining's multi_logloss: 0.247659\tvalid_1's multi_logloss: 0.321547        \n",
      "[27]\ttraining's multi_logloss: 0.23993\tvalid_1's multi_logloss: 0.316854         \n",
      "[28]\ttraining's multi_logloss: 0.232744\tvalid_1's multi_logloss: 0.313248        \n",
      "[29]\ttraining's multi_logloss: 0.225614\tvalid_1's multi_logloss: 0.309588        \n",
      "[30]\ttraining's multi_logloss: 0.219567\tvalid_1's multi_logloss: 0.307129        \n",
      "[31]\ttraining's multi_logloss: 0.213284\tvalid_1's multi_logloss: 0.304282        \n",
      "[32]\ttraining's multi_logloss: 0.207395\tvalid_1's multi_logloss: 0.302029        \n",
      "[33]\ttraining's multi_logloss: 0.202005\tvalid_1's multi_logloss: 0.300284        \n",
      "[34]\ttraining's multi_logloss: 0.196614\tvalid_1's multi_logloss: 0.298205        \n",
      "[35]\ttraining's multi_logloss: 0.191337\tvalid_1's multi_logloss: 0.296414        \n",
      "[36]\ttraining's multi_logloss: 0.186143\tvalid_1's multi_logloss: 0.294604        \n",
      "[37]\ttraining's multi_logloss: 0.181589\tvalid_1's multi_logloss: 0.292767        \n",
      "[38]\ttraining's multi_logloss: 0.176984\tvalid_1's multi_logloss: 0.291455        \n",
      "[39]\ttraining's multi_logloss: 0.172799\tvalid_1's multi_logloss: 0.290755        \n",
      "[40]\ttraining's multi_logloss: 0.168536\tvalid_1's multi_logloss: 0.289553        \n",
      "[41]\ttraining's multi_logloss: 0.164824\tvalid_1's multi_logloss: 0.28852         \n",
      "[42]\ttraining's multi_logloss: 0.160894\tvalid_1's multi_logloss: 0.287463        \n",
      "[43]\ttraining's multi_logloss: 0.15704\tvalid_1's multi_logloss: 0.286811         \n",
      "[44]\ttraining's multi_logloss: 0.153157\tvalid_1's multi_logloss: 0.28641         \n",
      "[45]\ttraining's multi_logloss: 0.14943\tvalid_1's multi_logloss: 0.286073         \n",
      "[46]\ttraining's multi_logloss: 0.145906\tvalid_1's multi_logloss: 0.285708        \n",
      "[47]\ttraining's multi_logloss: 0.142645\tvalid_1's multi_logloss: 0.285414        \n",
      "[48]\ttraining's multi_logloss: 0.139288\tvalid_1's multi_logloss: 0.285225        \n",
      "[49]\ttraining's multi_logloss: 0.13622\tvalid_1's multi_logloss: 0.285166         \n",
      "[50]\ttraining's multi_logloss: 0.133169\tvalid_1's multi_logloss: 0.285203        \n",
      "[51]\ttraining's multi_logloss: 0.130315\tvalid_1's multi_logloss: 0.285232        \n",
      "[52]\ttraining's multi_logloss: 0.127547\tvalid_1's multi_logloss: 0.285209        \n",
      "[53]\ttraining's multi_logloss: 0.124782\tvalid_1's multi_logloss: 0.285369        \n",
      "[54]\ttraining's multi_logloss: 0.122211\tvalid_1's multi_logloss: 0.285659        \n",
      "[55]\ttraining's multi_logloss: 0.119449\tvalid_1's multi_logloss: 0.285492        \n",
      "[56]\ttraining's multi_logloss: 0.116973\tvalid_1's multi_logloss: 0.285768        \n",
      "[57]\ttraining's multi_logloss: 0.11459\tvalid_1's multi_logloss: 0.285889         \n",
      "[58]\ttraining's multi_logloss: 0.11228\tvalid_1's multi_logloss: 0.285994         \n",
      "[59]\ttraining's multi_logloss: 0.109782\tvalid_1's multi_logloss: 0.286317        \n",
      "[60]\ttraining's multi_logloss: 0.107295\tvalid_1's multi_logloss: 0.286734        \n",
      "[61]\ttraining's multi_logloss: 0.104929\tvalid_1's multi_logloss: 0.287081        \n",
      "[62]\ttraining's multi_logloss: 0.102783\tvalid_1's multi_logloss: 0.287153        \n",
      "[63]\ttraining's multi_logloss: 0.100575\tvalid_1's multi_logloss: 0.287529        \n",
      "[64]\ttraining's multi_logloss: 0.0985794\tvalid_1's multi_logloss: 0.28805        \n",
      "[65]\ttraining's multi_logloss: 0.0965457\tvalid_1's multi_logloss: 0.288465       \n",
      "[66]\ttraining's multi_logloss: 0.0945701\tvalid_1's multi_logloss: 0.288861       \n",
      "[67]\ttraining's multi_logloss: 0.0926481\tvalid_1's multi_logloss: 0.289441       \n",
      "[68]\ttraining's multi_logloss: 0.0906981\tvalid_1's multi_logloss: 0.289838       \n",
      "[69]\ttraining's multi_logloss: 0.0888594\tvalid_1's multi_logloss: 0.290081       \n",
      "[70]\ttraining's multi_logloss: 0.0871724\tvalid_1's multi_logloss: 0.290655       \n",
      "[71]\ttraining's multi_logloss: 0.0855954\tvalid_1's multi_logloss: 0.291159       \n",
      "[72]\ttraining's multi_logloss: 0.0837952\tvalid_1's multi_logloss: 0.291451       \n",
      "[73]\ttraining's multi_logloss: 0.0823552\tvalid_1's multi_logloss: 0.291914       \n",
      "[74]\ttraining's multi_logloss: 0.0807548\tvalid_1's multi_logloss: 0.292139       \n",
      "[75]\ttraining's multi_logloss: 0.0792169\tvalid_1's multi_logloss: 0.292564       \n",
      "[76]\ttraining's multi_logloss: 0.0774275\tvalid_1's multi_logloss: 0.292937       \n",
      "[77]\ttraining's multi_logloss: 0.0757729\tvalid_1's multi_logloss: 0.293849       \n",
      "[78]\ttraining's multi_logloss: 0.0744493\tvalid_1's multi_logloss: 0.294305       \n",
      "[79]\ttraining's multi_logloss: 0.0731354\tvalid_1's multi_logloss: 0.294647       \n",
      "Early stopping, best iteration is:                                               \n",
      "[49]\ttraining's multi_logloss: 0.13622\tvalid_1's multi_logloss: 0.285166\n",
      "[1]\ttraining's multi_logloss: 1.54063\tvalid_1's multi_logloss: 1.54509           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.29705\tvalid_1's multi_logloss: 1.30313           \n",
      "[3]\ttraining's multi_logloss: 1.12226\tvalid_1's multi_logloss: 1.13011           \n",
      "[4]\ttraining's multi_logloss: 0.987121\tvalid_1's multi_logloss: 0.996548         \n",
      "[5]\ttraining's multi_logloss: 0.878377\tvalid_1's multi_logloss: 0.889928         \n",
      "[6]\ttraining's multi_logloss: 0.788303\tvalid_1's multi_logloss: 0.801663         \n",
      "[7]\ttraining's multi_logloss: 0.713255\tvalid_1's multi_logloss: 0.728112         \n",
      "[8]\ttraining's multi_logloss: 0.650181\tvalid_1's multi_logloss: 0.666871         \n",
      "[9]\ttraining's multi_logloss: 0.597635\tvalid_1's multi_logloss: 0.616625         \n",
      "[10]\ttraining's multi_logloss: 0.551808\tvalid_1's multi_logloss: 0.572851        \n",
      "[11]\ttraining's multi_logloss: 0.512456\tvalid_1's multi_logloss: 0.535598        \n",
      "[12]\ttraining's multi_logloss: 0.478018\tvalid_1's multi_logloss: 0.502991        \n",
      "[13]\ttraining's multi_logloss: 0.448137\tvalid_1's multi_logloss: 0.475144        \n",
      "[14]\ttraining's multi_logloss: 0.422107\tvalid_1's multi_logloss: 0.451569        \n",
      "[15]\ttraining's multi_logloss: 0.398795\tvalid_1's multi_logloss: 0.43031         \n",
      "[16]\ttraining's multi_logloss: 0.378122\tvalid_1's multi_logloss: 0.411925        \n",
      "[17]\ttraining's multi_logloss: 0.359104\tvalid_1's multi_logloss: 0.394826        \n",
      "[18]\ttraining's multi_logloss: 0.342781\tvalid_1's multi_logloss: 0.380482        \n",
      "[19]\ttraining's multi_logloss: 0.327653\tvalid_1's multi_logloss: 0.367766        \n",
      "[20]\ttraining's multi_logloss: 0.314172\tvalid_1's multi_logloss: 0.357405        \n",
      "[21]\ttraining's multi_logloss: 0.301764\tvalid_1's multi_logloss: 0.347134        \n",
      "[22]\ttraining's multi_logloss: 0.290573\tvalid_1's multi_logloss: 0.33848         \n",
      "[23]\ttraining's multi_logloss: 0.28043\tvalid_1's multi_logloss: 0.331032         \n",
      "[24]\ttraining's multi_logloss: 0.271057\tvalid_1's multi_logloss: 0.3246          \n",
      "[25]\ttraining's multi_logloss: 0.262249\tvalid_1's multi_logloss: 0.318361        \n",
      "[26]\ttraining's multi_logloss: 0.254143\tvalid_1's multi_logloss: 0.313088        \n",
      "[27]\ttraining's multi_logloss: 0.24635\tvalid_1's multi_logloss: 0.308771         \n",
      "[28]\ttraining's multi_logloss: 0.238848\tvalid_1's multi_logloss: 0.304513        \n",
      "[29]\ttraining's multi_logloss: 0.232282\tvalid_1's multi_logloss: 0.300759        \n",
      "[30]\ttraining's multi_logloss: 0.22567\tvalid_1's multi_logloss: 0.297072         \n",
      "[31]\ttraining's multi_logloss: 0.219583\tvalid_1's multi_logloss: 0.294068        \n",
      "[32]\ttraining's multi_logloss: 0.214037\tvalid_1's multi_logloss: 0.2914          \n",
      "[33]\ttraining's multi_logloss: 0.208501\tvalid_1's multi_logloss: 0.289126        \n",
      "[34]\ttraining's multi_logloss: 0.203314\tvalid_1's multi_logloss: 0.287002        \n",
      "[35]\ttraining's multi_logloss: 0.198222\tvalid_1's multi_logloss: 0.284909        \n",
      "[36]\ttraining's multi_logloss: 0.193322\tvalid_1's multi_logloss: 0.282895        \n",
      "[37]\ttraining's multi_logloss: 0.188755\tvalid_1's multi_logloss: 0.280917        \n",
      "[38]\ttraining's multi_logloss: 0.18418\tvalid_1's multi_logloss: 0.27992          \n",
      "[39]\ttraining's multi_logloss: 0.179854\tvalid_1's multi_logloss: 0.278651        \n",
      "[40]\ttraining's multi_logloss: 0.175746\tvalid_1's multi_logloss: 0.277858        \n",
      "[41]\ttraining's multi_logloss: 0.171619\tvalid_1's multi_logloss: 0.276675        \n",
      "[42]\ttraining's multi_logloss: 0.167573\tvalid_1's multi_logloss: 0.275937        \n",
      "[43]\ttraining's multi_logloss: 0.16383\tvalid_1's multi_logloss: 0.275233         \n",
      "[44]\ttraining's multi_logloss: 0.160166\tvalid_1's multi_logloss: 0.274644        \n",
      "[45]\ttraining's multi_logloss: 0.156542\tvalid_1's multi_logloss: 0.274057        \n",
      "[46]\ttraining's multi_logloss: 0.153129\tvalid_1's multi_logloss: 0.273417        \n",
      "[47]\ttraining's multi_logloss: 0.149545\tvalid_1's multi_logloss: 0.272544        \n",
      "[48]\ttraining's multi_logloss: 0.146167\tvalid_1's multi_logloss: 0.271873        \n",
      "[49]\ttraining's multi_logloss: 0.142713\tvalid_1's multi_logloss: 0.271389        \n",
      "[50]\ttraining's multi_logloss: 0.139533\tvalid_1's multi_logloss: 0.271107        \n",
      "[51]\ttraining's multi_logloss: 0.136571\tvalid_1's multi_logloss: 0.27085         \n",
      "[52]\ttraining's multi_logloss: 0.133661\tvalid_1's multi_logloss: 0.270338        \n",
      "[53]\ttraining's multi_logloss: 0.130734\tvalid_1's multi_logloss: 0.270178        \n",
      "[54]\ttraining's multi_logloss: 0.128122\tvalid_1's multi_logloss: 0.269819        \n",
      "[55]\ttraining's multi_logloss: 0.125596\tvalid_1's multi_logloss: 0.26934         \n",
      "[56]\ttraining's multi_logloss: 0.122964\tvalid_1's multi_logloss: 0.269103        \n",
      "[57]\ttraining's multi_logloss: 0.120374\tvalid_1's multi_logloss: 0.269315        \n",
      "[58]\ttraining's multi_logloss: 0.117834\tvalid_1's multi_logloss: 0.269492        \n",
      "[59]\ttraining's multi_logloss: 0.115504\tvalid_1's multi_logloss: 0.269649        \n",
      "[60]\ttraining's multi_logloss: 0.113024\tvalid_1's multi_logloss: 0.269456        \n",
      "[61]\ttraining's multi_logloss: 0.110817\tvalid_1's multi_logloss: 0.269702        \n",
      "[62]\ttraining's multi_logloss: 0.108538\tvalid_1's multi_logloss: 0.269533        \n",
      "[63]\ttraining's multi_logloss: 0.10634\tvalid_1's multi_logloss: 0.2696           \n",
      "[64]\ttraining's multi_logloss: 0.104099\tvalid_1's multi_logloss: 0.26966         \n",
      "[65]\ttraining's multi_logloss: 0.102121\tvalid_1's multi_logloss: 0.269732        \n",
      "[66]\ttraining's multi_logloss: 0.100258\tvalid_1's multi_logloss: 0.269794        \n",
      "[67]\ttraining's multi_logloss: 0.0983641\tvalid_1's multi_logloss: 0.270383       \n",
      "[68]\ttraining's multi_logloss: 0.0964699\tvalid_1's multi_logloss: 0.270646       \n",
      "[69]\ttraining's multi_logloss: 0.0945326\tvalid_1's multi_logloss: 0.270985       \n",
      "[70]\ttraining's multi_logloss: 0.092735\tvalid_1's multi_logloss: 0.271119        \n",
      "[71]\ttraining's multi_logloss: 0.0910327\tvalid_1's multi_logloss: 0.271482       \n",
      "[72]\ttraining's multi_logloss: 0.0892812\tvalid_1's multi_logloss: 0.272022       \n",
      "[73]\ttraining's multi_logloss: 0.0875563\tvalid_1's multi_logloss: 0.272044       \n",
      "[74]\ttraining's multi_logloss: 0.0858486\tvalid_1's multi_logloss: 0.272531       \n",
      "[75]\ttraining's multi_logloss: 0.0841016\tvalid_1's multi_logloss: 0.272778       \n",
      "[76]\ttraining's multi_logloss: 0.0825531\tvalid_1's multi_logloss: 0.272897       \n",
      "[77]\ttraining's multi_logloss: 0.0809425\tvalid_1's multi_logloss: 0.273004       \n",
      "[78]\ttraining's multi_logloss: 0.0792892\tvalid_1's multi_logloss: 0.273465       \n",
      "[79]\ttraining's multi_logloss: 0.077874\tvalid_1's multi_logloss: 0.273662        \n",
      "[80]\ttraining's multi_logloss: 0.0762854\tvalid_1's multi_logloss: 0.274018       \n",
      "[81]\ttraining's multi_logloss: 0.0748635\tvalid_1's multi_logloss: 0.274436       \n",
      "[82]\ttraining's multi_logloss: 0.0735469\tvalid_1's multi_logloss: 0.275089       \n",
      "[83]\ttraining's multi_logloss: 0.0721898\tvalid_1's multi_logloss: 0.275695       \n",
      "[84]\ttraining's multi_logloss: 0.0707069\tvalid_1's multi_logloss: 0.276328       \n",
      "[85]\ttraining's multi_logloss: 0.0695202\tvalid_1's multi_logloss: 0.276703       \n",
      "[86]\ttraining's multi_logloss: 0.0683209\tvalid_1's multi_logloss: 0.277231       \n",
      "Early stopping, best iteration is:                                               \n",
      "[56]\ttraining's multi_logloss: 0.122964\tvalid_1's multi_logloss: 0.269103\n",
      "[1]\ttraining's multi_logloss: 1.62201\tvalid_1's multi_logloss: 1.62683           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.40668\tvalid_1's multi_logloss: 1.41741           \n",
      "[3]\ttraining's multi_logloss: 1.24269\tvalid_1's multi_logloss: 1.25792           \n",
      "[4]\ttraining's multi_logloss: 1.11164\tvalid_1's multi_logloss: 1.13045           \n",
      "[5]\ttraining's multi_logloss: 1.00435\tvalid_1's multi_logloss: 1.02701           \n",
      "[6]\ttraining's multi_logloss: 0.914297\tvalid_1's multi_logloss: 0.940287         \n",
      "[7]\ttraining's multi_logloss: 0.837123\tvalid_1's multi_logloss: 0.865405         \n",
      "[8]\ttraining's multi_logloss: 0.770386\tvalid_1's multi_logloss: 0.801046         \n",
      "[9]\ttraining's multi_logloss: 0.712676\tvalid_1's multi_logloss: 0.745643         \n",
      "[10]\ttraining's multi_logloss: 0.66214\tvalid_1's multi_logloss: 0.696881         \n",
      "[11]\ttraining's multi_logloss: 0.617099\tvalid_1's multi_logloss: 0.654025        \n",
      "[12]\ttraining's multi_logloss: 0.576965\tvalid_1's multi_logloss: 0.616136        \n",
      "[13]\ttraining's multi_logloss: 0.541848\tvalid_1's multi_logloss: 0.583477        \n",
      "[14]\ttraining's multi_logloss: 0.510487\tvalid_1's multi_logloss: 0.554235        \n",
      "[15]\ttraining's multi_logloss: 0.482567\tvalid_1's multi_logloss: 0.528158        \n",
      "[16]\ttraining's multi_logloss: 0.457192\tvalid_1's multi_logloss: 0.504533        \n",
      "[17]\ttraining's multi_logloss: 0.434156\tvalid_1's multi_logloss: 0.483394        \n",
      "[18]\ttraining's multi_logloss: 0.413833\tvalid_1's multi_logloss: 0.464644        \n",
      "[19]\ttraining's multi_logloss: 0.395631\tvalid_1's multi_logloss: 0.447981        \n",
      "[20]\ttraining's multi_logloss: 0.378941\tvalid_1's multi_logloss: 0.432836        \n",
      "[21]\ttraining's multi_logloss: 0.363614\tvalid_1's multi_logloss: 0.41923         \n",
      "[22]\ttraining's multi_logloss: 0.34974\tvalid_1's multi_logloss: 0.407098         \n",
      "[23]\ttraining's multi_logloss: 0.337222\tvalid_1's multi_logloss: 0.396229        \n",
      "[24]\ttraining's multi_logloss: 0.325758\tvalid_1's multi_logloss: 0.38676         \n",
      "[25]\ttraining's multi_logloss: 0.315335\tvalid_1's multi_logloss: 0.377938        \n",
      "[26]\ttraining's multi_logloss: 0.305339\tvalid_1's multi_logloss: 0.369775        \n",
      "[27]\ttraining's multi_logloss: 0.296422\tvalid_1's multi_logloss: 0.362947        \n",
      "[28]\ttraining's multi_logloss: 0.288037\tvalid_1's multi_logloss: 0.356375        \n",
      "[29]\ttraining's multi_logloss: 0.280247\tvalid_1's multi_logloss: 0.350352        \n",
      "[30]\ttraining's multi_logloss: 0.272827\tvalid_1's multi_logloss: 0.344921        \n",
      "[31]\ttraining's multi_logloss: 0.265957\tvalid_1's multi_logloss: 0.34003         \n",
      "[32]\ttraining's multi_logloss: 0.259435\tvalid_1's multi_logloss: 0.335825        \n",
      "[33]\ttraining's multi_logloss: 0.253324\tvalid_1's multi_logloss: 0.331714        \n",
      "[34]\ttraining's multi_logloss: 0.247735\tvalid_1's multi_logloss: 0.327991        \n",
      "[35]\ttraining's multi_logloss: 0.242161\tvalid_1's multi_logloss: 0.324193        \n",
      "[36]\ttraining's multi_logloss: 0.237042\tvalid_1's multi_logloss: 0.321065        \n",
      "[37]\ttraining's multi_logloss: 0.232164\tvalid_1's multi_logloss: 0.318289        \n",
      "[38]\ttraining's multi_logloss: 0.227772\tvalid_1's multi_logloss: 0.316065        \n",
      "[39]\ttraining's multi_logloss: 0.223393\tvalid_1's multi_logloss: 0.313472        \n",
      "[40]\ttraining's multi_logloss: 0.219228\tvalid_1's multi_logloss: 0.311143        \n",
      "[41]\ttraining's multi_logloss: 0.215193\tvalid_1's multi_logloss: 0.309141        \n",
      "[42]\ttraining's multi_logloss: 0.211363\tvalid_1's multi_logloss: 0.30743         \n",
      "[43]\ttraining's multi_logloss: 0.207514\tvalid_1's multi_logloss: 0.305793        \n",
      "[44]\ttraining's multi_logloss: 0.203886\tvalid_1's multi_logloss: 0.304235        \n",
      "[45]\ttraining's multi_logloss: 0.200414\tvalid_1's multi_logloss: 0.302761        \n",
      "[46]\ttraining's multi_logloss: 0.197068\tvalid_1's multi_logloss: 0.301098        \n",
      "[47]\ttraining's multi_logloss: 0.193959\tvalid_1's multi_logloss: 0.299907        \n",
      "[48]\ttraining's multi_logloss: 0.190753\tvalid_1's multi_logloss: 0.298935        \n",
      "[49]\ttraining's multi_logloss: 0.187747\tvalid_1's multi_logloss: 0.297807        \n",
      "[50]\ttraining's multi_logloss: 0.1848\tvalid_1's multi_logloss: 0.297031          \n",
      "[51]\ttraining's multi_logloss: 0.181997\tvalid_1's multi_logloss: 0.295902        \n",
      "[52]\ttraining's multi_logloss: 0.179177\tvalid_1's multi_logloss: 0.295129        \n",
      "[53]\ttraining's multi_logloss: 0.176389\tvalid_1's multi_logloss: 0.294477        \n",
      "[54]\ttraining's multi_logloss: 0.173822\tvalid_1's multi_logloss: 0.293865        \n",
      "[55]\ttraining's multi_logloss: 0.17114\tvalid_1's multi_logloss: 0.292931         \n",
      "[56]\ttraining's multi_logloss: 0.168533\tvalid_1's multi_logloss: 0.292304        \n",
      "[57]\ttraining's multi_logloss: 0.166026\tvalid_1's multi_logloss: 0.291553        \n",
      "[58]\ttraining's multi_logloss: 0.163604\tvalid_1's multi_logloss: 0.291166        \n",
      "[59]\ttraining's multi_logloss: 0.16131\tvalid_1's multi_logloss: 0.290732         \n",
      "[60]\ttraining's multi_logloss: 0.159016\tvalid_1's multi_logloss: 0.290505        \n",
      "[61]\ttraining's multi_logloss: 0.156728\tvalid_1's multi_logloss: 0.290215        \n",
      "[62]\ttraining's multi_logloss: 0.154547\tvalid_1's multi_logloss: 0.289755        \n",
      "[63]\ttraining's multi_logloss: 0.152486\tvalid_1's multi_logloss: 0.289679        \n",
      "[64]\ttraining's multi_logloss: 0.150415\tvalid_1's multi_logloss: 0.289429        \n",
      "[65]\ttraining's multi_logloss: 0.148411\tvalid_1's multi_logloss: 0.289429        \n",
      "[66]\ttraining's multi_logloss: 0.146495\tvalid_1's multi_logloss: 0.289465        \n",
      "[67]\ttraining's multi_logloss: 0.14465\tvalid_1's multi_logloss: 0.289259         \n",
      "[68]\ttraining's multi_logloss: 0.14281\tvalid_1's multi_logloss: 0.289085         \n",
      "[69]\ttraining's multi_logloss: 0.141\tvalid_1's multi_logloss: 0.289064           \n",
      "[70]\ttraining's multi_logloss: 0.13929\tvalid_1's multi_logloss: 0.288889         \n",
      "[71]\ttraining's multi_logloss: 0.137464\tvalid_1's multi_logloss: 0.288736        \n",
      "[72]\ttraining's multi_logloss: 0.135628\tvalid_1's multi_logloss: 0.288653        \n",
      "[73]\ttraining's multi_logloss: 0.133932\tvalid_1's multi_logloss: 0.288715        \n",
      "[74]\ttraining's multi_logloss: 0.132233\tvalid_1's multi_logloss: 0.288885        \n",
      "[75]\ttraining's multi_logloss: 0.130702\tvalid_1's multi_logloss: 0.289096        \n",
      "[76]\ttraining's multi_logloss: 0.129185\tvalid_1's multi_logloss: 0.288711        \n",
      "[77]\ttraining's multi_logloss: 0.127652\tvalid_1's multi_logloss: 0.288685        \n",
      "[78]\ttraining's multi_logloss: 0.126036\tvalid_1's multi_logloss: 0.28868         \n",
      "[79]\ttraining's multi_logloss: 0.1245\tvalid_1's multi_logloss: 0.288517          \n",
      "[80]\ttraining's multi_logloss: 0.123183\tvalid_1's multi_logloss: 0.288273        \n",
      "[81]\ttraining's multi_logloss: 0.121828\tvalid_1's multi_logloss: 0.288355        \n",
      "[82]\ttraining's multi_logloss: 0.120284\tvalid_1's multi_logloss: 0.288393        \n",
      "[83]\ttraining's multi_logloss: 0.118889\tvalid_1's multi_logloss: 0.288206        \n",
      "[84]\ttraining's multi_logloss: 0.117656\tvalid_1's multi_logloss: 0.288125        \n",
      "[85]\ttraining's multi_logloss: 0.116384\tvalid_1's multi_logloss: 0.288295        \n",
      "[86]\ttraining's multi_logloss: 0.115156\tvalid_1's multi_logloss: 0.288157        \n",
      "[87]\ttraining's multi_logloss: 0.113823\tvalid_1's multi_logloss: 0.288618        \n",
      "[88]\ttraining's multi_logloss: 0.112563\tvalid_1's multi_logloss: 0.28873         \n",
      "[89]\ttraining's multi_logloss: 0.111229\tvalid_1's multi_logloss: 0.288823        \n",
      "[90]\ttraining's multi_logloss: 0.109932\tvalid_1's multi_logloss: 0.288895        \n",
      "[91]\ttraining's multi_logloss: 0.108726\tvalid_1's multi_logloss: 0.289343        \n",
      "[92]\ttraining's multi_logloss: 0.107544\tvalid_1's multi_logloss: 0.28972         \n",
      "[93]\ttraining's multi_logloss: 0.106458\tvalid_1's multi_logloss: 0.28978         \n",
      "[94]\ttraining's multi_logloss: 0.105387\tvalid_1's multi_logloss: 0.289981        \n",
      "[95]\ttraining's multi_logloss: 0.10415\tvalid_1's multi_logloss: 0.290054         \n",
      "[96]\ttraining's multi_logloss: 0.10308\tvalid_1's multi_logloss: 0.290222         \n",
      "[97]\ttraining's multi_logloss: 0.101976\tvalid_1's multi_logloss: 0.290272        \n",
      "[98]\ttraining's multi_logloss: 0.100897\tvalid_1's multi_logloss: 0.290366        \n",
      "[99]\ttraining's multi_logloss: 0.0998458\tvalid_1's multi_logloss: 0.290522       \n",
      "[100]\ttraining's multi_logloss: 0.0988732\tvalid_1's multi_logloss: 0.291003      \n",
      "[101]\ttraining's multi_logloss: 0.0978854\tvalid_1's multi_logloss: 0.291128      \n",
      "[102]\ttraining's multi_logloss: 0.0969156\tvalid_1's multi_logloss: 0.291352      \n",
      "[103]\ttraining's multi_logloss: 0.0959842\tvalid_1's multi_logloss: 0.291598      \n",
      "[104]\ttraining's multi_logloss: 0.0949338\tvalid_1's multi_logloss: 0.291712      \n",
      "[105]\ttraining's multi_logloss: 0.0938395\tvalid_1's multi_logloss: 0.292121      \n",
      "[106]\ttraining's multi_logloss: 0.0928114\tvalid_1's multi_logloss: 0.292202      \n",
      "[107]\ttraining's multi_logloss: 0.0918338\tvalid_1's multi_logloss: 0.292443      \n",
      "[108]\ttraining's multi_logloss: 0.0908587\tvalid_1's multi_logloss: 0.292303      \n",
      "[109]\ttraining's multi_logloss: 0.0898949\tvalid_1's multi_logloss: 0.292145      \n",
      "[110]\ttraining's multi_logloss: 0.0889875\tvalid_1's multi_logloss: 0.292329      \n",
      "[111]\ttraining's multi_logloss: 0.0880794\tvalid_1's multi_logloss: 0.292503      \n",
      "[112]\ttraining's multi_logloss: 0.0871635\tvalid_1's multi_logloss: 0.292922      \n",
      "[113]\ttraining's multi_logloss: 0.0862484\tvalid_1's multi_logloss: 0.29332       \n",
      "[114]\ttraining's multi_logloss: 0.0854104\tvalid_1's multi_logloss: 0.29346       \n",
      "Early stopping, best iteration is:                                               \n",
      "[84]\ttraining's multi_logloss: 0.117656\tvalid_1's multi_logloss: 0.288125\n",
      "[1]\ttraining's multi_logloss: 1.61919\tvalid_1's multi_logloss: 1.6236            \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.40593\tvalid_1's multi_logloss: 1.41136           \n",
      "[3]\ttraining's multi_logloss: 1.24499\tvalid_1's multi_logloss: 1.25333           \n",
      "[4]\ttraining's multi_logloss: 1.11574\tvalid_1's multi_logloss: 1.12589           \n",
      "[5]\ttraining's multi_logloss: 1.00932\tvalid_1's multi_logloss: 1.02206           \n",
      "[6]\ttraining's multi_logloss: 0.91944\tvalid_1's multi_logloss: 0.933741          \n",
      "[7]\ttraining's multi_logloss: 0.843135\tvalid_1's multi_logloss: 0.859463         \n",
      "[8]\ttraining's multi_logloss: 0.776979\tvalid_1's multi_logloss: 0.795564         \n",
      "[9]\ttraining's multi_logloss: 0.718894\tvalid_1's multi_logloss: 0.739812         \n",
      "[10]\ttraining's multi_logloss: 0.667936\tvalid_1's multi_logloss: 0.69112         \n",
      "[11]\ttraining's multi_logloss: 0.623166\tvalid_1's multi_logloss: 0.648349        \n",
      "[12]\ttraining's multi_logloss: 0.583576\tvalid_1's multi_logloss: 0.610404        \n",
      "[13]\ttraining's multi_logloss: 0.547894\tvalid_1's multi_logloss: 0.576038        \n",
      "[14]\ttraining's multi_logloss: 0.516624\tvalid_1's multi_logloss: 0.546673        \n",
      "[15]\ttraining's multi_logloss: 0.488299\tvalid_1's multi_logloss: 0.519793        \n",
      "[16]\ttraining's multi_logloss: 0.463424\tvalid_1's multi_logloss: 0.496869        \n",
      "[17]\ttraining's multi_logloss: 0.440765\tvalid_1's multi_logloss: 0.47653         \n",
      "[18]\ttraining's multi_logloss: 0.420058\tvalid_1's multi_logloss: 0.457975        \n",
      "[19]\ttraining's multi_logloss: 0.401778\tvalid_1's multi_logloss: 0.441773        \n",
      "[20]\ttraining's multi_logloss: 0.385198\tvalid_1's multi_logloss: 0.427085        \n",
      "[21]\ttraining's multi_logloss: 0.369739\tvalid_1's multi_logloss: 0.413666        \n",
      "[22]\ttraining's multi_logloss: 0.355768\tvalid_1's multi_logloss: 0.401668        \n",
      "[23]\ttraining's multi_logloss: 0.342937\tvalid_1's multi_logloss: 0.390619        \n",
      "[24]\ttraining's multi_logloss: 0.331219\tvalid_1's multi_logloss: 0.380972        \n",
      "[25]\ttraining's multi_logloss: 0.320782\tvalid_1's multi_logloss: 0.372448        \n",
      "[26]\ttraining's multi_logloss: 0.310271\tvalid_1's multi_logloss: 0.364328        \n",
      "[27]\ttraining's multi_logloss: 0.300656\tvalid_1's multi_logloss: 0.356552        \n",
      "[28]\ttraining's multi_logloss: 0.291643\tvalid_1's multi_logloss: 0.350097        \n",
      "[29]\ttraining's multi_logloss: 0.28334\tvalid_1's multi_logloss: 0.34363          \n",
      "[30]\ttraining's multi_logloss: 0.275453\tvalid_1's multi_logloss: 0.337863        \n",
      "[31]\ttraining's multi_logloss: 0.268428\tvalid_1's multi_logloss: 0.333116        \n",
      "[32]\ttraining's multi_logloss: 0.261849\tvalid_1's multi_logloss: 0.328735        \n",
      "[33]\ttraining's multi_logloss: 0.255645\tvalid_1's multi_logloss: 0.324768        \n",
      "[34]\ttraining's multi_logloss: 0.249818\tvalid_1's multi_logloss: 0.32113         \n",
      "[35]\ttraining's multi_logloss: 0.244424\tvalid_1's multi_logloss: 0.317913        \n",
      "[36]\ttraining's multi_logloss: 0.239057\tvalid_1's multi_logloss: 0.314831        \n",
      "[37]\ttraining's multi_logloss: 0.233939\tvalid_1's multi_logloss: 0.311918        \n",
      "[38]\ttraining's multi_logloss: 0.22934\tvalid_1's multi_logloss: 0.309485         \n",
      "[39]\ttraining's multi_logloss: 0.224759\tvalid_1's multi_logloss: 0.307525        \n",
      "[40]\ttraining's multi_logloss: 0.220405\tvalid_1's multi_logloss: 0.305193        \n",
      "[41]\ttraining's multi_logloss: 0.21648\tvalid_1's multi_logloss: 0.303421         \n",
      "[42]\ttraining's multi_logloss: 0.212688\tvalid_1's multi_logloss: 0.301781        \n",
      "[43]\ttraining's multi_logloss: 0.208938\tvalid_1's multi_logloss: 0.300281        \n",
      "[44]\ttraining's multi_logloss: 0.205337\tvalid_1's multi_logloss: 0.298835        \n",
      "[45]\ttraining's multi_logloss: 0.201877\tvalid_1's multi_logloss: 0.297761        \n",
      "[46]\ttraining's multi_logloss: 0.198359\tvalid_1's multi_logloss: 0.296508        \n",
      "[47]\ttraining's multi_logloss: 0.195055\tvalid_1's multi_logloss: 0.29536         \n",
      "[48]\ttraining's multi_logloss: 0.191787\tvalid_1's multi_logloss: 0.294545        \n",
      "[49]\ttraining's multi_logloss: 0.188621\tvalid_1's multi_logloss: 0.293452        \n",
      "[50]\ttraining's multi_logloss: 0.185568\tvalid_1's multi_logloss: 0.292423        \n",
      "[51]\ttraining's multi_logloss: 0.182629\tvalid_1's multi_logloss: 0.291488        \n",
      "[52]\ttraining's multi_logloss: 0.17958\tvalid_1's multi_logloss: 0.2905           \n",
      "[53]\ttraining's multi_logloss: 0.176799\tvalid_1's multi_logloss: 0.289678        \n",
      "[54]\ttraining's multi_logloss: 0.174241\tvalid_1's multi_logloss: 0.289099        \n",
      "[55]\ttraining's multi_logloss: 0.171571\tvalid_1's multi_logloss: 0.288771        \n",
      "[56]\ttraining's multi_logloss: 0.168913\tvalid_1's multi_logloss: 0.288349        \n",
      "[57]\ttraining's multi_logloss: 0.166389\tvalid_1's multi_logloss: 0.288058        \n",
      "[58]\ttraining's multi_logloss: 0.163775\tvalid_1's multi_logloss: 0.287785        \n",
      "[59]\ttraining's multi_logloss: 0.161224\tvalid_1's multi_logloss: 0.28738         \n",
      "[60]\ttraining's multi_logloss: 0.158965\tvalid_1's multi_logloss: 0.28721         \n",
      "[61]\ttraining's multi_logloss: 0.156707\tvalid_1's multi_logloss: 0.287105        \n",
      "[62]\ttraining's multi_logloss: 0.154504\tvalid_1's multi_logloss: 0.286721        \n",
      "[63]\ttraining's multi_logloss: 0.152185\tvalid_1's multi_logloss: 0.286259        \n",
      "[64]\ttraining's multi_logloss: 0.150052\tvalid_1's multi_logloss: 0.286034        \n",
      "[65]\ttraining's multi_logloss: 0.147972\tvalid_1's multi_logloss: 0.285581        \n",
      "[66]\ttraining's multi_logloss: 0.145938\tvalid_1's multi_logloss: 0.285379        \n",
      "[67]\ttraining's multi_logloss: 0.144011\tvalid_1's multi_logloss: 0.284946        \n",
      "[68]\ttraining's multi_logloss: 0.142143\tvalid_1's multi_logloss: 0.284761        \n",
      "[69]\ttraining's multi_logloss: 0.140364\tvalid_1's multi_logloss: 0.284706        \n",
      "[70]\ttraining's multi_logloss: 0.138557\tvalid_1's multi_logloss: 0.284367        \n",
      "[71]\ttraining's multi_logloss: 0.136941\tvalid_1's multi_logloss: 0.284444        \n",
      "[72]\ttraining's multi_logloss: 0.135036\tvalid_1's multi_logloss: 0.284414        \n",
      "[73]\ttraining's multi_logloss: 0.133306\tvalid_1's multi_logloss: 0.284297        \n",
      "[74]\ttraining's multi_logloss: 0.131694\tvalid_1's multi_logloss: 0.284339        \n",
      "[75]\ttraining's multi_logloss: 0.130079\tvalid_1's multi_logloss: 0.284402        \n",
      "[76]\ttraining's multi_logloss: 0.128376\tvalid_1's multi_logloss: 0.284363        \n",
      "[77]\ttraining's multi_logloss: 0.126953\tvalid_1's multi_logloss: 0.284446        \n",
      "[78]\ttraining's multi_logloss: 0.125336\tvalid_1's multi_logloss: 0.284546        \n",
      "[79]\ttraining's multi_logloss: 0.123786\tvalid_1's multi_logloss: 0.284752        \n",
      "[80]\ttraining's multi_logloss: 0.122285\tvalid_1's multi_logloss: 0.284821        \n",
      "[81]\ttraining's multi_logloss: 0.120865\tvalid_1's multi_logloss: 0.284733        \n",
      "[82]\ttraining's multi_logloss: 0.119301\tvalid_1's multi_logloss: 0.284569        \n",
      "[83]\ttraining's multi_logloss: 0.117797\tvalid_1's multi_logloss: 0.284918        \n",
      "[84]\ttraining's multi_logloss: 0.116319\tvalid_1's multi_logloss: 0.28501         \n",
      "[85]\ttraining's multi_logloss: 0.114962\tvalid_1's multi_logloss: 0.284935        \n",
      "[86]\ttraining's multi_logloss: 0.113583\tvalid_1's multi_logloss: 0.285079        \n",
      "[87]\ttraining's multi_logloss: 0.112292\tvalid_1's multi_logloss: 0.285057        \n",
      "[88]\ttraining's multi_logloss: 0.111086\tvalid_1's multi_logloss: 0.285273        \n",
      "[89]\ttraining's multi_logloss: 0.109858\tvalid_1's multi_logloss: 0.285186        \n",
      "[90]\ttraining's multi_logloss: 0.108577\tvalid_1's multi_logloss: 0.285228        \n",
      "[91]\ttraining's multi_logloss: 0.107344\tvalid_1's multi_logloss: 0.285464        \n",
      "[92]\ttraining's multi_logloss: 0.106136\tvalid_1's multi_logloss: 0.285542        \n",
      "[93]\ttraining's multi_logloss: 0.105031\tvalid_1's multi_logloss: 0.285866        \n",
      "[94]\ttraining's multi_logloss: 0.103918\tvalid_1's multi_logloss: 0.285769        \n",
      "[95]\ttraining's multi_logloss: 0.102692\tvalid_1's multi_logloss: 0.286136        \n",
      "[96]\ttraining's multi_logloss: 0.101592\tvalid_1's multi_logloss: 0.286053        \n",
      "[97]\ttraining's multi_logloss: 0.100392\tvalid_1's multi_logloss: 0.286178        \n",
      "[98]\ttraining's multi_logloss: 0.0993818\tvalid_1's multi_logloss: 0.286579       \n",
      "[99]\ttraining's multi_logloss: 0.0982001\tvalid_1's multi_logloss: 0.286825       \n",
      "[100]\ttraining's multi_logloss: 0.097291\tvalid_1's multi_logloss: 0.286992       \n",
      "[101]\ttraining's multi_logloss: 0.096164\tvalid_1's multi_logloss: 0.287244       \n",
      "[102]\ttraining's multi_logloss: 0.095167\tvalid_1's multi_logloss: 0.287621       \n",
      "[103]\ttraining's multi_logloss: 0.0941715\tvalid_1's multi_logloss: 0.287956      \n",
      "Early stopping, best iteration is:                                               \n",
      "[73]\ttraining's multi_logloss: 0.133306\tvalid_1's multi_logloss: 0.284297\n",
      "[1]\ttraining's multi_logloss: 1.62085\tvalid_1's multi_logloss: 1.62465           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.40867\tvalid_1's multi_logloss: 1.41447           \n",
      "[3]\ttraining's multi_logloss: 1.24701\tvalid_1's multi_logloss: 1.2542            \n",
      "[4]\ttraining's multi_logloss: 1.11721\tvalid_1's multi_logloss: 1.12526           \n",
      "[5]\ttraining's multi_logloss: 1.01002\tvalid_1's multi_logloss: 1.01963           \n",
      "[6]\ttraining's multi_logloss: 0.92046\tvalid_1's multi_logloss: 0.930599          \n",
      "[7]\ttraining's multi_logloss: 0.843217\tvalid_1's multi_logloss: 0.85467          \n",
      "[8]\ttraining's multi_logloss: 0.777031\tvalid_1's multi_logloss: 0.790272         \n",
      "[9]\ttraining's multi_logloss: 0.71972\tvalid_1's multi_logloss: 0.734615          \n",
      "[10]\ttraining's multi_logloss: 0.669254\tvalid_1's multi_logloss: 0.68588         \n",
      "[11]\ttraining's multi_logloss: 0.624534\tvalid_1's multi_logloss: 0.642587        \n",
      "[12]\ttraining's multi_logloss: 0.585691\tvalid_1's multi_logloss: 0.605361        \n",
      "[13]\ttraining's multi_logloss: 0.550753\tvalid_1's multi_logloss: 0.571938        \n",
      "[14]\ttraining's multi_logloss: 0.519496\tvalid_1's multi_logloss: 0.542461        \n",
      "[15]\ttraining's multi_logloss: 0.491646\tvalid_1's multi_logloss: 0.516399        \n",
      "[16]\ttraining's multi_logloss: 0.466626\tvalid_1's multi_logloss: 0.493147        \n",
      "[17]\ttraining's multi_logloss: 0.444355\tvalid_1's multi_logloss: 0.472452        \n",
      "[18]\ttraining's multi_logloss: 0.424051\tvalid_1's multi_logloss: 0.453729        \n",
      "[19]\ttraining's multi_logloss: 0.405733\tvalid_1's multi_logloss: 0.43697         \n",
      "[20]\ttraining's multi_logloss: 0.389538\tvalid_1's multi_logloss: 0.422003        \n",
      "[21]\ttraining's multi_logloss: 0.373607\tvalid_1's multi_logloss: 0.407087        \n",
      "[22]\ttraining's multi_logloss: 0.359684\tvalid_1's multi_logloss: 0.394906        \n",
      "[23]\ttraining's multi_logloss: 0.346503\tvalid_1's multi_logloss: 0.383205        \n",
      "[24]\ttraining's multi_logloss: 0.334834\tvalid_1's multi_logloss: 0.373036        \n",
      "[25]\ttraining's multi_logloss: 0.324219\tvalid_1's multi_logloss: 0.36403         \n",
      "[26]\ttraining's multi_logloss: 0.314166\tvalid_1's multi_logloss: 0.355904        \n",
      "[27]\ttraining's multi_logloss: 0.30484\tvalid_1's multi_logloss: 0.348402         \n",
      "[28]\ttraining's multi_logloss: 0.296086\tvalid_1's multi_logloss: 0.341586        \n",
      "[29]\ttraining's multi_logloss: 0.288213\tvalid_1's multi_logloss: 0.335421        \n",
      "[30]\ttraining's multi_logloss: 0.280788\tvalid_1's multi_logloss: 0.329631        \n",
      "[31]\ttraining's multi_logloss: 0.273696\tvalid_1's multi_logloss: 0.324735        \n",
      "[32]\ttraining's multi_logloss: 0.267166\tvalid_1's multi_logloss: 0.319641        \n",
      "[33]\ttraining's multi_logloss: 0.261011\tvalid_1's multi_logloss: 0.315037        \n",
      "[34]\ttraining's multi_logloss: 0.255333\tvalid_1's multi_logloss: 0.31134         \n",
      "[35]\ttraining's multi_logloss: 0.250129\tvalid_1's multi_logloss: 0.308068        \n",
      "[36]\ttraining's multi_logloss: 0.244992\tvalid_1's multi_logloss: 0.305137        \n",
      "[37]\ttraining's multi_logloss: 0.240178\tvalid_1's multi_logloss: 0.302328        \n",
      "[38]\ttraining's multi_logloss: 0.235419\tvalid_1's multi_logloss: 0.299604        \n",
      "[39]\ttraining's multi_logloss: 0.230966\tvalid_1's multi_logloss: 0.297368        \n",
      "[40]\ttraining's multi_logloss: 0.226448\tvalid_1's multi_logloss: 0.294889        \n",
      "[41]\ttraining's multi_logloss: 0.222612\tvalid_1's multi_logloss: 0.292612        \n",
      "[42]\ttraining's multi_logloss: 0.218781\tvalid_1's multi_logloss: 0.290622        \n",
      "[43]\ttraining's multi_logloss: 0.215001\tvalid_1's multi_logloss: 0.288892        \n",
      "[44]\ttraining's multi_logloss: 0.21129\tvalid_1's multi_logloss: 0.286778         \n",
      "[45]\ttraining's multi_logloss: 0.207735\tvalid_1's multi_logloss: 0.285203        \n",
      "[46]\ttraining's multi_logloss: 0.204351\tvalid_1's multi_logloss: 0.283621        \n",
      "[47]\ttraining's multi_logloss: 0.201317\tvalid_1's multi_logloss: 0.282471        \n",
      "[48]\ttraining's multi_logloss: 0.198013\tvalid_1's multi_logloss: 0.281219        \n",
      "[49]\ttraining's multi_logloss: 0.194906\tvalid_1's multi_logloss: 0.279928        \n",
      "[50]\ttraining's multi_logloss: 0.191895\tvalid_1's multi_logloss: 0.278752        \n",
      "[51]\ttraining's multi_logloss: 0.188996\tvalid_1's multi_logloss: 0.277815        \n",
      "[52]\ttraining's multi_logloss: 0.186008\tvalid_1's multi_logloss: 0.276799        \n",
      "[53]\ttraining's multi_logloss: 0.183409\tvalid_1's multi_logloss: 0.275817        \n",
      "[54]\ttraining's multi_logloss: 0.180681\tvalid_1's multi_logloss: 0.275439        \n",
      "[55]\ttraining's multi_logloss: 0.178069\tvalid_1's multi_logloss: 0.274605        \n",
      "[56]\ttraining's multi_logloss: 0.175571\tvalid_1's multi_logloss: 0.274197        \n",
      "[57]\ttraining's multi_logloss: 0.173206\tvalid_1's multi_logloss: 0.273742        \n",
      "[58]\ttraining's multi_logloss: 0.170683\tvalid_1's multi_logloss: 0.273032        \n",
      "[59]\ttraining's multi_logloss: 0.168267\tvalid_1's multi_logloss: 0.27245         \n",
      "[60]\ttraining's multi_logloss: 0.165874\tvalid_1's multi_logloss: 0.272397        \n",
      "[61]\ttraining's multi_logloss: 0.163588\tvalid_1's multi_logloss: 0.272075        \n",
      "[62]\ttraining's multi_logloss: 0.161295\tvalid_1's multi_logloss: 0.271538        \n",
      "[63]\ttraining's multi_logloss: 0.158958\tvalid_1's multi_logloss: 0.271171        \n",
      "[64]\ttraining's multi_logloss: 0.156903\tvalid_1's multi_logloss: 0.270789        \n",
      "[65]\ttraining's multi_logloss: 0.154854\tvalid_1's multi_logloss: 0.270417        \n",
      "[66]\ttraining's multi_logloss: 0.152941\tvalid_1's multi_logloss: 0.270315        \n",
      "[67]\ttraining's multi_logloss: 0.150832\tvalid_1's multi_logloss: 0.269939        \n",
      "[68]\ttraining's multi_logloss: 0.148978\tvalid_1's multi_logloss: 0.26983         \n",
      "[69]\ttraining's multi_logloss: 0.147118\tvalid_1's multi_logloss: 0.269741        \n",
      "[70]\ttraining's multi_logloss: 0.145212\tvalid_1's multi_logloss: 0.269628        \n",
      "[71]\ttraining's multi_logloss: 0.143471\tvalid_1's multi_logloss: 0.269514        \n",
      "[72]\ttraining's multi_logloss: 0.14176\tvalid_1's multi_logloss: 0.269445         \n",
      "[73]\ttraining's multi_logloss: 0.140087\tvalid_1's multi_logloss: 0.26929         \n",
      "[74]\ttraining's multi_logloss: 0.138436\tvalid_1's multi_logloss: 0.269334        \n",
      "[75]\ttraining's multi_logloss: 0.136797\tvalid_1's multi_logloss: 0.269253        \n",
      "[76]\ttraining's multi_logloss: 0.135278\tvalid_1's multi_logloss: 0.269225        \n",
      "[77]\ttraining's multi_logloss: 0.13373\tvalid_1's multi_logloss: 0.269223         \n",
      "[78]\ttraining's multi_logloss: 0.132292\tvalid_1's multi_logloss: 0.269048        \n",
      "[79]\ttraining's multi_logloss: 0.130834\tvalid_1's multi_logloss: 0.269008        \n",
      "[80]\ttraining's multi_logloss: 0.129486\tvalid_1's multi_logloss: 0.26916         \n",
      "[81]\ttraining's multi_logloss: 0.128097\tvalid_1's multi_logloss: 0.269186        \n",
      "[82]\ttraining's multi_logloss: 0.126618\tvalid_1's multi_logloss: 0.269097        \n",
      "[83]\ttraining's multi_logloss: 0.12516\tvalid_1's multi_logloss: 0.269005         \n",
      "[84]\ttraining's multi_logloss: 0.123746\tvalid_1's multi_logloss: 0.269039        \n",
      "[85]\ttraining's multi_logloss: 0.122383\tvalid_1's multi_logloss: 0.26918         \n",
      "[86]\ttraining's multi_logloss: 0.121014\tvalid_1's multi_logloss: 0.269125        \n",
      "[87]\ttraining's multi_logloss: 0.11967\tvalid_1's multi_logloss: 0.269329         \n",
      "[88]\ttraining's multi_logloss: 0.118406\tvalid_1's multi_logloss: 0.269359        \n",
      "[89]\ttraining's multi_logloss: 0.117029\tvalid_1's multi_logloss: 0.269424        \n",
      "[90]\ttraining's multi_logloss: 0.115947\tvalid_1's multi_logloss: 0.269486        \n",
      "[91]\ttraining's multi_logloss: 0.114617\tvalid_1's multi_logloss: 0.269691        \n",
      "[92]\ttraining's multi_logloss: 0.113406\tvalid_1's multi_logloss: 0.269858        \n",
      "[93]\ttraining's multi_logloss: 0.112006\tvalid_1's multi_logloss: 0.269851        \n",
      "[94]\ttraining's multi_logloss: 0.110869\tvalid_1's multi_logloss: 0.26981         \n",
      "[95]\ttraining's multi_logloss: 0.109632\tvalid_1's multi_logloss: 0.269952        \n",
      "[96]\ttraining's multi_logloss: 0.108498\tvalid_1's multi_logloss: 0.270083        \n",
      "[97]\ttraining's multi_logloss: 0.107361\tvalid_1's multi_logloss: 0.269924        \n",
      "[98]\ttraining's multi_logloss: 0.106242\tvalid_1's multi_logloss: 0.269982        \n",
      "[99]\ttraining's multi_logloss: 0.105262\tvalid_1's multi_logloss: 0.269931        \n",
      "[100]\ttraining's multi_logloss: 0.104295\tvalid_1's multi_logloss: 0.270172       \n",
      "[101]\ttraining's multi_logloss: 0.103207\tvalid_1's multi_logloss: 0.270283       \n",
      "[102]\ttraining's multi_logloss: 0.102157\tvalid_1's multi_logloss: 0.270423       \n",
      "[103]\ttraining's multi_logloss: 0.101221\tvalid_1's multi_logloss: 0.270718       \n",
      "[104]\ttraining's multi_logloss: 0.100171\tvalid_1's multi_logloss: 0.270706       \n",
      "[105]\ttraining's multi_logloss: 0.0990979\tvalid_1's multi_logloss: 0.270739      \n",
      "[106]\ttraining's multi_logloss: 0.0981069\tvalid_1's multi_logloss: 0.270771      \n",
      "[107]\ttraining's multi_logloss: 0.0971237\tvalid_1's multi_logloss: 0.270924      \n",
      "[108]\ttraining's multi_logloss: 0.0961234\tvalid_1's multi_logloss: 0.270923      \n",
      "[109]\ttraining's multi_logloss: 0.095265\tvalid_1's multi_logloss: 0.271167       \n",
      "[110]\ttraining's multi_logloss: 0.0942914\tvalid_1's multi_logloss: 0.271225      \n",
      "[111]\ttraining's multi_logloss: 0.0934876\tvalid_1's multi_logloss: 0.271427      \n",
      "[112]\ttraining's multi_logloss: 0.0926392\tvalid_1's multi_logloss: 0.271607      \n",
      "[113]\ttraining's multi_logloss: 0.0916846\tvalid_1's multi_logloss: 0.271861      \n",
      "Early stopping, best iteration is:                                               \n",
      "[83]\ttraining's multi_logloss: 0.12516\tvalid_1's multi_logloss: 0.269005\n",
      "[1]\ttraining's multi_logloss: 1.41567\tvalid_1's multi_logloss: 1.42487           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.14119\tvalid_1's multi_logloss: 1.15814           \n",
      "[3]\ttraining's multi_logloss: 0.953498\tvalid_1's multi_logloss: 0.977208         \n",
      "[4]\ttraining's multi_logloss: 0.81569\tvalid_1's multi_logloss: 0.844044          \n",
      "[5]\ttraining's multi_logloss: 0.711286\tvalid_1's multi_logloss: 0.744016         \n",
      "[6]\ttraining's multi_logloss: 0.627119\tvalid_1's multi_logloss: 0.663306         \n",
      "[7]\ttraining's multi_logloss: 0.560801\tvalid_1's multi_logloss: 0.600297         \n",
      "[8]\ttraining's multi_logloss: 0.50552\tvalid_1's multi_logloss: 0.548839          \n",
      "[9]\ttraining's multi_logloss: 0.459701\tvalid_1's multi_logloss: 0.506195         \n",
      "[10]\ttraining's multi_logloss: 0.42151\tvalid_1's multi_logloss: 0.470916         \n",
      "[11]\ttraining's multi_logloss: 0.389536\tvalid_1's multi_logloss: 0.442583        \n",
      "[12]\ttraining's multi_logloss: 0.362065\tvalid_1's multi_logloss: 0.417692        \n",
      "[13]\ttraining's multi_logloss: 0.339573\tvalid_1's multi_logloss: 0.398327        \n",
      "[14]\ttraining's multi_logloss: 0.319424\tvalid_1's multi_logloss: 0.382064        \n",
      "[15]\ttraining's multi_logloss: 0.302054\tvalid_1's multi_logloss: 0.368246        \n",
      "[16]\ttraining's multi_logloss: 0.287046\tvalid_1's multi_logloss: 0.356788        \n",
      "[17]\ttraining's multi_logloss: 0.273187\tvalid_1's multi_logloss: 0.346958        \n",
      "[18]\ttraining's multi_logloss: 0.260926\tvalid_1's multi_logloss: 0.338717        \n",
      "[19]\ttraining's multi_logloss: 0.249957\tvalid_1's multi_logloss: 0.331723        \n",
      "[20]\ttraining's multi_logloss: 0.239655\tvalid_1's multi_logloss: 0.325534        \n",
      "[21]\ttraining's multi_logloss: 0.230548\tvalid_1's multi_logloss: 0.3202          \n",
      "[22]\ttraining's multi_logloss: 0.221624\tvalid_1's multi_logloss: 0.315032        \n",
      "[23]\ttraining's multi_logloss: 0.213752\tvalid_1's multi_logloss: 0.310552        \n",
      "[24]\ttraining's multi_logloss: 0.20646\tvalid_1's multi_logloss: 0.3077           \n",
      "[25]\ttraining's multi_logloss: 0.19961\tvalid_1's multi_logloss: 0.305338         \n",
      "[26]\ttraining's multi_logloss: 0.19309\tvalid_1's multi_logloss: 0.303419         \n",
      "[27]\ttraining's multi_logloss: 0.187309\tvalid_1's multi_logloss: 0.300658        \n",
      "[28]\ttraining's multi_logloss: 0.181525\tvalid_1's multi_logloss: 0.299395        \n",
      "[29]\ttraining's multi_logloss: 0.175892\tvalid_1's multi_logloss: 0.298611        \n",
      "[30]\ttraining's multi_logloss: 0.170334\tvalid_1's multi_logloss: 0.296832        \n",
      "[31]\ttraining's multi_logloss: 0.16524\tvalid_1's multi_logloss: 0.295704         \n",
      "[32]\ttraining's multi_logloss: 0.16011\tvalid_1's multi_logloss: 0.29439          \n",
      "[33]\ttraining's multi_logloss: 0.155184\tvalid_1's multi_logloss: 0.293271        \n",
      "[34]\ttraining's multi_logloss: 0.150802\tvalid_1's multi_logloss: 0.292216        \n",
      "[35]\ttraining's multi_logloss: 0.146449\tvalid_1's multi_logloss: 0.291696        \n",
      "[36]\ttraining's multi_logloss: 0.142261\tvalid_1's multi_logloss: 0.291858        \n",
      "[37]\ttraining's multi_logloss: 0.138174\tvalid_1's multi_logloss: 0.291283        \n",
      "[38]\ttraining's multi_logloss: 0.134136\tvalid_1's multi_logloss: 0.291304        \n",
      "[39]\ttraining's multi_logloss: 0.130253\tvalid_1's multi_logloss: 0.290789        \n",
      "[40]\ttraining's multi_logloss: 0.126408\tvalid_1's multi_logloss: 0.290375        \n",
      "[41]\ttraining's multi_logloss: 0.122393\tvalid_1's multi_logloss: 0.289801        \n",
      "[42]\ttraining's multi_logloss: 0.119086\tvalid_1's multi_logloss: 0.289834        \n",
      "[43]\ttraining's multi_logloss: 0.115717\tvalid_1's multi_logloss: 0.290148        \n",
      "[44]\ttraining's multi_logloss: 0.112298\tvalid_1's multi_logloss: 0.289895        \n",
      "[45]\ttraining's multi_logloss: 0.109362\tvalid_1's multi_logloss: 0.290541        \n",
      "[46]\ttraining's multi_logloss: 0.106407\tvalid_1's multi_logloss: 0.290825        \n",
      "[47]\ttraining's multi_logloss: 0.103482\tvalid_1's multi_logloss: 0.291365        \n",
      "[48]\ttraining's multi_logloss: 0.100797\tvalid_1's multi_logloss: 0.291383        \n",
      "[49]\ttraining's multi_logloss: 0.0983096\tvalid_1's multi_logloss: 0.291665       \n",
      "[50]\ttraining's multi_logloss: 0.0956526\tvalid_1's multi_logloss: 0.291906       \n",
      "[51]\ttraining's multi_logloss: 0.0932808\tvalid_1's multi_logloss: 0.292224       \n",
      "[52]\ttraining's multi_logloss: 0.0909997\tvalid_1's multi_logloss: 0.292345       \n",
      "[53]\ttraining's multi_logloss: 0.0886161\tvalid_1's multi_logloss: 0.29315        \n",
      "[54]\ttraining's multi_logloss: 0.0865442\tvalid_1's multi_logloss: 0.293478       \n",
      "[55]\ttraining's multi_logloss: 0.084352\tvalid_1's multi_logloss: 0.294121        \n",
      "[56]\ttraining's multi_logloss: 0.082335\tvalid_1's multi_logloss: 0.29538         \n",
      "[57]\ttraining's multi_logloss: 0.0801396\tvalid_1's multi_logloss: 0.296043       \n",
      "[58]\ttraining's multi_logloss: 0.0781924\tvalid_1's multi_logloss: 0.29663        \n",
      "[59]\ttraining's multi_logloss: 0.0763738\tvalid_1's multi_logloss: 0.298022       \n",
      "[60]\ttraining's multi_logloss: 0.0746451\tvalid_1's multi_logloss: 0.298829       \n",
      "[61]\ttraining's multi_logloss: 0.0727709\tvalid_1's multi_logloss: 0.298994       \n",
      "[62]\ttraining's multi_logloss: 0.0711023\tvalid_1's multi_logloss: 0.299828       \n",
      "[63]\ttraining's multi_logloss: 0.0691779\tvalid_1's multi_logloss: 0.300179       \n",
      "[64]\ttraining's multi_logloss: 0.0672797\tvalid_1's multi_logloss: 0.300505       \n",
      "[65]\ttraining's multi_logloss: 0.0655806\tvalid_1's multi_logloss: 0.300609       \n",
      "[66]\ttraining's multi_logloss: 0.0641949\tvalid_1's multi_logloss: 0.301613       \n",
      "[67]\ttraining's multi_logloss: 0.062545\tvalid_1's multi_logloss: 0.302386        \n",
      "[68]\ttraining's multi_logloss: 0.06091\tvalid_1's multi_logloss: 0.303317         \n",
      "[69]\ttraining's multi_logloss: 0.0595159\tvalid_1's multi_logloss: 0.304051       \n",
      "[70]\ttraining's multi_logloss: 0.0580339\tvalid_1's multi_logloss: 0.304067       \n",
      "[71]\ttraining's multi_logloss: 0.0566703\tvalid_1's multi_logloss: 0.304547       \n",
      "Early stopping, best iteration is:                                               \n",
      "[41]\ttraining's multi_logloss: 0.122393\tvalid_1's multi_logloss: 0.289801\n",
      "[1]\ttraining's multi_logloss: 1.41409\tvalid_1's multi_logloss: 1.41896           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.14142\tvalid_1's multi_logloss: 1.15095           \n",
      "[3]\ttraining's multi_logloss: 0.958604\tvalid_1's multi_logloss: 0.970636         \n",
      "[4]\ttraining's multi_logloss: 0.822901\tvalid_1's multi_logloss: 0.838154         \n",
      "[5]\ttraining's multi_logloss: 0.717083\tvalid_1's multi_logloss: 0.735947         \n",
      "[6]\ttraining's multi_logloss: 0.634085\tvalid_1's multi_logloss: 0.656698         \n",
      "[7]\ttraining's multi_logloss: 0.566425\tvalid_1's multi_logloss: 0.591998         \n",
      "[8]\ttraining's multi_logloss: 0.512\tvalid_1's multi_logloss: 0.541328            \n",
      "[9]\ttraining's multi_logloss: 0.466937\tvalid_1's multi_logloss: 0.499361         \n",
      "[10]\ttraining's multi_logloss: 0.4279\tvalid_1's multi_logloss: 0.463857          \n",
      "[11]\ttraining's multi_logloss: 0.396301\tvalid_1's multi_logloss: 0.435673        \n",
      "[12]\ttraining's multi_logloss: 0.36871\tvalid_1's multi_logloss: 0.411619         \n",
      "[13]\ttraining's multi_logloss: 0.345265\tvalid_1's multi_logloss: 0.391815        \n",
      "[14]\ttraining's multi_logloss: 0.324812\tvalid_1's multi_logloss: 0.375036        \n",
      "[15]\ttraining's multi_logloss: 0.307493\tvalid_1's multi_logloss: 0.361351        \n",
      "[16]\ttraining's multi_logloss: 0.291318\tvalid_1's multi_logloss: 0.348705        \n",
      "[17]\ttraining's multi_logloss: 0.276608\tvalid_1's multi_logloss: 0.338073        \n",
      "[18]\ttraining's multi_logloss: 0.26412\tvalid_1's multi_logloss: 0.329754         \n",
      "[19]\ttraining's multi_logloss: 0.252276\tvalid_1's multi_logloss: 0.323082        \n",
      "[20]\ttraining's multi_logloss: 0.242041\tvalid_1's multi_logloss: 0.317191        \n",
      "[21]\ttraining's multi_logloss: 0.232168\tvalid_1's multi_logloss: 0.312096        \n",
      "[22]\ttraining's multi_logloss: 0.223439\tvalid_1's multi_logloss: 0.308275        \n",
      "[23]\ttraining's multi_logloss: 0.215349\tvalid_1's multi_logloss: 0.30398         \n",
      "[24]\ttraining's multi_logloss: 0.2078\tvalid_1's multi_logloss: 0.300867          \n",
      "[25]\ttraining's multi_logloss: 0.200717\tvalid_1's multi_logloss: 0.298509        \n",
      "[26]\ttraining's multi_logloss: 0.194005\tvalid_1's multi_logloss: 0.296457        \n",
      "[27]\ttraining's multi_logloss: 0.187817\tvalid_1's multi_logloss: 0.294012        \n",
      "[28]\ttraining's multi_logloss: 0.181529\tvalid_1's multi_logloss: 0.292483        \n",
      "[29]\ttraining's multi_logloss: 0.175675\tvalid_1's multi_logloss: 0.290967        \n",
      "[30]\ttraining's multi_logloss: 0.170255\tvalid_1's multi_logloss: 0.289248        \n",
      "[31]\ttraining's multi_logloss: 0.165015\tvalid_1's multi_logloss: 0.288006        \n",
      "[32]\ttraining's multi_logloss: 0.160143\tvalid_1's multi_logloss: 0.28758         \n",
      "[33]\ttraining's multi_logloss: 0.155389\tvalid_1's multi_logloss: 0.28681         \n",
      "[34]\ttraining's multi_logloss: 0.150581\tvalid_1's multi_logloss: 0.286739        \n",
      "[35]\ttraining's multi_logloss: 0.146425\tvalid_1's multi_logloss: 0.286764        \n",
      "[36]\ttraining's multi_logloss: 0.142167\tvalid_1's multi_logloss: 0.286055        \n",
      "[37]\ttraining's multi_logloss: 0.137558\tvalid_1's multi_logloss: 0.285941        \n",
      "[38]\ttraining's multi_logloss: 0.133879\tvalid_1's multi_logloss: 0.285929        \n",
      "[39]\ttraining's multi_logloss: 0.130492\tvalid_1's multi_logloss: 0.286067        \n",
      "[40]\ttraining's multi_logloss: 0.126363\tvalid_1's multi_logloss: 0.285124        \n",
      "[41]\ttraining's multi_logloss: 0.122563\tvalid_1's multi_logloss: 0.285135        \n",
      "[42]\ttraining's multi_logloss: 0.118895\tvalid_1's multi_logloss: 0.284947        \n",
      "[43]\ttraining's multi_logloss: 0.115661\tvalid_1's multi_logloss: 0.285096        \n",
      "[44]\ttraining's multi_logloss: 0.112552\tvalid_1's multi_logloss: 0.285087        \n",
      "[45]\ttraining's multi_logloss: 0.109342\tvalid_1's multi_logloss: 0.285514        \n",
      "[46]\ttraining's multi_logloss: 0.106603\tvalid_1's multi_logloss: 0.28518         \n",
      "[47]\ttraining's multi_logloss: 0.103836\tvalid_1's multi_logloss: 0.285675        \n",
      "[48]\ttraining's multi_logloss: 0.100975\tvalid_1's multi_logloss: 0.285986        \n",
      "[49]\ttraining's multi_logloss: 0.0981171\tvalid_1's multi_logloss: 0.286226       \n",
      "[50]\ttraining's multi_logloss: 0.0954606\tvalid_1's multi_logloss: 0.286784       \n",
      "[51]\ttraining's multi_logloss: 0.0926902\tvalid_1's multi_logloss: 0.286609       \n",
      "[52]\ttraining's multi_logloss: 0.0902633\tvalid_1's multi_logloss: 0.287143       \n",
      "[53]\ttraining's multi_logloss: 0.0880231\tvalid_1's multi_logloss: 0.287411       \n",
      "[54]\ttraining's multi_logloss: 0.0857423\tvalid_1's multi_logloss: 0.287773       \n",
      "[55]\ttraining's multi_logloss: 0.0835795\tvalid_1's multi_logloss: 0.288349       \n",
      "[56]\ttraining's multi_logloss: 0.0816136\tvalid_1's multi_logloss: 0.289273       \n",
      "[57]\ttraining's multi_logloss: 0.0793954\tvalid_1's multi_logloss: 0.289763       \n",
      "[58]\ttraining's multi_logloss: 0.0775128\tvalid_1's multi_logloss: 0.290562       \n",
      "[59]\ttraining's multi_logloss: 0.0754281\tvalid_1's multi_logloss: 0.291904       \n",
      "[60]\ttraining's multi_logloss: 0.0734734\tvalid_1's multi_logloss: 0.292317       \n",
      "[61]\ttraining's multi_logloss: 0.0718157\tvalid_1's multi_logloss: 0.293191       \n",
      "[62]\ttraining's multi_logloss: 0.0700482\tvalid_1's multi_logloss: 0.293498       \n",
      "[63]\ttraining's multi_logloss: 0.0682343\tvalid_1's multi_logloss: 0.294705       \n",
      "[64]\ttraining's multi_logloss: 0.0665545\tvalid_1's multi_logloss: 0.295331       \n",
      "[65]\ttraining's multi_logloss: 0.064889\tvalid_1's multi_logloss: 0.295794        \n",
      "[66]\ttraining's multi_logloss: 0.0631341\tvalid_1's multi_logloss: 0.296688       \n",
      "[67]\ttraining's multi_logloss: 0.0614759\tvalid_1's multi_logloss: 0.297564       \n",
      "[68]\ttraining's multi_logloss: 0.059937\tvalid_1's multi_logloss: 0.297924        \n",
      "[69]\ttraining's multi_logloss: 0.0582823\tvalid_1's multi_logloss: 0.298925       \n",
      "[70]\ttraining's multi_logloss: 0.0570179\tvalid_1's multi_logloss: 0.299828       \n",
      "[71]\ttraining's multi_logloss: 0.055694\tvalid_1's multi_logloss: 0.300502        \n",
      "[72]\ttraining's multi_logloss: 0.0544423\tvalid_1's multi_logloss: 0.301522       \n",
      "Early stopping, best iteration is:                                               \n",
      "[42]\ttraining's multi_logloss: 0.118895\tvalid_1's multi_logloss: 0.284947\n",
      "[1]\ttraining's multi_logloss: 1.41736\tvalid_1's multi_logloss: 1.42261           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.14517\tvalid_1's multi_logloss: 1.1529            \n",
      "[3]\ttraining's multi_logloss: 0.961037\tvalid_1's multi_logloss: 0.971419         \n",
      "[4]\ttraining's multi_logloss: 0.825314\tvalid_1's multi_logloss: 0.838287         \n",
      "[5]\ttraining's multi_logloss: 0.718283\tvalid_1's multi_logloss: 0.733592         \n",
      "[6]\ttraining's multi_logloss: 0.635793\tvalid_1's multi_logloss: 0.653757         \n",
      "[7]\ttraining's multi_logloss: 0.569096\tvalid_1's multi_logloss: 0.589922         \n",
      "[8]\ttraining's multi_logloss: 0.513796\tvalid_1's multi_logloss: 0.537424         \n",
      "[9]\ttraining's multi_logloss: 0.468393\tvalid_1's multi_logloss: 0.494624         \n",
      "[10]\ttraining's multi_logloss: 0.430905\tvalid_1's multi_logloss: 0.459511        \n",
      "[11]\ttraining's multi_logloss: 0.398586\tvalid_1's multi_logloss: 0.430093        \n",
      "[12]\ttraining's multi_logloss: 0.371172\tvalid_1's multi_logloss: 0.405238        \n",
      "[13]\ttraining's multi_logloss: 0.347744\tvalid_1's multi_logloss: 0.384575        \n",
      "[14]\ttraining's multi_logloss: 0.327832\tvalid_1's multi_logloss: 0.367631        \n",
      "[15]\ttraining's multi_logloss: 0.310324\tvalid_1's multi_logloss: 0.353491        \n",
      "[16]\ttraining's multi_logloss: 0.294837\tvalid_1's multi_logloss: 0.341105        \n",
      "[17]\ttraining's multi_logloss: 0.280923\tvalid_1's multi_logloss: 0.330701        \n",
      "[18]\ttraining's multi_logloss: 0.268614\tvalid_1's multi_logloss: 0.322249        \n",
      "[19]\ttraining's multi_logloss: 0.256428\tvalid_1's multi_logloss: 0.314079        \n",
      "[20]\ttraining's multi_logloss: 0.246503\tvalid_1's multi_logloss: 0.308616        \n",
      "[21]\ttraining's multi_logloss: 0.237094\tvalid_1's multi_logloss: 0.303094        \n",
      "[22]\ttraining's multi_logloss: 0.228583\tvalid_1's multi_logloss: 0.298483        \n",
      "[23]\ttraining's multi_logloss: 0.220603\tvalid_1's multi_logloss: 0.294323        \n",
      "[24]\ttraining's multi_logloss: 0.213194\tvalid_1's multi_logloss: 0.29039         \n",
      "[25]\ttraining's multi_logloss: 0.20622\tvalid_1's multi_logloss: 0.287201         \n",
      "[26]\ttraining's multi_logloss: 0.199551\tvalid_1's multi_logloss: 0.284248        \n",
      "[27]\ttraining's multi_logloss: 0.192991\tvalid_1's multi_logloss: 0.282279        \n",
      "[28]\ttraining's multi_logloss: 0.187146\tvalid_1's multi_logloss: 0.280348        \n",
      "[29]\ttraining's multi_logloss: 0.181236\tvalid_1's multi_logloss: 0.278613        \n",
      "[30]\ttraining's multi_logloss: 0.175686\tvalid_1's multi_logloss: 0.277345        \n",
      "[31]\ttraining's multi_logloss: 0.170062\tvalid_1's multi_logloss: 0.276419        \n",
      "[32]\ttraining's multi_logloss: 0.164697\tvalid_1's multi_logloss: 0.27536         \n",
      "[33]\ttraining's multi_logloss: 0.1598\tvalid_1's multi_logloss: 0.274342          \n",
      "[34]\ttraining's multi_logloss: 0.155154\tvalid_1's multi_logloss: 0.273111        \n",
      "[35]\ttraining's multi_logloss: 0.150386\tvalid_1's multi_logloss: 0.272137        \n",
      "[36]\ttraining's multi_logloss: 0.145957\tvalid_1's multi_logloss: 0.271941        \n",
      "[37]\ttraining's multi_logloss: 0.14176\tvalid_1's multi_logloss: 0.271341         \n",
      "[38]\ttraining's multi_logloss: 0.137347\tvalid_1's multi_logloss: 0.270485        \n",
      "[39]\ttraining's multi_logloss: 0.133325\tvalid_1's multi_logloss: 0.269804        \n",
      "[40]\ttraining's multi_logloss: 0.129755\tvalid_1's multi_logloss: 0.269458        \n",
      "[41]\ttraining's multi_logloss: 0.12611\tvalid_1's multi_logloss: 0.268821         \n",
      "[42]\ttraining's multi_logloss: 0.122669\tvalid_1's multi_logloss: 0.26915         \n",
      "[43]\ttraining's multi_logloss: 0.11941\tvalid_1's multi_logloss: 0.268962         \n",
      "[44]\ttraining's multi_logloss: 0.116234\tvalid_1's multi_logloss: 0.268861        \n",
      "[45]\ttraining's multi_logloss: 0.113271\tvalid_1's multi_logloss: 0.268788        \n",
      "[46]\ttraining's multi_logloss: 0.110491\tvalid_1's multi_logloss: 0.268613        \n",
      "[47]\ttraining's multi_logloss: 0.107775\tvalid_1's multi_logloss: 0.268589        \n",
      "[48]\ttraining's multi_logloss: 0.105109\tvalid_1's multi_logloss: 0.268687        \n",
      "[49]\ttraining's multi_logloss: 0.10232\tvalid_1's multi_logloss: 0.268988         \n",
      "[50]\ttraining's multi_logloss: 0.0997161\tvalid_1's multi_logloss: 0.269425       \n",
      "[51]\ttraining's multi_logloss: 0.0973083\tvalid_1's multi_logloss: 0.269969       \n",
      "[52]\ttraining's multi_logloss: 0.0946734\tvalid_1's multi_logloss: 0.270091       \n",
      "[53]\ttraining's multi_logloss: 0.092122\tvalid_1's multi_logloss: 0.2704          \n",
      "[54]\ttraining's multi_logloss: 0.0898451\tvalid_1's multi_logloss: 0.271076       \n",
      "[55]\ttraining's multi_logloss: 0.0877081\tvalid_1's multi_logloss: 0.271926       \n",
      "[56]\ttraining's multi_logloss: 0.0856771\tvalid_1's multi_logloss: 0.272308       \n",
      "[57]\ttraining's multi_logloss: 0.0835857\tvalid_1's multi_logloss: 0.272956       \n",
      "[58]\ttraining's multi_logloss: 0.0816633\tvalid_1's multi_logloss: 0.273236       \n",
      "[59]\ttraining's multi_logloss: 0.0795423\tvalid_1's multi_logloss: 0.274178       \n",
      "[60]\ttraining's multi_logloss: 0.0777462\tvalid_1's multi_logloss: 0.274495       \n",
      "[61]\ttraining's multi_logloss: 0.0760022\tvalid_1's multi_logloss: 0.275433       \n",
      "[62]\ttraining's multi_logloss: 0.0742664\tvalid_1's multi_logloss: 0.276353       \n",
      "[63]\ttraining's multi_logloss: 0.0724844\tvalid_1's multi_logloss: 0.277016       \n",
      "[64]\ttraining's multi_logloss: 0.0707679\tvalid_1's multi_logloss: 0.277563       \n",
      "[65]\ttraining's multi_logloss: 0.0689904\tvalid_1's multi_logloss: 0.278968       \n",
      "[66]\ttraining's multi_logloss: 0.0673757\tvalid_1's multi_logloss: 0.279566       \n",
      "[67]\ttraining's multi_logloss: 0.0658463\tvalid_1's multi_logloss: 0.280153       \n",
      "[68]\ttraining's multi_logloss: 0.064057\tvalid_1's multi_logloss: 0.281013        \n",
      "[69]\ttraining's multi_logloss: 0.0626217\tvalid_1's multi_logloss: 0.281815       \n",
      "[70]\ttraining's multi_logloss: 0.0610375\tvalid_1's multi_logloss: 0.282142       \n",
      "[71]\ttraining's multi_logloss: 0.0598037\tvalid_1's multi_logloss: 0.282742       \n",
      "[72]\ttraining's multi_logloss: 0.0582934\tvalid_1's multi_logloss: 0.283546       \n",
      "[73]\ttraining's multi_logloss: 0.0570933\tvalid_1's multi_logloss: 0.284203       \n",
      "[74]\ttraining's multi_logloss: 0.055808\tvalid_1's multi_logloss: 0.284771        \n",
      "[75]\ttraining's multi_logloss: 0.0544317\tvalid_1's multi_logloss: 0.285348       \n",
      "[76]\ttraining's multi_logloss: 0.0531876\tvalid_1's multi_logloss: 0.286044       \n",
      "[77]\ttraining's multi_logloss: 0.0520078\tvalid_1's multi_logloss: 0.286813       \n",
      "Early stopping, best iteration is:                                               \n",
      "[47]\ttraining's multi_logloss: 0.107775\tvalid_1's multi_logloss: 0.268589\n",
      "[1]\ttraining's multi_logloss: 1.5844\tvalid_1's multi_logloss: 1.59152            \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.35507\tvalid_1's multi_logloss: 1.36966           \n",
      "[3]\ttraining's multi_logloss: 1.18235\tvalid_1's multi_logloss: 1.20333           \n",
      "[4]\ttraining's multi_logloss: 1.0468\tvalid_1's multi_logloss: 1.07233            \n",
      "[5]\ttraining's multi_logloss: 0.937061\tvalid_1's multi_logloss: 0.966793         \n",
      "[6]\ttraining's multi_logloss: 0.845433\tvalid_1's multi_logloss: 0.878812         \n",
      "[7]\ttraining's multi_logloss: 0.767618\tvalid_1's multi_logloss: 0.804276         \n",
      "[8]\ttraining's multi_logloss: 0.700975\tvalid_1's multi_logloss: 0.740357         \n",
      "[9]\ttraining's multi_logloss: 0.643864\tvalid_1's multi_logloss: 0.686028         \n",
      "[10]\ttraining's multi_logloss: 0.594492\tvalid_1's multi_logloss: 0.639869        \n",
      "[11]\ttraining's multi_logloss: 0.550815\tvalid_1's multi_logloss: 0.59918         \n",
      "[12]\ttraining's multi_logloss: 0.512428\tvalid_1's multi_logloss: 0.563475        \n",
      "[13]\ttraining's multi_logloss: 0.479035\tvalid_1's multi_logloss: 0.532522        \n",
      "[14]\ttraining's multi_logloss: 0.44911\tvalid_1's multi_logloss: 0.505253         \n",
      "[15]\ttraining's multi_logloss: 0.422639\tvalid_1's multi_logloss: 0.481484        \n",
      "[16]\ttraining's multi_logloss: 0.398748\tvalid_1's multi_logloss: 0.460203        \n",
      "[17]\ttraining's multi_logloss: 0.377554\tvalid_1's multi_logloss: 0.441676        \n",
      "[18]\ttraining's multi_logloss: 0.358626\tvalid_1's multi_logloss: 0.425306        \n",
      "[19]\ttraining's multi_logloss: 0.341696\tvalid_1's multi_logloss: 0.410789        \n",
      "[20]\ttraining's multi_logloss: 0.32631\tvalid_1's multi_logloss: 0.398038         \n",
      "[21]\ttraining's multi_logloss: 0.311966\tvalid_1's multi_logloss: 0.386566        \n",
      "[22]\ttraining's multi_logloss: 0.299464\tvalid_1's multi_logloss: 0.376563        \n",
      "[23]\ttraining's multi_logloss: 0.287798\tvalid_1's multi_logloss: 0.367563        \n",
      "[24]\ttraining's multi_logloss: 0.277049\tvalid_1's multi_logloss: 0.359551        \n",
      "[25]\ttraining's multi_logloss: 0.267002\tvalid_1's multi_logloss: 0.352442        \n",
      "[26]\ttraining's multi_logloss: 0.257375\tvalid_1's multi_logloss: 0.345866        \n",
      "[27]\ttraining's multi_logloss: 0.249097\tvalid_1's multi_logloss: 0.340763        \n",
      "[28]\ttraining's multi_logloss: 0.241354\tvalid_1's multi_logloss: 0.335943        \n",
      "[29]\ttraining's multi_logloss: 0.233795\tvalid_1's multi_logloss: 0.331222        \n",
      "[30]\ttraining's multi_logloss: 0.22695\tvalid_1's multi_logloss: 0.327364         \n",
      "[31]\ttraining's multi_logloss: 0.220283\tvalid_1's multi_logloss: 0.323757        \n",
      "[32]\ttraining's multi_logloss: 0.214003\tvalid_1's multi_logloss: 0.320535        \n",
      "[33]\ttraining's multi_logloss: 0.208194\tvalid_1's multi_logloss: 0.317149        \n",
      "[34]\ttraining's multi_logloss: 0.202444\tvalid_1's multi_logloss: 0.314787        \n",
      "[35]\ttraining's multi_logloss: 0.197065\tvalid_1's multi_logloss: 0.312239        \n",
      "[36]\ttraining's multi_logloss: 0.191708\tvalid_1's multi_logloss: 0.309738        \n",
      "[37]\ttraining's multi_logloss: 0.187072\tvalid_1's multi_logloss: 0.308038        \n",
      "[38]\ttraining's multi_logloss: 0.182287\tvalid_1's multi_logloss: 0.306392        \n",
      "[39]\ttraining's multi_logloss: 0.177734\tvalid_1's multi_logloss: 0.305003        \n",
      "[40]\ttraining's multi_logloss: 0.173415\tvalid_1's multi_logloss: 0.303952        \n",
      "[41]\ttraining's multi_logloss: 0.169352\tvalid_1's multi_logloss: 0.302386        \n",
      "[42]\ttraining's multi_logloss: 0.165383\tvalid_1's multi_logloss: 0.300856        \n",
      "[43]\ttraining's multi_logloss: 0.161504\tvalid_1's multi_logloss: 0.299958        \n",
      "[44]\ttraining's multi_logloss: 0.157906\tvalid_1's multi_logloss: 0.299042        \n",
      "[45]\ttraining's multi_logloss: 0.154308\tvalid_1's multi_logloss: 0.298346        \n",
      "[46]\ttraining's multi_logloss: 0.150918\tvalid_1's multi_logloss: 0.297424        \n",
      "[47]\ttraining's multi_logloss: 0.147741\tvalid_1's multi_logloss: 0.296587        \n",
      "[48]\ttraining's multi_logloss: 0.144565\tvalid_1's multi_logloss: 0.296201        \n",
      "[49]\ttraining's multi_logloss: 0.141573\tvalid_1's multi_logloss: 0.29573         \n",
      "[50]\ttraining's multi_logloss: 0.138629\tvalid_1's multi_logloss: 0.29517         \n",
      "[51]\ttraining's multi_logloss: 0.135552\tvalid_1's multi_logloss: 0.294325        \n",
      "[52]\ttraining's multi_logloss: 0.132736\tvalid_1's multi_logloss: 0.293621        \n",
      "[53]\ttraining's multi_logloss: 0.129989\tvalid_1's multi_logloss: 0.293199        \n",
      "[54]\ttraining's multi_logloss: 0.127354\tvalid_1's multi_logloss: 0.292643        \n",
      "[55]\ttraining's multi_logloss: 0.12479\tvalid_1's multi_logloss: 0.29207          \n",
      "[56]\ttraining's multi_logloss: 0.122506\tvalid_1's multi_logloss: 0.292186        \n",
      "[57]\ttraining's multi_logloss: 0.119918\tvalid_1's multi_logloss: 0.292056        \n",
      "[58]\ttraining's multi_logloss: 0.117672\tvalid_1's multi_logloss: 0.292072        \n",
      "[59]\ttraining's multi_logloss: 0.11548\tvalid_1's multi_logloss: 0.292106         \n",
      "[60]\ttraining's multi_logloss: 0.113313\tvalid_1's multi_logloss: 0.291831        \n",
      "[61]\ttraining's multi_logloss: 0.11109\tvalid_1's multi_logloss: 0.291727         \n",
      "[62]\ttraining's multi_logloss: 0.109153\tvalid_1's multi_logloss: 0.291491        \n",
      "[63]\ttraining's multi_logloss: 0.107033\tvalid_1's multi_logloss: 0.291513        \n",
      "[64]\ttraining's multi_logloss: 0.105216\tvalid_1's multi_logloss: 0.291104        \n",
      "[65]\ttraining's multi_logloss: 0.103293\tvalid_1's multi_logloss: 0.291342        \n",
      "[66]\ttraining's multi_logloss: 0.101354\tvalid_1's multi_logloss: 0.291527        \n",
      "[67]\ttraining's multi_logloss: 0.0996525\tvalid_1's multi_logloss: 0.291427       \n",
      "[68]\ttraining's multi_logloss: 0.0979211\tvalid_1's multi_logloss: 0.291525       \n",
      "[69]\ttraining's multi_logloss: 0.0961461\tvalid_1's multi_logloss: 0.291463       \n",
      "[70]\ttraining's multi_logloss: 0.0944506\tvalid_1's multi_logloss: 0.2916         \n",
      "[71]\ttraining's multi_logloss: 0.0928987\tvalid_1's multi_logloss: 0.291874       \n",
      "[72]\ttraining's multi_logloss: 0.0913793\tvalid_1's multi_logloss: 0.292306       \n",
      "[73]\ttraining's multi_logloss: 0.0898016\tvalid_1's multi_logloss: 0.292585       \n",
      "[74]\ttraining's multi_logloss: 0.0883627\tvalid_1's multi_logloss: 0.292924       \n",
      "[75]\ttraining's multi_logloss: 0.0870306\tvalid_1's multi_logloss: 0.293387       \n",
      "[76]\ttraining's multi_logloss: 0.0856396\tvalid_1's multi_logloss: 0.293949       \n",
      "[77]\ttraining's multi_logloss: 0.0840765\tvalid_1's multi_logloss: 0.294275       \n",
      "[78]\ttraining's multi_logloss: 0.0826681\tvalid_1's multi_logloss: 0.294591       \n",
      "[79]\ttraining's multi_logloss: 0.0813226\tvalid_1's multi_logloss: 0.294845       \n",
      "[80]\ttraining's multi_logloss: 0.0800301\tvalid_1's multi_logloss: 0.295186       \n",
      "[81]\ttraining's multi_logloss: 0.0786709\tvalid_1's multi_logloss: 0.295495       \n",
      "[82]\ttraining's multi_logloss: 0.0774933\tvalid_1's multi_logloss: 0.295941       \n",
      "[83]\ttraining's multi_logloss: 0.0761466\tvalid_1's multi_logloss: 0.295995       \n",
      "[84]\ttraining's multi_logloss: 0.0749905\tvalid_1's multi_logloss: 0.29636        \n",
      "[85]\ttraining's multi_logloss: 0.073866\tvalid_1's multi_logloss: 0.296767        \n",
      "[86]\ttraining's multi_logloss: 0.0727848\tvalid_1's multi_logloss: 0.29733        \n",
      "[87]\ttraining's multi_logloss: 0.071544\tvalid_1's multi_logloss: 0.297699        \n",
      "[88]\ttraining's multi_logloss: 0.0703988\tvalid_1's multi_logloss: 0.298098       \n",
      "[89]\ttraining's multi_logloss: 0.0693231\tvalid_1's multi_logloss: 0.298543       \n",
      "[90]\ttraining's multi_logloss: 0.0683129\tvalid_1's multi_logloss: 0.298916       \n",
      "[91]\ttraining's multi_logloss: 0.0671053\tvalid_1's multi_logloss: 0.299146       \n",
      "[92]\ttraining's multi_logloss: 0.0660049\tvalid_1's multi_logloss: 0.299461       \n",
      "[93]\ttraining's multi_logloss: 0.0649792\tvalid_1's multi_logloss: 0.300008       \n",
      "[94]\ttraining's multi_logloss: 0.0640229\tvalid_1's multi_logloss: 0.300712       \n",
      "Early stopping, best iteration is:                                               \n",
      "[64]\ttraining's multi_logloss: 0.105216\tvalid_1's multi_logloss: 0.291104\n",
      "[1]\ttraining's multi_logloss: 1.5826\tvalid_1's multi_logloss: 1.58795            \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.35326\tvalid_1's multi_logloss: 1.36114           \n",
      "[3]\ttraining's multi_logloss: 1.18263\tvalid_1's multi_logloss: 1.19452           \n",
      "[4]\ttraining's multi_logloss: 1.04848\tvalid_1's multi_logloss: 1.06302           \n",
      "[5]\ttraining's multi_logloss: 0.939389\tvalid_1's multi_logloss: 0.956892         \n",
      "[6]\ttraining's multi_logloss: 0.847841\tvalid_1's multi_logloss: 0.868038         \n",
      "[7]\ttraining's multi_logloss: 0.77075\tvalid_1's multi_logloss: 0.793975          \n",
      "[8]\ttraining's multi_logloss: 0.705045\tvalid_1's multi_logloss: 0.731174         \n",
      "[9]\ttraining's multi_logloss: 0.6483\tvalid_1's multi_logloss: 0.677192           \n",
      "[10]\ttraining's multi_logloss: 0.598426\tvalid_1's multi_logloss: 0.630209        \n",
      "[11]\ttraining's multi_logloss: 0.554803\tvalid_1's multi_logloss: 0.589639        \n",
      "[12]\ttraining's multi_logloss: 0.516913\tvalid_1's multi_logloss: 0.554141        \n",
      "[13]\ttraining's multi_logloss: 0.483187\tvalid_1's multi_logloss: 0.52312         \n",
      "[14]\ttraining's multi_logloss: 0.453622\tvalid_1's multi_logloss: 0.49647         \n",
      "[15]\ttraining's multi_logloss: 0.427222\tvalid_1's multi_logloss: 0.472697        \n",
      "[16]\ttraining's multi_logloss: 0.403903\tvalid_1's multi_logloss: 0.452396        \n",
      "[17]\ttraining's multi_logloss: 0.383032\tvalid_1's multi_logloss: 0.434351        \n",
      "[18]\ttraining's multi_logloss: 0.36375\tvalid_1's multi_logloss: 0.417863         \n",
      "[19]\ttraining's multi_logloss: 0.346576\tvalid_1's multi_logloss: 0.403803        \n",
      "[20]\ttraining's multi_logloss: 0.331218\tvalid_1's multi_logloss: 0.391635        \n",
      "[21]\ttraining's multi_logloss: 0.317106\tvalid_1's multi_logloss: 0.38027         \n",
      "[22]\ttraining's multi_logloss: 0.304003\tvalid_1's multi_logloss: 0.370045        \n",
      "[23]\ttraining's multi_logloss: 0.291941\tvalid_1's multi_logloss: 0.360903        \n",
      "[24]\ttraining's multi_logloss: 0.280544\tvalid_1's multi_logloss: 0.352658        \n",
      "[25]\ttraining's multi_logloss: 0.270101\tvalid_1's multi_logloss: 0.345267        \n",
      "[26]\ttraining's multi_logloss: 0.260457\tvalid_1's multi_logloss: 0.338063        \n",
      "[27]\ttraining's multi_logloss: 0.251744\tvalid_1's multi_logloss: 0.332046        \n",
      "[28]\ttraining's multi_logloss: 0.24374\tvalid_1's multi_logloss: 0.326926         \n",
      "[29]\ttraining's multi_logloss: 0.236157\tvalid_1's multi_logloss: 0.322487        \n",
      "[30]\ttraining's multi_logloss: 0.229058\tvalid_1's multi_logloss: 0.318203        \n",
      "[31]\ttraining's multi_logloss: 0.222377\tvalid_1's multi_logloss: 0.314835        \n",
      "[32]\ttraining's multi_logloss: 0.216248\tvalid_1's multi_logloss: 0.311964        \n",
      "[33]\ttraining's multi_logloss: 0.21018\tvalid_1's multi_logloss: 0.309027         \n",
      "[34]\ttraining's multi_logloss: 0.20434\tvalid_1's multi_logloss: 0.306423         \n",
      "[35]\ttraining's multi_logloss: 0.198504\tvalid_1's multi_logloss: 0.304077        \n",
      "[36]\ttraining's multi_logloss: 0.193544\tvalid_1's multi_logloss: 0.302185        \n",
      "[37]\ttraining's multi_logloss: 0.188522\tvalid_1's multi_logloss: 0.300387        \n",
      "[38]\ttraining's multi_logloss: 0.183799\tvalid_1's multi_logloss: 0.298844        \n",
      "[39]\ttraining's multi_logloss: 0.179359\tvalid_1's multi_logloss: 0.297826        \n",
      "[40]\ttraining's multi_logloss: 0.175038\tvalid_1's multi_logloss: 0.296143        \n",
      "[41]\ttraining's multi_logloss: 0.170892\tvalid_1's multi_logloss: 0.295105        \n",
      "[42]\ttraining's multi_logloss: 0.166946\tvalid_1's multi_logloss: 0.293678        \n",
      "[43]\ttraining's multi_logloss: 0.163015\tvalid_1's multi_logloss: 0.292671        \n",
      "[44]\ttraining's multi_logloss: 0.159154\tvalid_1's multi_logloss: 0.291641        \n",
      "[45]\ttraining's multi_logloss: 0.155462\tvalid_1's multi_logloss: 0.290423        \n",
      "[46]\ttraining's multi_logloss: 0.151925\tvalid_1's multi_logloss: 0.290348        \n",
      "[47]\ttraining's multi_logloss: 0.14875\tvalid_1's multi_logloss: 0.289885         \n",
      "[48]\ttraining's multi_logloss: 0.145495\tvalid_1's multi_logloss: 0.288679        \n",
      "[49]\ttraining's multi_logloss: 0.142298\tvalid_1's multi_logloss: 0.288268        \n",
      "[50]\ttraining's multi_logloss: 0.139191\tvalid_1's multi_logloss: 0.28762         \n",
      "[51]\ttraining's multi_logloss: 0.1362\tvalid_1's multi_logloss: 0.287158          \n",
      "[52]\ttraining's multi_logloss: 0.133332\tvalid_1's multi_logloss: 0.286576        \n",
      "[53]\ttraining's multi_logloss: 0.130525\tvalid_1's multi_logloss: 0.286663        \n",
      "[54]\ttraining's multi_logloss: 0.127741\tvalid_1's multi_logloss: 0.286501        \n",
      "[55]\ttraining's multi_logloss: 0.125247\tvalid_1's multi_logloss: 0.286157        \n",
      "[56]\ttraining's multi_logloss: 0.122815\tvalid_1's multi_logloss: 0.285834        \n",
      "[57]\ttraining's multi_logloss: 0.120333\tvalid_1's multi_logloss: 0.286152        \n",
      "[58]\ttraining's multi_logloss: 0.117933\tvalid_1's multi_logloss: 0.286107        \n",
      "[59]\ttraining's multi_logloss: 0.11553\tvalid_1's multi_logloss: 0.286371         \n",
      "[60]\ttraining's multi_logloss: 0.113015\tvalid_1's multi_logloss: 0.286746        \n",
      "[61]\ttraining's multi_logloss: 0.110785\tvalid_1's multi_logloss: 0.286804        \n",
      "[62]\ttraining's multi_logloss: 0.108655\tvalid_1's multi_logloss: 0.287113        \n",
      "[63]\ttraining's multi_logloss: 0.106639\tvalid_1's multi_logloss: 0.287302        \n",
      "[64]\ttraining's multi_logloss: 0.104545\tvalid_1's multi_logloss: 0.287434        \n",
      "[65]\ttraining's multi_logloss: 0.102635\tvalid_1's multi_logloss: 0.287419        \n",
      "[66]\ttraining's multi_logloss: 0.100683\tvalid_1's multi_logloss: 0.287733        \n",
      "[67]\ttraining's multi_logloss: 0.0988163\tvalid_1's multi_logloss: 0.288175       \n",
      "[68]\ttraining's multi_logloss: 0.0970978\tvalid_1's multi_logloss: 0.288742       \n",
      "[69]\ttraining's multi_logloss: 0.0954223\tvalid_1's multi_logloss: 0.289211       \n",
      "[70]\ttraining's multi_logloss: 0.0936612\tvalid_1's multi_logloss: 0.289349       \n",
      "[71]\ttraining's multi_logloss: 0.0920449\tvalid_1's multi_logloss: 0.289648       \n",
      "[72]\ttraining's multi_logloss: 0.0903988\tvalid_1's multi_logloss: 0.290018       \n",
      "[73]\ttraining's multi_logloss: 0.0887956\tvalid_1's multi_logloss: 0.290155       \n",
      "[74]\ttraining's multi_logloss: 0.0871923\tvalid_1's multi_logloss: 0.290563       \n",
      "[75]\ttraining's multi_logloss: 0.0856385\tvalid_1's multi_logloss: 0.290716       \n",
      "[76]\ttraining's multi_logloss: 0.0840756\tvalid_1's multi_logloss: 0.291385       \n",
      "[77]\ttraining's multi_logloss: 0.0825985\tvalid_1's multi_logloss: 0.291955       \n",
      "[78]\ttraining's multi_logloss: 0.0810603\tvalid_1's multi_logloss: 0.292385       \n",
      "[79]\ttraining's multi_logloss: 0.0797028\tvalid_1's multi_logloss: 0.292686       \n",
      "[80]\ttraining's multi_logloss: 0.078325\tvalid_1's multi_logloss: 0.292747        \n",
      "[81]\ttraining's multi_logloss: 0.0770196\tvalid_1's multi_logloss: 0.29287        \n",
      "[82]\ttraining's multi_logloss: 0.0757571\tvalid_1's multi_logloss: 0.293124       \n",
      "[83]\ttraining's multi_logloss: 0.0744862\tvalid_1's multi_logloss: 0.293742       \n",
      "[84]\ttraining's multi_logloss: 0.0732588\tvalid_1's multi_logloss: 0.294111       \n",
      "[85]\ttraining's multi_logloss: 0.0719699\tvalid_1's multi_logloss: 0.294631       \n",
      "[86]\ttraining's multi_logloss: 0.0707835\tvalid_1's multi_logloss: 0.295246       \n",
      "Early stopping, best iteration is:                                               \n",
      "[56]\ttraining's multi_logloss: 0.122815\tvalid_1's multi_logloss: 0.285834\n",
      "[1]\ttraining's multi_logloss: 1.58377\tvalid_1's multi_logloss: 1.58898           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.35559\tvalid_1's multi_logloss: 1.36346           \n",
      "[3]\ttraining's multi_logloss: 1.18502\tvalid_1's multi_logloss: 1.19536           \n",
      "[4]\ttraining's multi_logloss: 1.05133\tvalid_1's multi_logloss: 1.06349           \n",
      "[5]\ttraining's multi_logloss: 0.941581\tvalid_1's multi_logloss: 0.955668         \n",
      "[6]\ttraining's multi_logloss: 0.850484\tvalid_1's multi_logloss: 0.866509         \n",
      "[7]\ttraining's multi_logloss: 0.773057\tvalid_1's multi_logloss: 0.791614         \n",
      "[8]\ttraining's multi_logloss: 0.707101\tvalid_1's multi_logloss: 0.72715          \n",
      "[9]\ttraining's multi_logloss: 0.650243\tvalid_1's multi_logloss: 0.672675         \n",
      "[10]\ttraining's multi_logloss: 0.601014\tvalid_1's multi_logloss: 0.625906        \n",
      "[11]\ttraining's multi_logloss: 0.558003\tvalid_1's multi_logloss: 0.585339        \n",
      "[12]\ttraining's multi_logloss: 0.520453\tvalid_1's multi_logloss: 0.550028        \n",
      "[13]\ttraining's multi_logloss: 0.487332\tvalid_1's multi_logloss: 0.519358        \n",
      "[14]\ttraining's multi_logloss: 0.457979\tvalid_1's multi_logloss: 0.492305        \n",
      "[15]\ttraining's multi_logloss: 0.431972\tvalid_1's multi_logloss: 0.468473        \n",
      "[16]\ttraining's multi_logloss: 0.40905\tvalid_1's multi_logloss: 0.447819         \n",
      "[17]\ttraining's multi_logloss: 0.387771\tvalid_1's multi_logloss: 0.429023        \n",
      "[18]\ttraining's multi_logloss: 0.368625\tvalid_1's multi_logloss: 0.411962        \n",
      "[19]\ttraining's multi_logloss: 0.351139\tvalid_1's multi_logloss: 0.396777        \n",
      "[20]\ttraining's multi_logloss: 0.335674\tvalid_1's multi_logloss: 0.384096        \n",
      "[21]\ttraining's multi_logloss: 0.321665\tvalid_1's multi_logloss: 0.372567        \n",
      "[22]\ttraining's multi_logloss: 0.308453\tvalid_1's multi_logloss: 0.361967        \n",
      "[23]\ttraining's multi_logloss: 0.296609\tvalid_1's multi_logloss: 0.352854        \n",
      "[24]\ttraining's multi_logloss: 0.285484\tvalid_1's multi_logloss: 0.344396        \n",
      "[25]\ttraining's multi_logloss: 0.275069\tvalid_1's multi_logloss: 0.337139        \n",
      "[26]\ttraining's multi_logloss: 0.265701\tvalid_1's multi_logloss: 0.330981        \n",
      "[27]\ttraining's multi_logloss: 0.25718\tvalid_1's multi_logloss: 0.325155         \n",
      "[28]\ttraining's multi_logloss: 0.249019\tvalid_1's multi_logloss: 0.32023         \n",
      "[29]\ttraining's multi_logloss: 0.241439\tvalid_1's multi_logloss: 0.314993        \n",
      "[30]\ttraining's multi_logloss: 0.234534\tvalid_1's multi_logloss: 0.310773        \n",
      "[31]\ttraining's multi_logloss: 0.227911\tvalid_1's multi_logloss: 0.306725        \n",
      "[32]\ttraining's multi_logloss: 0.221536\tvalid_1's multi_logloss: 0.302889        \n",
      "[33]\ttraining's multi_logloss: 0.215643\tvalid_1's multi_logloss: 0.299848        \n",
      "[34]\ttraining's multi_logloss: 0.209863\tvalid_1's multi_logloss: 0.297068        \n",
      "[35]\ttraining's multi_logloss: 0.204475\tvalid_1's multi_logloss: 0.294672        \n",
      "[36]\ttraining's multi_logloss: 0.199297\tvalid_1's multi_logloss: 0.292672        \n",
      "[37]\ttraining's multi_logloss: 0.194131\tvalid_1's multi_logloss: 0.29041         \n",
      "[38]\ttraining's multi_logloss: 0.189374\tvalid_1's multi_logloss: 0.289002        \n",
      "[39]\ttraining's multi_logloss: 0.184784\tvalid_1's multi_logloss: 0.287198        \n",
      "[40]\ttraining's multi_logloss: 0.180499\tvalid_1's multi_logloss: 0.28591         \n",
      "[41]\ttraining's multi_logloss: 0.176319\tvalid_1's multi_logloss: 0.28455         \n",
      "[42]\ttraining's multi_logloss: 0.172349\tvalid_1's multi_logloss: 0.283039        \n",
      "[43]\ttraining's multi_logloss: 0.168606\tvalid_1's multi_logloss: 0.281776        \n",
      "[44]\ttraining's multi_logloss: 0.164829\tvalid_1's multi_logloss: 0.280676        \n",
      "[45]\ttraining's multi_logloss: 0.161213\tvalid_1's multi_logloss: 0.280043        \n",
      "[46]\ttraining's multi_logloss: 0.157671\tvalid_1's multi_logloss: 0.279393        \n",
      "[47]\ttraining's multi_logloss: 0.154287\tvalid_1's multi_logloss: 0.27856         \n",
      "[48]\ttraining's multi_logloss: 0.150953\tvalid_1's multi_logloss: 0.277785        \n",
      "[49]\ttraining's multi_logloss: 0.147827\tvalid_1's multi_logloss: 0.277397        \n",
      "[50]\ttraining's multi_logloss: 0.144752\tvalid_1's multi_logloss: 0.276872        \n",
      "[51]\ttraining's multi_logloss: 0.141636\tvalid_1's multi_logloss: 0.276113        \n",
      "[52]\ttraining's multi_logloss: 0.138727\tvalid_1's multi_logloss: 0.275656        \n",
      "[53]\ttraining's multi_logloss: 0.136001\tvalid_1's multi_logloss: 0.27507         \n",
      "[54]\ttraining's multi_logloss: 0.133197\tvalid_1's multi_logloss: 0.274666        \n",
      "[55]\ttraining's multi_logloss: 0.130496\tvalid_1's multi_logloss: 0.274135        \n",
      "[56]\ttraining's multi_logloss: 0.127733\tvalid_1's multi_logloss: 0.273598        \n",
      "[57]\ttraining's multi_logloss: 0.125265\tvalid_1's multi_logloss: 0.273414        \n",
      "[58]\ttraining's multi_logloss: 0.122875\tvalid_1's multi_logloss: 0.273164        \n",
      "[59]\ttraining's multi_logloss: 0.120586\tvalid_1's multi_logloss: 0.272853        \n",
      "[60]\ttraining's multi_logloss: 0.118435\tvalid_1's multi_logloss: 0.272663        \n",
      "[61]\ttraining's multi_logloss: 0.116216\tvalid_1's multi_logloss: 0.27263         \n",
      "[62]\ttraining's multi_logloss: 0.1141\tvalid_1's multi_logloss: 0.272369          \n",
      "[63]\ttraining's multi_logloss: 0.11196\tvalid_1's multi_logloss: 0.272651         \n",
      "[64]\ttraining's multi_logloss: 0.109887\tvalid_1's multi_logloss: 0.272331        \n",
      "[65]\ttraining's multi_logloss: 0.107885\tvalid_1's multi_logloss: 0.272295        \n",
      "[66]\ttraining's multi_logloss: 0.105891\tvalid_1's multi_logloss: 0.272221        \n",
      "[67]\ttraining's multi_logloss: 0.104079\tvalid_1's multi_logloss: 0.272431        \n",
      "[68]\ttraining's multi_logloss: 0.1021\tvalid_1's multi_logloss: 0.272354          \n",
      "[69]\ttraining's multi_logloss: 0.100257\tvalid_1's multi_logloss: 0.272628        \n",
      "[70]\ttraining's multi_logloss: 0.0984183\tvalid_1's multi_logloss: 0.272646       \n",
      "[71]\ttraining's multi_logloss: 0.0965679\tvalid_1's multi_logloss: 0.273047       \n",
      "[72]\ttraining's multi_logloss: 0.0948932\tvalid_1's multi_logloss: 0.273447       \n",
      "[73]\ttraining's multi_logloss: 0.0932425\tvalid_1's multi_logloss: 0.274014       \n",
      "[74]\ttraining's multi_logloss: 0.0916282\tvalid_1's multi_logloss: 0.27441        \n",
      "[75]\ttraining's multi_logloss: 0.090095\tvalid_1's multi_logloss: 0.274606        \n",
      "[76]\ttraining's multi_logloss: 0.0885429\tvalid_1's multi_logloss: 0.274713       \n",
      "[77]\ttraining's multi_logloss: 0.0871645\tvalid_1's multi_logloss: 0.274807       \n",
      "[78]\ttraining's multi_logloss: 0.085689\tvalid_1's multi_logloss: 0.275073        \n",
      "[79]\ttraining's multi_logloss: 0.0841903\tvalid_1's multi_logloss: 0.275004       \n",
      "[80]\ttraining's multi_logloss: 0.0827926\tvalid_1's multi_logloss: 0.275512       \n",
      "[81]\ttraining's multi_logloss: 0.0814793\tvalid_1's multi_logloss: 0.275777       \n",
      "[82]\ttraining's multi_logloss: 0.0801295\tvalid_1's multi_logloss: 0.275898       \n",
      "[83]\ttraining's multi_logloss: 0.0787551\tvalid_1's multi_logloss: 0.276212       \n",
      "[84]\ttraining's multi_logloss: 0.0774215\tvalid_1's multi_logloss: 0.276545       \n",
      "[85]\ttraining's multi_logloss: 0.0761761\tvalid_1's multi_logloss: 0.276852       \n",
      "[86]\ttraining's multi_logloss: 0.074977\tvalid_1's multi_logloss: 0.277352        \n",
      "[87]\ttraining's multi_logloss: 0.0738145\tvalid_1's multi_logloss: 0.277662       \n",
      "[88]\ttraining's multi_logloss: 0.0727447\tvalid_1's multi_logloss: 0.278243       \n",
      "[89]\ttraining's multi_logloss: 0.0716708\tvalid_1's multi_logloss: 0.278661       \n",
      "[90]\ttraining's multi_logloss: 0.070474\tvalid_1's multi_logloss: 0.278885        \n",
      "[91]\ttraining's multi_logloss: 0.0694276\tvalid_1's multi_logloss: 0.279526       \n",
      "[92]\ttraining's multi_logloss: 0.0683394\tvalid_1's multi_logloss: 0.27989        \n",
      "[93]\ttraining's multi_logloss: 0.0673016\tvalid_1's multi_logloss: 0.280207       \n",
      "[94]\ttraining's multi_logloss: 0.0662776\tvalid_1's multi_logloss: 0.280438       \n",
      "[95]\ttraining's multi_logloss: 0.0653009\tvalid_1's multi_logloss: 0.280614       \n",
      "[96]\ttraining's multi_logloss: 0.0643472\tvalid_1's multi_logloss: 0.28083        \n",
      "Early stopping, best iteration is:                                               \n",
      "[66]\ttraining's multi_logloss: 0.105891\tvalid_1's multi_logloss: 0.272221\n",
      "[1]\ttraining's multi_logloss: 1.32647\tvalid_1's multi_logloss: 1.34073           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.03474\tvalid_1's multi_logloss: 1.0595            \n",
      "[3]\ttraining's multi_logloss: 0.846582\tvalid_1's multi_logloss: 0.879388         \n",
      "[4]\ttraining's multi_logloss: 0.711121\tvalid_1's multi_logloss: 0.750311         \n",
      "[5]\ttraining's multi_logloss: 0.609765\tvalid_1's multi_logloss: 0.654072         \n",
      "[6]\ttraining's multi_logloss: 0.530579\tvalid_1's multi_logloss: 0.580159         \n",
      "[7]\ttraining's multi_logloss: 0.46886\tvalid_1's multi_logloss: 0.523789          \n",
      "[8]\ttraining's multi_logloss: 0.419333\tvalid_1's multi_logloss: 0.478947         \n",
      "[9]\ttraining's multi_logloss: 0.378659\tvalid_1's multi_logloss: 0.442591         \n",
      "[10]\ttraining's multi_logloss: 0.345609\tvalid_1's multi_logloss: 0.414328        \n",
      "[11]\ttraining's multi_logloss: 0.317509\tvalid_1's multi_logloss: 0.39214         \n",
      "[12]\ttraining's multi_logloss: 0.294397\tvalid_1's multi_logloss: 0.374495        \n",
      "[13]\ttraining's multi_logloss: 0.274533\tvalid_1's multi_logloss: 0.35884         \n",
      "[14]\ttraining's multi_logloss: 0.257554\tvalid_1's multi_logloss: 0.347209        \n",
      "[15]\ttraining's multi_logloss: 0.242259\tvalid_1's multi_logloss: 0.338011        \n",
      "[16]\ttraining's multi_logloss: 0.228869\tvalid_1's multi_logloss: 0.3299          \n",
      "[17]\ttraining's multi_logloss: 0.216684\tvalid_1's multi_logloss: 0.32348         \n",
      "[18]\ttraining's multi_logloss: 0.205864\tvalid_1's multi_logloss: 0.318691        \n",
      "[19]\ttraining's multi_logloss: 0.195942\tvalid_1's multi_logloss: 0.313598        \n",
      "[20]\ttraining's multi_logloss: 0.186857\tvalid_1's multi_logloss: 0.310484        \n",
      "[21]\ttraining's multi_logloss: 0.177691\tvalid_1's multi_logloss: 0.306565        \n",
      "[22]\ttraining's multi_logloss: 0.169503\tvalid_1's multi_logloss: 0.302992        \n",
      "[23]\ttraining's multi_logloss: 0.162086\tvalid_1's multi_logloss: 0.302034        \n",
      "[24]\ttraining's multi_logloss: 0.155264\tvalid_1's multi_logloss: 0.300819        \n",
      "[25]\ttraining's multi_logloss: 0.148795\tvalid_1's multi_logloss: 0.298492        \n",
      "[26]\ttraining's multi_logloss: 0.142679\tvalid_1's multi_logloss: 0.297575        \n",
      "[27]\ttraining's multi_logloss: 0.136889\tvalid_1's multi_logloss: 0.296641        \n",
      "[28]\ttraining's multi_logloss: 0.131345\tvalid_1's multi_logloss: 0.29548         \n",
      "[29]\ttraining's multi_logloss: 0.125924\tvalid_1's multi_logloss: 0.295135        \n",
      "[30]\ttraining's multi_logloss: 0.121156\tvalid_1's multi_logloss: 0.294728        \n",
      "[31]\ttraining's multi_logloss: 0.116317\tvalid_1's multi_logloss: 0.2957          \n",
      "[32]\ttraining's multi_logloss: 0.112203\tvalid_1's multi_logloss: 0.296037        \n",
      "[33]\ttraining's multi_logloss: 0.10794\tvalid_1's multi_logloss: 0.296622         \n",
      "[34]\ttraining's multi_logloss: 0.103974\tvalid_1's multi_logloss: 0.296353        \n",
      "[35]\ttraining's multi_logloss: 0.100379\tvalid_1's multi_logloss: 0.296264        \n",
      "[36]\ttraining's multi_logloss: 0.0968134\tvalid_1's multi_logloss: 0.296257       \n",
      "[37]\ttraining's multi_logloss: 0.0935387\tvalid_1's multi_logloss: 0.296469       \n",
      "[38]\ttraining's multi_logloss: 0.0904257\tvalid_1's multi_logloss: 0.297595       \n",
      "[39]\ttraining's multi_logloss: 0.0872464\tvalid_1's multi_logloss: 0.297968       \n",
      "[40]\ttraining's multi_logloss: 0.084235\tvalid_1's multi_logloss: 0.299073        \n",
      "[41]\ttraining's multi_logloss: 0.0813582\tvalid_1's multi_logloss: 0.299817       \n",
      "[42]\ttraining's multi_logloss: 0.0786956\tvalid_1's multi_logloss: 0.300378       \n",
      "[43]\ttraining's multi_logloss: 0.076159\tvalid_1's multi_logloss: 0.300396        \n",
      "[44]\ttraining's multi_logloss: 0.0736476\tvalid_1's multi_logloss: 0.300795       \n",
      "[45]\ttraining's multi_logloss: 0.0713543\tvalid_1's multi_logloss: 0.301415       \n",
      "[46]\ttraining's multi_logloss: 0.0691184\tvalid_1's multi_logloss: 0.302409       \n",
      "[47]\ttraining's multi_logloss: 0.0671917\tvalid_1's multi_logloss: 0.303598       \n",
      "[48]\ttraining's multi_logloss: 0.0650668\tvalid_1's multi_logloss: 0.304144       \n",
      "[49]\ttraining's multi_logloss: 0.0631972\tvalid_1's multi_logloss: 0.305447       \n",
      "[50]\ttraining's multi_logloss: 0.0613089\tvalid_1's multi_logloss: 0.305987       \n",
      "[51]\ttraining's multi_logloss: 0.0595329\tvalid_1's multi_logloss: 0.307457       \n",
      "[52]\ttraining's multi_logloss: 0.0576146\tvalid_1's multi_logloss: 0.308516       \n",
      "[53]\ttraining's multi_logloss: 0.0556178\tvalid_1's multi_logloss: 0.309759       \n",
      "[54]\ttraining's multi_logloss: 0.0538318\tvalid_1's multi_logloss: 0.310398       \n",
      "[55]\ttraining's multi_logloss: 0.0520779\tvalid_1's multi_logloss: 0.311602       \n",
      "[56]\ttraining's multi_logloss: 0.0505029\tvalid_1's multi_logloss: 0.312772       \n",
      "[57]\ttraining's multi_logloss: 0.048994\tvalid_1's multi_logloss: 0.314259        \n",
      "[58]\ttraining's multi_logloss: 0.047474\tvalid_1's multi_logloss: 0.315865        \n",
      "[59]\ttraining's multi_logloss: 0.046222\tvalid_1's multi_logloss: 0.316817        \n",
      "[60]\ttraining's multi_logloss: 0.0449162\tvalid_1's multi_logloss: 0.317785       \n",
      "Early stopping, best iteration is:                                               \n",
      "[30]\ttraining's multi_logloss: 0.121156\tvalid_1's multi_logloss: 0.294728\n",
      "[1]\ttraining's multi_logloss: 1.32335\tvalid_1's multi_logloss: 1.33083           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.03681\tvalid_1's multi_logloss: 1.04924           \n",
      "[3]\ttraining's multi_logloss: 0.848791\tvalid_1's multi_logloss: 0.868281         \n",
      "[4]\ttraining's multi_logloss: 0.713569\tvalid_1's multi_logloss: 0.738404         \n",
      "[5]\ttraining's multi_logloss: 0.611761\tvalid_1's multi_logloss: 0.641809         \n",
      "[6]\ttraining's multi_logloss: 0.53295\tvalid_1's multi_logloss: 0.567516          \n",
      "[7]\ttraining's multi_logloss: 0.471008\tvalid_1's multi_logloss: 0.510202         \n",
      "[8]\ttraining's multi_logloss: 0.42152\tvalid_1's multi_logloss: 0.466169          \n",
      "[9]\ttraining's multi_logloss: 0.381588\tvalid_1's multi_logloss: 0.431883         \n",
      "[10]\ttraining's multi_logloss: 0.348517\tvalid_1's multi_logloss: 0.404228        \n",
      "[11]\ttraining's multi_logloss: 0.320386\tvalid_1's multi_logloss: 0.382338        \n",
      "[12]\ttraining's multi_logloss: 0.296528\tvalid_1's multi_logloss: 0.364012        \n",
      "[13]\ttraining's multi_logloss: 0.27662\tvalid_1's multi_logloss: 0.349847         \n",
      "[14]\ttraining's multi_logloss: 0.258729\tvalid_1's multi_logloss: 0.337536        \n",
      "[15]\ttraining's multi_logloss: 0.243049\tvalid_1's multi_logloss: 0.327741        \n",
      "[16]\ttraining's multi_logloss: 0.229815\tvalid_1's multi_logloss: 0.320213        \n",
      "[17]\ttraining's multi_logloss: 0.21755\tvalid_1's multi_logloss: 0.313654         \n",
      "[18]\ttraining's multi_logloss: 0.206077\tvalid_1's multi_logloss: 0.307761        \n",
      "[19]\ttraining's multi_logloss: 0.196222\tvalid_1's multi_logloss: 0.304053        \n",
      "[20]\ttraining's multi_logloss: 0.186713\tvalid_1's multi_logloss: 0.30065         \n",
      "[21]\ttraining's multi_logloss: 0.178062\tvalid_1's multi_logloss: 0.298232        \n",
      "[22]\ttraining's multi_logloss: 0.169741\tvalid_1's multi_logloss: 0.295833        \n",
      "[23]\ttraining's multi_logloss: 0.162155\tvalid_1's multi_logloss: 0.29444         \n",
      "[24]\ttraining's multi_logloss: 0.155253\tvalid_1's multi_logloss: 0.293315        \n",
      "[25]\ttraining's multi_logloss: 0.148909\tvalid_1's multi_logloss: 0.292142        \n",
      "[26]\ttraining's multi_logloss: 0.142469\tvalid_1's multi_logloss: 0.291872        \n",
      "[27]\ttraining's multi_logloss: 0.136525\tvalid_1's multi_logloss: 0.29077         \n",
      "[28]\ttraining's multi_logloss: 0.130798\tvalid_1's multi_logloss: 0.290847        \n",
      "[29]\ttraining's multi_logloss: 0.125274\tvalid_1's multi_logloss: 0.290486        \n",
      "[30]\ttraining's multi_logloss: 0.12019\tvalid_1's multi_logloss: 0.290385         \n",
      "[31]\ttraining's multi_logloss: 0.115061\tvalid_1's multi_logloss: 0.290482        \n",
      "[32]\ttraining's multi_logloss: 0.110634\tvalid_1's multi_logloss: 0.290913        \n",
      "[33]\ttraining's multi_logloss: 0.10615\tvalid_1's multi_logloss: 0.291711         \n",
      "[34]\ttraining's multi_logloss: 0.102222\tvalid_1's multi_logloss: 0.292329        \n",
      "[35]\ttraining's multi_logloss: 0.0986367\tvalid_1's multi_logloss: 0.293685       \n",
      "[36]\ttraining's multi_logloss: 0.0949332\tvalid_1's multi_logloss: 0.293615       \n",
      "[37]\ttraining's multi_logloss: 0.0915002\tvalid_1's multi_logloss: 0.294664       \n",
      "[38]\ttraining's multi_logloss: 0.0879525\tvalid_1's multi_logloss: 0.294595       \n",
      "[39]\ttraining's multi_logloss: 0.0848349\tvalid_1's multi_logloss: 0.295201       \n",
      "[40]\ttraining's multi_logloss: 0.0819941\tvalid_1's multi_logloss: 0.296252       \n",
      "[41]\ttraining's multi_logloss: 0.0792086\tvalid_1's multi_logloss: 0.297084       \n",
      "[42]\ttraining's multi_logloss: 0.0766102\tvalid_1's multi_logloss: 0.297028       \n",
      "[43]\ttraining's multi_logloss: 0.0740525\tvalid_1's multi_logloss: 0.298032       \n",
      "[44]\ttraining's multi_logloss: 0.0715389\tvalid_1's multi_logloss: 0.298029       \n",
      "[45]\ttraining's multi_logloss: 0.0691657\tvalid_1's multi_logloss: 0.298332       \n",
      "[46]\ttraining's multi_logloss: 0.0669681\tvalid_1's multi_logloss: 0.299174       \n",
      "[47]\ttraining's multi_logloss: 0.06496\tvalid_1's multi_logloss: 0.299672         \n",
      "[48]\ttraining's multi_logloss: 0.0627739\tvalid_1's multi_logloss: 0.299655       \n",
      "[49]\ttraining's multi_logloss: 0.060801\tvalid_1's multi_logloss: 0.300704        \n",
      "[50]\ttraining's multi_logloss: 0.059066\tvalid_1's multi_logloss: 0.301562        \n",
      "[51]\ttraining's multi_logloss: 0.0572719\tvalid_1's multi_logloss: 0.302829       \n",
      "[52]\ttraining's multi_logloss: 0.055522\tvalid_1's multi_logloss: 0.304156        \n",
      "[53]\ttraining's multi_logloss: 0.0536568\tvalid_1's multi_logloss: 0.305228       \n",
      "[54]\ttraining's multi_logloss: 0.0519244\tvalid_1's multi_logloss: 0.30616        \n",
      "[55]\ttraining's multi_logloss: 0.0502611\tvalid_1's multi_logloss: 0.307635       \n",
      "[56]\ttraining's multi_logloss: 0.0487709\tvalid_1's multi_logloss: 0.308587       \n",
      "[57]\ttraining's multi_logloss: 0.0473076\tvalid_1's multi_logloss: 0.310237       \n",
      "[58]\ttraining's multi_logloss: 0.0458705\tvalid_1's multi_logloss: 0.311394       \n",
      "[59]\ttraining's multi_logloss: 0.0444602\tvalid_1's multi_logloss: 0.312961       \n",
      "[60]\ttraining's multi_logloss: 0.0431633\tvalid_1's multi_logloss: 0.313882       \n",
      "Early stopping, best iteration is:                                               \n",
      "[30]\ttraining's multi_logloss: 0.12019\tvalid_1's multi_logloss: 0.290385\n",
      "[1]\ttraining's multi_logloss: 1.32606\tvalid_1's multi_logloss: 1.33266           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.04002\tvalid_1's multi_logloss: 1.05017           \n",
      "[3]\ttraining's multi_logloss: 0.850543\tvalid_1's multi_logloss: 0.864564         \n",
      "[4]\ttraining's multi_logloss: 0.715649\tvalid_1's multi_logloss: 0.733286         \n",
      "[5]\ttraining's multi_logloss: 0.614257\tvalid_1's multi_logloss: 0.635513         \n",
      "[6]\ttraining's multi_logloss: 0.536496\tvalid_1's multi_logloss: 0.562699         \n",
      "[7]\ttraining's multi_logloss: 0.475567\tvalid_1's multi_logloss: 0.505837         \n",
      "[8]\ttraining's multi_logloss: 0.426831\tvalid_1's multi_logloss: 0.46118          \n",
      "[9]\ttraining's multi_logloss: 0.386962\tvalid_1's multi_logloss: 0.42604          \n",
      "[10]\ttraining's multi_logloss: 0.354192\tvalid_1's multi_logloss: 0.397532        \n",
      "[11]\ttraining's multi_logloss: 0.326017\tvalid_1's multi_logloss: 0.374319        \n",
      "[12]\ttraining's multi_logloss: 0.302103\tvalid_1's multi_logloss: 0.355258        \n",
      "[13]\ttraining's multi_logloss: 0.282218\tvalid_1's multi_logloss: 0.340715        \n",
      "[14]\ttraining's multi_logloss: 0.264933\tvalid_1's multi_logloss: 0.328624        \n",
      "[15]\ttraining's multi_logloss: 0.249135\tvalid_1's multi_logloss: 0.318479        \n",
      "[16]\ttraining's multi_logloss: 0.235477\tvalid_1's multi_logloss: 0.310045        \n",
      "[17]\ttraining's multi_logloss: 0.22312\tvalid_1's multi_logloss: 0.303961         \n",
      "[18]\ttraining's multi_logloss: 0.211928\tvalid_1's multi_logloss: 0.29822         \n",
      "[19]\ttraining's multi_logloss: 0.201801\tvalid_1's multi_logloss: 0.293551        \n",
      "[20]\ttraining's multi_logloss: 0.192079\tvalid_1's multi_logloss: 0.289483        \n",
      "[21]\ttraining's multi_logloss: 0.183662\tvalid_1's multi_logloss: 0.286614        \n",
      "[22]\ttraining's multi_logloss: 0.175655\tvalid_1's multi_logloss: 0.284103        \n",
      "[23]\ttraining's multi_logloss: 0.167881\tvalid_1's multi_logloss: 0.281874        \n",
      "[24]\ttraining's multi_logloss: 0.16068\tvalid_1's multi_logloss: 0.280112         \n",
      "[25]\ttraining's multi_logloss: 0.154145\tvalid_1's multi_logloss: 0.279444        \n",
      "[26]\ttraining's multi_logloss: 0.147826\tvalid_1's multi_logloss: 0.277982        \n",
      "[27]\ttraining's multi_logloss: 0.14185\tvalid_1's multi_logloss: 0.276925         \n",
      "[28]\ttraining's multi_logloss: 0.136366\tvalid_1's multi_logloss: 0.276281        \n",
      "[29]\ttraining's multi_logloss: 0.130942\tvalid_1's multi_logloss: 0.276108        \n",
      "[30]\ttraining's multi_logloss: 0.125677\tvalid_1's multi_logloss: 0.275608        \n",
      "[31]\ttraining's multi_logloss: 0.120606\tvalid_1's multi_logloss: 0.27517         \n",
      "[32]\ttraining's multi_logloss: 0.116173\tvalid_1's multi_logloss: 0.274462        \n",
      "[33]\ttraining's multi_logloss: 0.111693\tvalid_1's multi_logloss: 0.27442         \n",
      "[34]\ttraining's multi_logloss: 0.107659\tvalid_1's multi_logloss: 0.274534        \n",
      "[35]\ttraining's multi_logloss: 0.103994\tvalid_1's multi_logloss: 0.27414         \n",
      "[36]\ttraining's multi_logloss: 0.100108\tvalid_1's multi_logloss: 0.274505        \n",
      "[37]\ttraining's multi_logloss: 0.0963843\tvalid_1's multi_logloss: 0.274098       \n",
      "[38]\ttraining's multi_logloss: 0.0931245\tvalid_1's multi_logloss: 0.274288       \n",
      "[39]\ttraining's multi_logloss: 0.0895945\tvalid_1's multi_logloss: 0.274255       \n",
      "[40]\ttraining's multi_logloss: 0.0865273\tvalid_1's multi_logloss: 0.274544       \n",
      "[41]\ttraining's multi_logloss: 0.0837749\tvalid_1's multi_logloss: 0.275138       \n",
      "[42]\ttraining's multi_logloss: 0.0809699\tvalid_1's multi_logloss: 0.276119       \n",
      "[43]\ttraining's multi_logloss: 0.0782652\tvalid_1's multi_logloss: 0.27718        \n",
      "[44]\ttraining's multi_logloss: 0.0756917\tvalid_1's multi_logloss: 0.277771       \n",
      "[45]\ttraining's multi_logloss: 0.0731645\tvalid_1's multi_logloss: 0.278372       \n",
      "[46]\ttraining's multi_logloss: 0.0709132\tvalid_1's multi_logloss: 0.279035       \n",
      "[47]\ttraining's multi_logloss: 0.0686509\tvalid_1's multi_logloss: 0.279633       \n",
      "[48]\ttraining's multi_logloss: 0.0665331\tvalid_1's multi_logloss: 0.280403       \n",
      "[49]\ttraining's multi_logloss: 0.0645548\tvalid_1's multi_logloss: 0.28129        \n",
      "[50]\ttraining's multi_logloss: 0.062623\tvalid_1's multi_logloss: 0.281906        \n",
      "[51]\ttraining's multi_logloss: 0.0607004\tvalid_1's multi_logloss: 0.282626       \n",
      "[52]\ttraining's multi_logloss: 0.0590652\tvalid_1's multi_logloss: 0.283493       \n",
      "[53]\ttraining's multi_logloss: 0.0572602\tvalid_1's multi_logloss: 0.284242       \n",
      "[54]\ttraining's multi_logloss: 0.0556425\tvalid_1's multi_logloss: 0.285491       \n",
      "[55]\ttraining's multi_logloss: 0.0537605\tvalid_1's multi_logloss: 0.286389       \n",
      "[56]\ttraining's multi_logloss: 0.0522888\tvalid_1's multi_logloss: 0.287031       \n",
      "[57]\ttraining's multi_logloss: 0.0507322\tvalid_1's multi_logloss: 0.287446       \n",
      "[58]\ttraining's multi_logloss: 0.0493653\tvalid_1's multi_logloss: 0.288351       \n",
      "[59]\ttraining's multi_logloss: 0.047857\tvalid_1's multi_logloss: 0.289013        \n",
      "[60]\ttraining's multi_logloss: 0.0464197\tvalid_1's multi_logloss: 0.289984       \n",
      "[61]\ttraining's multi_logloss: 0.0450929\tvalid_1's multi_logloss: 0.290745       \n",
      "[62]\ttraining's multi_logloss: 0.0437843\tvalid_1's multi_logloss: 0.292038       \n",
      "[63]\ttraining's multi_logloss: 0.0423692\tvalid_1's multi_logloss: 0.29268        \n",
      "[64]\ttraining's multi_logloss: 0.041127\tvalid_1's multi_logloss: 0.293808        \n",
      "[65]\ttraining's multi_logloss: 0.0400074\tvalid_1's multi_logloss: 0.29499        \n",
      "[66]\ttraining's multi_logloss: 0.0388719\tvalid_1's multi_logloss: 0.295796       \n",
      "[67]\ttraining's multi_logloss: 0.0377231\tvalid_1's multi_logloss: 0.296889       \n",
      "Early stopping, best iteration is:                                               \n",
      "[37]\ttraining's multi_logloss: 0.0963843\tvalid_1's multi_logloss: 0.274098\n",
      "[1]\ttraining's multi_logloss: 1.71301\tvalid_1's multi_logloss: 1.71556           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.54285\tvalid_1's multi_logloss: 1.54983           \n",
      "[3]\ttraining's multi_logloss: 1.40567\tvalid_1's multi_logloss: 1.41636           \n",
      "[4]\ttraining's multi_logloss: 1.28955\tvalid_1's multi_logloss: 1.30382           \n",
      "[5]\ttraining's multi_logloss: 1.19064\tvalid_1's multi_logloss: 1.20795           \n",
      "[6]\ttraining's multi_logloss: 1.1053\tvalid_1's multi_logloss: 1.12564            \n",
      "[7]\ttraining's multi_logloss: 1.03046\tvalid_1's multi_logloss: 1.05324           \n",
      "[8]\ttraining's multi_logloss: 0.964049\tvalid_1's multi_logloss: 0.989366         \n",
      "[9]\ttraining's multi_logloss: 0.904447\tvalid_1's multi_logloss: 0.932116         \n",
      "[10]\ttraining's multi_logloss: 0.850804\tvalid_1's multi_logloss: 0.88052         \n",
      "[11]\ttraining's multi_logloss: 0.802001\tvalid_1's multi_logloss: 0.833316        \n",
      "[12]\ttraining's multi_logloss: 0.757573\tvalid_1's multi_logloss: 0.790542        \n",
      "[13]\ttraining's multi_logloss: 0.7173\tvalid_1's multi_logloss: 0.752062          \n",
      "[14]\ttraining's multi_logloss: 0.680872\tvalid_1's multi_logloss: 0.717436        \n",
      "[15]\ttraining's multi_logloss: 0.647363\tvalid_1's multi_logloss: 0.685585        \n",
      "[16]\ttraining's multi_logloss: 0.61627\tvalid_1's multi_logloss: 0.656247         \n",
      "[17]\ttraining's multi_logloss: 0.587533\tvalid_1's multi_logloss: 0.629179        \n",
      "[18]\ttraining's multi_logloss: 0.561528\tvalid_1's multi_logloss: 0.604828        \n",
      "[19]\ttraining's multi_logloss: 0.537269\tvalid_1's multi_logloss: 0.582057        \n",
      "[20]\ttraining's multi_logloss: 0.51522\tvalid_1's multi_logloss: 0.561514         \n",
      "[21]\ttraining's multi_logloss: 0.494801\tvalid_1's multi_logloss: 0.542365        \n",
      "[22]\ttraining's multi_logloss: 0.475549\tvalid_1's multi_logloss: 0.524817        \n",
      "[23]\ttraining's multi_logloss: 0.457696\tvalid_1's multi_logloss: 0.508484        \n",
      "[24]\ttraining's multi_logloss: 0.440852\tvalid_1's multi_logloss: 0.493259        \n",
      "[25]\ttraining's multi_logloss: 0.425404\tvalid_1's multi_logloss: 0.479256        \n",
      "[26]\ttraining's multi_logloss: 0.410837\tvalid_1's multi_logloss: 0.466415        \n",
      "[27]\ttraining's multi_logloss: 0.397336\tvalid_1's multi_logloss: 0.454334        \n",
      "[28]\ttraining's multi_logloss: 0.384727\tvalid_1's multi_logloss: 0.443132        \n",
      "[29]\ttraining's multi_logloss: 0.373001\tvalid_1's multi_logloss: 0.432705        \n",
      "[30]\ttraining's multi_logloss: 0.361974\tvalid_1's multi_logloss: 0.422899        \n",
      "[31]\ttraining's multi_logloss: 0.351629\tvalid_1's multi_logloss: 0.413798        \n",
      "[32]\ttraining's multi_logloss: 0.342101\tvalid_1's multi_logloss: 0.405848        \n",
      "[33]\ttraining's multi_logloss: 0.333047\tvalid_1's multi_logloss: 0.398392        \n",
      "[34]\ttraining's multi_logloss: 0.324107\tvalid_1's multi_logloss: 0.391206        \n",
      "[35]\ttraining's multi_logloss: 0.315891\tvalid_1's multi_logloss: 0.384564        \n",
      "[36]\ttraining's multi_logloss: 0.308054\tvalid_1's multi_logloss: 0.378183        \n",
      "[37]\ttraining's multi_logloss: 0.300652\tvalid_1's multi_logloss: 0.372378        \n",
      "[38]\ttraining's multi_logloss: 0.293876\tvalid_1's multi_logloss: 0.367087        \n",
      "[39]\ttraining's multi_logloss: 0.287153\tvalid_1's multi_logloss: 0.362118        \n",
      "[40]\ttraining's multi_logloss: 0.280878\tvalid_1's multi_logloss: 0.357473        \n",
      "[41]\ttraining's multi_logloss: 0.274665\tvalid_1's multi_logloss: 0.35292         \n",
      "[42]\ttraining's multi_logloss: 0.268856\tvalid_1's multi_logloss: 0.348892        \n",
      "[43]\ttraining's multi_logloss: 0.263216\tvalid_1's multi_logloss: 0.34507         \n",
      "[44]\ttraining's multi_logloss: 0.25802\tvalid_1's multi_logloss: 0.34174          \n",
      "[45]\ttraining's multi_logloss: 0.25295\tvalid_1's multi_logloss: 0.338713         \n",
      "[46]\ttraining's multi_logloss: 0.248022\tvalid_1's multi_logloss: 0.335374        \n",
      "[47]\ttraining's multi_logloss: 0.243267\tvalid_1's multi_logloss: 0.332446        \n",
      "[48]\ttraining's multi_logloss: 0.23875\tvalid_1's multi_logloss: 0.329791         \n",
      "[49]\ttraining's multi_logloss: 0.234488\tvalid_1's multi_logloss: 0.327147        \n",
      "[50]\ttraining's multi_logloss: 0.230418\tvalid_1's multi_logloss: 0.324816        \n",
      "[51]\ttraining's multi_logloss: 0.226372\tvalid_1's multi_logloss: 0.322565        \n",
      "[52]\ttraining's multi_logloss: 0.222288\tvalid_1's multi_logloss: 0.320277        \n",
      "[53]\ttraining's multi_logloss: 0.218336\tvalid_1's multi_logloss: 0.318059        \n",
      "[54]\ttraining's multi_logloss: 0.214689\tvalid_1's multi_logloss: 0.316108        \n",
      "[55]\ttraining's multi_logloss: 0.211051\tvalid_1's multi_logloss: 0.314428        \n",
      "[56]\ttraining's multi_logloss: 0.207536\tvalid_1's multi_logloss: 0.312939        \n",
      "[57]\ttraining's multi_logloss: 0.204099\tvalid_1's multi_logloss: 0.31132         \n",
      "[58]\ttraining's multi_logloss: 0.200674\tvalid_1's multi_logloss: 0.309697        \n",
      "[59]\ttraining's multi_logloss: 0.197548\tvalid_1's multi_logloss: 0.308539        \n",
      "[60]\ttraining's multi_logloss: 0.194401\tvalid_1's multi_logloss: 0.30715         \n",
      "[61]\ttraining's multi_logloss: 0.191341\tvalid_1's multi_logloss: 0.306028        \n",
      "[62]\ttraining's multi_logloss: 0.18849\tvalid_1's multi_logloss: 0.304925         \n",
      "[63]\ttraining's multi_logloss: 0.185433\tvalid_1's multi_logloss: 0.30379         \n",
      "[64]\ttraining's multi_logloss: 0.182634\tvalid_1's multi_logloss: 0.302754        \n",
      "[65]\ttraining's multi_logloss: 0.179878\tvalid_1's multi_logloss: 0.301931        \n",
      "[66]\ttraining's multi_logloss: 0.177243\tvalid_1's multi_logloss: 0.301111        \n",
      "[67]\ttraining's multi_logloss: 0.174527\tvalid_1's multi_logloss: 0.300182        \n",
      "[68]\ttraining's multi_logloss: 0.171967\tvalid_1's multi_logloss: 0.299241        \n",
      "[69]\ttraining's multi_logloss: 0.169421\tvalid_1's multi_logloss: 0.298691        \n",
      "[70]\ttraining's multi_logloss: 0.166953\tvalid_1's multi_logloss: 0.298097        \n",
      "[71]\ttraining's multi_logloss: 0.164548\tvalid_1's multi_logloss: 0.297608        \n",
      "[72]\ttraining's multi_logloss: 0.162176\tvalid_1's multi_logloss: 0.297189        \n",
      "[73]\ttraining's multi_logloss: 0.159816\tvalid_1's multi_logloss: 0.296445        \n",
      "[74]\ttraining's multi_logloss: 0.157667\tvalid_1's multi_logloss: 0.295827        \n",
      "[75]\ttraining's multi_logloss: 0.155524\tvalid_1's multi_logloss: 0.295546        \n",
      "[76]\ttraining's multi_logloss: 0.153486\tvalid_1's multi_logloss: 0.295105        \n",
      "[77]\ttraining's multi_logloss: 0.15141\tvalid_1's multi_logloss: 0.294543         \n",
      "[78]\ttraining's multi_logloss: 0.149355\tvalid_1's multi_logloss: 0.294119        \n",
      "[79]\ttraining's multi_logloss: 0.147262\tvalid_1's multi_logloss: 0.293637        \n",
      "[80]\ttraining's multi_logloss: 0.145268\tvalid_1's multi_logloss: 0.293172        \n",
      "[81]\ttraining's multi_logloss: 0.143281\tvalid_1's multi_logloss: 0.292841        \n",
      "[82]\ttraining's multi_logloss: 0.141367\tvalid_1's multi_logloss: 0.292493        \n",
      "[83]\ttraining's multi_logloss: 0.139378\tvalid_1's multi_logloss: 0.292024        \n",
      "[84]\ttraining's multi_logloss: 0.137515\tvalid_1's multi_logloss: 0.29176         \n",
      "[85]\ttraining's multi_logloss: 0.135663\tvalid_1's multi_logloss: 0.291554        \n",
      "[86]\ttraining's multi_logloss: 0.133825\tvalid_1's multi_logloss: 0.291297        \n",
      "[87]\ttraining's multi_logloss: 0.132111\tvalid_1's multi_logloss: 0.291211        \n",
      "[88]\ttraining's multi_logloss: 0.130279\tvalid_1's multi_logloss: 0.290665        \n",
      "[89]\ttraining's multi_logloss: 0.128492\tvalid_1's multi_logloss: 0.290432        \n",
      "[90]\ttraining's multi_logloss: 0.12687\tvalid_1's multi_logloss: 0.290367         \n",
      "[91]\ttraining's multi_logloss: 0.125102\tvalid_1's multi_logloss: 0.290121        \n",
      "[92]\ttraining's multi_logloss: 0.123534\tvalid_1's multi_logloss: 0.28986         \n",
      "[93]\ttraining's multi_logloss: 0.121908\tvalid_1's multi_logloss: 0.289869        \n",
      "[94]\ttraining's multi_logloss: 0.120222\tvalid_1's multi_logloss: 0.289869        \n",
      "[95]\ttraining's multi_logloss: 0.118602\tvalid_1's multi_logloss: 0.289708        \n",
      "[96]\ttraining's multi_logloss: 0.117083\tvalid_1's multi_logloss: 0.289664        \n",
      "[97]\ttraining's multi_logloss: 0.115381\tvalid_1's multi_logloss: 0.2897          \n",
      "[98]\ttraining's multi_logloss: 0.113684\tvalid_1's multi_logloss: 0.289555        \n",
      "[99]\ttraining's multi_logloss: 0.112148\tvalid_1's multi_logloss: 0.289637        \n",
      "[100]\ttraining's multi_logloss: 0.110739\tvalid_1's multi_logloss: 0.289479       \n",
      "[101]\ttraining's multi_logloss: 0.109407\tvalid_1's multi_logloss: 0.289441       \n",
      "[102]\ttraining's multi_logloss: 0.108016\tvalid_1's multi_logloss: 0.289468       \n",
      "[103]\ttraining's multi_logloss: 0.106705\tvalid_1's multi_logloss: 0.28948        \n",
      "[104]\ttraining's multi_logloss: 0.105301\tvalid_1's multi_logloss: 0.28929        \n",
      "[105]\ttraining's multi_logloss: 0.103935\tvalid_1's multi_logloss: 0.289477       \n",
      "[106]\ttraining's multi_logloss: 0.102585\tvalid_1's multi_logloss: 0.289525       \n",
      "[107]\ttraining's multi_logloss: 0.101273\tvalid_1's multi_logloss: 0.289703       \n",
      "[108]\ttraining's multi_logloss: 0.0999559\tvalid_1's multi_logloss: 0.28973       \n",
      "[109]\ttraining's multi_logloss: 0.0985847\tvalid_1's multi_logloss: 0.289757      \n",
      "[110]\ttraining's multi_logloss: 0.0973584\tvalid_1's multi_logloss: 0.289989      \n",
      "[111]\ttraining's multi_logloss: 0.0960779\tvalid_1's multi_logloss: 0.290123      \n",
      "[112]\ttraining's multi_logloss: 0.0947796\tvalid_1's multi_logloss: 0.29044       \n",
      "[113]\ttraining's multi_logloss: 0.0935299\tvalid_1's multi_logloss: 0.290631      \n",
      "[114]\ttraining's multi_logloss: 0.0923299\tvalid_1's multi_logloss: 0.291064      \n",
      "[115]\ttraining's multi_logloss: 0.091133\tvalid_1's multi_logloss: 0.291257       \n",
      "[116]\ttraining's multi_logloss: 0.0899301\tvalid_1's multi_logloss: 0.291343      \n",
      "[117]\ttraining's multi_logloss: 0.0886872\tvalid_1's multi_logloss: 0.291393      \n",
      "[118]\ttraining's multi_logloss: 0.0875114\tvalid_1's multi_logloss: 0.291431      \n",
      "[119]\ttraining's multi_logloss: 0.0864297\tvalid_1's multi_logloss: 0.291596      \n",
      "[120]\ttraining's multi_logloss: 0.0853852\tvalid_1's multi_logloss: 0.291769      \n",
      "[121]\ttraining's multi_logloss: 0.0843519\tvalid_1's multi_logloss: 0.292006      \n",
      "[122]\ttraining's multi_logloss: 0.0832749\tvalid_1's multi_logloss: 0.292183      \n",
      "[123]\ttraining's multi_logloss: 0.0823002\tvalid_1's multi_logloss: 0.292369      \n",
      "[124]\ttraining's multi_logloss: 0.0813224\tvalid_1's multi_logloss: 0.292583      \n",
      "[125]\ttraining's multi_logloss: 0.080311\tvalid_1's multi_logloss: 0.292826       \n",
      "[126]\ttraining's multi_logloss: 0.0793654\tvalid_1's multi_logloss: 0.29304       \n",
      "[127]\ttraining's multi_logloss: 0.0784556\tvalid_1's multi_logloss: 0.293549      \n",
      "[128]\ttraining's multi_logloss: 0.0774947\tvalid_1's multi_logloss: 0.293774      \n",
      "[129]\ttraining's multi_logloss: 0.0765401\tvalid_1's multi_logloss: 0.29391       \n",
      "[130]\ttraining's multi_logloss: 0.0756575\tvalid_1's multi_logloss: 0.294231      \n",
      "[131]\ttraining's multi_logloss: 0.0747489\tvalid_1's multi_logloss: 0.294295      \n",
      "[132]\ttraining's multi_logloss: 0.0738988\tvalid_1's multi_logloss: 0.294436      \n",
      "[133]\ttraining's multi_logloss: 0.0729982\tvalid_1's multi_logloss: 0.29471       \n",
      "[134]\ttraining's multi_logloss: 0.0722266\tvalid_1's multi_logloss: 0.294895      \n",
      "Early stopping, best iteration is:                                               \n",
      "[104]\ttraining's multi_logloss: 0.105301\tvalid_1's multi_logloss: 0.28929\n",
      "[1]\ttraining's multi_logloss: 1.711\tvalid_1's multi_logloss: 1.71466             \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.54342\tvalid_1's multi_logloss: 1.54821           \n",
      "[3]\ttraining's multi_logloss: 1.40699\tvalid_1's multi_logloss: 1.41288           \n",
      "[4]\ttraining's multi_logloss: 1.29312\tvalid_1's multi_logloss: 1.30084           \n",
      "[5]\ttraining's multi_logloss: 1.19568\tvalid_1's multi_logloss: 1.20553           \n",
      "[6]\ttraining's multi_logloss: 1.1103\tvalid_1's multi_logloss: 1.12166            \n",
      "[7]\ttraining's multi_logloss: 1.03532\tvalid_1's multi_logloss: 1.04799           \n",
      "[8]\ttraining's multi_logloss: 0.969082\tvalid_1's multi_logloss: 0.983769         \n",
      "[9]\ttraining's multi_logloss: 0.910235\tvalid_1's multi_logloss: 0.926502         \n",
      "[10]\ttraining's multi_logloss: 0.856669\tvalid_1's multi_logloss: 0.874464        \n",
      "[11]\ttraining's multi_logloss: 0.808234\tvalid_1's multi_logloss: 0.827636        \n",
      "[12]\ttraining's multi_logloss: 0.763903\tvalid_1's multi_logloss: 0.784773        \n",
      "[13]\ttraining's multi_logloss: 0.724164\tvalid_1's multi_logloss: 0.746559        \n",
      "[14]\ttraining's multi_logloss: 0.687351\tvalid_1's multi_logloss: 0.711276        \n",
      "[15]\ttraining's multi_logloss: 0.653511\tvalid_1's multi_logloss: 0.679008        \n",
      "[16]\ttraining's multi_logloss: 0.622416\tvalid_1's multi_logloss: 0.649742        \n",
      "[17]\ttraining's multi_logloss: 0.593732\tvalid_1's multi_logloss: 0.622445        \n",
      "[18]\ttraining's multi_logloss: 0.567166\tvalid_1's multi_logloss: 0.597089        \n",
      "[19]\ttraining's multi_logloss: 0.54303\tvalid_1's multi_logloss: 0.574279         \n",
      "[20]\ttraining's multi_logloss: 0.520648\tvalid_1's multi_logloss: 0.553503        \n",
      "[21]\ttraining's multi_logloss: 0.500104\tvalid_1's multi_logloss: 0.534485        \n",
      "[22]\ttraining's multi_logloss: 0.481044\tvalid_1's multi_logloss: 0.516917        \n",
      "[23]\ttraining's multi_logloss: 0.463135\tvalid_1's multi_logloss: 0.500669        \n",
      "[24]\ttraining's multi_logloss: 0.44646\tvalid_1's multi_logloss: 0.485472         \n",
      "[25]\ttraining's multi_logloss: 0.43077\tvalid_1's multi_logloss: 0.471689         \n",
      "[26]\ttraining's multi_logloss: 0.416295\tvalid_1's multi_logloss: 0.459216        \n",
      "[27]\ttraining's multi_logloss: 0.402685\tvalid_1's multi_logloss: 0.447392        \n",
      "[28]\ttraining's multi_logloss: 0.390183\tvalid_1's multi_logloss: 0.436735        \n",
      "[29]\ttraining's multi_logloss: 0.378333\tvalid_1's multi_logloss: 0.426582        \n",
      "[30]\ttraining's multi_logloss: 0.367235\tvalid_1's multi_logloss: 0.417385        \n",
      "[31]\ttraining's multi_logloss: 0.356637\tvalid_1's multi_logloss: 0.408476        \n",
      "[32]\ttraining's multi_logloss: 0.34651\tvalid_1's multi_logloss: 0.400048         \n",
      "[33]\ttraining's multi_logloss: 0.337088\tvalid_1's multi_logloss: 0.392418        \n",
      "[34]\ttraining's multi_logloss: 0.328104\tvalid_1's multi_logloss: 0.385101        \n",
      "[35]\ttraining's multi_logloss: 0.319685\tvalid_1's multi_logloss: 0.378465        \n",
      "[36]\ttraining's multi_logloss: 0.311842\tvalid_1's multi_logloss: 0.37215         \n",
      "[37]\ttraining's multi_logloss: 0.304136\tvalid_1's multi_logloss: 0.3661          \n",
      "[38]\ttraining's multi_logloss: 0.296976\tvalid_1's multi_logloss: 0.360857        \n",
      "[39]\ttraining's multi_logloss: 0.290177\tvalid_1's multi_logloss: 0.355732        \n",
      "[40]\ttraining's multi_logloss: 0.283603\tvalid_1's multi_logloss: 0.35071         \n",
      "[41]\ttraining's multi_logloss: 0.277207\tvalid_1's multi_logloss: 0.346119        \n",
      "[42]\ttraining's multi_logloss: 0.271329\tvalid_1's multi_logloss: 0.342032        \n",
      "[43]\ttraining's multi_logloss: 0.265827\tvalid_1's multi_logloss: 0.338389        \n",
      "[44]\ttraining's multi_logloss: 0.260241\tvalid_1's multi_logloss: 0.334743        \n",
      "[45]\ttraining's multi_logloss: 0.254947\tvalid_1's multi_logloss: 0.331511        \n",
      "[46]\ttraining's multi_logloss: 0.249842\tvalid_1's multi_logloss: 0.328258        \n",
      "[47]\ttraining's multi_logloss: 0.245157\tvalid_1's multi_logloss: 0.325503        \n",
      "[48]\ttraining's multi_logloss: 0.240354\tvalid_1's multi_logloss: 0.322518        \n",
      "[49]\ttraining's multi_logloss: 0.235878\tvalid_1's multi_logloss: 0.320017        \n",
      "[50]\ttraining's multi_logloss: 0.231478\tvalid_1's multi_logloss: 0.317725        \n",
      "[51]\ttraining's multi_logloss: 0.227416\tvalid_1's multi_logloss: 0.315878        \n",
      "[52]\ttraining's multi_logloss: 0.223518\tvalid_1's multi_logloss: 0.31375         \n",
      "[53]\ttraining's multi_logloss: 0.219569\tvalid_1's multi_logloss: 0.31178         \n",
      "[54]\ttraining's multi_logloss: 0.215753\tvalid_1's multi_logloss: 0.310052        \n",
      "[55]\ttraining's multi_logloss: 0.212034\tvalid_1's multi_logloss: 0.308179        \n",
      "[56]\ttraining's multi_logloss: 0.208391\tvalid_1's multi_logloss: 0.306566        \n",
      "[57]\ttraining's multi_logloss: 0.205026\tvalid_1's multi_logloss: 0.304945        \n",
      "[58]\ttraining's multi_logloss: 0.201733\tvalid_1's multi_logloss: 0.303643        \n",
      "[59]\ttraining's multi_logloss: 0.198675\tvalid_1's multi_logloss: 0.302386        \n",
      "[60]\ttraining's multi_logloss: 0.195499\tvalid_1's multi_logloss: 0.30128         \n",
      "[61]\ttraining's multi_logloss: 0.192442\tvalid_1's multi_logloss: 0.299988        \n",
      "[62]\ttraining's multi_logloss: 0.189417\tvalid_1's multi_logloss: 0.298785        \n",
      "[63]\ttraining's multi_logloss: 0.186381\tvalid_1's multi_logloss: 0.297596        \n",
      "[64]\ttraining's multi_logloss: 0.183477\tvalid_1's multi_logloss: 0.296447        \n",
      "[65]\ttraining's multi_logloss: 0.180643\tvalid_1's multi_logloss: 0.295758        \n",
      "[66]\ttraining's multi_logloss: 0.177871\tvalid_1's multi_logloss: 0.294586        \n",
      "[67]\ttraining's multi_logloss: 0.175329\tvalid_1's multi_logloss: 0.293854        \n",
      "[68]\ttraining's multi_logloss: 0.172709\tvalid_1's multi_logloss: 0.293292        \n",
      "[69]\ttraining's multi_logloss: 0.170259\tvalid_1's multi_logloss: 0.292695        \n",
      "[70]\ttraining's multi_logloss: 0.167791\tvalid_1's multi_logloss: 0.291935        \n",
      "[71]\ttraining's multi_logloss: 0.165338\tvalid_1's multi_logloss: 0.291232        \n",
      "[72]\ttraining's multi_logloss: 0.162947\tvalid_1's multi_logloss: 0.290679        \n",
      "[73]\ttraining's multi_logloss: 0.160542\tvalid_1's multi_logloss: 0.29029         \n",
      "[74]\ttraining's multi_logloss: 0.158211\tvalid_1's multi_logloss: 0.289717        \n",
      "[75]\ttraining's multi_logloss: 0.155986\tvalid_1's multi_logloss: 0.289058        \n",
      "[76]\ttraining's multi_logloss: 0.153551\tvalid_1's multi_logloss: 0.288526        \n",
      "[77]\ttraining's multi_logloss: 0.151226\tvalid_1's multi_logloss: 0.287989        \n",
      "[78]\ttraining's multi_logloss: 0.148971\tvalid_1's multi_logloss: 0.287702        \n",
      "[79]\ttraining's multi_logloss: 0.146651\tvalid_1's multi_logloss: 0.287259        \n",
      "[80]\ttraining's multi_logloss: 0.144659\tvalid_1's multi_logloss: 0.28684         \n",
      "[81]\ttraining's multi_logloss: 0.14245\tvalid_1's multi_logloss: 0.286562         \n",
      "[82]\ttraining's multi_logloss: 0.140552\tvalid_1's multi_logloss: 0.286573        \n",
      "[83]\ttraining's multi_logloss: 0.138668\tvalid_1's multi_logloss: 0.286127        \n",
      "[84]\ttraining's multi_logloss: 0.136691\tvalid_1's multi_logloss: 0.286026        \n",
      "[85]\ttraining's multi_logloss: 0.134714\tvalid_1's multi_logloss: 0.285885        \n",
      "[86]\ttraining's multi_logloss: 0.132855\tvalid_1's multi_logloss: 0.285819        \n",
      "[87]\ttraining's multi_logloss: 0.131047\tvalid_1's multi_logloss: 0.285727        \n",
      "[88]\ttraining's multi_logloss: 0.129109\tvalid_1's multi_logloss: 0.285475        \n",
      "[89]\ttraining's multi_logloss: 0.12735\tvalid_1's multi_logloss: 0.285371         \n",
      "[90]\ttraining's multi_logloss: 0.125478\tvalid_1's multi_logloss: 0.285076        \n",
      "[91]\ttraining's multi_logloss: 0.123746\tvalid_1's multi_logloss: 0.284886        \n",
      "[92]\ttraining's multi_logloss: 0.122102\tvalid_1's multi_logloss: 0.284661        \n",
      "[93]\ttraining's multi_logloss: 0.120414\tvalid_1's multi_logloss: 0.284557        \n",
      "[94]\ttraining's multi_logloss: 0.118814\tvalid_1's multi_logloss: 0.284504        \n",
      "[95]\ttraining's multi_logloss: 0.117119\tvalid_1's multi_logloss: 0.284451        \n",
      "[96]\ttraining's multi_logloss: 0.115464\tvalid_1's multi_logloss: 0.28436         \n",
      "[97]\ttraining's multi_logloss: 0.11389\tvalid_1's multi_logloss: 0.284315         \n",
      "[98]\ttraining's multi_logloss: 0.112266\tvalid_1's multi_logloss: 0.284363        \n",
      "[99]\ttraining's multi_logloss: 0.110771\tvalid_1's multi_logloss: 0.284398        \n",
      "[100]\ttraining's multi_logloss: 0.10923\tvalid_1's multi_logloss: 0.284292        \n",
      "[101]\ttraining's multi_logloss: 0.107764\tvalid_1's multi_logloss: 0.284265       \n",
      "[102]\ttraining's multi_logloss: 0.106379\tvalid_1's multi_logloss: 0.284388       \n",
      "[103]\ttraining's multi_logloss: 0.10494\tvalid_1's multi_logloss: 0.28438         \n",
      "[104]\ttraining's multi_logloss: 0.103643\tvalid_1's multi_logloss: 0.284397       \n",
      "[105]\ttraining's multi_logloss: 0.102231\tvalid_1's multi_logloss: 0.284632       \n",
      "[106]\ttraining's multi_logloss: 0.10086\tvalid_1's multi_logloss: 0.284804        \n",
      "[107]\ttraining's multi_logloss: 0.0995463\tvalid_1's multi_logloss: 0.284829      \n",
      "[108]\ttraining's multi_logloss: 0.0982688\tvalid_1's multi_logloss: 0.284786      \n",
      "[109]\ttraining's multi_logloss: 0.0970398\tvalid_1's multi_logloss: 0.285007      \n",
      "[110]\ttraining's multi_logloss: 0.095822\tvalid_1's multi_logloss: 0.28507        \n",
      "[111]\ttraining's multi_logloss: 0.0945716\tvalid_1's multi_logloss: 0.285407      \n",
      "[112]\ttraining's multi_logloss: 0.0932285\tvalid_1's multi_logloss: 0.285576      \n",
      "[113]\ttraining's multi_logloss: 0.0920278\tvalid_1's multi_logloss: 0.285705      \n",
      "[114]\ttraining's multi_logloss: 0.0907632\tvalid_1's multi_logloss: 0.285908      \n",
      "[115]\ttraining's multi_logloss: 0.0895462\tvalid_1's multi_logloss: 0.28619       \n",
      "[116]\ttraining's multi_logloss: 0.0884068\tvalid_1's multi_logloss: 0.2866        \n",
      "[117]\ttraining's multi_logloss: 0.0873585\tvalid_1's multi_logloss: 0.286991      \n",
      "[118]\ttraining's multi_logloss: 0.0861988\tvalid_1's multi_logloss: 0.287364      \n",
      "[119]\ttraining's multi_logloss: 0.0851077\tvalid_1's multi_logloss: 0.287698      \n",
      "[120]\ttraining's multi_logloss: 0.0840214\tvalid_1's multi_logloss: 0.287922      \n",
      "[121]\ttraining's multi_logloss: 0.0829919\tvalid_1's multi_logloss: 0.288276      \n",
      "[122]\ttraining's multi_logloss: 0.0818801\tvalid_1's multi_logloss: 0.28871       \n",
      "[123]\ttraining's multi_logloss: 0.0808098\tvalid_1's multi_logloss: 0.288937      \n",
      "[124]\ttraining's multi_logloss: 0.0798157\tvalid_1's multi_logloss: 0.289319      \n",
      "[125]\ttraining's multi_logloss: 0.0787432\tvalid_1's multi_logloss: 0.289567      \n",
      "[126]\ttraining's multi_logloss: 0.0777681\tvalid_1's multi_logloss: 0.289714      \n",
      "[127]\ttraining's multi_logloss: 0.076744\tvalid_1's multi_logloss: 0.289914       \n",
      "[128]\ttraining's multi_logloss: 0.0757606\tvalid_1's multi_logloss: 0.290159      \n",
      "[129]\ttraining's multi_logloss: 0.0747764\tvalid_1's multi_logloss: 0.290508      \n",
      "[130]\ttraining's multi_logloss: 0.073811\tvalid_1's multi_logloss: 0.290822       \n",
      "[131]\ttraining's multi_logloss: 0.0729352\tvalid_1's multi_logloss: 0.291172      \n",
      "Early stopping, best iteration is:                                               \n",
      "[101]\ttraining's multi_logloss: 0.107764\tvalid_1's multi_logloss: 0.284265\n",
      "[1]\ttraining's multi_logloss: 1.71225\tvalid_1's multi_logloss: 1.71602           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.54532\tvalid_1's multi_logloss: 1.55101           \n",
      "[3]\ttraining's multi_logloss: 1.40901\tvalid_1's multi_logloss: 1.41551           \n",
      "[4]\ttraining's multi_logloss: 1.29414\tvalid_1's multi_logloss: 1.30165           \n",
      "[5]\ttraining's multi_logloss: 1.19618\tvalid_1's multi_logloss: 1.20484           \n",
      "[6]\ttraining's multi_logloss: 1.11135\tvalid_1's multi_logloss: 1.12101           \n",
      "[7]\ttraining's multi_logloss: 1.03636\tvalid_1's multi_logloss: 1.04677           \n",
      "[8]\ttraining's multi_logloss: 0.970354\tvalid_1's multi_logloss: 0.981283         \n",
      "[9]\ttraining's multi_logloss: 0.911059\tvalid_1's multi_logloss: 0.923226         \n",
      "[10]\ttraining's multi_logloss: 0.857311\tvalid_1's multi_logloss: 0.870313        \n",
      "[11]\ttraining's multi_logloss: 0.808827\tvalid_1's multi_logloss: 0.822523        \n",
      "[12]\ttraining's multi_logloss: 0.764672\tvalid_1's multi_logloss: 0.779269        \n",
      "[13]\ttraining's multi_logloss: 0.724792\tvalid_1's multi_logloss: 0.74059         \n",
      "[14]\ttraining's multi_logloss: 0.688355\tvalid_1's multi_logloss: 0.705375        \n",
      "[15]\ttraining's multi_logloss: 0.65488\tvalid_1's multi_logloss: 0.673039         \n",
      "[16]\ttraining's multi_logloss: 0.624471\tvalid_1's multi_logloss: 0.643993        \n",
      "[17]\ttraining's multi_logloss: 0.596028\tvalid_1's multi_logloss: 0.616566        \n",
      "[18]\ttraining's multi_logloss: 0.570345\tvalid_1's multi_logloss: 0.592416        \n",
      "[19]\ttraining's multi_logloss: 0.546509\tvalid_1's multi_logloss: 0.570069        \n",
      "[20]\ttraining's multi_logloss: 0.524452\tvalid_1's multi_logloss: 0.549318        \n",
      "[21]\ttraining's multi_logloss: 0.503992\tvalid_1's multi_logloss: 0.530264        \n",
      "[22]\ttraining's multi_logloss: 0.485105\tvalid_1's multi_logloss: 0.512605        \n",
      "[23]\ttraining's multi_logloss: 0.467515\tvalid_1's multi_logloss: 0.496475        \n",
      "[24]\ttraining's multi_logloss: 0.451212\tvalid_1's multi_logloss: 0.481361        \n",
      "[25]\ttraining's multi_logloss: 0.435729\tvalid_1's multi_logloss: 0.467205        \n",
      "[26]\ttraining's multi_logloss: 0.421324\tvalid_1's multi_logloss: 0.454042        \n",
      "[27]\ttraining's multi_logloss: 0.407878\tvalid_1's multi_logloss: 0.441973        \n",
      "[28]\ttraining's multi_logloss: 0.395224\tvalid_1's multi_logloss: 0.430363        \n",
      "[29]\ttraining's multi_logloss: 0.383089\tvalid_1's multi_logloss: 0.419405        \n",
      "[30]\ttraining's multi_logloss: 0.371931\tvalid_1's multi_logloss: 0.409429        \n",
      "[31]\ttraining's multi_logloss: 0.361602\tvalid_1's multi_logloss: 0.400425        \n",
      "[32]\ttraining's multi_logloss: 0.351367\tvalid_1's multi_logloss: 0.391547        \n",
      "[33]\ttraining's multi_logloss: 0.342009\tvalid_1's multi_logloss: 0.383513        \n",
      "[34]\ttraining's multi_logloss: 0.333123\tvalid_1's multi_logloss: 0.37595         \n",
      "[35]\ttraining's multi_logloss: 0.324758\tvalid_1's multi_logloss: 0.368967        \n",
      "[36]\ttraining's multi_logloss: 0.316811\tvalid_1's multi_logloss: 0.362532        \n",
      "[37]\ttraining's multi_logloss: 0.309437\tvalid_1's multi_logloss: 0.356743        \n",
      "[38]\ttraining's multi_logloss: 0.30242\tvalid_1's multi_logloss: 0.351157         \n",
      "[39]\ttraining's multi_logloss: 0.295537\tvalid_1's multi_logloss: 0.346076        \n",
      "[40]\ttraining's multi_logloss: 0.289041\tvalid_1's multi_logloss: 0.34106         \n",
      "[41]\ttraining's multi_logloss: 0.282978\tvalid_1's multi_logloss: 0.336706        \n",
      "[42]\ttraining's multi_logloss: 0.277051\tvalid_1's multi_logloss: 0.332245        \n",
      "[43]\ttraining's multi_logloss: 0.271357\tvalid_1's multi_logloss: 0.328123        \n",
      "[44]\ttraining's multi_logloss: 0.266062\tvalid_1's multi_logloss: 0.324498        \n",
      "[45]\ttraining's multi_logloss: 0.260887\tvalid_1's multi_logloss: 0.32098         \n",
      "[46]\ttraining's multi_logloss: 0.255727\tvalid_1's multi_logloss: 0.317549        \n",
      "[47]\ttraining's multi_logloss: 0.250977\tvalid_1's multi_logloss: 0.314438        \n",
      "[48]\ttraining's multi_logloss: 0.246438\tvalid_1's multi_logloss: 0.311598        \n",
      "[49]\ttraining's multi_logloss: 0.242092\tvalid_1's multi_logloss: 0.308731        \n",
      "[50]\ttraining's multi_logloss: 0.237868\tvalid_1's multi_logloss: 0.30639         \n",
      "[51]\ttraining's multi_logloss: 0.233737\tvalid_1's multi_logloss: 0.304072        \n",
      "[52]\ttraining's multi_logloss: 0.229699\tvalid_1's multi_logloss: 0.302018        \n",
      "[53]\ttraining's multi_logloss: 0.225995\tvalid_1's multi_logloss: 0.300146        \n",
      "[54]\ttraining's multi_logloss: 0.222255\tvalid_1's multi_logloss: 0.298225        \n",
      "[55]\ttraining's multi_logloss: 0.218733\tvalid_1's multi_logloss: 0.296586        \n",
      "[56]\ttraining's multi_logloss: 0.215346\tvalid_1's multi_logloss: 0.295023        \n",
      "[57]\ttraining's multi_logloss: 0.211814\tvalid_1's multi_logloss: 0.293269        \n",
      "[58]\ttraining's multi_logloss: 0.208534\tvalid_1's multi_logloss: 0.292078        \n",
      "[59]\ttraining's multi_logloss: 0.205325\tvalid_1's multi_logloss: 0.290737        \n",
      "[60]\ttraining's multi_logloss: 0.202053\tvalid_1's multi_logloss: 0.289281        \n",
      "[61]\ttraining's multi_logloss: 0.199169\tvalid_1's multi_logloss: 0.288251        \n",
      "[62]\ttraining's multi_logloss: 0.196147\tvalid_1's multi_logloss: 0.286947        \n",
      "[63]\ttraining's multi_logloss: 0.193186\tvalid_1's multi_logloss: 0.285799        \n",
      "[64]\ttraining's multi_logloss: 0.190401\tvalid_1's multi_logloss: 0.284975        \n",
      "[65]\ttraining's multi_logloss: 0.187573\tvalid_1's multi_logloss: 0.283971        \n",
      "[66]\ttraining's multi_logloss: 0.184783\tvalid_1's multi_logloss: 0.283021        \n",
      "[67]\ttraining's multi_logloss: 0.182018\tvalid_1's multi_logloss: 0.282218        \n",
      "[68]\ttraining's multi_logloss: 0.179321\tvalid_1's multi_logloss: 0.281536        \n",
      "[69]\ttraining's multi_logloss: 0.17658\tvalid_1's multi_logloss: 0.280605         \n",
      "[70]\ttraining's multi_logloss: 0.173914\tvalid_1's multi_logloss: 0.279613        \n",
      "[71]\ttraining's multi_logloss: 0.171286\tvalid_1's multi_logloss: 0.278893        \n",
      "[72]\ttraining's multi_logloss: 0.168891\tvalid_1's multi_logloss: 0.278366        \n",
      "[73]\ttraining's multi_logloss: 0.166459\tvalid_1's multi_logloss: 0.277584        \n",
      "[74]\ttraining's multi_logloss: 0.164057\tvalid_1's multi_logloss: 0.277047        \n",
      "[75]\ttraining's multi_logloss: 0.161507\tvalid_1's multi_logloss: 0.276492        \n",
      "[76]\ttraining's multi_logloss: 0.159129\tvalid_1's multi_logloss: 0.275804        \n",
      "[77]\ttraining's multi_logloss: 0.156986\tvalid_1's multi_logloss: 0.27525         \n",
      "[78]\ttraining's multi_logloss: 0.154739\tvalid_1's multi_logloss: 0.275139        \n",
      "[79]\ttraining's multi_logloss: 0.15264\tvalid_1's multi_logloss: 0.274838         \n",
      "[80]\ttraining's multi_logloss: 0.150485\tvalid_1's multi_logloss: 0.274502        \n",
      "[81]\ttraining's multi_logloss: 0.148483\tvalid_1's multi_logloss: 0.274258        \n",
      "[82]\ttraining's multi_logloss: 0.146472\tvalid_1's multi_logloss: 0.273936        \n",
      "[83]\ttraining's multi_logloss: 0.144466\tvalid_1's multi_logloss: 0.273895        \n",
      "[84]\ttraining's multi_logloss: 0.142431\tvalid_1's multi_logloss: 0.273532        \n",
      "[85]\ttraining's multi_logloss: 0.1405\tvalid_1's multi_logloss: 0.273379          \n",
      "[86]\ttraining's multi_logloss: 0.138548\tvalid_1's multi_logloss: 0.273129        \n",
      "[87]\ttraining's multi_logloss: 0.136765\tvalid_1's multi_logloss: 0.273001        \n",
      "[88]\ttraining's multi_logloss: 0.134941\tvalid_1's multi_logloss: 0.272881        \n",
      "[89]\ttraining's multi_logloss: 0.13318\tvalid_1's multi_logloss: 0.272822         \n",
      "[90]\ttraining's multi_logloss: 0.131282\tvalid_1's multi_logloss: 0.272509        \n",
      "[91]\ttraining's multi_logloss: 0.12938\tvalid_1's multi_logloss: 0.272152         \n",
      "[92]\ttraining's multi_logloss: 0.127554\tvalid_1's multi_logloss: 0.271888        \n",
      "[93]\ttraining's multi_logloss: 0.125842\tvalid_1's multi_logloss: 0.271722        \n",
      "[94]\ttraining's multi_logloss: 0.12409\tvalid_1's multi_logloss: 0.271669         \n",
      "[95]\ttraining's multi_logloss: 0.122336\tvalid_1's multi_logloss: 0.271639        \n",
      "[96]\ttraining's multi_logloss: 0.120647\tvalid_1's multi_logloss: 0.271575        \n",
      "[97]\ttraining's multi_logloss: 0.11903\tvalid_1's multi_logloss: 0.271346         \n",
      "[98]\ttraining's multi_logloss: 0.117434\tvalid_1's multi_logloss: 0.271323        \n",
      "[99]\ttraining's multi_logloss: 0.115848\tvalid_1's multi_logloss: 0.271111        \n",
      "[100]\ttraining's multi_logloss: 0.114318\tvalid_1's multi_logloss: 0.271004       \n",
      "[101]\ttraining's multi_logloss: 0.11278\tvalid_1's multi_logloss: 0.271021        \n",
      "[102]\ttraining's multi_logloss: 0.111329\tvalid_1's multi_logloss: 0.270933       \n",
      "[103]\ttraining's multi_logloss: 0.109913\tvalid_1's multi_logloss: 0.270947       \n",
      "[104]\ttraining's multi_logloss: 0.108519\tvalid_1's multi_logloss: 0.270853       \n",
      "[105]\ttraining's multi_logloss: 0.10717\tvalid_1's multi_logloss: 0.270906        \n",
      "[106]\ttraining's multi_logloss: 0.105731\tvalid_1's multi_logloss: 0.270807       \n",
      "[107]\ttraining's multi_logloss: 0.104363\tvalid_1's multi_logloss: 0.270935       \n",
      "[108]\ttraining's multi_logloss: 0.102905\tvalid_1's multi_logloss: 0.270999       \n",
      "[109]\ttraining's multi_logloss: 0.101597\tvalid_1's multi_logloss: 0.271181       \n",
      "[110]\ttraining's multi_logloss: 0.100292\tvalid_1's multi_logloss: 0.271413       \n",
      "[111]\ttraining's multi_logloss: 0.0989942\tvalid_1's multi_logloss: 0.271354      \n",
      "[112]\ttraining's multi_logloss: 0.0977079\tvalid_1's multi_logloss: 0.271457      \n",
      "[113]\ttraining's multi_logloss: 0.0964525\tvalid_1's multi_logloss: 0.271605      \n",
      "[114]\ttraining's multi_logloss: 0.0952721\tvalid_1's multi_logloss: 0.271734      \n",
      "[115]\ttraining's multi_logloss: 0.0941451\tvalid_1's multi_logloss: 0.271956      \n",
      "[116]\ttraining's multi_logloss: 0.0930399\tvalid_1's multi_logloss: 0.272193      \n",
      "[117]\ttraining's multi_logloss: 0.0918025\tvalid_1's multi_logloss: 0.272204      \n",
      "[118]\ttraining's multi_logloss: 0.0907241\tvalid_1's multi_logloss: 0.27264       \n",
      "[119]\ttraining's multi_logloss: 0.0896189\tvalid_1's multi_logloss: 0.272887      \n",
      "[120]\ttraining's multi_logloss: 0.0886147\tvalid_1's multi_logloss: 0.273118      \n",
      "[121]\ttraining's multi_logloss: 0.0875427\tvalid_1's multi_logloss: 0.273287      \n",
      "[122]\ttraining's multi_logloss: 0.0864767\tvalid_1's multi_logloss: 0.273564      \n",
      "[123]\ttraining's multi_logloss: 0.0854423\tvalid_1's multi_logloss: 0.273648      \n",
      "[124]\ttraining's multi_logloss: 0.0844469\tvalid_1's multi_logloss: 0.273794      \n",
      "[125]\ttraining's multi_logloss: 0.0833312\tvalid_1's multi_logloss: 0.27425       \n",
      "[126]\ttraining's multi_logloss: 0.0822752\tvalid_1's multi_logloss: 0.274568      \n",
      "[127]\ttraining's multi_logloss: 0.0813385\tvalid_1's multi_logloss: 0.274748      \n",
      "[128]\ttraining's multi_logloss: 0.0803391\tvalid_1's multi_logloss: 0.27502       \n",
      "[129]\ttraining's multi_logloss: 0.0792668\tvalid_1's multi_logloss: 0.27506       \n",
      "[130]\ttraining's multi_logloss: 0.0782865\tvalid_1's multi_logloss: 0.275316      \n",
      "[131]\ttraining's multi_logloss: 0.077403\tvalid_1's multi_logloss: 0.2756         \n",
      "[132]\ttraining's multi_logloss: 0.0764581\tvalid_1's multi_logloss: 0.275804      \n",
      "[133]\ttraining's multi_logloss: 0.075512\tvalid_1's multi_logloss: 0.275887       \n",
      "[134]\ttraining's multi_logloss: 0.0745681\tvalid_1's multi_logloss: 0.276203      \n",
      "[135]\ttraining's multi_logloss: 0.0736586\tvalid_1's multi_logloss: 0.276344      \n",
      "[136]\ttraining's multi_logloss: 0.0727889\tvalid_1's multi_logloss: 0.27656       \n",
      "Early stopping, best iteration is:                                               \n",
      "[106]\ttraining's multi_logloss: 0.105731\tvalid_1's multi_logloss: 0.270807\n",
      "[1]\ttraining's multi_logloss: 1.75789\tvalid_1's multi_logloss: 1.75918           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.61681\tvalid_1's multi_logloss: 1.62093           \n",
      "[3]\ttraining's multi_logloss: 1.49825\tvalid_1's multi_logloss: 1.5057            \n",
      "[4]\ttraining's multi_logloss: 1.39614\tvalid_1's multi_logloss: 1.40679           \n",
      "[5]\ttraining's multi_logloss: 1.30614\tvalid_1's multi_logloss: 1.31933           \n",
      "[6]\ttraining's multi_logloss: 1.22716\tvalid_1's multi_logloss: 1.24248           \n",
      "[7]\ttraining's multi_logloss: 1.15686\tvalid_1's multi_logloss: 1.17429           \n",
      "[8]\ttraining's multi_logloss: 1.09314\tvalid_1's multi_logloss: 1.11251           \n",
      "[9]\ttraining's multi_logloss: 1.03525\tvalid_1's multi_logloss: 1.05647           \n",
      "[10]\ttraining's multi_logloss: 0.982798\tvalid_1's multi_logloss: 1.00552         \n",
      "[11]\ttraining's multi_logloss: 0.934401\tvalid_1's multi_logloss: 0.95856         \n",
      "[12]\ttraining's multi_logloss: 0.890388\tvalid_1's multi_logloss: 0.915911        \n",
      "[13]\ttraining's multi_logloss: 0.849537\tvalid_1's multi_logloss: 0.8768          \n",
      "[14]\ttraining's multi_logloss: 0.811974\tvalid_1's multi_logloss: 0.840444        \n",
      "[15]\ttraining's multi_logloss: 0.777053\tvalid_1's multi_logloss: 0.806603        \n",
      "[16]\ttraining's multi_logloss: 0.744808\tvalid_1's multi_logloss: 0.775446        \n",
      "[17]\ttraining's multi_logloss: 0.714973\tvalid_1's multi_logloss: 0.746798        \n",
      "[18]\ttraining's multi_logloss: 0.686932\tvalid_1's multi_logloss: 0.719496        \n",
      "[19]\ttraining's multi_logloss: 0.660813\tvalid_1's multi_logloss: 0.694568        \n",
      "[20]\ttraining's multi_logloss: 0.636356\tvalid_1's multi_logloss: 0.67119         \n",
      "[21]\ttraining's multi_logloss: 0.613079\tvalid_1's multi_logloss: 0.648898        \n",
      "[22]\ttraining's multi_logloss: 0.591696\tvalid_1's multi_logloss: 0.628553        \n",
      "[23]\ttraining's multi_logloss: 0.571356\tvalid_1's multi_logloss: 0.609339        \n",
      "[24]\ttraining's multi_logloss: 0.552371\tvalid_1's multi_logloss: 0.591494        \n",
      "[25]\ttraining's multi_logloss: 0.534685\tvalid_1's multi_logloss: 0.574648        \n",
      "[26]\ttraining's multi_logloss: 0.518006\tvalid_1's multi_logloss: 0.559108        \n",
      "[27]\ttraining's multi_logloss: 0.502335\tvalid_1's multi_logloss: 0.544557        \n",
      "[28]\ttraining's multi_logloss: 0.487774\tvalid_1's multi_logloss: 0.531016        \n",
      "[29]\ttraining's multi_logloss: 0.473696\tvalid_1's multi_logloss: 0.517732        \n",
      "[30]\ttraining's multi_logloss: 0.460624\tvalid_1's multi_logloss: 0.505573        \n",
      "[31]\ttraining's multi_logloss: 0.448132\tvalid_1's multi_logloss: 0.494056        \n",
      "[32]\ttraining's multi_logloss: 0.436406\tvalid_1's multi_logloss: 0.483425        \n",
      "[33]\ttraining's multi_logloss: 0.425065\tvalid_1's multi_logloss: 0.473086        \n",
      "[34]\ttraining's multi_logloss: 0.414442\tvalid_1's multi_logloss: 0.463398        \n",
      "[35]\ttraining's multi_logloss: 0.404445\tvalid_1's multi_logloss: 0.454613        \n",
      "[36]\ttraining's multi_logloss: 0.394917\tvalid_1's multi_logloss: 0.446122        \n",
      "[37]\ttraining's multi_logloss: 0.385864\tvalid_1's multi_logloss: 0.438094        \n",
      "[38]\ttraining's multi_logloss: 0.377499\tvalid_1's multi_logloss: 0.430921        \n",
      "[39]\ttraining's multi_logloss: 0.369484\tvalid_1's multi_logloss: 0.423903        \n",
      "[40]\ttraining's multi_logloss: 0.361751\tvalid_1's multi_logloss: 0.417144        \n",
      "[41]\ttraining's multi_logloss: 0.35442\tvalid_1's multi_logloss: 0.410897         \n",
      "[42]\ttraining's multi_logloss: 0.347522\tvalid_1's multi_logloss: 0.405195        \n",
      "[43]\ttraining's multi_logloss: 0.340526\tvalid_1's multi_logloss: 0.399289        \n",
      "[44]\ttraining's multi_logloss: 0.334025\tvalid_1's multi_logloss: 0.393976        \n",
      "[45]\ttraining's multi_logloss: 0.327867\tvalid_1's multi_logloss: 0.388783        \n",
      "[46]\ttraining's multi_logloss: 0.321991\tvalid_1's multi_logloss: 0.383776        \n",
      "[47]\ttraining's multi_logloss: 0.316534\tvalid_1's multi_logloss: 0.379334        \n",
      "[48]\ttraining's multi_logloss: 0.31099\tvalid_1's multi_logloss: 0.374687         \n",
      "[49]\ttraining's multi_logloss: 0.305844\tvalid_1's multi_logloss: 0.370724        \n",
      "[50]\ttraining's multi_logloss: 0.30094\tvalid_1's multi_logloss: 0.366826         \n",
      "[51]\ttraining's multi_logloss: 0.296053\tvalid_1's multi_logloss: 0.363054        \n",
      "[52]\ttraining's multi_logloss: 0.29157\tvalid_1's multi_logloss: 0.359558         \n",
      "[53]\ttraining's multi_logloss: 0.287188\tvalid_1's multi_logloss: 0.356211        \n",
      "[54]\ttraining's multi_logloss: 0.282925\tvalid_1's multi_logloss: 0.353111        \n",
      "[55]\ttraining's multi_logloss: 0.27883\tvalid_1's multi_logloss: 0.35017          \n",
      "[56]\ttraining's multi_logloss: 0.274858\tvalid_1's multi_logloss: 0.347222        \n",
      "[57]\ttraining's multi_logloss: 0.270949\tvalid_1's multi_logloss: 0.344607        \n",
      "[58]\ttraining's multi_logloss: 0.267109\tvalid_1's multi_logloss: 0.342078        \n",
      "[59]\ttraining's multi_logloss: 0.263412\tvalid_1's multi_logloss: 0.33958         \n",
      "[60]\ttraining's multi_logloss: 0.259905\tvalid_1's multi_logloss: 0.337343        \n",
      "[61]\ttraining's multi_logloss: 0.256443\tvalid_1's multi_logloss: 0.334958        \n",
      "[62]\ttraining's multi_logloss: 0.253147\tvalid_1's multi_logloss: 0.332848        \n",
      "[63]\ttraining's multi_logloss: 0.249854\tvalid_1's multi_logloss: 0.330627        \n",
      "[64]\ttraining's multi_logloss: 0.246673\tvalid_1's multi_logloss: 0.328464        \n",
      "[65]\ttraining's multi_logloss: 0.243642\tvalid_1's multi_logloss: 0.326646        \n",
      "[66]\ttraining's multi_logloss: 0.240573\tvalid_1's multi_logloss: 0.324932        \n",
      "[67]\ttraining's multi_logloss: 0.237738\tvalid_1's multi_logloss: 0.323274        \n",
      "[68]\ttraining's multi_logloss: 0.235\tvalid_1's multi_logloss: 0.321648           \n",
      "[69]\ttraining's multi_logloss: 0.232304\tvalid_1's multi_logloss: 0.320272        \n",
      "[70]\ttraining's multi_logloss: 0.22967\tvalid_1's multi_logloss: 0.318957         \n",
      "[71]\ttraining's multi_logloss: 0.227008\tvalid_1's multi_logloss: 0.317635        \n",
      "[72]\ttraining's multi_logloss: 0.224438\tvalid_1's multi_logloss: 0.316341        \n",
      "[73]\ttraining's multi_logloss: 0.222083\tvalid_1's multi_logloss: 0.315204        \n",
      "[74]\ttraining's multi_logloss: 0.219641\tvalid_1's multi_logloss: 0.31399         \n",
      "[75]\ttraining's multi_logloss: 0.217341\tvalid_1's multi_logloss: 0.312816        \n",
      "[76]\ttraining's multi_logloss: 0.215073\tvalid_1's multi_logloss: 0.311855        \n",
      "[77]\ttraining's multi_logloss: 0.212887\tvalid_1's multi_logloss: 0.310777        \n",
      "[78]\ttraining's multi_logloss: 0.21075\tvalid_1's multi_logloss: 0.309729         \n",
      "[79]\ttraining's multi_logloss: 0.208477\tvalid_1's multi_logloss: 0.30877         \n",
      "[80]\ttraining's multi_logloss: 0.206463\tvalid_1's multi_logloss: 0.307883        \n",
      "[81]\ttraining's multi_logloss: 0.204207\tvalid_1's multi_logloss: 0.306694        \n",
      "[82]\ttraining's multi_logloss: 0.202058\tvalid_1's multi_logloss: 0.306074        \n",
      "[83]\ttraining's multi_logloss: 0.199963\tvalid_1's multi_logloss: 0.305202        \n",
      "[84]\ttraining's multi_logloss: 0.197951\tvalid_1's multi_logloss: 0.304488        \n",
      "[85]\ttraining's multi_logloss: 0.195851\tvalid_1's multi_logloss: 0.303687        \n",
      "[86]\ttraining's multi_logloss: 0.193874\tvalid_1's multi_logloss: 0.302941        \n",
      "[87]\ttraining's multi_logloss: 0.191993\tvalid_1's multi_logloss: 0.302212        \n",
      "[88]\ttraining's multi_logloss: 0.190122\tvalid_1's multi_logloss: 0.301575        \n",
      "[89]\ttraining's multi_logloss: 0.188261\tvalid_1's multi_logloss: 0.301051        \n",
      "[90]\ttraining's multi_logloss: 0.186397\tvalid_1's multi_logloss: 0.300429        \n",
      "[91]\ttraining's multi_logloss: 0.18457\tvalid_1's multi_logloss: 0.299862         \n",
      "[92]\ttraining's multi_logloss: 0.182708\tvalid_1's multi_logloss: 0.299555        \n",
      "[93]\ttraining's multi_logloss: 0.18089\tvalid_1's multi_logloss: 0.29929          \n",
      "[94]\ttraining's multi_logloss: 0.179098\tvalid_1's multi_logloss: 0.298867        \n",
      "[95]\ttraining's multi_logloss: 0.177352\tvalid_1's multi_logloss: 0.298355        \n",
      "[96]\ttraining's multi_logloss: 0.175538\tvalid_1's multi_logloss: 0.298074        \n",
      "[97]\ttraining's multi_logloss: 0.173806\tvalid_1's multi_logloss: 0.297719        \n",
      "[98]\ttraining's multi_logloss: 0.172064\tvalid_1's multi_logloss: 0.297329        \n",
      "[99]\ttraining's multi_logloss: 0.170479\tvalid_1's multi_logloss: 0.296931        \n",
      "[100]\ttraining's multi_logloss: 0.168807\tvalid_1's multi_logloss: 0.29664        \n",
      "[101]\ttraining's multi_logloss: 0.16717\tvalid_1's multi_logloss: 0.296205        \n",
      "[102]\ttraining's multi_logloss: 0.165417\tvalid_1's multi_logloss: 0.295699       \n",
      "[103]\ttraining's multi_logloss: 0.163873\tvalid_1's multi_logloss: 0.295509       \n",
      "[104]\ttraining's multi_logloss: 0.162356\tvalid_1's multi_logloss: 0.295195       \n",
      "[105]\ttraining's multi_logloss: 0.160707\tvalid_1's multi_logloss: 0.294864       \n",
      "[106]\ttraining's multi_logloss: 0.159093\tvalid_1's multi_logloss: 0.294639       \n",
      "[107]\ttraining's multi_logloss: 0.157476\tvalid_1's multi_logloss: 0.294518       \n",
      "[108]\ttraining's multi_logloss: 0.155843\tvalid_1's multi_logloss: 0.294201       \n",
      "[109]\ttraining's multi_logloss: 0.154164\tvalid_1's multi_logloss: 0.294092       \n",
      "[110]\ttraining's multi_logloss: 0.152614\tvalid_1's multi_logloss: 0.293741       \n",
      "[111]\ttraining's multi_logloss: 0.15121\tvalid_1's multi_logloss: 0.293697        \n",
      "[112]\ttraining's multi_logloss: 0.14968\tvalid_1's multi_logloss: 0.293348        \n",
      "[113]\ttraining's multi_logloss: 0.148226\tvalid_1's multi_logloss: 0.293133       \n",
      "[114]\ttraining's multi_logloss: 0.146814\tvalid_1's multi_logloss: 0.292944       \n",
      "[115]\ttraining's multi_logloss: 0.145427\tvalid_1's multi_logloss: 0.292885       \n",
      "[116]\ttraining's multi_logloss: 0.143986\tvalid_1's multi_logloss: 0.292669       \n",
      "[117]\ttraining's multi_logloss: 0.142597\tvalid_1's multi_logloss: 0.292357       \n",
      "[118]\ttraining's multi_logloss: 0.141266\tvalid_1's multi_logloss: 0.29215        \n",
      "[119]\ttraining's multi_logloss: 0.13994\tvalid_1's multi_logloss: 0.292033        \n",
      "[120]\ttraining's multi_logloss: 0.138589\tvalid_1's multi_logloss: 0.292145       \n",
      "[121]\ttraining's multi_logloss: 0.137204\tvalid_1's multi_logloss: 0.291984       \n",
      "[122]\ttraining's multi_logloss: 0.13595\tvalid_1's multi_logloss: 0.291906        \n",
      "[123]\ttraining's multi_logloss: 0.134625\tvalid_1's multi_logloss: 0.291682       \n",
      "[124]\ttraining's multi_logloss: 0.133263\tvalid_1's multi_logloss: 0.291769       \n",
      "[125]\ttraining's multi_logloss: 0.131956\tvalid_1's multi_logloss: 0.291658       \n",
      "[126]\ttraining's multi_logloss: 0.13065\tvalid_1's multi_logloss: 0.291618        \n",
      "[127]\ttraining's multi_logloss: 0.129442\tvalid_1's multi_logloss: 0.291664       \n",
      "[128]\ttraining's multi_logloss: 0.128215\tvalid_1's multi_logloss: 0.291572       \n",
      "[129]\ttraining's multi_logloss: 0.126875\tvalid_1's multi_logloss: 0.291523       \n",
      "[130]\ttraining's multi_logloss: 0.125542\tvalid_1's multi_logloss: 0.291252       \n",
      "[131]\ttraining's multi_logloss: 0.124233\tvalid_1's multi_logloss: 0.291126       \n",
      "[132]\ttraining's multi_logloss: 0.123095\tvalid_1's multi_logloss: 0.291122       \n",
      "[133]\ttraining's multi_logloss: 0.121834\tvalid_1's multi_logloss: 0.291043       \n",
      "[134]\ttraining's multi_logloss: 0.120599\tvalid_1's multi_logloss: 0.291112       \n",
      "[135]\ttraining's multi_logloss: 0.119353\tvalid_1's multi_logloss: 0.291029       \n",
      "[136]\ttraining's multi_logloss: 0.118201\tvalid_1's multi_logloss: 0.29087        \n",
      "[137]\ttraining's multi_logloss: 0.117107\tvalid_1's multi_logloss: 0.290761       \n",
      "[138]\ttraining's multi_logloss: 0.116037\tvalid_1's multi_logloss: 0.290783       \n",
      "[139]\ttraining's multi_logloss: 0.114935\tvalid_1's multi_logloss: 0.290938       \n",
      "[140]\ttraining's multi_logloss: 0.113745\tvalid_1's multi_logloss: 0.291007       \n",
      "[141]\ttraining's multi_logloss: 0.1127\tvalid_1's multi_logloss: 0.291001         \n",
      "[142]\ttraining's multi_logloss: 0.111645\tvalid_1's multi_logloss: 0.29088        \n",
      "[143]\ttraining's multi_logloss: 0.110654\tvalid_1's multi_logloss: 0.291076       \n",
      "[144]\ttraining's multi_logloss: 0.109561\tvalid_1's multi_logloss: 0.291266       \n",
      "[145]\ttraining's multi_logloss: 0.108515\tvalid_1's multi_logloss: 0.29137        \n",
      "[146]\ttraining's multi_logloss: 0.107516\tvalid_1's multi_logloss: 0.291449       \n",
      "[147]\ttraining's multi_logloss: 0.106441\tvalid_1's multi_logloss: 0.29131        \n",
      "[148]\ttraining's multi_logloss: 0.105385\tvalid_1's multi_logloss: 0.291399       \n",
      "[149]\ttraining's multi_logloss: 0.10447\tvalid_1's multi_logloss: 0.291483        \n",
      "[150]\ttraining's multi_logloss: 0.103486\tvalid_1's multi_logloss: 0.291627       \n",
      "[151]\ttraining's multi_logloss: 0.102609\tvalid_1's multi_logloss: 0.291491       \n",
      "[152]\ttraining's multi_logloss: 0.101664\tvalid_1's multi_logloss: 0.291629       \n",
      "[153]\ttraining's multi_logloss: 0.10077\tvalid_1's multi_logloss: 0.291618        \n",
      "[154]\ttraining's multi_logloss: 0.099866\tvalid_1's multi_logloss: 0.291746       \n",
      "[155]\ttraining's multi_logloss: 0.098976\tvalid_1's multi_logloss: 0.291899       \n",
      "[156]\ttraining's multi_logloss: 0.0980772\tvalid_1's multi_logloss: 0.291945      \n",
      "[157]\ttraining's multi_logloss: 0.0970867\tvalid_1's multi_logloss: 0.292028      \n",
      "[158]\ttraining's multi_logloss: 0.0962335\tvalid_1's multi_logloss: 0.292155      \n",
      "[159]\ttraining's multi_logloss: 0.0954081\tvalid_1's multi_logloss: 0.292265      \n",
      "[160]\ttraining's multi_logloss: 0.09456\tvalid_1's multi_logloss: 0.292472        \n",
      "[161]\ttraining's multi_logloss: 0.0937809\tvalid_1's multi_logloss: 0.292812      \n",
      "[162]\ttraining's multi_logloss: 0.0929077\tvalid_1's multi_logloss: 0.292942      \n",
      "[163]\ttraining's multi_logloss: 0.0921305\tvalid_1's multi_logloss: 0.292882      \n",
      "[164]\ttraining's multi_logloss: 0.0913475\tvalid_1's multi_logloss: 0.292997      \n",
      "[165]\ttraining's multi_logloss: 0.0905926\tvalid_1's multi_logloss: 0.293154      \n",
      "[166]\ttraining's multi_logloss: 0.089762\tvalid_1's multi_logloss: 0.293291       \n",
      "[167]\ttraining's multi_logloss: 0.0889929\tvalid_1's multi_logloss: 0.29337       \n",
      "Early stopping, best iteration is:                                               \n",
      "[137]\ttraining's multi_logloss: 0.117107\tvalid_1's multi_logloss: 0.290761\n",
      "[1]\ttraining's multi_logloss: 1.75635\tvalid_1's multi_logloss: 1.75894           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.61562\tvalid_1's multi_logloss: 1.61903           \n",
      "[3]\ttraining's multi_logloss: 1.49809\tvalid_1's multi_logloss: 1.50233           \n",
      "[4]\ttraining's multi_logloss: 1.3971\tvalid_1's multi_logloss: 1.4026             \n",
      "[5]\ttraining's multi_logloss: 1.30896\tvalid_1's multi_logloss: 1.31532           \n",
      "[6]\ttraining's multi_logloss: 1.23153\tvalid_1's multi_logloss: 1.23908           \n",
      "[7]\ttraining's multi_logloss: 1.16128\tvalid_1's multi_logloss: 1.16936           \n",
      "[8]\ttraining's multi_logloss: 1.09822\tvalid_1's multi_logloss: 1.1069            \n",
      "[9]\ttraining's multi_logloss: 1.04086\tvalid_1's multi_logloss: 1.05048           \n",
      "[10]\ttraining's multi_logloss: 0.9884\tvalid_1's multi_logloss: 0.999048          \n",
      "[11]\ttraining's multi_logloss: 0.940985\tvalid_1's multi_logloss: 0.952562        \n",
      "[12]\ttraining's multi_logloss: 0.897227\tvalid_1's multi_logloss: 0.909778        \n",
      "[13]\ttraining's multi_logloss: 0.856731\tvalid_1's multi_logloss: 0.86996         \n",
      "[14]\ttraining's multi_logloss: 0.819396\tvalid_1's multi_logloss: 0.833487        \n",
      "[15]\ttraining's multi_logloss: 0.784616\tvalid_1's multi_logloss: 0.799654        \n",
      "[16]\ttraining's multi_logloss: 0.752162\tvalid_1's multi_logloss: 0.768304        \n",
      "[17]\ttraining's multi_logloss: 0.72245\tvalid_1's multi_logloss: 0.739681         \n",
      "[18]\ttraining's multi_logloss: 0.694539\tvalid_1's multi_logloss: 0.712936        \n",
      "[19]\ttraining's multi_logloss: 0.667939\tvalid_1's multi_logloss: 0.687532        \n",
      "[20]\ttraining's multi_logloss: 0.643212\tvalid_1's multi_logloss: 0.66367         \n",
      "[21]\ttraining's multi_logloss: 0.620207\tvalid_1's multi_logloss: 0.641658        \n",
      "[22]\ttraining's multi_logloss: 0.598689\tvalid_1's multi_logloss: 0.621144        \n",
      "[23]\ttraining's multi_logloss: 0.578634\tvalid_1's multi_logloss: 0.601955        \n",
      "[24]\ttraining's multi_logloss: 0.559883\tvalid_1's multi_logloss: 0.584141        \n",
      "[25]\ttraining's multi_logloss: 0.542354\tvalid_1's multi_logloss: 0.56782         \n",
      "[26]\ttraining's multi_logloss: 0.525873\tvalid_1's multi_logloss: 0.552219        \n",
      "[27]\ttraining's multi_logloss: 0.510009\tvalid_1's multi_logloss: 0.537445        \n",
      "[28]\ttraining's multi_logloss: 0.495318\tvalid_1's multi_logloss: 0.523667        \n",
      "[29]\ttraining's multi_logloss: 0.48083\tvalid_1's multi_logloss: 0.510126         \n",
      "[30]\ttraining's multi_logloss: 0.467141\tvalid_1's multi_logloss: 0.497506        \n",
      "[31]\ttraining's multi_logloss: 0.454458\tvalid_1's multi_logloss: 0.48584         \n",
      "[32]\ttraining's multi_logloss: 0.442613\tvalid_1's multi_logloss: 0.475093        \n",
      "[33]\ttraining's multi_logloss: 0.43139\tvalid_1's multi_logloss: 0.464866         \n",
      "[34]\ttraining's multi_logloss: 0.420759\tvalid_1's multi_logloss: 0.455172        \n",
      "[35]\ttraining's multi_logloss: 0.41045\tvalid_1's multi_logloss: 0.446125         \n",
      "[36]\ttraining's multi_logloss: 0.401025\tvalid_1's multi_logloss: 0.437834        \n",
      "[37]\ttraining's multi_logloss: 0.391695\tvalid_1's multi_logloss: 0.429436        \n",
      "[38]\ttraining's multi_logloss: 0.383076\tvalid_1's multi_logloss: 0.42184         \n",
      "[39]\ttraining's multi_logloss: 0.375142\tvalid_1's multi_logloss: 0.414957        \n",
      "[40]\ttraining's multi_logloss: 0.367316\tvalid_1's multi_logloss: 0.408104        \n",
      "[41]\ttraining's multi_logloss: 0.359817\tvalid_1's multi_logloss: 0.401669        \n",
      "[42]\ttraining's multi_logloss: 0.352772\tvalid_1's multi_logloss: 0.39559         \n",
      "[43]\ttraining's multi_logloss: 0.345816\tvalid_1's multi_logloss: 0.389549        \n",
      "[44]\ttraining's multi_logloss: 0.339121\tvalid_1's multi_logloss: 0.383947        \n",
      "[45]\ttraining's multi_logloss: 0.332587\tvalid_1's multi_logloss: 0.378477        \n",
      "[46]\ttraining's multi_logloss: 0.326378\tvalid_1's multi_logloss: 0.373457        \n",
      "[47]\ttraining's multi_logloss: 0.320525\tvalid_1's multi_logloss: 0.368637        \n",
      "[48]\ttraining's multi_logloss: 0.314714\tvalid_1's multi_logloss: 0.363962        \n",
      "[49]\ttraining's multi_logloss: 0.309376\tvalid_1's multi_logloss: 0.359665        \n",
      "[50]\ttraining's multi_logloss: 0.304246\tvalid_1's multi_logloss: 0.35571         \n",
      "[51]\ttraining's multi_logloss: 0.299414\tvalid_1's multi_logloss: 0.351973        \n",
      "[52]\ttraining's multi_logloss: 0.294895\tvalid_1's multi_logloss: 0.348586        \n",
      "[53]\ttraining's multi_logloss: 0.290158\tvalid_1's multi_logloss: 0.345147        \n",
      "[54]\ttraining's multi_logloss: 0.285596\tvalid_1's multi_logloss: 0.341826        \n",
      "[55]\ttraining's multi_logloss: 0.281282\tvalid_1's multi_logloss: 0.338555        \n",
      "[56]\ttraining's multi_logloss: 0.277288\tvalid_1's multi_logloss: 0.335693        \n",
      "[57]\ttraining's multi_logloss: 0.273243\tvalid_1's multi_logloss: 0.332807        \n",
      "[58]\ttraining's multi_logloss: 0.269344\tvalid_1's multi_logloss: 0.330078        \n",
      "[59]\ttraining's multi_logloss: 0.265761\tvalid_1's multi_logloss: 0.327833        \n",
      "[60]\ttraining's multi_logloss: 0.262071\tvalid_1's multi_logloss: 0.325487        \n",
      "[61]\ttraining's multi_logloss: 0.258676\tvalid_1's multi_logloss: 0.323344        \n",
      "[62]\ttraining's multi_logloss: 0.25526\tvalid_1's multi_logloss: 0.321188         \n",
      "[63]\ttraining's multi_logloss: 0.252039\tvalid_1's multi_logloss: 0.319152        \n",
      "[64]\ttraining's multi_logloss: 0.24873\tvalid_1's multi_logloss: 0.317093         \n",
      "[65]\ttraining's multi_logloss: 0.245535\tvalid_1's multi_logloss: 0.315285        \n",
      "[66]\ttraining's multi_logloss: 0.242476\tvalid_1's multi_logloss: 0.313663        \n",
      "[67]\ttraining's multi_logloss: 0.239419\tvalid_1's multi_logloss: 0.312175        \n",
      "[68]\ttraining's multi_logloss: 0.236466\tvalid_1's multi_logloss: 0.310518        \n",
      "[69]\ttraining's multi_logloss: 0.233528\tvalid_1's multi_logloss: 0.309166        \n",
      "[70]\ttraining's multi_logloss: 0.230848\tvalid_1's multi_logloss: 0.307699        \n",
      "[71]\ttraining's multi_logloss: 0.228141\tvalid_1's multi_logloss: 0.306463        \n",
      "[72]\ttraining's multi_logloss: 0.225476\tvalid_1's multi_logloss: 0.305324        \n",
      "[73]\ttraining's multi_logloss: 0.222871\tvalid_1's multi_logloss: 0.304222        \n",
      "[74]\ttraining's multi_logloss: 0.220331\tvalid_1's multi_logloss: 0.30312         \n",
      "[75]\ttraining's multi_logloss: 0.217921\tvalid_1's multi_logloss: 0.302155        \n",
      "[76]\ttraining's multi_logloss: 0.215606\tvalid_1's multi_logloss: 0.300976        \n",
      "[77]\ttraining's multi_logloss: 0.213081\tvalid_1's multi_logloss: 0.29982         \n",
      "[78]\ttraining's multi_logloss: 0.210639\tvalid_1's multi_logloss: 0.299029        \n",
      "[79]\ttraining's multi_logloss: 0.208416\tvalid_1's multi_logloss: 0.29804         \n",
      "[80]\ttraining's multi_logloss: 0.206101\tvalid_1's multi_logloss: 0.297199        \n",
      "[81]\ttraining's multi_logloss: 0.203967\tvalid_1's multi_logloss: 0.296344        \n",
      "[82]\ttraining's multi_logloss: 0.201816\tvalid_1's multi_logloss: 0.29541         \n",
      "[83]\ttraining's multi_logloss: 0.199716\tvalid_1's multi_logloss: 0.294664        \n",
      "[84]\ttraining's multi_logloss: 0.197506\tvalid_1's multi_logloss: 0.293971        \n",
      "[85]\ttraining's multi_logloss: 0.195307\tvalid_1's multi_logloss: 0.293257        \n",
      "[86]\ttraining's multi_logloss: 0.193268\tvalid_1's multi_logloss: 0.292597        \n",
      "[87]\ttraining's multi_logloss: 0.191405\tvalid_1's multi_logloss: 0.292022        \n",
      "[88]\ttraining's multi_logloss: 0.189456\tvalid_1's multi_logloss: 0.291452        \n",
      "[89]\ttraining's multi_logloss: 0.187493\tvalid_1's multi_logloss: 0.290745        \n",
      "[90]\ttraining's multi_logloss: 0.185548\tvalid_1's multi_logloss: 0.290137        \n",
      "[91]\ttraining's multi_logloss: 0.183734\tvalid_1's multi_logloss: 0.289581        \n",
      "[92]\ttraining's multi_logloss: 0.181923\tvalid_1's multi_logloss: 0.289311        \n",
      "[93]\ttraining's multi_logloss: 0.180078\tvalid_1's multi_logloss: 0.288799        \n",
      "[94]\ttraining's multi_logloss: 0.178268\tvalid_1's multi_logloss: 0.288423        \n",
      "[95]\ttraining's multi_logloss: 0.176513\tvalid_1's multi_logloss: 0.28801         \n",
      "[96]\ttraining's multi_logloss: 0.174695\tvalid_1's multi_logloss: 0.287568        \n",
      "[97]\ttraining's multi_logloss: 0.17286\tvalid_1's multi_logloss: 0.287207         \n",
      "[98]\ttraining's multi_logloss: 0.171155\tvalid_1's multi_logloss: 0.286779        \n",
      "[99]\ttraining's multi_logloss: 0.169298\tvalid_1's multi_logloss: 0.286337        \n",
      "[100]\ttraining's multi_logloss: 0.167535\tvalid_1's multi_logloss: 0.286142       \n",
      "[101]\ttraining's multi_logloss: 0.165797\tvalid_1's multi_logloss: 0.285759       \n",
      "[102]\ttraining's multi_logloss: 0.164152\tvalid_1's multi_logloss: 0.285424       \n",
      "[103]\ttraining's multi_logloss: 0.162527\tvalid_1's multi_logloss: 0.285206       \n",
      "[104]\ttraining's multi_logloss: 0.160979\tvalid_1's multi_logloss: 0.284961       \n",
      "[105]\ttraining's multi_logloss: 0.159357\tvalid_1's multi_logloss: 0.284868       \n",
      "[106]\ttraining's multi_logloss: 0.157843\tvalid_1's multi_logloss: 0.284581       \n",
      "[107]\ttraining's multi_logloss: 0.156389\tvalid_1's multi_logloss: 0.28439        \n",
      "[108]\ttraining's multi_logloss: 0.154869\tvalid_1's multi_logloss: 0.284404       \n",
      "[109]\ttraining's multi_logloss: 0.153257\tvalid_1's multi_logloss: 0.284337       \n",
      "[110]\ttraining's multi_logloss: 0.151725\tvalid_1's multi_logloss: 0.284357       \n",
      "[111]\ttraining's multi_logloss: 0.150359\tvalid_1's multi_logloss: 0.284204       \n",
      "[112]\ttraining's multi_logloss: 0.14888\tvalid_1's multi_logloss: 0.284083        \n",
      "[113]\ttraining's multi_logloss: 0.147481\tvalid_1's multi_logloss: 0.283959       \n",
      "[114]\ttraining's multi_logloss: 0.146066\tvalid_1's multi_logloss: 0.283733       \n",
      "[115]\ttraining's multi_logloss: 0.144645\tvalid_1's multi_logloss: 0.283695       \n",
      "[116]\ttraining's multi_logloss: 0.143337\tvalid_1's multi_logloss: 0.28347        \n",
      "[117]\ttraining's multi_logloss: 0.142098\tvalid_1's multi_logloss: 0.283441       \n",
      "[118]\ttraining's multi_logloss: 0.140797\tvalid_1's multi_logloss: 0.28325        \n",
      "[119]\ttraining's multi_logloss: 0.139483\tvalid_1's multi_logloss: 0.283217       \n",
      "[120]\ttraining's multi_logloss: 0.13811\tvalid_1's multi_logloss: 0.283154        \n",
      "[121]\ttraining's multi_logloss: 0.136937\tvalid_1's multi_logloss: 0.2831         \n",
      "[122]\ttraining's multi_logloss: 0.135682\tvalid_1's multi_logloss: 0.282952       \n",
      "[123]\ttraining's multi_logloss: 0.13439\tvalid_1's multi_logloss: 0.283034        \n",
      "[124]\ttraining's multi_logloss: 0.133018\tvalid_1's multi_logloss: 0.282872       \n",
      "[125]\ttraining's multi_logloss: 0.131686\tvalid_1's multi_logloss: 0.282589       \n",
      "[126]\ttraining's multi_logloss: 0.130278\tvalid_1's multi_logloss: 0.282508       \n",
      "[127]\ttraining's multi_logloss: 0.128912\tvalid_1's multi_logloss: 0.282477       \n",
      "[128]\ttraining's multi_logloss: 0.127598\tvalid_1's multi_logloss: 0.282318       \n",
      "[129]\ttraining's multi_logloss: 0.126398\tvalid_1's multi_logloss: 0.282519       \n",
      "[130]\ttraining's multi_logloss: 0.125237\tvalid_1's multi_logloss: 0.282409       \n",
      "[131]\ttraining's multi_logloss: 0.123961\tvalid_1's multi_logloss: 0.282425       \n",
      "[132]\ttraining's multi_logloss: 0.122649\tvalid_1's multi_logloss: 0.282325       \n",
      "[133]\ttraining's multi_logloss: 0.121351\tvalid_1's multi_logloss: 0.282319       \n",
      "[134]\ttraining's multi_logloss: 0.120142\tvalid_1's multi_logloss: 0.282476       \n",
      "[135]\ttraining's multi_logloss: 0.118969\tvalid_1's multi_logloss: 0.282525       \n",
      "[136]\ttraining's multi_logloss: 0.117802\tvalid_1's multi_logloss: 0.282731       \n",
      "[137]\ttraining's multi_logloss: 0.116575\tvalid_1's multi_logloss: 0.282753       \n",
      "[138]\ttraining's multi_logloss: 0.115429\tvalid_1's multi_logloss: 0.282772       \n",
      "[139]\ttraining's multi_logloss: 0.114341\tvalid_1's multi_logloss: 0.282908       \n",
      "[140]\ttraining's multi_logloss: 0.113161\tvalid_1's multi_logloss: 0.282979       \n",
      "[141]\ttraining's multi_logloss: 0.112088\tvalid_1's multi_logloss: 0.283043       \n",
      "[142]\ttraining's multi_logloss: 0.111095\tvalid_1's multi_logloss: 0.283053       \n",
      "[143]\ttraining's multi_logloss: 0.110023\tvalid_1's multi_logloss: 0.283055       \n",
      "[144]\ttraining's multi_logloss: 0.108995\tvalid_1's multi_logloss: 0.282997       \n",
      "[145]\ttraining's multi_logloss: 0.107882\tvalid_1's multi_logloss: 0.282981       \n",
      "[146]\ttraining's multi_logloss: 0.106828\tvalid_1's multi_logloss: 0.283001       \n",
      "[147]\ttraining's multi_logloss: 0.105788\tvalid_1's multi_logloss: 0.282907       \n",
      "[148]\ttraining's multi_logloss: 0.104756\tvalid_1's multi_logloss: 0.28287        \n",
      "[149]\ttraining's multi_logloss: 0.103817\tvalid_1's multi_logloss: 0.283015       \n",
      "[150]\ttraining's multi_logloss: 0.102832\tvalid_1's multi_logloss: 0.283228       \n",
      "[151]\ttraining's multi_logloss: 0.101861\tvalid_1's multi_logloss: 0.283247       \n",
      "[152]\ttraining's multi_logloss: 0.100902\tvalid_1's multi_logloss: 0.28328        \n",
      "[153]\ttraining's multi_logloss: 0.0999752\tvalid_1's multi_logloss: 0.283427      \n",
      "[154]\ttraining's multi_logloss: 0.0990667\tvalid_1's multi_logloss: 0.283378      \n",
      "[155]\ttraining's multi_logloss: 0.0981799\tvalid_1's multi_logloss: 0.283376      \n",
      "[156]\ttraining's multi_logloss: 0.0971906\tvalid_1's multi_logloss: 0.283476      \n",
      "[157]\ttraining's multi_logloss: 0.0963449\tvalid_1's multi_logloss: 0.283602      \n",
      "[158]\ttraining's multi_logloss: 0.0954154\tvalid_1's multi_logloss: 0.283735      \n",
      "Early stopping, best iteration is:                                               \n",
      "[128]\ttraining's multi_logloss: 0.127598\tvalid_1's multi_logloss: 0.282318\n",
      "[1]\ttraining's multi_logloss: 1.75713\tvalid_1's multi_logloss: 1.75987           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.61768\tvalid_1's multi_logloss: 1.62156           \n",
      "[3]\ttraining's multi_logloss: 1.50037\tvalid_1's multi_logloss: 1.50548           \n",
      "[4]\ttraining's multi_logloss: 1.39927\tvalid_1's multi_logloss: 1.4047            \n",
      "[5]\ttraining's multi_logloss: 1.31054\tvalid_1's multi_logloss: 1.31692           \n",
      "[6]\ttraining's multi_logloss: 1.2319\tvalid_1's multi_logloss: 1.23883            \n",
      "[7]\ttraining's multi_logloss: 1.16222\tvalid_1's multi_logloss: 1.16994           \n",
      "[8]\ttraining's multi_logloss: 1.09914\tvalid_1's multi_logloss: 1.10733           \n",
      "[9]\ttraining's multi_logloss: 1.04166\tvalid_1's multi_logloss: 1.05028           \n",
      "[10]\ttraining's multi_logloss: 0.989464\tvalid_1's multi_logloss: 0.998926        \n",
      "[11]\ttraining's multi_logloss: 0.94138\tvalid_1's multi_logloss: 0.951182         \n",
      "[12]\ttraining's multi_logloss: 0.897272\tvalid_1's multi_logloss: 0.907843        \n",
      "[13]\ttraining's multi_logloss: 0.856357\tvalid_1's multi_logloss: 0.867613        \n",
      "[14]\ttraining's multi_logloss: 0.818809\tvalid_1's multi_logloss: 0.830772        \n",
      "[15]\ttraining's multi_logloss: 0.783746\tvalid_1's multi_logloss: 0.796437        \n",
      "[16]\ttraining's multi_logloss: 0.751675\tvalid_1's multi_logloss: 0.765202        \n",
      "[17]\ttraining's multi_logloss: 0.721673\tvalid_1's multi_logloss: 0.735816        \n",
      "[18]\ttraining's multi_logloss: 0.693647\tvalid_1's multi_logloss: 0.708624        \n",
      "[19]\ttraining's multi_logloss: 0.667906\tvalid_1's multi_logloss: 0.683889        \n",
      "[20]\ttraining's multi_logloss: 0.643717\tvalid_1's multi_logloss: 0.660478        \n",
      "[21]\ttraining's multi_logloss: 0.620744\tvalid_1's multi_logloss: 0.638133        \n",
      "[22]\ttraining's multi_logloss: 0.599262\tvalid_1's multi_logloss: 0.61735         \n",
      "[23]\ttraining's multi_logloss: 0.579226\tvalid_1's multi_logloss: 0.598027        \n",
      "[24]\ttraining's multi_logloss: 0.560702\tvalid_1's multi_logloss: 0.580261        \n",
      "[25]\ttraining's multi_logloss: 0.543091\tvalid_1's multi_logloss: 0.563422        \n",
      "[26]\ttraining's multi_logloss: 0.526534\tvalid_1's multi_logloss: 0.547526        \n",
      "[27]\ttraining's multi_logloss: 0.510992\tvalid_1's multi_logloss: 0.532716        \n",
      "[28]\ttraining's multi_logloss: 0.496194\tvalid_1's multi_logloss: 0.518743        \n",
      "[29]\ttraining's multi_logloss: 0.482348\tvalid_1's multi_logloss: 0.505638        \n",
      "[30]\ttraining's multi_logloss: 0.46939\tvalid_1's multi_logloss: 0.493478         \n",
      "[31]\ttraining's multi_logloss: 0.456933\tvalid_1's multi_logloss: 0.481729        \n",
      "[32]\ttraining's multi_logloss: 0.445128\tvalid_1's multi_logloss: 0.470768        \n",
      "[33]\ttraining's multi_logloss: 0.434108\tvalid_1's multi_logloss: 0.460474        \n",
      "[34]\ttraining's multi_logloss: 0.423544\tvalid_1's multi_logloss: 0.450535        \n",
      "[35]\ttraining's multi_logloss: 0.41353\tvalid_1's multi_logloss: 0.441259         \n",
      "[36]\ttraining's multi_logloss: 0.403687\tvalid_1's multi_logloss: 0.432196        \n",
      "[37]\ttraining's multi_logloss: 0.394866\tvalid_1's multi_logloss: 0.424108        \n",
      "[38]\ttraining's multi_logloss: 0.386117\tvalid_1's multi_logloss: 0.416143        \n",
      "[39]\ttraining's multi_logloss: 0.377815\tvalid_1's multi_logloss: 0.408575        \n",
      "[40]\ttraining's multi_logloss: 0.369922\tvalid_1's multi_logloss: 0.401607        \n",
      "[41]\ttraining's multi_logloss: 0.362432\tvalid_1's multi_logloss: 0.395128        \n",
      "[42]\ttraining's multi_logloss: 0.355384\tvalid_1's multi_logloss: 0.388745        \n",
      "[43]\ttraining's multi_logloss: 0.348556\tvalid_1's multi_logloss: 0.382836        \n",
      "[44]\ttraining's multi_logloss: 0.342117\tvalid_1's multi_logloss: 0.377319        \n",
      "[45]\ttraining's multi_logloss: 0.336024\tvalid_1's multi_logloss: 0.372002        \n",
      "[46]\ttraining's multi_logloss: 0.330069\tvalid_1's multi_logloss: 0.366901        \n",
      "[47]\ttraining's multi_logloss: 0.324404\tvalid_1's multi_logloss: 0.362101        \n",
      "[48]\ttraining's multi_logloss: 0.319002\tvalid_1's multi_logloss: 0.357548        \n",
      "[49]\ttraining's multi_logloss: 0.313838\tvalid_1's multi_logloss: 0.353196        \n",
      "[50]\ttraining's multi_logloss: 0.308901\tvalid_1's multi_logloss: 0.349254        \n",
      "[51]\ttraining's multi_logloss: 0.304053\tvalid_1's multi_logloss: 0.345447        \n",
      "[52]\ttraining's multi_logloss: 0.299329\tvalid_1's multi_logloss: 0.34155         \n",
      "[53]\ttraining's multi_logloss: 0.294848\tvalid_1's multi_logloss: 0.337935        \n",
      "[54]\ttraining's multi_logloss: 0.29046\tvalid_1's multi_logloss: 0.334602         \n",
      "[55]\ttraining's multi_logloss: 0.286066\tvalid_1's multi_logloss: 0.331354        \n",
      "[56]\ttraining's multi_logloss: 0.281809\tvalid_1's multi_logloss: 0.328317        \n",
      "[57]\ttraining's multi_logloss: 0.277952\tvalid_1's multi_logloss: 0.325586        \n",
      "[58]\ttraining's multi_logloss: 0.274319\tvalid_1's multi_logloss: 0.323026        \n",
      "[59]\ttraining's multi_logloss: 0.270698\tvalid_1's multi_logloss: 0.320388        \n",
      "[60]\ttraining's multi_logloss: 0.267084\tvalid_1's multi_logloss: 0.317853        \n",
      "[61]\ttraining's multi_logloss: 0.263521\tvalid_1's multi_logloss: 0.31558         \n",
      "[62]\ttraining's multi_logloss: 0.260335\tvalid_1's multi_logloss: 0.313622        \n",
      "[63]\ttraining's multi_logloss: 0.257045\tvalid_1's multi_logloss: 0.311446        \n",
      "[64]\ttraining's multi_logloss: 0.253837\tvalid_1's multi_logloss: 0.309447        \n",
      "[65]\ttraining's multi_logloss: 0.250692\tvalid_1's multi_logloss: 0.30757         \n",
      "[66]\ttraining's multi_logloss: 0.24773\tvalid_1's multi_logloss: 0.305653         \n",
      "[67]\ttraining's multi_logloss: 0.244564\tvalid_1's multi_logloss: 0.303851        \n",
      "[68]\ttraining's multi_logloss: 0.241624\tvalid_1's multi_logloss: 0.30207         \n",
      "[69]\ttraining's multi_logloss: 0.238831\tvalid_1's multi_logloss: 0.300293        \n",
      "[70]\ttraining's multi_logloss: 0.236095\tvalid_1's multi_logloss: 0.298627        \n",
      "[71]\ttraining's multi_logloss: 0.233417\tvalid_1's multi_logloss: 0.296982        \n",
      "[72]\ttraining's multi_logloss: 0.23079\tvalid_1's multi_logloss: 0.29551          \n",
      "[73]\ttraining's multi_logloss: 0.228428\tvalid_1's multi_logloss: 0.294365        \n",
      "[74]\ttraining's multi_logloss: 0.225965\tvalid_1's multi_logloss: 0.293095        \n",
      "[75]\ttraining's multi_logloss: 0.223544\tvalid_1's multi_logloss: 0.291894        \n",
      "[76]\ttraining's multi_logloss: 0.22126\tvalid_1's multi_logloss: 0.290846         \n",
      "[77]\ttraining's multi_logloss: 0.21899\tvalid_1's multi_logloss: 0.289705         \n",
      "[78]\ttraining's multi_logloss: 0.216701\tvalid_1's multi_logloss: 0.288707        \n",
      "[79]\ttraining's multi_logloss: 0.214551\tvalid_1's multi_logloss: 0.287756        \n",
      "[80]\ttraining's multi_logloss: 0.212273\tvalid_1's multi_logloss: 0.286923        \n",
      "[81]\ttraining's multi_logloss: 0.210091\tvalid_1's multi_logloss: 0.286259        \n",
      "[82]\ttraining's multi_logloss: 0.208002\tvalid_1's multi_logloss: 0.285416        \n",
      "[83]\ttraining's multi_logloss: 0.20592\tvalid_1's multi_logloss: 0.284484         \n",
      "[84]\ttraining's multi_logloss: 0.203822\tvalid_1's multi_logloss: 0.28376         \n",
      "[85]\ttraining's multi_logloss: 0.201698\tvalid_1's multi_logloss: 0.282942        \n",
      "[86]\ttraining's multi_logloss: 0.199774\tvalid_1's multi_logloss: 0.282225        \n",
      "[87]\ttraining's multi_logloss: 0.197762\tvalid_1's multi_logloss: 0.281554        \n",
      "[88]\ttraining's multi_logloss: 0.195732\tvalid_1's multi_logloss: 0.280812        \n",
      "[89]\ttraining's multi_logloss: 0.193731\tvalid_1's multi_logloss: 0.28012         \n",
      "[90]\ttraining's multi_logloss: 0.191822\tvalid_1's multi_logloss: 0.279564        \n",
      "[91]\ttraining's multi_logloss: 0.189964\tvalid_1's multi_logloss: 0.278876        \n",
      "[92]\ttraining's multi_logloss: 0.188142\tvalid_1's multi_logloss: 0.27821         \n",
      "[93]\ttraining's multi_logloss: 0.186379\tvalid_1's multi_logloss: 0.277845        \n",
      "[94]\ttraining's multi_logloss: 0.184599\tvalid_1's multi_logloss: 0.277218        \n",
      "[95]\ttraining's multi_logloss: 0.182848\tvalid_1's multi_logloss: 0.276872        \n",
      "[96]\ttraining's multi_logloss: 0.181125\tvalid_1's multi_logloss: 0.276336        \n",
      "[97]\ttraining's multi_logloss: 0.179298\tvalid_1's multi_logloss: 0.275963        \n",
      "[98]\ttraining's multi_logloss: 0.177629\tvalid_1's multi_logloss: 0.275548        \n",
      "[99]\ttraining's multi_logloss: 0.175933\tvalid_1's multi_logloss: 0.275121        \n",
      "[100]\ttraining's multi_logloss: 0.174036\tvalid_1's multi_logloss: 0.274735       \n",
      "[101]\ttraining's multi_logloss: 0.17251\tvalid_1's multi_logloss: 0.27466         \n",
      "[102]\ttraining's multi_logloss: 0.170726\tvalid_1's multi_logloss: 0.274185       \n",
      "[103]\ttraining's multi_logloss: 0.169162\tvalid_1's multi_logloss: 0.27387        \n",
      "[104]\ttraining's multi_logloss: 0.167524\tvalid_1's multi_logloss: 0.27347        \n",
      "[105]\ttraining's multi_logloss: 0.165975\tvalid_1's multi_logloss: 0.273295       \n",
      "[106]\ttraining's multi_logloss: 0.164283\tvalid_1's multi_logloss: 0.272855       \n",
      "[107]\ttraining's multi_logloss: 0.162584\tvalid_1's multi_logloss: 0.272518       \n",
      "[108]\ttraining's multi_logloss: 0.160868\tvalid_1's multi_logloss: 0.271983       \n",
      "[109]\ttraining's multi_logloss: 0.159284\tvalid_1's multi_logloss: 0.271726       \n",
      "[110]\ttraining's multi_logloss: 0.157822\tvalid_1's multi_logloss: 0.27135        \n",
      "[111]\ttraining's multi_logloss: 0.156382\tvalid_1's multi_logloss: 0.271239       \n",
      "[112]\ttraining's multi_logloss: 0.154775\tvalid_1's multi_logloss: 0.271034       \n",
      "[113]\ttraining's multi_logloss: 0.153322\tvalid_1's multi_logloss: 0.270825       \n",
      "[114]\ttraining's multi_logloss: 0.151808\tvalid_1's multi_logloss: 0.270666       \n",
      "[115]\ttraining's multi_logloss: 0.15042\tvalid_1's multi_logloss: 0.270472        \n",
      "[116]\ttraining's multi_logloss: 0.148787\tvalid_1's multi_logloss: 0.270228       \n",
      "[117]\ttraining's multi_logloss: 0.147404\tvalid_1's multi_logloss: 0.270074       \n",
      "[118]\ttraining's multi_logloss: 0.146108\tvalid_1's multi_logloss: 0.269974       \n",
      "[119]\ttraining's multi_logloss: 0.144433\tvalid_1's multi_logloss: 0.269696       \n",
      "[120]\ttraining's multi_logloss: 0.143064\tvalid_1's multi_logloss: 0.269664       \n",
      "[121]\ttraining's multi_logloss: 0.141775\tvalid_1's multi_logloss: 0.269652       \n",
      "[122]\ttraining's multi_logloss: 0.140452\tvalid_1's multi_logloss: 0.269409       \n",
      "[123]\ttraining's multi_logloss: 0.139178\tvalid_1's multi_logloss: 0.269412       \n",
      "[124]\ttraining's multi_logloss: 0.137913\tvalid_1's multi_logloss: 0.269232       \n",
      "[125]\ttraining's multi_logloss: 0.136548\tvalid_1's multi_logloss: 0.2691         \n",
      "[126]\ttraining's multi_logloss: 0.135266\tvalid_1's multi_logloss: 0.268918       \n",
      "[127]\ttraining's multi_logloss: 0.134094\tvalid_1's multi_logloss: 0.26873        \n",
      "[128]\ttraining's multi_logloss: 0.13287\tvalid_1's multi_logloss: 0.268687        \n",
      "[129]\ttraining's multi_logloss: 0.131736\tvalid_1's multi_logloss: 0.268713       \n",
      "[130]\ttraining's multi_logloss: 0.130433\tvalid_1's multi_logloss: 0.268496       \n",
      "[131]\ttraining's multi_logloss: 0.129312\tvalid_1's multi_logloss: 0.268508       \n",
      "[132]\ttraining's multi_logloss: 0.128128\tvalid_1's multi_logloss: 0.268438       \n",
      "[133]\ttraining's multi_logloss: 0.127116\tvalid_1's multi_logloss: 0.268351       \n",
      "[134]\ttraining's multi_logloss: 0.125939\tvalid_1's multi_logloss: 0.268211       \n",
      "[135]\ttraining's multi_logloss: 0.124681\tvalid_1's multi_logloss: 0.268131       \n",
      "[136]\ttraining's multi_logloss: 0.123511\tvalid_1's multi_logloss: 0.26821        \n",
      "[137]\ttraining's multi_logloss: 0.122358\tvalid_1's multi_logloss: 0.268135       \n",
      "[138]\ttraining's multi_logloss: 0.121235\tvalid_1's multi_logloss: 0.268155       \n",
      "[139]\ttraining's multi_logloss: 0.12013\tvalid_1's multi_logloss: 0.268133        \n",
      "[140]\ttraining's multi_logloss: 0.119004\tvalid_1's multi_logloss: 0.268106       \n",
      "[141]\ttraining's multi_logloss: 0.118053\tvalid_1's multi_logloss: 0.268265       \n",
      "[142]\ttraining's multi_logloss: 0.116963\tvalid_1's multi_logloss: 0.268275       \n",
      "[143]\ttraining's multi_logloss: 0.116033\tvalid_1's multi_logloss: 0.268199       \n",
      "[144]\ttraining's multi_logloss: 0.115044\tvalid_1's multi_logloss: 0.268328       \n",
      "[145]\ttraining's multi_logloss: 0.113987\tvalid_1's multi_logloss: 0.268246       \n",
      "[146]\ttraining's multi_logloss: 0.112971\tvalid_1's multi_logloss: 0.268305       \n",
      "[147]\ttraining's multi_logloss: 0.111939\tvalid_1's multi_logloss: 0.268365       \n",
      "[148]\ttraining's multi_logloss: 0.111065\tvalid_1's multi_logloss: 0.268377       \n",
      "[149]\ttraining's multi_logloss: 0.110063\tvalid_1's multi_logloss: 0.268476       \n",
      "[150]\ttraining's multi_logloss: 0.109076\tvalid_1's multi_logloss: 0.268526       \n",
      "[151]\ttraining's multi_logloss: 0.108157\tvalid_1's multi_logloss: 0.268625       \n",
      "[152]\ttraining's multi_logloss: 0.107204\tvalid_1's multi_logloss: 0.268805       \n",
      "[153]\ttraining's multi_logloss: 0.106186\tvalid_1's multi_logloss: 0.268716       \n",
      "[154]\ttraining's multi_logloss: 0.105184\tvalid_1's multi_logloss: 0.268862       \n",
      "[155]\ttraining's multi_logloss: 0.104096\tvalid_1's multi_logloss: 0.268903       \n",
      "[156]\ttraining's multi_logloss: 0.103253\tvalid_1's multi_logloss: 0.268963       \n",
      "[157]\ttraining's multi_logloss: 0.102376\tvalid_1's multi_logloss: 0.269106       \n",
      "[158]\ttraining's multi_logloss: 0.101442\tvalid_1's multi_logloss: 0.269146       \n",
      "[159]\ttraining's multi_logloss: 0.100569\tvalid_1's multi_logloss: 0.269353       \n",
      "[160]\ttraining's multi_logloss: 0.0997062\tvalid_1's multi_logloss: 0.269514      \n",
      "[161]\ttraining's multi_logloss: 0.0987932\tvalid_1's multi_logloss: 0.269481      \n",
      "[162]\ttraining's multi_logloss: 0.0979143\tvalid_1's multi_logloss: 0.269781      \n",
      "[163]\ttraining's multi_logloss: 0.0970414\tvalid_1's multi_logloss: 0.269792      \n",
      "[164]\ttraining's multi_logloss: 0.0960496\tvalid_1's multi_logloss: 0.26996       \n",
      "[165]\ttraining's multi_logloss: 0.0951739\tvalid_1's multi_logloss: 0.270086      \n",
      "[166]\ttraining's multi_logloss: 0.0942689\tvalid_1's multi_logloss: 0.270116      \n",
      "[167]\ttraining's multi_logloss: 0.0933923\tvalid_1's multi_logloss: 0.270335      \n",
      "[168]\ttraining's multi_logloss: 0.092601\tvalid_1's multi_logloss: 0.270552       \n",
      "[169]\ttraining's multi_logloss: 0.0917582\tvalid_1's multi_logloss: 0.27051       \n",
      "[170]\ttraining's multi_logloss: 0.0909449\tvalid_1's multi_logloss: 0.270712      \n",
      "Early stopping, best iteration is:                                               \n",
      "[140]\ttraining's multi_logloss: 0.119004\tvalid_1's multi_logloss: 0.268106\n",
      "[1]\ttraining's multi_logloss: 1.65044\tvalid_1's multi_logloss: 1.65443           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.44951\tvalid_1's multi_logloss: 1.45754           \n",
      "[3]\ttraining's multi_logloss: 1.2938\tvalid_1's multi_logloss: 1.30694            \n",
      "[4]\ttraining's multi_logloss: 1.16795\tvalid_1's multi_logloss: 1.18482           \n",
      "[5]\ttraining's multi_logloss: 1.0634\tvalid_1's multi_logloss: 1.08352            \n",
      "[6]\ttraining's multi_logloss: 0.974854\tvalid_1's multi_logloss: 0.997692         \n",
      "[7]\ttraining's multi_logloss: 0.89672\tvalid_1's multi_logloss: 0.921804          \n",
      "[8]\ttraining's multi_logloss: 0.830545\tvalid_1's multi_logloss: 0.857898         \n",
      "[9]\ttraining's multi_logloss: 0.772744\tvalid_1's multi_logloss: 0.801888         \n",
      "[10]\ttraining's multi_logloss: 0.720974\tvalid_1's multi_logloss: 0.752221        \n",
      "[11]\ttraining's multi_logloss: 0.674606\tvalid_1's multi_logloss: 0.70749         \n",
      "[12]\ttraining's multi_logloss: 0.633364\tvalid_1's multi_logloss: 0.668077        \n",
      "[13]\ttraining's multi_logloss: 0.596071\tvalid_1's multi_logloss: 0.632515        \n",
      "[14]\ttraining's multi_logloss: 0.563039\tvalid_1's multi_logloss: 0.601215        \n",
      "[15]\ttraining's multi_logloss: 0.533148\tvalid_1's multi_logloss: 0.573091        \n",
      "[16]\ttraining's multi_logloss: 0.506291\tvalid_1's multi_logloss: 0.547953        \n",
      "[17]\ttraining's multi_logloss: 0.482123\tvalid_1's multi_logloss: 0.525484        \n",
      "[18]\ttraining's multi_logloss: 0.460035\tvalid_1's multi_logloss: 0.505027        \n",
      "[19]\ttraining's multi_logloss: 0.439863\tvalid_1's multi_logloss: 0.486479        \n",
      "[20]\ttraining's multi_logloss: 0.420944\tvalid_1's multi_logloss: 0.469298        \n",
      "[21]\ttraining's multi_logloss: 0.403866\tvalid_1's multi_logloss: 0.454216        \n",
      "[22]\ttraining's multi_logloss: 0.38838\tvalid_1's multi_logloss: 0.440379         \n",
      "[23]\ttraining's multi_logloss: 0.374048\tvalid_1's multi_logloss: 0.427808        \n",
      "[24]\ttraining's multi_logloss: 0.361225\tvalid_1's multi_logloss: 0.41658         \n",
      "[25]\ttraining's multi_logloss: 0.34912\tvalid_1's multi_logloss: 0.406273         \n",
      "[26]\ttraining's multi_logloss: 0.337934\tvalid_1's multi_logloss: 0.39702         \n",
      "[27]\ttraining's multi_logloss: 0.327689\tvalid_1's multi_logloss: 0.388332        \n",
      "[28]\ttraining's multi_logloss: 0.317876\tvalid_1's multi_logloss: 0.380098        \n",
      "[29]\ttraining's multi_logloss: 0.308875\tvalid_1's multi_logloss: 0.373158        \n",
      "[30]\ttraining's multi_logloss: 0.300217\tvalid_1's multi_logloss: 0.366536        \n",
      "[31]\ttraining's multi_logloss: 0.292554\tvalid_1's multi_logloss: 0.360648        \n",
      "[32]\ttraining's multi_logloss: 0.284845\tvalid_1's multi_logloss: 0.355151        \n",
      "[33]\ttraining's multi_logloss: 0.277954\tvalid_1's multi_logloss: 0.349979        \n",
      "[34]\ttraining's multi_logloss: 0.271438\tvalid_1's multi_logloss: 0.34514         \n",
      "[35]\ttraining's multi_logloss: 0.265364\tvalid_1's multi_logloss: 0.340878        \n",
      "[36]\ttraining's multi_logloss: 0.259278\tvalid_1's multi_logloss: 0.336801        \n",
      "[37]\ttraining's multi_logloss: 0.253639\tvalid_1's multi_logloss: 0.333176        \n",
      "[38]\ttraining's multi_logloss: 0.247989\tvalid_1's multi_logloss: 0.329913        \n",
      "[39]\ttraining's multi_logloss: 0.242753\tvalid_1's multi_logloss: 0.326139        \n",
      "[40]\ttraining's multi_logloss: 0.237849\tvalid_1's multi_logloss: 0.322967        \n",
      "[41]\ttraining's multi_logloss: 0.233229\tvalid_1's multi_logloss: 0.320329        \n",
      "[42]\ttraining's multi_logloss: 0.228736\tvalid_1's multi_logloss: 0.317966        \n",
      "[43]\ttraining's multi_logloss: 0.224359\tvalid_1's multi_logloss: 0.315418        \n",
      "[44]\ttraining's multi_logloss: 0.220179\tvalid_1's multi_logloss: 0.313551        \n",
      "[45]\ttraining's multi_logloss: 0.216432\tvalid_1's multi_logloss: 0.311792        \n",
      "[46]\ttraining's multi_logloss: 0.212452\tvalid_1's multi_logloss: 0.310111        \n",
      "[47]\ttraining's multi_logloss: 0.208856\tvalid_1's multi_logloss: 0.308608        \n",
      "[48]\ttraining's multi_logloss: 0.205177\tvalid_1's multi_logloss: 0.307258        \n",
      "[49]\ttraining's multi_logloss: 0.201723\tvalid_1's multi_logloss: 0.305904        \n",
      "[50]\ttraining's multi_logloss: 0.198146\tvalid_1's multi_logloss: 0.304611        \n",
      "[51]\ttraining's multi_logloss: 0.195033\tvalid_1's multi_logloss: 0.303749        \n",
      "[52]\ttraining's multi_logloss: 0.191789\tvalid_1's multi_logloss: 0.302693        \n",
      "[53]\ttraining's multi_logloss: 0.188605\tvalid_1's multi_logloss: 0.301771        \n",
      "[54]\ttraining's multi_logloss: 0.185748\tvalid_1's multi_logloss: 0.300886        \n",
      "[55]\ttraining's multi_logloss: 0.182611\tvalid_1's multi_logloss: 0.299902        \n",
      "[56]\ttraining's multi_logloss: 0.179529\tvalid_1's multi_logloss: 0.299242        \n",
      "[57]\ttraining's multi_logloss: 0.176582\tvalid_1's multi_logloss: 0.298461        \n",
      "[58]\ttraining's multi_logloss: 0.173483\tvalid_1's multi_logloss: 0.297593        \n",
      "[59]\ttraining's multi_logloss: 0.170454\tvalid_1's multi_logloss: 0.29705         \n",
      "[60]\ttraining's multi_logloss: 0.167811\tvalid_1's multi_logloss: 0.296627        \n",
      "[61]\ttraining's multi_logloss: 0.165194\tvalid_1's multi_logloss: 0.295999        \n",
      "[62]\ttraining's multi_logloss: 0.16265\tvalid_1's multi_logloss: 0.295485         \n",
      "[63]\ttraining's multi_logloss: 0.160075\tvalid_1's multi_logloss: 0.295021        \n",
      "[64]\ttraining's multi_logloss: 0.157538\tvalid_1's multi_logloss: 0.29469         \n",
      "[65]\ttraining's multi_logloss: 0.155059\tvalid_1's multi_logloss: 0.294731        \n",
      "[66]\ttraining's multi_logloss: 0.152608\tvalid_1's multi_logloss: 0.294179        \n",
      "[67]\ttraining's multi_logloss: 0.150215\tvalid_1's multi_logloss: 0.293962        \n",
      "[68]\ttraining's multi_logloss: 0.147632\tvalid_1's multi_logloss: 0.293429        \n",
      "[69]\ttraining's multi_logloss: 0.145336\tvalid_1's multi_logloss: 0.29316         \n",
      "[70]\ttraining's multi_logloss: 0.142968\tvalid_1's multi_logloss: 0.292954        \n",
      "[71]\ttraining's multi_logloss: 0.14083\tvalid_1's multi_logloss: 0.292777         \n",
      "[72]\ttraining's multi_logloss: 0.138686\tvalid_1's multi_logloss: 0.292534        \n",
      "[73]\ttraining's multi_logloss: 0.136627\tvalid_1's multi_logloss: 0.292046        \n",
      "[74]\ttraining's multi_logloss: 0.134467\tvalid_1's multi_logloss: 0.29172         \n",
      "[75]\ttraining's multi_logloss: 0.132321\tvalid_1's multi_logloss: 0.291544        \n",
      "[76]\ttraining's multi_logloss: 0.13047\tvalid_1's multi_logloss: 0.291337         \n",
      "[77]\ttraining's multi_logloss: 0.12815\tvalid_1's multi_logloss: 0.291427         \n",
      "[78]\ttraining's multi_logloss: 0.126071\tvalid_1's multi_logloss: 0.291404        \n",
      "[79]\ttraining's multi_logloss: 0.123951\tvalid_1's multi_logloss: 0.291196        \n",
      "[80]\ttraining's multi_logloss: 0.122035\tvalid_1's multi_logloss: 0.290967        \n",
      "[81]\ttraining's multi_logloss: 0.120082\tvalid_1's multi_logloss: 0.291161        \n",
      "[82]\ttraining's multi_logloss: 0.11817\tvalid_1's multi_logloss: 0.291075         \n",
      "[83]\ttraining's multi_logloss: 0.116428\tvalid_1's multi_logloss: 0.291018        \n",
      "[84]\ttraining's multi_logloss: 0.114495\tvalid_1's multi_logloss: 0.291173        \n",
      "[85]\ttraining's multi_logloss: 0.112764\tvalid_1's multi_logloss: 0.291156        \n",
      "[86]\ttraining's multi_logloss: 0.110888\tvalid_1's multi_logloss: 0.291229        \n",
      "[87]\ttraining's multi_logloss: 0.109263\tvalid_1's multi_logloss: 0.291828        \n",
      "[88]\ttraining's multi_logloss: 0.107423\tvalid_1's multi_logloss: 0.291801        \n",
      "[89]\ttraining's multi_logloss: 0.105698\tvalid_1's multi_logloss: 0.29189         \n",
      "[90]\ttraining's multi_logloss: 0.104157\tvalid_1's multi_logloss: 0.292191        \n",
      "[91]\ttraining's multi_logloss: 0.102547\tvalid_1's multi_logloss: 0.292232        \n",
      "[92]\ttraining's multi_logloss: 0.100977\tvalid_1's multi_logloss: 0.292383        \n",
      "[93]\ttraining's multi_logloss: 0.0994988\tvalid_1's multi_logloss: 0.292436       \n",
      "[94]\ttraining's multi_logloss: 0.0980305\tvalid_1's multi_logloss: 0.292806       \n",
      "[95]\ttraining's multi_logloss: 0.0963141\tvalid_1's multi_logloss: 0.293221       \n",
      "[96]\ttraining's multi_logloss: 0.0947455\tvalid_1's multi_logloss: 0.293235       \n",
      "[97]\ttraining's multi_logloss: 0.0933265\tvalid_1's multi_logloss: 0.293501       \n",
      "[98]\ttraining's multi_logloss: 0.0920445\tvalid_1's multi_logloss: 0.293617       \n",
      "[99]\ttraining's multi_logloss: 0.0906014\tvalid_1's multi_logloss: 0.293565       \n",
      "[100]\ttraining's multi_logloss: 0.0892541\tvalid_1's multi_logloss: 0.293975      \n",
      "[101]\ttraining's multi_logloss: 0.0880273\tvalid_1's multi_logloss: 0.294142      \n",
      "[102]\ttraining's multi_logloss: 0.0866742\tvalid_1's multi_logloss: 0.294842      \n",
      "[103]\ttraining's multi_logloss: 0.0854147\tvalid_1's multi_logloss: 0.295116      \n",
      "[104]\ttraining's multi_logloss: 0.0843011\tvalid_1's multi_logloss: 0.295557      \n",
      "[105]\ttraining's multi_logloss: 0.0831665\tvalid_1's multi_logloss: 0.295893      \n",
      "[106]\ttraining's multi_logloss: 0.0821045\tvalid_1's multi_logloss: 0.296342      \n",
      "[107]\ttraining's multi_logloss: 0.0810346\tvalid_1's multi_logloss: 0.296604      \n",
      "[108]\ttraining's multi_logloss: 0.0798291\tvalid_1's multi_logloss: 0.297073      \n",
      "[109]\ttraining's multi_logloss: 0.0788566\tvalid_1's multi_logloss: 0.297342      \n",
      "[110]\ttraining's multi_logloss: 0.0778283\tvalid_1's multi_logloss: 0.297812      \n",
      "Early stopping, best iteration is:                                               \n",
      "[80]\ttraining's multi_logloss: 0.122035\tvalid_1's multi_logloss: 0.290967\n",
      "[1]\ttraining's multi_logloss: 1.64936\tvalid_1's multi_logloss: 1.65267           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.4508\tvalid_1's multi_logloss: 1.45458            \n",
      "[3]\ttraining's multi_logloss: 1.29741\tvalid_1's multi_logloss: 1.3032            \n",
      "[4]\ttraining's multi_logloss: 1.17306\tvalid_1's multi_logloss: 1.18089           \n",
      "[5]\ttraining's multi_logloss: 1.06877\tvalid_1's multi_logloss: 1.07795           \n",
      "[6]\ttraining's multi_logloss: 0.980917\tvalid_1's multi_logloss: 0.991818         \n",
      "[7]\ttraining's multi_logloss: 0.903993\tvalid_1's multi_logloss: 0.916149         \n",
      "[8]\ttraining's multi_logloss: 0.837861\tvalid_1's multi_logloss: 0.851611         \n",
      "[9]\ttraining's multi_logloss: 0.779552\tvalid_1's multi_logloss: 0.7949           \n",
      "[10]\ttraining's multi_logloss: 0.72835\tvalid_1's multi_logloss: 0.745498         \n",
      "[11]\ttraining's multi_logloss: 0.682194\tvalid_1's multi_logloss: 0.701481        \n",
      "[12]\ttraining's multi_logloss: 0.640725\tvalid_1's multi_logloss: 0.661681        \n",
      "[13]\ttraining's multi_logloss: 0.603496\tvalid_1's multi_logloss: 0.626011        \n",
      "[14]\ttraining's multi_logloss: 0.570392\tvalid_1's multi_logloss: 0.594465        \n",
      "[15]\ttraining's multi_logloss: 0.540282\tvalid_1's multi_logloss: 0.565933        \n",
      "[16]\ttraining's multi_logloss: 0.513338\tvalid_1's multi_logloss: 0.54062         \n",
      "[17]\ttraining's multi_logloss: 0.489151\tvalid_1's multi_logloss: 0.518315        \n",
      "[18]\ttraining's multi_logloss: 0.466383\tvalid_1's multi_logloss: 0.497476        \n",
      "[19]\ttraining's multi_logloss: 0.445627\tvalid_1's multi_logloss: 0.4782          \n",
      "[20]\ttraining's multi_logloss: 0.426866\tvalid_1's multi_logloss: 0.46113         \n",
      "[21]\ttraining's multi_logloss: 0.410103\tvalid_1's multi_logloss: 0.446023        \n",
      "[22]\ttraining's multi_logloss: 0.394429\tvalid_1's multi_logloss: 0.432409        \n",
      "[23]\ttraining's multi_logloss: 0.380548\tvalid_1's multi_logloss: 0.420098        \n",
      "[24]\ttraining's multi_logloss: 0.367574\tvalid_1's multi_logloss: 0.408604        \n",
      "[25]\ttraining's multi_logloss: 0.355112\tvalid_1's multi_logloss: 0.397952        \n",
      "[26]\ttraining's multi_logloss: 0.343947\tvalid_1's multi_logloss: 0.388611        \n",
      "[27]\ttraining's multi_logloss: 0.333257\tvalid_1's multi_logloss: 0.379574        \n",
      "[28]\ttraining's multi_logloss: 0.323188\tvalid_1's multi_logloss: 0.371346        \n",
      "[29]\ttraining's multi_logloss: 0.313621\tvalid_1's multi_logloss: 0.363704        \n",
      "[30]\ttraining's multi_logloss: 0.3049\tvalid_1's multi_logloss: 0.356558          \n",
      "[31]\ttraining's multi_logloss: 0.296571\tvalid_1's multi_logloss: 0.350183        \n",
      "[32]\ttraining's multi_logloss: 0.288917\tvalid_1's multi_logloss: 0.344541        \n",
      "[33]\ttraining's multi_logloss: 0.281707\tvalid_1's multi_logloss: 0.339134        \n",
      "[34]\ttraining's multi_logloss: 0.274989\tvalid_1's multi_logloss: 0.334327        \n",
      "[35]\ttraining's multi_logloss: 0.268712\tvalid_1's multi_logloss: 0.330066        \n",
      "[36]\ttraining's multi_logloss: 0.262726\tvalid_1's multi_logloss: 0.326166        \n",
      "[37]\ttraining's multi_logloss: 0.256956\tvalid_1's multi_logloss: 0.322733        \n",
      "[38]\ttraining's multi_logloss: 0.251654\tvalid_1's multi_logloss: 0.319313        \n",
      "[39]\ttraining's multi_logloss: 0.24663\tvalid_1's multi_logloss: 0.316            \n",
      "[40]\ttraining's multi_logloss: 0.241448\tvalid_1's multi_logloss: 0.313045        \n",
      "[41]\ttraining's multi_logloss: 0.236704\tvalid_1's multi_logloss: 0.310612        \n",
      "[42]\ttraining's multi_logloss: 0.232054\tvalid_1's multi_logloss: 0.308281        \n",
      "[43]\ttraining's multi_logloss: 0.227426\tvalid_1's multi_logloss: 0.306036        \n",
      "[44]\ttraining's multi_logloss: 0.223015\tvalid_1's multi_logloss: 0.304077        \n",
      "[45]\ttraining's multi_logloss: 0.218817\tvalid_1's multi_logloss: 0.302496        \n",
      "[46]\ttraining's multi_logloss: 0.214864\tvalid_1's multi_logloss: 0.300482        \n",
      "[47]\ttraining's multi_logloss: 0.211005\tvalid_1's multi_logloss: 0.299136        \n",
      "[48]\ttraining's multi_logloss: 0.207313\tvalid_1's multi_logloss: 0.297676        \n",
      "[49]\ttraining's multi_logloss: 0.203543\tvalid_1's multi_logloss: 0.296449        \n",
      "[50]\ttraining's multi_logloss: 0.200036\tvalid_1's multi_logloss: 0.295433        \n",
      "[51]\ttraining's multi_logloss: 0.196513\tvalid_1's multi_logloss: 0.294397        \n",
      "[52]\ttraining's multi_logloss: 0.193141\tvalid_1's multi_logloss: 0.293284        \n",
      "[53]\ttraining's multi_logloss: 0.189848\tvalid_1's multi_logloss: 0.292317        \n",
      "[54]\ttraining's multi_logloss: 0.186519\tvalid_1's multi_logloss: 0.291573        \n",
      "[55]\ttraining's multi_logloss: 0.18346\tvalid_1's multi_logloss: 0.290727         \n",
      "[56]\ttraining's multi_logloss: 0.180348\tvalid_1's multi_logloss: 0.29022         \n",
      "[57]\ttraining's multi_logloss: 0.177085\tvalid_1's multi_logloss: 0.289407        \n",
      "[58]\ttraining's multi_logloss: 0.174147\tvalid_1's multi_logloss: 0.288535        \n",
      "[59]\ttraining's multi_logloss: 0.171466\tvalid_1's multi_logloss: 0.287806        \n",
      "[60]\ttraining's multi_logloss: 0.168534\tvalid_1's multi_logloss: 0.287295        \n",
      "[61]\ttraining's multi_logloss: 0.165696\tvalid_1's multi_logloss: 0.286818        \n",
      "[62]\ttraining's multi_logloss: 0.16288\tvalid_1's multi_logloss: 0.286157         \n",
      "[63]\ttraining's multi_logloss: 0.159968\tvalid_1's multi_logloss: 0.285617        \n",
      "[64]\ttraining's multi_logloss: 0.15717\tvalid_1's multi_logloss: 0.2851           \n",
      "[65]\ttraining's multi_logloss: 0.154684\tvalid_1's multi_logloss: 0.284603        \n",
      "[66]\ttraining's multi_logloss: 0.152352\tvalid_1's multi_logloss: 0.284502        \n",
      "[67]\ttraining's multi_logloss: 0.149805\tvalid_1's multi_logloss: 0.284131        \n",
      "[68]\ttraining's multi_logloss: 0.147609\tvalid_1's multi_logloss: 0.283985        \n",
      "[69]\ttraining's multi_logloss: 0.145352\tvalid_1's multi_logloss: 0.283874        \n",
      "[70]\ttraining's multi_logloss: 0.143196\tvalid_1's multi_logloss: 0.283694        \n",
      "[71]\ttraining's multi_logloss: 0.140839\tvalid_1's multi_logloss: 0.283264        \n",
      "[72]\ttraining's multi_logloss: 0.138646\tvalid_1's multi_logloss: 0.283057        \n",
      "[73]\ttraining's multi_logloss: 0.136377\tvalid_1's multi_logloss: 0.283136        \n",
      "[74]\ttraining's multi_logloss: 0.134206\tvalid_1's multi_logloss: 0.283219        \n",
      "[75]\ttraining's multi_logloss: 0.132064\tvalid_1's multi_logloss: 0.282889        \n",
      "[76]\ttraining's multi_logloss: 0.130111\tvalid_1's multi_logloss: 0.282636        \n",
      "[77]\ttraining's multi_logloss: 0.128\tvalid_1's multi_logloss: 0.282542           \n",
      "[78]\ttraining's multi_logloss: 0.125781\tvalid_1's multi_logloss: 0.282747        \n",
      "[79]\ttraining's multi_logloss: 0.123701\tvalid_1's multi_logloss: 0.282625        \n",
      "[80]\ttraining's multi_logloss: 0.121579\tvalid_1's multi_logloss: 0.282236        \n",
      "[81]\ttraining's multi_logloss: 0.119655\tvalid_1's multi_logloss: 0.282086        \n",
      "[82]\ttraining's multi_logloss: 0.117634\tvalid_1's multi_logloss: 0.281788        \n",
      "[83]\ttraining's multi_logloss: 0.115659\tvalid_1's multi_logloss: 0.281884        \n",
      "[84]\ttraining's multi_logloss: 0.113777\tvalid_1's multi_logloss: 0.28164         \n",
      "[85]\ttraining's multi_logloss: 0.111849\tvalid_1's multi_logloss: 0.281795        \n",
      "[86]\ttraining's multi_logloss: 0.109947\tvalid_1's multi_logloss: 0.281688        \n",
      "[87]\ttraining's multi_logloss: 0.108143\tvalid_1's multi_logloss: 0.281612        \n",
      "[88]\ttraining's multi_logloss: 0.106475\tvalid_1's multi_logloss: 0.281724        \n",
      "[89]\ttraining's multi_logloss: 0.104718\tvalid_1's multi_logloss: 0.281844        \n",
      "[90]\ttraining's multi_logloss: 0.10303\tvalid_1's multi_logloss: 0.281616         \n",
      "[91]\ttraining's multi_logloss: 0.101385\tvalid_1's multi_logloss: 0.2818          \n",
      "[92]\ttraining's multi_logloss: 0.099998\tvalid_1's multi_logloss: 0.281896        \n",
      "[93]\ttraining's multi_logloss: 0.0983971\tvalid_1's multi_logloss: 0.281829       \n",
      "[94]\ttraining's multi_logloss: 0.0969002\tvalid_1's multi_logloss: 0.282062       \n",
      "[95]\ttraining's multi_logloss: 0.0953381\tvalid_1's multi_logloss: 0.282011       \n",
      "[96]\ttraining's multi_logloss: 0.0940028\tvalid_1's multi_logloss: 0.282097       \n",
      "[97]\ttraining's multi_logloss: 0.0926666\tvalid_1's multi_logloss: 0.282353       \n",
      "[98]\ttraining's multi_logloss: 0.0912663\tvalid_1's multi_logloss: 0.282606       \n",
      "[99]\ttraining's multi_logloss: 0.090006\tvalid_1's multi_logloss: 0.283013        \n",
      "[100]\ttraining's multi_logloss: 0.0886166\tvalid_1's multi_logloss: 0.283465      \n",
      "[101]\ttraining's multi_logloss: 0.0873915\tvalid_1's multi_logloss: 0.283855      \n",
      "[102]\ttraining's multi_logloss: 0.0862052\tvalid_1's multi_logloss: 0.28418       \n",
      "[103]\ttraining's multi_logloss: 0.0849637\tvalid_1's multi_logloss: 0.284441      \n",
      "[104]\ttraining's multi_logloss: 0.0836703\tvalid_1's multi_logloss: 0.28462       \n",
      "[105]\ttraining's multi_logloss: 0.0825798\tvalid_1's multi_logloss: 0.284917      \n",
      "[106]\ttraining's multi_logloss: 0.08135\tvalid_1's multi_logloss: 0.285338        \n",
      "[107]\ttraining's multi_logloss: 0.0801025\tvalid_1's multi_logloss: 0.285687      \n",
      "[108]\ttraining's multi_logloss: 0.0788773\tvalid_1's multi_logloss: 0.285777      \n",
      "[109]\ttraining's multi_logloss: 0.07774\tvalid_1's multi_logloss: 0.286171        \n",
      "[110]\ttraining's multi_logloss: 0.0765281\tvalid_1's multi_logloss: 0.286633      \n",
      "[111]\ttraining's multi_logloss: 0.0753053\tvalid_1's multi_logloss: 0.286783      \n",
      "[112]\ttraining's multi_logloss: 0.0740589\tvalid_1's multi_logloss: 0.287016      \n",
      "[113]\ttraining's multi_logloss: 0.0728105\tvalid_1's multi_logloss: 0.287563      \n",
      "[114]\ttraining's multi_logloss: 0.0718444\tvalid_1's multi_logloss: 0.287986      \n",
      "[115]\ttraining's multi_logloss: 0.0706641\tvalid_1's multi_logloss: 0.288329      \n",
      "[116]\ttraining's multi_logloss: 0.0696135\tvalid_1's multi_logloss: 0.289005      \n",
      "[117]\ttraining's multi_logloss: 0.0686107\tvalid_1's multi_logloss: 0.289451      \n",
      "Early stopping, best iteration is:                                               \n",
      "[87]\ttraining's multi_logloss: 0.108143\tvalid_1's multi_logloss: 0.281612\n",
      "[1]\ttraining's multi_logloss: 1.65044\tvalid_1's multi_logloss: 1.65371           \n",
      "Training until validation scores don't improve for 30 rounds                     \n",
      "[2]\ttraining's multi_logloss: 1.45313\tvalid_1's multi_logloss: 1.4587            \n",
      "[3]\ttraining's multi_logloss: 1.29867\tvalid_1's multi_logloss: 1.30493           \n",
      "[4]\ttraining's multi_logloss: 1.1748\tvalid_1's multi_logloss: 1.18214            \n",
      "[5]\ttraining's multi_logloss: 1.07086\tvalid_1's multi_logloss: 1.0793            \n",
      "[6]\ttraining's multi_logloss: 0.982395\tvalid_1's multi_logloss: 0.991905         \n",
      "[7]\ttraining's multi_logloss: 0.905697\tvalid_1's multi_logloss: 0.91578          \n",
      "[8]\ttraining's multi_logloss: 0.838177\tvalid_1's multi_logloss: 0.849572         \n",
      "[9]\ttraining's multi_logloss: 0.779347\tvalid_1's multi_logloss: 0.791654         \n",
      "[10]\ttraining's multi_logloss: 0.727899\tvalid_1's multi_logloss: 0.741297        \n",
      "[11]\ttraining's multi_logloss: 0.6826\tvalid_1's multi_logloss: 0.697368          \n",
      "[12]\ttraining's multi_logloss: 0.64193\tvalid_1's multi_logloss: 0.658403         \n",
      "[13]\ttraining's multi_logloss: 0.604808\tvalid_1's multi_logloss: 0.622474        \n",
      "[14]\ttraining's multi_logloss: 0.571776\tvalid_1's multi_logloss: 0.59079         \n",
      "[15]\ttraining's multi_logloss: 0.542425\tvalid_1's multi_logloss: 0.562895        \n",
      "[16]\ttraining's multi_logloss: 0.515766\tvalid_1's multi_logloss: 0.537441        \n",
      "[17]\ttraining's multi_logloss: 0.491517\tvalid_1's multi_logloss: 0.514678        \n",
      "[18]\ttraining's multi_logloss: 0.4695\tvalid_1's multi_logloss: 0.493936          \n",
      "[19]\ttraining's multi_logloss: 0.449365\tvalid_1's multi_logloss: 0.475019        \n",
      "[20]\ttraining's multi_logloss: 0.431119\tvalid_1's multi_logloss: 0.458031        \n",
      "[21]\ttraining's multi_logloss: 0.414176\tvalid_1's multi_logloss: 0.44225         \n",
      "[22]\ttraining's multi_logloss: 0.398491\tvalid_1's multi_logloss: 0.427954        \n",
      "[23]\ttraining's multi_logloss: 0.383821\tvalid_1's multi_logloss: 0.414635        \n",
      "[24]\ttraining's multi_logloss: 0.370965\tvalid_1's multi_logloss: 0.402972        \n",
      "[25]\ttraining's multi_logloss: 0.358771\tvalid_1's multi_logloss: 0.392115        \n",
      "[26]\ttraining's multi_logloss: 0.347753\tvalid_1's multi_logloss: 0.38245         \n",
      "[27]\ttraining's multi_logloss: 0.337228\tvalid_1's multi_logloss: 0.373541        \n",
      "[28]\ttraining's multi_logloss: 0.327582\tvalid_1's multi_logloss: 0.365509        \n",
      "[29]\ttraining's multi_logloss: 0.318335\tvalid_1's multi_logloss: 0.357601        \n",
      "[30]\ttraining's multi_logloss: 0.309878\tvalid_1's multi_logloss: 0.350639        \n",
      "[31]\ttraining's multi_logloss: 0.301782\tvalid_1's multi_logloss: 0.344348        \n",
      "[32]\ttraining's multi_logloss: 0.294159\tvalid_1's multi_logloss: 0.338618        \n",
      "[33]\ttraining's multi_logloss: 0.287047\tvalid_1's multi_logloss: 0.333089        \n",
      "[34]\ttraining's multi_logloss: 0.280517\tvalid_1's multi_logloss: 0.328337        \n",
      "[35]\ttraining's multi_logloss: 0.27397\tvalid_1's multi_logloss: 0.323775         \n",
      "[36]\ttraining's multi_logloss: 0.268039\tvalid_1's multi_logloss: 0.319891        \n",
      "[37]\ttraining's multi_logloss: 0.262216\tvalid_1's multi_logloss: 0.316012        \n",
      "[38]\ttraining's multi_logloss: 0.256755\tvalid_1's multi_logloss: 0.312613        \n",
      "[39]\ttraining's multi_logloss: 0.251444\tvalid_1's multi_logloss: 0.309481        \n",
      "[40]\ttraining's multi_logloss: 0.246412\tvalid_1's multi_logloss: 0.306434        \n",
      "[41]\ttraining's multi_logloss: 0.241529\tvalid_1's multi_logloss: 0.303318        \n",
      "[42]\ttraining's multi_logloss: 0.236886\tvalid_1's multi_logloss: 0.300576        \n",
      "[43]\ttraining's multi_logloss: 0.232678\tvalid_1's multi_logloss: 0.298224        \n",
      "[44]\ttraining's multi_logloss: 0.228679\tvalid_1's multi_logloss: 0.295859        \n",
      "[45]\ttraining's multi_logloss: 0.224604\tvalid_1's multi_logloss: 0.293802        \n",
      "[46]\ttraining's multi_logloss: 0.220631\tvalid_1's multi_logloss: 0.291952        \n",
      "[47]\ttraining's multi_logloss: 0.216913\tvalid_1's multi_logloss: 0.290156        \n",
      "[48]\ttraining's multi_logloss: 0.213251\tvalid_1's multi_logloss: 0.288499        \n",
      "[49]\ttraining's multi_logloss: 0.209507\tvalid_1's multi_logloss: 0.286896        \n",
      "[50]\ttraining's multi_logloss: 0.206023\tvalid_1's multi_logloss: 0.28547         \n",
      "[51]\ttraining's multi_logloss: 0.202657\tvalid_1's multi_logloss: 0.284012        \n",
      "[52]\ttraining's multi_logloss: 0.199311\tvalid_1's multi_logloss: 0.282836        \n",
      "[53]\ttraining's multi_logloss: 0.196051\tvalid_1's multi_logloss: 0.282013        \n",
      "[54]\ttraining's multi_logloss: 0.192656\tvalid_1's multi_logloss: 0.28084         \n",
      "[55]\ttraining's multi_logloss: 0.189638\tvalid_1's multi_logloss: 0.280013        \n",
      "[56]\ttraining's multi_logloss: 0.186521\tvalid_1's multi_logloss: 0.278804        \n",
      "[57]\ttraining's multi_logloss: 0.183552\tvalid_1's multi_logloss: 0.277894        \n",
      "[58]\ttraining's multi_logloss: 0.180563\tvalid_1's multi_logloss: 0.276753        \n",
      "[59]\ttraining's multi_logloss: 0.177776\tvalid_1's multi_logloss: 0.276109        \n",
      "[60]\ttraining's multi_logloss: 0.174888\tvalid_1's multi_logloss: 0.275435        \n",
      "[61]\ttraining's multi_logloss: 0.172176\tvalid_1's multi_logloss: 0.275222        \n",
      "[62]\ttraining's multi_logloss: 0.169284\tvalid_1's multi_logloss: 0.274832        \n",
      "[63]\ttraining's multi_logloss: 0.166796\tvalid_1's multi_logloss: 0.274364        \n",
      "[64]\ttraining's multi_logloss: 0.164011\tvalid_1's multi_logloss: 0.274137        \n",
      "[65]\ttraining's multi_logloss: 0.161395\tvalid_1's multi_logloss: 0.273721        \n",
      "[66]\ttraining's multi_logloss: 0.158764\tvalid_1's multi_logloss: 0.273097        \n",
      "[67]\ttraining's multi_logloss: 0.15635\tvalid_1's multi_logloss: 0.272944         \n",
      "[68]\ttraining's multi_logloss: 0.153806\tvalid_1's multi_logloss: 0.272273        \n",
      "[69]\ttraining's multi_logloss: 0.151527\tvalid_1's multi_logloss: 0.272072        \n",
      "[70]\ttraining's multi_logloss: 0.149\tvalid_1's multi_logloss: 0.27181            \n",
      "[71]\ttraining's multi_logloss: 0.146829\tvalid_1's multi_logloss: 0.271618        \n",
      "[72]\ttraining's multi_logloss: 0.144471\tvalid_1's multi_logloss: 0.271262        \n",
      "[73]\ttraining's multi_logloss: 0.142387\tvalid_1's multi_logloss: 0.270897        \n",
      "[74]\ttraining's multi_logloss: 0.140181\tvalid_1's multi_logloss: 0.270852        \n",
      "[75]\ttraining's multi_logloss: 0.138014\tvalid_1's multi_logloss: 0.270519        \n",
      "[76]\ttraining's multi_logloss: 0.135955\tvalid_1's multi_logloss: 0.27056         \n",
      "[77]\ttraining's multi_logloss: 0.133597\tvalid_1's multi_logloss: 0.270123        \n",
      "[78]\ttraining's multi_logloss: 0.131823\tvalid_1's multi_logloss: 0.270079        \n",
      "[79]\ttraining's multi_logloss: 0.129665\tvalid_1's multi_logloss: 0.270023        \n",
      "[80]\ttraining's multi_logloss: 0.127781\tvalid_1's multi_logloss: 0.269882        \n",
      "[81]\ttraining's multi_logloss: 0.125805\tvalid_1's multi_logloss: 0.269943        \n",
      "[82]\ttraining's multi_logloss: 0.1241\tvalid_1's multi_logloss: 0.270034          \n",
      "[83]\ttraining's multi_logloss: 0.1222\tvalid_1's multi_logloss: 0.269995          \n",
      "[84]\ttraining's multi_logloss: 0.120318\tvalid_1's multi_logloss: 0.270161        \n",
      "[85]\ttraining's multi_logloss: 0.118405\tvalid_1's multi_logloss: 0.270455        \n",
      "[86]\ttraining's multi_logloss: 0.116816\tvalid_1's multi_logloss: 0.27053         \n",
      "[87]\ttraining's multi_logloss: 0.115051\tvalid_1's multi_logloss: 0.270505        \n",
      "[88]\ttraining's multi_logloss: 0.113139\tvalid_1's multi_logloss: 0.270315        \n",
      "[89]\ttraining's multi_logloss: 0.111448\tvalid_1's multi_logloss: 0.270098        \n",
      "[90]\ttraining's multi_logloss: 0.109737\tvalid_1's multi_logloss: 0.270257        \n",
      "[91]\ttraining's multi_logloss: 0.108181\tvalid_1's multi_logloss: 0.270345        \n",
      "[92]\ttraining's multi_logloss: 0.106651\tvalid_1's multi_logloss: 0.270731        \n",
      "[93]\ttraining's multi_logloss: 0.105187\tvalid_1's multi_logloss: 0.271254        \n",
      "[94]\ttraining's multi_logloss: 0.103513\tvalid_1's multi_logloss: 0.271239        \n",
      "[95]\ttraining's multi_logloss: 0.102101\tvalid_1's multi_logloss: 0.271314        \n",
      "[96]\ttraining's multi_logloss: 0.100456\tvalid_1's multi_logloss: 0.271408        \n",
      "[97]\ttraining's multi_logloss: 0.0989534\tvalid_1's multi_logloss: 0.271448       \n",
      "[98]\ttraining's multi_logloss: 0.0974553\tvalid_1's multi_logloss: 0.271514       \n",
      "[99]\ttraining's multi_logloss: 0.0960108\tvalid_1's multi_logloss: 0.271626       \n",
      "[100]\ttraining's multi_logloss: 0.0945806\tvalid_1's multi_logloss: 0.271581      \n",
      "[101]\ttraining's multi_logloss: 0.0931981\tvalid_1's multi_logloss: 0.271796      \n",
      "[102]\ttraining's multi_logloss: 0.0917164\tvalid_1's multi_logloss: 0.271974      \n",
      "[103]\ttraining's multi_logloss: 0.0901336\tvalid_1's multi_logloss: 0.272272      \n",
      "[104]\ttraining's multi_logloss: 0.0886936\tvalid_1's multi_logloss: 0.272386      \n",
      "[105]\ttraining's multi_logloss: 0.0873889\tvalid_1's multi_logloss: 0.272639      \n",
      "[106]\ttraining's multi_logloss: 0.0861718\tvalid_1's multi_logloss: 0.272773      \n",
      "[107]\ttraining's multi_logloss: 0.0849155\tvalid_1's multi_logloss: 0.273001      \n",
      "[108]\ttraining's multi_logloss: 0.0836846\tvalid_1's multi_logloss: 0.273067      \n",
      "[109]\ttraining's multi_logloss: 0.0825005\tvalid_1's multi_logloss: 0.273541      \n",
      "[110]\ttraining's multi_logloss: 0.0813242\tvalid_1's multi_logloss: 0.273652      \n",
      "Early stopping, best iteration is:                                               \n",
      "[80]\ttraining's multi_logloss: 0.127781\tvalid_1's multi_logloss: 0.269882\n",
      "100%|██████████| 50/50 [10:05<00:00, 12.11s/trial, best loss: -0.905696931246769]\n",
      "best_param: {'learning_rate': 0.0689832363957912, 'max_depth': 127.0, 'min_child_samples': 93.0, 'num_leaves': 58.0, 'subsample': 0.9646802814923896}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "# fmin()함수를 호출. max_evals 지정된 횟수만큼 반복 후 목적함수의 최솟값을 가지는 최적 입력값 추출.\n",
    "best = fmin(fn=objective_func, space=lgbm_search_space, algo=tpe.suggest,\\\n",
    "            max_evals=50,\n",
    "            trials= trials, rstate=np.random.default_rng(seed=42))\n",
    "\n",
    "print('best_param:',best) # 최적의 파라미터 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's multi_logloss: 1.63432\tvalid_1's multi_logloss: 1.63352\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's multi_logloss: 1.42627\tvalid_1's multi_logloss: 1.42956\n",
      "[3]\ttraining's multi_logloss: 1.2668\tvalid_1's multi_logloss: 1.27269\n",
      "[4]\ttraining's multi_logloss: 1.13876\tvalid_1's multi_logloss: 1.14757\n",
      "[5]\ttraining's multi_logloss: 1.03177\tvalid_1's multi_logloss: 1.04267\n",
      "[6]\ttraining's multi_logloss: 0.94203\tvalid_1's multi_logloss: 0.954818\n",
      "[7]\ttraining's multi_logloss: 0.864193\tvalid_1's multi_logloss: 0.879496\n",
      "[8]\ttraining's multi_logloss: 0.797155\tvalid_1's multi_logloss: 0.814133\n",
      "[9]\ttraining's multi_logloss: 0.739105\tvalid_1's multi_logloss: 0.757548\n",
      "[10]\ttraining's multi_logloss: 0.687723\tvalid_1's multi_logloss: 0.707103\n",
      "[11]\ttraining's multi_logloss: 0.641931\tvalid_1's multi_logloss: 0.662618\n",
      "[12]\ttraining's multi_logloss: 0.601623\tvalid_1's multi_logloss: 0.623473\n",
      "[13]\ttraining's multi_logloss: 0.565353\tvalid_1's multi_logloss: 0.58895\n",
      "[14]\ttraining's multi_logloss: 0.53307\tvalid_1's multi_logloss: 0.558868\n",
      "[15]\ttraining's multi_logloss: 0.504008\tvalid_1's multi_logloss: 0.531647\n",
      "[16]\ttraining's multi_logloss: 0.478098\tvalid_1's multi_logloss: 0.50734\n",
      "[17]\ttraining's multi_logloss: 0.454313\tvalid_1's multi_logloss: 0.484682\n",
      "[18]\ttraining's multi_logloss: 0.433331\tvalid_1's multi_logloss: 0.465016\n",
      "[19]\ttraining's multi_logloss: 0.4139\tvalid_1's multi_logloss: 0.447028\n",
      "[20]\ttraining's multi_logloss: 0.396056\tvalid_1's multi_logloss: 0.430643\n",
      "[21]\ttraining's multi_logloss: 0.380166\tvalid_1's multi_logloss: 0.416371\n",
      "[22]\ttraining's multi_logloss: 0.365541\tvalid_1's multi_logloss: 0.40369\n",
      "[23]\ttraining's multi_logloss: 0.35228\tvalid_1's multi_logloss: 0.391994\n",
      "[24]\ttraining's multi_logloss: 0.340241\tvalid_1's multi_logloss: 0.381724\n",
      "[25]\ttraining's multi_logloss: 0.329005\tvalid_1's multi_logloss: 0.37239\n",
      "[26]\ttraining's multi_logloss: 0.318491\tvalid_1's multi_logloss: 0.364094\n",
      "[27]\ttraining's multi_logloss: 0.308783\tvalid_1's multi_logloss: 0.356313\n",
      "[28]\ttraining's multi_logloss: 0.299103\tvalid_1's multi_logloss: 0.34839\n",
      "[29]\ttraining's multi_logloss: 0.290716\tvalid_1's multi_logloss: 0.341522\n",
      "[30]\ttraining's multi_logloss: 0.282764\tvalid_1's multi_logloss: 0.335458\n",
      "[31]\ttraining's multi_logloss: 0.275071\tvalid_1's multi_logloss: 0.329669\n",
      "[32]\ttraining's multi_logloss: 0.26808\tvalid_1's multi_logloss: 0.324755\n",
      "[33]\ttraining's multi_logloss: 0.261598\tvalid_1's multi_logloss: 0.319876\n",
      "[34]\ttraining's multi_logloss: 0.255284\tvalid_1's multi_logloss: 0.315547\n",
      "[35]\ttraining's multi_logloss: 0.249275\tvalid_1's multi_logloss: 0.312449\n",
      "[36]\ttraining's multi_logloss: 0.243771\tvalid_1's multi_logloss: 0.308706\n",
      "[37]\ttraining's multi_logloss: 0.238527\tvalid_1's multi_logloss: 0.305851\n",
      "[38]\ttraining's multi_logloss: 0.233349\tvalid_1's multi_logloss: 0.302964\n",
      "[39]\ttraining's multi_logloss: 0.22848\tvalid_1's multi_logloss: 0.300101\n",
      "[40]\ttraining's multi_logloss: 0.223588\tvalid_1's multi_logloss: 0.297519\n",
      "[41]\ttraining's multi_logloss: 0.219218\tvalid_1's multi_logloss: 0.295152\n",
      "[42]\ttraining's multi_logloss: 0.214833\tvalid_1's multi_logloss: 0.292852\n",
      "[43]\ttraining's multi_logloss: 0.210763\tvalid_1's multi_logloss: 0.290811\n",
      "[44]\ttraining's multi_logloss: 0.206971\tvalid_1's multi_logloss: 0.289273\n",
      "[45]\ttraining's multi_logloss: 0.203248\tvalid_1's multi_logloss: 0.287754\n",
      "[46]\ttraining's multi_logloss: 0.199496\tvalid_1's multi_logloss: 0.286679\n",
      "[47]\ttraining's multi_logloss: 0.196004\tvalid_1's multi_logloss: 0.285657\n",
      "[48]\ttraining's multi_logloss: 0.19261\tvalid_1's multi_logloss: 0.284363\n",
      "[49]\ttraining's multi_logloss: 0.189274\tvalid_1's multi_logloss: 0.283327\n",
      "[50]\ttraining's multi_logloss: 0.185784\tvalid_1's multi_logloss: 0.282356\n",
      "[51]\ttraining's multi_logloss: 0.18243\tvalid_1's multi_logloss: 0.2817\n",
      "[52]\ttraining's multi_logloss: 0.179325\tvalid_1's multi_logloss: 0.281086\n",
      "[53]\ttraining's multi_logloss: 0.176415\tvalid_1's multi_logloss: 0.280565\n",
      "[54]\ttraining's multi_logloss: 0.173323\tvalid_1's multi_logloss: 0.279689\n",
      "[55]\ttraining's multi_logloss: 0.170266\tvalid_1's multi_logloss: 0.278544\n",
      "[56]\ttraining's multi_logloss: 0.167518\tvalid_1's multi_logloss: 0.277784\n",
      "[57]\ttraining's multi_logloss: 0.16484\tvalid_1's multi_logloss: 0.276991\n",
      "[58]\ttraining's multi_logloss: 0.162031\tvalid_1's multi_logloss: 0.276405\n",
      "[59]\ttraining's multi_logloss: 0.159485\tvalid_1's multi_logloss: 0.27626\n",
      "[60]\ttraining's multi_logloss: 0.156891\tvalid_1's multi_logloss: 0.275634\n",
      "[61]\ttraining's multi_logloss: 0.154281\tvalid_1's multi_logloss: 0.275245\n",
      "[62]\ttraining's multi_logloss: 0.151837\tvalid_1's multi_logloss: 0.274741\n",
      "[63]\ttraining's multi_logloss: 0.149353\tvalid_1's multi_logloss: 0.274149\n",
      "[64]\ttraining's multi_logloss: 0.14696\tvalid_1's multi_logloss: 0.273056\n",
      "[65]\ttraining's multi_logloss: 0.144668\tvalid_1's multi_logloss: 0.272558\n",
      "[66]\ttraining's multi_logloss: 0.142414\tvalid_1's multi_logloss: 0.272261\n",
      "[67]\ttraining's multi_logloss: 0.140384\tvalid_1's multi_logloss: 0.272019\n",
      "[68]\ttraining's multi_logloss: 0.13827\tvalid_1's multi_logloss: 0.27192\n",
      "[69]\ttraining's multi_logloss: 0.136204\tvalid_1's multi_logloss: 0.271349\n",
      "[70]\ttraining's multi_logloss: 0.134121\tvalid_1's multi_logloss: 0.271497\n",
      "[71]\ttraining's multi_logloss: 0.132289\tvalid_1's multi_logloss: 0.271185\n",
      "[72]\ttraining's multi_logloss: 0.130351\tvalid_1's multi_logloss: 0.270763\n",
      "[73]\ttraining's multi_logloss: 0.128558\tvalid_1's multi_logloss: 0.270949\n",
      "[74]\ttraining's multi_logloss: 0.126623\tvalid_1's multi_logloss: 0.270874\n",
      "[75]\ttraining's multi_logloss: 0.124741\tvalid_1's multi_logloss: 0.270882\n",
      "[76]\ttraining's multi_logloss: 0.122914\tvalid_1's multi_logloss: 0.271106\n",
      "[77]\ttraining's multi_logloss: 0.121189\tvalid_1's multi_logloss: 0.271396\n",
      "[78]\ttraining's multi_logloss: 0.119526\tvalid_1's multi_logloss: 0.271247\n",
      "[79]\ttraining's multi_logloss: 0.117761\tvalid_1's multi_logloss: 0.271511\n",
      "[80]\ttraining's multi_logloss: 0.116185\tvalid_1's multi_logloss: 0.271993\n",
      "[81]\ttraining's multi_logloss: 0.114605\tvalid_1's multi_logloss: 0.27185\n",
      "[82]\ttraining's multi_logloss: 0.113043\tvalid_1's multi_logloss: 0.271938\n",
      "[83]\ttraining's multi_logloss: 0.111566\tvalid_1's multi_logloss: 0.271887\n",
      "[84]\ttraining's multi_logloss: 0.110166\tvalid_1's multi_logloss: 0.272378\n",
      "[85]\ttraining's multi_logloss: 0.108617\tvalid_1's multi_logloss: 0.272661\n",
      "[86]\ttraining's multi_logloss: 0.107207\tvalid_1's multi_logloss: 0.272966\n",
      "[87]\ttraining's multi_logloss: 0.105719\tvalid_1's multi_logloss: 0.272921\n",
      "[88]\ttraining's multi_logloss: 0.104393\tvalid_1's multi_logloss: 0.273331\n",
      "[89]\ttraining's multi_logloss: 0.103079\tvalid_1's multi_logloss: 0.273498\n",
      "[90]\ttraining's multi_logloss: 0.101634\tvalid_1's multi_logloss: 0.273475\n",
      "[91]\ttraining's multi_logloss: 0.100234\tvalid_1's multi_logloss: 0.273624\n",
      "[92]\ttraining's multi_logloss: 0.0989823\tvalid_1's multi_logloss: 0.273679\n",
      "[93]\ttraining's multi_logloss: 0.0977041\tvalid_1's multi_logloss: 0.273802\n",
      "[94]\ttraining's multi_logloss: 0.0964729\tvalid_1's multi_logloss: 0.273627\n",
      "[95]\ttraining's multi_logloss: 0.0952438\tvalid_1's multi_logloss: 0.2735\n",
      "[96]\ttraining's multi_logloss: 0.0940317\tvalid_1's multi_logloss: 0.273615\n",
      "[97]\ttraining's multi_logloss: 0.092841\tvalid_1's multi_logloss: 0.273885\n",
      "[98]\ttraining's multi_logloss: 0.0916022\tvalid_1's multi_logloss: 0.274074\n",
      "[99]\ttraining's multi_logloss: 0.0904404\tvalid_1's multi_logloss: 0.274607\n",
      "[100]\ttraining's multi_logloss: 0.0893318\tvalid_1's multi_logloss: 0.274932\n",
      "[101]\ttraining's multi_logloss: 0.0882165\tvalid_1's multi_logloss: 0.275146\n",
      "[102]\ttraining's multi_logloss: 0.087146\tvalid_1's multi_logloss: 0.275634\n",
      "[103]\ttraining's multi_logloss: 0.0860981\tvalid_1's multi_logloss: 0.27546\n",
      "[104]\ttraining's multi_logloss: 0.0850782\tvalid_1's multi_logloss: 0.275401\n",
      "[105]\ttraining's multi_logloss: 0.0840819\tvalid_1's multi_logloss: 0.275346\n",
      "[106]\ttraining's multi_logloss: 0.083079\tvalid_1's multi_logloss: 0.275515\n",
      "[107]\ttraining's multi_logloss: 0.0821072\tvalid_1's multi_logloss: 0.275423\n",
      "[108]\ttraining's multi_logloss: 0.0812083\tvalid_1's multi_logloss: 0.275654\n",
      "[109]\ttraining's multi_logloss: 0.0802731\tvalid_1's multi_logloss: 0.276205\n",
      "[110]\ttraining's multi_logloss: 0.0793736\tvalid_1's multi_logloss: 0.275963\n",
      "[111]\ttraining's multi_logloss: 0.0784331\tvalid_1's multi_logloss: 0.276042\n",
      "[112]\ttraining's multi_logloss: 0.0775249\tvalid_1's multi_logloss: 0.276041\n",
      "[113]\ttraining's multi_logloss: 0.0766851\tvalid_1's multi_logloss: 0.276316\n",
      "[114]\ttraining's multi_logloss: 0.075801\tvalid_1's multi_logloss: 0.276704\n",
      "[115]\ttraining's multi_logloss: 0.0749113\tvalid_1's multi_logloss: 0.27709\n",
      "[116]\ttraining's multi_logloss: 0.0740277\tvalid_1's multi_logloss: 0.277151\n",
      "[117]\ttraining's multi_logloss: 0.0730625\tvalid_1's multi_logloss: 0.27751\n",
      "[118]\ttraining's multi_logloss: 0.0722343\tvalid_1's multi_logloss: 0.2778\n",
      "[119]\ttraining's multi_logloss: 0.0713561\tvalid_1's multi_logloss: 0.27773\n",
      "[120]\ttraining's multi_logloss: 0.0704786\tvalid_1's multi_logloss: 0.27744\n",
      "[121]\ttraining's multi_logloss: 0.0695928\tvalid_1's multi_logloss: 0.277898\n",
      "[122]\ttraining's multi_logloss: 0.0687707\tvalid_1's multi_logloss: 0.278197\n",
      "[123]\ttraining's multi_logloss: 0.0679419\tvalid_1's multi_logloss: 0.27854\n",
      "[124]\ttraining's multi_logloss: 0.067141\tvalid_1's multi_logloss: 0.279187\n",
      "[125]\ttraining's multi_logloss: 0.0663639\tvalid_1's multi_logloss: 0.279746\n",
      "[126]\ttraining's multi_logloss: 0.0654978\tvalid_1's multi_logloss: 0.279842\n",
      "[127]\ttraining's multi_logloss: 0.0647106\tvalid_1's multi_logloss: 0.280473\n",
      "[128]\ttraining's multi_logloss: 0.0639061\tvalid_1's multi_logloss: 0.280962\n",
      "[129]\ttraining's multi_logloss: 0.063137\tvalid_1's multi_logloss: 0.281393\n",
      "[130]\ttraining's multi_logloss: 0.0623908\tvalid_1's multi_logloss: 0.281901\n",
      "[131]\ttraining's multi_logloss: 0.0616456\tvalid_1's multi_logloss: 0.282528\n",
      "[132]\ttraining's multi_logloss: 0.060921\tvalid_1's multi_logloss: 0.28288\n",
      "[133]\ttraining's multi_logloss: 0.06019\tvalid_1's multi_logloss: 0.283479\n",
      "[134]\ttraining's multi_logloss: 0.0594813\tvalid_1's multi_logloss: 0.28364\n",
      "[135]\ttraining's multi_logloss: 0.058842\tvalid_1's multi_logloss: 0.283929\n",
      "[136]\ttraining's multi_logloss: 0.0582227\tvalid_1's multi_logloss: 0.284073\n",
      "[137]\ttraining's multi_logloss: 0.0575866\tvalid_1's multi_logloss: 0.284246\n",
      "[138]\ttraining's multi_logloss: 0.0569509\tvalid_1's multi_logloss: 0.284675\n",
      "[139]\ttraining's multi_logloss: 0.0563122\tvalid_1's multi_logloss: 0.285248\n",
      "[140]\ttraining's multi_logloss: 0.0556142\tvalid_1's multi_logloss: 0.285823\n",
      "[141]\ttraining's multi_logloss: 0.0550117\tvalid_1's multi_logloss: 0.286561\n",
      "[142]\ttraining's multi_logloss: 0.0543975\tvalid_1's multi_logloss: 0.287254\n",
      "[143]\ttraining's multi_logloss: 0.0538103\tvalid_1's multi_logloss: 0.287692\n",
      "[144]\ttraining's multi_logloss: 0.0531501\tvalid_1's multi_logloss: 0.28845\n",
      "[145]\ttraining's multi_logloss: 0.0525496\tvalid_1's multi_logloss: 0.288807\n",
      "[146]\ttraining's multi_logloss: 0.0519521\tvalid_1's multi_logloss: 0.2893\n",
      "[147]\ttraining's multi_logloss: 0.0514218\tvalid_1's multi_logloss: 0.289833\n",
      "[148]\ttraining's multi_logloss: 0.050793\tvalid_1's multi_logloss: 0.290272\n",
      "[149]\ttraining's multi_logloss: 0.0502289\tvalid_1's multi_logloss: 0.29073\n",
      "[150]\ttraining's multi_logloss: 0.0497143\tvalid_1's multi_logloss: 0.291344\n",
      "[151]\ttraining's multi_logloss: 0.0491658\tvalid_1's multi_logloss: 0.292156\n",
      "[152]\ttraining's multi_logloss: 0.0486048\tvalid_1's multi_logloss: 0.292422\n",
      "[153]\ttraining's multi_logloss: 0.0480867\tvalid_1's multi_logloss: 0.292857\n",
      "[154]\ttraining's multi_logloss: 0.0475644\tvalid_1's multi_logloss: 0.293445\n",
      "[155]\ttraining's multi_logloss: 0.0470557\tvalid_1's multi_logloss: 0.293612\n",
      "[156]\ttraining's multi_logloss: 0.046554\tvalid_1's multi_logloss: 0.293847\n",
      "[157]\ttraining's multi_logloss: 0.0460503\tvalid_1's multi_logloss: 0.294573\n",
      "[158]\ttraining's multi_logloss: 0.0455757\tvalid_1's multi_logloss: 0.295114\n",
      "[159]\ttraining's multi_logloss: 0.0450994\tvalid_1's multi_logloss: 0.295781\n",
      "[160]\ttraining's multi_logloss: 0.0446385\tvalid_1's multi_logloss: 0.296299\n",
      "[161]\ttraining's multi_logloss: 0.0441599\tvalid_1's multi_logloss: 0.296782\n",
      "[162]\ttraining's multi_logloss: 0.0437003\tvalid_1's multi_logloss: 0.29714\n",
      "[163]\ttraining's multi_logloss: 0.0432113\tvalid_1's multi_logloss: 0.297772\n",
      "[164]\ttraining's multi_logloss: 0.0427331\tvalid_1's multi_logloss: 0.298135\n",
      "[165]\ttraining's multi_logloss: 0.0422847\tvalid_1's multi_logloss: 0.298947\n",
      "[166]\ttraining's multi_logloss: 0.0418515\tvalid_1's multi_logloss: 0.299193\n",
      "[167]\ttraining's multi_logloss: 0.0414163\tvalid_1's multi_logloss: 0.299491\n",
      "[168]\ttraining's multi_logloss: 0.0410147\tvalid_1's multi_logloss: 0.300385\n",
      "[169]\ttraining's multi_logloss: 0.0405406\tvalid_1's multi_logloss: 0.300666\n",
      "[170]\ttraining's multi_logloss: 0.0400912\tvalid_1's multi_logloss: 0.300737\n",
      "[171]\ttraining's multi_logloss: 0.0396469\tvalid_1's multi_logloss: 0.30122\n",
      "[172]\ttraining's multi_logloss: 0.0392348\tvalid_1's multi_logloss: 0.301888\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's multi_logloss: 0.130351\tvalid_1's multi_logloss: 0.270763\n",
      "ACCURACY: 0.9056\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       524\n",
      "           1       0.88      0.89      0.89       626\n",
      "           2       0.87      0.87      0.87       543\n",
      "           3       0.97      0.97      0.97       657\n",
      "           4       1.00      1.00      1.00       804\n",
      "           5       0.78      0.80      0.79       484\n",
      "           6       0.82      0.81      0.81       514\n",
      "\n",
      "    accuracy                           0.91      4152\n",
      "   macro avg       0.90      0.90      0.90      4152\n",
      "weighted avg       0.91      0.91      0.91      4152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 최적의 파라미터로 모델 생성 후, 정확도 확인\n",
    "lgbm_clf = LGBMClassifier(n_estimators=500, num_leaves=int(best['num_leaves']),\n",
    "                          max_depth = int(best['max_depth']),\n",
    "                          min_child_samples = int(best['min_child_samples']),\n",
    "                          subsample= round(best['subsample'],5),\n",
    "                          learning_rate = round(best['learning_rate'],5)\n",
    "                          )\n",
    "# evaluation metric을 multi_logloss로, early stoppping은 100으로 설정하고 학습 수행.\n",
    "lgbm_clf.fit(X_tr, y_tr, early_stopping_rounds=100,\n",
    "             eval_metric='multi_logloss', eval_set=[(X_tr, y_tr),(X_val, y_val)])\n",
    "\n",
    "lgbm_accuracy = accuracy_score(y_test, lgbm_clf.predict(X_test))\n",
    "print('ACCURACY: {0:.4f}'.format(lgbm_accuracy))\n",
    "print(classification_report(y_test, lgbm_clf.predict(X_test)))\n",
    "\n",
    "# 90.56으로 처음에 셋팅한 파라미터 정확도보다 낮으므로 폐기한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0wAAAIlCAYAAADmEXiRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAACrKUlEQVR4nOzdd1xV9f8H8Ne5i8veooIbQURRFEVTM8WRpjnKSsuZfm2Ymlam5ShLs/krbZhmZo5MM9PcK/fKPXErKCJ7331+f1y5gYBc8MK5wOv5ePCAe+b73A/WffH5nM8RRFEUQURERERERAXIpC6AiIiIiIjIXjEwERERERERFYGBiYiIiIiIqAgMTEREREREREVgYCIiIiIiIioCAxMREREREVERGJiIiIiIiIiKwMBERERERERUBAYmIiIiIiKiIjAwEVG5mTt3LoKDg6366ty5s83Ou2bNGgQHB2Px4sWl2n/w4MEIDg5Genq6zWqyd3369EFwcPBDt3n55ZcRHByM7du3P3Q7o9GIxx57DOHh4cjKyrK6hgff99jYWAQHB+O1114rdt8LFy4gODgY7777rtXne9C9e/fwxx9/5FvWuXNnRERElPqYjyrvv6Hvvvvuodt+9NFHlm1jY2NLdb7g4GD06dMn37JHfV/effddBAcH4/Dhw6WqyRZy38fifneJiABAIXUBRFR1tG7dGmPGjMm37M8//8Tt27cxZMgQuLm5WZa7urra7LwhISEYM2YMmjdvXqr9+/Xrh9atW8PBwcFmNVUGffv2xb59+7Bp0yZ06dKlyO3279+PpKQk9OvXD87OzqU+n5ubG8aMGYP69euX+hjWSkpKwpNPPok2bdrgmWeesSwfMmQIdDpdmZ/fGtu2bSsyPIqiiK1bt9r8nBXhfSEisjUGJiIqN5GRkYiMjMy37MiRI7h9+zaGDh2KgICAMjlvSEgIQkJCSr1///79bVhN5dG1a1e4uLhg586dyMnJgaOjY6HbrV+/HoA5eD4KNzc3vPHGG490DGvl5OQU2hs2bNiwcjl/cXx9fXH+/HnExsYW+u/mxIkTiI+Ph5OTE7Kzs212Xnt/X4iIygKH5BERUamo1Wp0794d2dnZ+OeffwrdJicnB9u3b4e/vz9at25dvgVWYlFRUQBQ5JCyLVu2wNXVVdLhg0RElQUDExHZrcOHDyM4OBjLly/HhAkTEBYWhvbt2+PYsWMAgNu3b2P69Ono0qULmjZtivDwcPTv3x8rVqzId5zC7mHq3LkzBg8ejKtXr+KVV15By5YtER4ejlGjRuHixYv59n/wXprcutasWYPVq1ejd+/eaNq0KR5//HHMmTMHOTk5Ba7lt99+Q+/evdGsWTNERUVhwYIFWLt2rdX3cpT0Wg8ePIiffvoJ3bp1Q5MmTdClSxd8//33MBqN+bbXaDT48ssv0blzZ4SFheG5557D0aNHi60nV26v0caNGwtdv3PnTmRnZ6Nv374QBAEAcOzYMYwZMwbt27dHkyZN0KpVKwwfPhyHDh166LmKuofp4sWLePXVV9G6dWu0atUKkydPRmpqaqHHsOZ9XLNmjSWQ7Nixw9LWQOH36uh0Ovzwww/o2bMnmjRpgsjISLz66qs4c+ZMvu1K83tTlDZt2sDNza3IYXdbt25F586doVQq8y1/2H1gxd3XU9L3xVbu3buHadOmoWPHjmjSpAk6duyIadOm4d69ewW2TUxMxLRp09ChQwc0a9YMgwYNwvHjxzFs2DCr7os8ffo0XnvtNURGRqJp06bo2bMnfvjhhwLDDbOysjBr1iw8+eSTaNq0Kdq2bYsxY8bg3LlzpdqOiOwbh+QRkd379ttv4eTkhJdeeglXrlxBaGgoYmNj8eyzzyInJwddu3ZFjRo1EB8fjy1btmDGjBkwGo146aWXHnrcuLg4vPDCC6hbty6ee+45XL9+Hbt27cLJkyexZcsWeHl5PXT/pUuX4tKlS+jWrRs6dOiAbdu2YdGiRbh37x6++OILy3azZs3CL7/8gtq1a2PAgAFISUnB//3f/6FGjRpWXX9prvWzzz7D9evX8eSTT6JTp07YsGED/u///g8ajQZvvvkmAMBkMmHUqFE4cuQIwsLC0LVrV5w5cwYjRowocnjdgyIiIhAQEIDdu3cjMzMTLi4u+davX78egiBYgtX27dsxduxYeHl5oUuXLnB2dsbly5exZ88eHDlyBKtXry7R8MkLFy7gxRdfhE6nQ/fu3eHm5oYdO3Zg7969pX4fQ0JCMGTIECxZsgT16tXDU089VWRNWq0Ww4cPx7FjxxAUFISBAwciMTER27dvx969e/F///d/Be7vsvb35mGUSiU6d+6MdevWITExET4+PpZ1p0+fxp07d/Dkk09i9erVVr+XxSnJ+2Irt27dsrynjz32GHr06IHo6GisXLkSO3fuxIoVK1CrVi0AQEpKCgYNGoSbN2+iffv2CA4OxqFDhzB06FB4eHgUCI8P2r59O8aNGweZTIYuXbrAx8cHhw4dwldffYW9e/fi559/hkqlAgCMHz8ee/bsQadOndClSxckJiZi48aN2LdvH9asWWO5z87a7YjIzolERBJ66aWXxKCgIDEmJqbAukOHDolBQUFis2bNxHv37uVbN3XqVDEoKEjcv39/vuWnTp0Sg4KCxOeff96y7I8//hCDgoLEn3/+2bKsU6dOYlBQkPjBBx+IJpPJsvz9998Xg4KCxOXLlxeoMS0tLV9dISEh4vHjxy3bpaeni23atBEbN24sZmZmiqIoiqdPnxaDg4PF5557zrJMFEVx165dYlBQkBgUFCQeOnTooe9Raa61ZcuW4o0bNyzLY2JixNDQUPGxxx6zLFu9erUYFBQkTp48WTQajZblc+bMsdRmja+//loMCgoS//rrr3zLk5OTxdDQUPHFF1+0LOvevbvYunVrMSEhId+2P/74oxgUFCR+8cUXlmUPvu8xMTFiUFCQ+Oqrr1q2efHFF8WQkBDxwIEDlmVJSUliz549xaCgIHHSpEmW5SV5Hws7lyiaf29atmxpeT1v3jwxKChIfPfdd0W9Xm9ZfvbsWTEsLEyMiIgQMzIyRFEs2e9NUb755hsxKChI3LZtm7h9+3YxKChI/O233/JtM2fOHLFFixaiVqsVX3311Xz/voq6rgePnSsoKEh8+umnS/y+PMykSZOs+r0XRVEcMmSIGBQUJP7+++/5li9btkwMCgoShwwZYln24YcfikFBQeLChQsty4xGozhu3DgxKChI7NSpU5HXmpGRIbZq1Ups0aKFePbsWct2er1enDhxohgUFCTOmzdPFEVRjI6OFoOCgsR33nknX02bNm0Sg4KCxE8++aRE2xGR/eOQPCKyey1atICvr2++ZU8//TRmzZqFxx57LN/ysLAwqNVqJCUlWXXsUaNGWYaKAUDHjh0BmIduFadVq1YIDw+3vHZ1dUV4eDgMBgPu3r0LAPjrr78giiLGjx+fb4a4J554Au3atbOqxtJca7du3VCnTh3L64CAADRo0ACJiYnQarUAgA0bNkAQBEycOBEy2X//Oxg/fnyJZins27cvgILD8jZt2gS9Xm/pXTKZTJg4cSI+/fTTfD0iACyTgVjbbgAQHx+Po0ePokOHDmjbtq1luZeXF15//fUC29vqdyavP//8E46OjnjvvfegUPw3aCM0NBSDBg1Cenp6gWFz1vzeWKN9+/ZwcnIqcPzc4Xi5vSEVVVxcHA4dOoSIiAgMGDAg37pBgwahadOmOHToEGJjY2E0GrF+/Xr4+/vnm4BCJpPhnXfegVwuf+i5tm/fjrS0NAwZMgShoaGW5QqFAlOmTIFarbZMpW4ymQAA169fR2ZmpmXbLl26YPv27XjrrbdKtB0R2T8OySMiu1fYLGARERGIiIhAamoqLly4gFu3buH69es4efIktFptgXt1CuPg4FBgWFzukDJrpkiuW7dugWW5QUOv1wOA5T6WsLCwAtu2aNEC+/fvL/Y8pbnWh9Wm0+ng4OCAixcvombNmvD29s63nUqlQmhoaLH3FOWqXbs2WrZsiX379iE9Pd0yPfzff/8NR0dHdO/eHYD5w2vXrl0BmAPp5cuXcevWLVy5csVyH1fuh0xr5N5r1qRJkwLr8gaSXLb4nckrMzMTMTExaNGiRYGhiADQsmVLLFq0qMA9cdb83ljDwcEBTzzxBLZt24aMjAy4urri3LlziImJweTJk0t0LfbowoULAFDkvVEtWrTAmTNncPHiReh0OqSlpaFNmzYFwlHNmjVRvXr1h54rt41atWpVYJ2Xlxfq1auHCxcuICMjA8HBwQgPD8eJEyfQrl07tG7dGo8//jg6depkGR4IwOrtiMj+MTARkd0r7PlHaWlpmD17Nv7++2/o9XoIggB/f3+0adMG58+ft+q4hf0FPre3SRRFm+yfkpICJyenQp8/VK1aNavqLM21WlNbenp6gbCUy93d3aracvXt2xfHjh3D1q1b8eyzz+L27ds4fvw4nn766XxhIjo6Gh999BGOHDkCwHwvToMGDdCkSRPcuHHDqvc9V+4kHIW9t4XVb4vfmbxyp9cuqjcut301Gk2+5Y/6e5dXt27dsHHjRuzatQtPP/00tmzZAmdnZ3To0KFEx7Gl9PR0/PLLLwWW9+vXr0SPDsjtlbHm/U1JSQGAAj2XebctbJKIB89VWPDN3f/ChQvIycmBq6srfvrpJyxcuBDr16/Hnj17sGfPHnz00Ud47LHHMHPmTAQEBEAQBKu2IyL7x8BERBXS22+/jd27d+OFF15Anz59EBQUZPmwk/vcH3vg4uKC2NhY6PX6Ajed5x2m8zBlda1ubm7IyMgodF1Jn93To0cPfPTRR9i0aROeffZZbNiwAaIo5nv2UmZmJkaMGIGMjAxMmjQJjz32GOrXrw+VSoVTp07h77//LnH9AAq9hsLqt/X7mBvU4uPjC12fG+g8PDxKfGxrdezYEWq1Gtu2bbMEpk6dOhU5HC83mBXWk1eSWfoeJj09HfPmzSuwvHXr1iUKCCV5f3Pbsah/U4U9O6qwcxUVqh5sS2dnZ4wbNw7jxo3D9evXsX//fqxfvx4HDhzAm2++iVWrVpVoOyKybwxMRFThpKenY/fu3WjSpAk++OCDfOtiY2Oh1WpL/Jf6shIaGopz587h3LlzaN68eb51p06dKnb/srzW0NBQ7NmzB3fu3EHNmjUty41Go2U4lLVcXV3RpUsXbN26Fenp6di8ebOl9ybXoUOHkJiYiBEjRmDEiBH59r969SqAkvWwNG7cGIIg4Pjx4wXWnT17Nt/rkr6Pee9rK4qLiwsCAgJw48YNJCcnF5hVMXd69sDAQKuvqaScnJzQvn177N27F6dPn8aNGzfw9ttvF7l9bmgvLBzFxMQUez5r3peAgABER0cXu11xcmfgK6x9AfP7KwgCAgMD4e3tDScnJ5w+fbrAdunp6bh+/fpDe3Rzz3Xs2LECsxpmZmbiwoULqFOnDlQqFS5evIi//voL3bt3R/PmzVGvXj3Uq1cPAwcORM+ePXH69GnodDpcu3bNqu0q+r1mRFUBJ30gogpHqVRCJpMhPT09371GGo0GM2fOBFCye0HKUv/+/QEAX331Vb4PqYcOHSryeTd5leW15vb+fPLJJ/mO8dNPPyExMbHEx+vTpw/0ej1+++03nDt3Dk8//XS+D9i5QysfnFzhzp07lh4Jg8Fg9fl8fX3RoUMHHDp0CFu2bLEsz8zMLNDDUdL3MXcCh+Le2379+kGj0WDWrFn5aj937hyWLl0KNzc3q57/8yi6deuGnJwcfPzxx3BycnrocDxvb2+4u7vj9OnT+drh/PnzRT58OC9r3xdbqFmzJiIjI3H27FksX74837pVq1bh+PHjiIyMRPXq1aFUKtG7d29cv3493zO1TCYTPvvss2Lr7dKlC1xdXbF8+fJ8z0gyGAz4+OOPodFo0KdPHwDmewAXLVqE7777Ll/IzszMRFpaGnx9faFSqazejojsH3uYiKjCcXR0RNeuXbFlyxYMGDAA7dq1Q3Z2Nnbt2oXExES4u7sjIyMDJpMp3+xvUggPD8cLL7yA3377DX379kWHDh2QlJSErVu3wtXVFSkpKQ+dwassr7Vnz57YsmULNm/ejOvXr6Nt27a4cuUKDh06BH9/f6tmCsyrffv28PX1xXfffQfgv7CYq2XLlvD398dff/2FlJQUNGrUCHFxcdixYwccHBwgCEKRD5wtyrRp0/DCCy9g/Pjx6NKlC/z8/LBr164C70VJ30dPT0+oVCocPnwYs2fPRteuXQudfGDUqFHYt28f1q9fj+joaLRp0wZJSUnYvn07RFHEV199VeR9MbaS+4DakydPolevXoXe85dLLpfjmWeewaJFizBgwAB0794dycnJ2Lx5M8LCwvDvv/8+9FzWvi/WmDVrlmVY5YPGjRuHiIgIfPjhh3jxxRfxwQcfYNu2bQgODsalS5ewf/9+VKtWzRJ2AfPsjnv37sWMGTOwY8cOBAYG4ujRo7h27RrUavVD/324uLhg1qxZePPNN/HCCy+ga9eu8Pb2xqFDh3Dp0iVERERg1KhRAMwTuHTv3h1btmxBv3790KZNGxgMBmzfvh0pKSn4+OOPS7QdEdk/9jARUYU0a9YsDB06FBkZGVi6dCn27t2Lpk2bYsWKFejbty80Go1l5jWpTZs2De+88w4A4LfffsPp06fx9ttv45lnngEAqNXqh+5fltf65Zdf4q233oJOp8OKFSuQkJCAefPmoVGjRiU+llwuR+/evZGTk4OWLVuidu3a+dY7OTnh559/Rrdu3Sw9MOfPn8fTTz+NdevWoVGjRvj333+Lvd8kr1q1amHlypXo2bMnjh49ij/++AONGzfG999/X2DbkryPKpUK06ZNg7u7O5YvX17kjIEODg5YvHgxxo4dC71ejxUrVuDQoUPo1KkTVq5cWWB4V1lwdXW1TKueOyPhw0yYMMEy7fqvv/6Kc+fOYerUqRg+fHix+1r7vljj4sWLOHLkSKFfucG5bt26+OOPP/Dcc8/hypUrWLp0KW7cuIHBgwdj7dq1+X7HvLy8sGLFCvTu3RtnzpzB8uXL4eTkhCVLlsDZ2bnYhzF369YNy5cvR7t27bB37178/vvvAIB33nkHixcvztcb9Omnn2LixIkwGo1YuXIl1qxZg1q1auH777/Hs88+W+LtiMi+CaK9DPQnIqqEEhISoFQqC73xf9KkSVi7di0OHDhQ5Gx1RGSdW7duoXr16gWGuel0OrRo0QJt27bFggULJKqOiCoy9jAREZWhdevWITIyEn/++We+5bdu3cK2bdssN6wT0aN57bXX0K5dO8uMdrl++eUX6PV6y8ORiYhKij1MRERl6O7du5ZhalFRUahduzYSExOxdetW6HQ6LFiwIN9MckRUOsuWLcOHH36I6tWrIyoqCo6Ojjh//jwOHDiA4OBgrFq16qH3dxERFYWBiYiojN28eRPz58/HoUOHkJCQADc3N7Rs2RKjR49GaGio1OURVRpbt27Fr7/+isuXLyM7Oxs1atRA9+7dMXr06EIfcExEZA0GJiIiIiIioiLwHiYiIiIiIqIiMDAREREREREVoUo9uFaj0SAmJgaurq6Wp5UTEREREVHVYzAYkJGRgVq1aj30mYhVKjXExMRg165dUpdBRERERER2olOnTmjYsGGR66tUYHJ1dQVgflM8PT0lrUWv12P9+vXo3bs3lEqlpLVQfmwb+8W2sV9sG/vFtrFfbBv7xbaxX7Zsm5SUFOzatcuSEYpSpQJT7jA8T09P+Pj4SFqLTqcDAHh7exd4KjlJi21jv9g29ottY7/YNvaLbWO/2Db2qyzaprhbdTjpAxERERERUREYmIiIiIiIiIrAwERERERERFQEBiYiIiIiIqIiVKlJH4iIiIiqivT0dKSlpUldRoVkMpkQFhaGuLg4yGTsX7AnJW0bd3d3uLm5PdI5GZiIiIiIKpl79+5BEAQEBARAEASpy6lwTCYTnJyc4O3tzcBkZ0rSNqIoIjExEffu3UO1atVKfU7+BhARERFVMlqtFr6+vgxLVKUJggBfX19otdpHOg4DExERERERUREYmIiIiIiIiIrAwERERERERFQEBiYiIiIiktS7776L4ODgIr8OHz5c4mMOHjwYc+fOtWrbzp07Y82aNSU+R3EOHz6M4OBgREVFFbr+zTfftPr6YmNjERwcjNjYWABATEwMdu/eXei6ouooC2V5bHvBWfKIiIiISFLvvfceJk6cCADYuHEjFi1ahNWrV1vWu7u7l/iYc+fOhVKptGrb1atXw8nJqcTnsFZ8fDwuXbqEoKAgyzKdToe9e/eW+phTpkxB69at0bFjR9SoUQP79u2Dl5eXLcqlBzAwEREREZGkXF1d4erqavlZLpfD19f3kY7p4eFh9bZlHTQiIiKwc+fOfIHp4MGDCAwMxIkTJx75+LZ4v6hoHJJHREREVMmJogiTJqdcv0RRtFn9uUPOvv32W7Rq1QoffvghRFHEDz/8gM6dO6NJkyZo37495s2bZ9kn75C8d999F7Nnz8b48ePRrFkzdOzYEWvXrrVsm3dI3uDBg/HDDz9gwoQJaN68Obp3756vJyglJQVjxoxBeHg4oqKisGLFimKHpEVFRWHnzp35lu3YsQNdunTJt+zBoYFFDXd79913ceTIEcybNw+DBw8udkhecUwmExYuXIioqCiEhYVh8ODBiI6OtqwvyTXfvXsX48aNQ+vWrREZGYmPPvoIOp0OAKDX6/H+++8jMjIS4eHheOWVVxAfHw/A/KDlN954AxEREWjVqhXeeustZGZmlup6bI09TERERESVmCiKuPf2y9BdOF2u51U1boZqny606bOgjh8/jj/++AMmkwlr167FL7/8gi+//BK1atXC3r17MWPGDHTq1AmhoaEF9l22bBnGjRuHiRMnYsmSJZg+fTqioqIsPVt5zZ8/HxMmTMDMmTPx1VdfYerUqdi5cydkMhkmTJgArVaLFStWID4+Hu+9916xdXfu3BmzZs1CYmIifHx8YDKZsHPnTixduhSfffZZid+H9957Dzdu3EB4eDhGjx79yMHi22+/xYoVKzBz5kzUrVsXCxYswMiRI7FlyxY4OTlZfc06nQ5Dhw5FnTp18OuvvyI5ORlTp04FALz//vtYtmwZjh49ikWLFkGtVmPGjBmYNWsWvv76a3zzzTdISEjAihUrYDAY8Pbbb+O7777DO++880jXZgvsYSIiIiKq7CrJA2yHDh2K2rVro27duqhRowZmz56Ntm3bIiAgAAMHDoSvry8uX75c6L7BwcEYNWoUatWqhXHjxkGj0RS5bceOHdGzZ0/Url0br776KuLi4pCQkIDr16/jwIEDmDNnDho1aoSOHTtizJgxxdbt7++P4OBg7Nq1CwBw8uRJeHh4oG7duqV6H1xdXaFUKuHk5FSioYeFEUURS5cuxbhx4xAVFYUGDRpg5syZkMvlWLduXYmuee/evYiPj8dnn32G4OBgtG3bFtOmTcOKFSuQlZWF2NhYODg4wN/fHw0aNMAnn3yC//3vfwCA27dvw9nZGQEBAQgJCcHXX3+NZ5555pGuzVbYwySRnNgYOGTbRzcjERERVV6CIKDapwshajXle14HtU17lwBz8MjVpk0bnDp1Cl988QWuXr2KCxcuICEhASaTqdB984YTFxcXAIDBYCh02zp16hS6bXR0NDw8PFCrVi3L+ubNm1tVe1RUFHbs2IEBAwZg+/btBYbj2cq6deswffp0y+sPPvgAfn5+RW6flJSE1NRUNGvWzLJMqVSiSZMmuHr1Kjw8PKy+5qtXr6Ju3br5Julo0aIFDAYDbt26heeffx4bNmxA+/bt0bp1a3Tp0gX9+/cHAAwZMgSvvfYa2rZti7Zt26J79+7o3bt3ad8Gm2IPkwQMWi0GLz2OjSm+Rf6jJiIiIrIVQRAgUzuW65etwxIAODg4WH5etWoVhg0bBq1Wi27dumHx4sWoXr16kfsWNmNeUfdZFbWtQqEo9b1ZUVFROHjwIHJycrBjxw507dq12H2MRmOJz9O5c2esXbvW8tW5c+eHbp/3PX3w3CaTqUTXXNixcq/BaDSiYcOG2LlzJz777DP4+vriyy+/xIgRIyCKItq2bYvdu3dj+vTpUKlUmDZtGiZNmmTVecsae5gkoNEZEOfoDQDISc+AWq2WuCIiIiKiimXFihV4/fXXMXLkSADmSQOSkpJsOtnEgxo0aIC0tDTExMRYelzOnj1r1b6NGzeGl5cXli1bBr1eX+h9VkqlEllZWZbXMTExJa7RxcXF0itmDVdXV/j4+ODkyZNo1KgRAPPkDOfOnUO7du1KdM316tXDjRs3kJqaahkqePLkSSgUCtSuXRtr166FSqVCz5490aNHD5w8eRLPP/88kpKS8PfffyM4OBj9+vVDv379sGHDBkyePLnE118WGJgk4OziBKVJD71MiZTEFHhW4zSQRERERCXh6emJgwcPIioqCllZWfjqq6+g1+stM7KVhXr16qF9+/aYMmUK3nvvPSQlJeGbb76xev/OnTvju+++K/LenKZNm2L16tWIjIxESkoKFi1aVOSxnJyccOPGDSQlJVl9/j179uR77eDggMjISAwbNgzffPMNqlWrhjp16mDBggXQarXo2bMnvLy8rL7mdu3aoVatWnjnnXcwceJEpKSkYObMmejVqxfc3NyQkZGBH374AZ6enggICMD69etRvXp1eHp64u7du1i5ciVmz54NDw8PbNmyBY0bN7b62soSA5MEBEGAq1GDZJkSqSnpUpdDREREVOFMmTIFU6ZMQZ8+feDt7Y0ePXrA0dERFy5cKNPzzp49G1OnTsVzzz0HPz8/9O/fHwsXLrRq36ioKCxdurTI+5fGjx+PyZMno3///qhfvz7GjRuHN998s9BtBwwYgClTpmDkyJGW6dOLM2rUqHyv/fz8sGfPHowYMQKZmZmYOnUqMjMzER4ejl9//dXyfCprr1kul+O7777DzJkz8dxzz8HZ2Rm9e/fGhAkTAAAvvvgi7t69i7fffhtpaWlo0qQJvv/+e8jlcowbNw4ZGRl49dVXkZ2djVatWpVqBsGyIIhl2W9pZxITE7FmzRr0798fPj4+ktYy4ONVuKHyxpxQGTr3fELSWig/nU6HxYsXY9iwYVCpVFKXQ3mwbewX28Z+sW3sV1m2Td7hU1RyJpMJSUlJ8Pb2hkz23y3/OTk5OHDgAB5//HHLfU6bNm3CZ599VuA5S5WFvV1zUW3zMEX9e7A2G9jNpA86nQ69evXC4cOHi9wmOjoaAwcORFhYGHr37o1Dhw6VY4W25SaYb4BLzciWuBIiIiIisoaDgwOmTJmCb7/9FjExMThx4gS+/fZbdO/eXerSykxVvOYH2UVg0mq1mDBhQpFz4QNARkYGRowYgcDAQKxfvx5du3bFmDFjSjRu0564yc2z46Vmle8Un0RERERUOjKZDN9++y0OHDiAXr16YcyYMejQoUORw+Yqg6p4zQ+S/B6mK1euYOLEicXOaPLnn3/CyckJM2bMgFwux9ixY7F7926cPXsWHTt2LKdqbcddCcAIpOfopS6FiIiIiKwUERGB33//XeoyylVVvOa8JO9hOnLkCCIjI7Fy5cpit4uKioJcLrcs++OPPypkWAIAdwdzVk3Tlnx+fSIiIiIiKh+S9zANGjTIqu1iYmIQFhaGqVOnYufOnfD398ekSZPQsmXLEp+zrKectIarWg5kA6k6UfJaKL/c9mC72B+2jf1i29gvto39Ksu2MZlMMJlMNj9uVZE78kkURb6PdqY0bWMymQr9d6bXWzfSy65myQsODsaSJUsQGRlZYF3Xrl2RkpKCIUOGoEuXLtiwYQOWLVuGTZs2oUaNGlYdP3cmDHuQGJeFP52aoVHmLXTw5//EiIiIyHbCwsLQoEEDqcsgsgtXr17F6dOni1xf3Cx5kvcwWUsulyMkJARjx44FYH5a8v79+/HXX3/hlVdeKdGxevfuDW9v77Io02r/bNmLPy8CWqUThg2zrpeNyodOp8Py5csxaNAgTsFrZ9g29ottY7/YNvarLNsmLi5O8s86FZkoikhOToaXlxcEQZC6HMqjNG2TnZ2NFi1aFFielJSE9evXF7t/hQlMvr6+qF+/fr5ldevWRVxcXImPpVQqJf+fhreXO4B0pMscJK+FCqdSqdg2doptY7/YNvaLbWO/yqJtZDKZ1c+ooYJyh3oJgsD30c6Upm1kMlmh/8ZynytV7P7Wlyet5s2bIzo6Ot+ya9euwd/fX6KKHo2nlzsAIEOmLnaGQCIiIiIikoZdB6aEhARoNObnFL3wwguIjo7G3LlzcfPmTXz99deIiYlBnz59JK6ydDy8PQEAOrkS2Zl8eC0RERFVXYMGDcLEiRMLXbdu3Tq0atXqoZNjxMbGIjg4GLGxsQDM98UfPny40G0PHz6M4OBgq2vbtGmT5bmfc+fOxeDBg63etyQ6d+6M4OBgHD16tMC6PXv2IDg4GO+++65Vxxo8eDDmzp0LwDz0M++U4HnXFVVHWd3zX5bHLkt2HZjat2+PjRs3AgD8/f2xcOFC7Nq1C7169cKuXbvw448/ws/PT+IqS8fJzQUKkwEAkJxYMR++S0RERGQLTz31FHbv3l1oKNq0aRO6detWomGL+/btQ3h4+CPXdfv2bYwfPx45OTkAgBEjRjw0bDwqpVKJnTt3Fli+ffv2Ut9LtWHDBvzwww+W13PnzsWIESNKXWNVZFeBKTo6Ot8MedHR0ejfv7/ldcuWLbFmzRqcOXMGa9euRatWraQo0yZkMhlcDeaepdSkNImrISIiIpJOjx49kJOTg4MHD+ZbnpmZiX379qFXr14lOp6vr2+Z3LPn7OwMDw8Pmx83V0RERIHAJIoidu7ciebNm5fqmA/e+uHh4QFnZ+fSllgl2VVgqmqcDebhhimp6RJXQkRERJWZKIrI0RnL9ask92h7eXmhbdu22Lp1a77l27dvh4eHByIjIxEfH4+xY8eiVatWaNKkCfr164djx44Very8Q/IyMzMxYcIEhIeHo3v37jhz5ky+bY8dO4aBAweiWbNmaN68OUaNGoV79+4BALp06QIAiIqKwpo1awoMyTtx4gQGDhyI5s2bo3PnzlixYoVl3bvvvovZs2dj/PjxaNasGTp27Ii1a9c+9H144oknEBsbi6tXr1qWnTx5Eu7u7qhbt65lWWFDAwsb7nb48GFMnjwZt2/ftgxZLG5IXnEeds0AsHjxYnTo0AEtWrTARx99hMGDBxc6DM9kMmHhwoWIiopCWFgYBg8enG++go0bN6J79+5o2rQpevbsie3bt1vWrVq1Cp07d0bTpk3Rv39//Pvvv6W+HmtUmFnyKiMXkzkwpabzHiYiIiIqG6IoYuTy4zh9p3xHtDTzd8eCgS2sHkrWq1cvfPLJJ/jwww8hl8sBAJs3b0bPnj0hk8nw1ltvwc3NDb/99htEUcTnn3+OGTNmFDst9PTp03Ht2jUsXboUycnJ+e4DysjIwOjRozFs2DB8+umnuHfvHqZMmYIFCxbglVdewe+//47nnnsOq1atQlBQEBYsWGDZ9+rVqxg6dCiGDRuGjz/+GKdOncIHH3wAHx8fdO3aFQCwbNkyjBs3DhMnTsSSJUswffp0REVFwdXVtdBa3dzc0LJlS+zcudPyHK1t27ahS5cuiI+Pt+p9zCs8PBxTpkzBokWLsHr1anh5eZX4GHkVd83r1q3DN998g48//hiBgYH44osvcPToUfTr16/Asb799lusWLECM2fORN26dbFgwQKMHDkSW7ZsQU5ODt555x18+OGHiIyMxObNmzFhwgTs2bMHsbGx+O677/DNN98gKCgIS5Yswfjx47Fnz54ym9GQPUwSchTN43RTMjUSV0JERESVWUV4lFCXLl2QnZ1tmfQgIyMD+/btQ+/evSGKIrp06YKpU6eiQYMGCAwMxIsvvogrV6489JgZGRnYtGkT3n//fYSGhqJDhw547bXXLOs1Gg1ee+01vP7666hVqxZatmyJbt26WY6bGzC8vLygVqvzHfv3339H48aNMWHCBNSvXx/9+vXDSy+9hIULF1q2CQ4OxqhRo1CrVi2MGzcOGo0Gly9ffmjNUVFR+Ybl7dixw9LTVVIqlQqurq6Qy+Xw9fW1BNHSKu6aly9fjqFDh6JHjx5o2LAh5syZU+B9A8whfunSpRg3bhyioqLQoEEDzJw5E3K5HOvWrUN8fDz0ej2qV68Of39/jBgxAt999x0cHBxw+/ZtCIKAmjVrIiAgAOPHj8dnn31mmW68LLCHSUJOoh4AkJZd9KwvRERERI9CEAQsGNgCGn3ZfaAsjFopK9FEBS4uLnjiiSewdetWtGnTBtu3b0dAQACaNGkCABg4cCA2btyI48eP4/r16zh79myxH5KvX78Oo9GIRo0aWZY1bdrU8rOvry/69u2LxYsX48KFC7hy5Qqio6OtmjDi6tWrCAsLy7csPDwcv/32m+V13mF0Li4uAACDwfDQ40ZFRWHOnDlITk5GcnIytFptvpptKe91tmzZMl/YK0xx1xwdHY3//e9/lnXu7u6oV69egeMkJSUhNTUVzZo1syxTKpVo0qQJrl69iueffx5PPPEEhg8fjnr16iEqKgoDBgyAo6Mj2rdvj/r166NPnz5o3LixZZ1CUXaxhoFJQmoYAQBpGr3ElRAREVFlJggCHFWP1rtQHnr37o2ZM2di6tSp2LRpk2WyB5PJhBEjRiA9PR09e/ZE586dodfrMWbMmBKfI+9kEPHx8XjmmWcQGhqKxx57DM899xz++ecfnDx5stjjODg4FFhmMplgNBotrwt7MGpx93YFBAQgMDAQ//zzD+7du1do71JhQbS4IFaYvPdUFdYT9KDirlkulxe4vsKut7DjAIDRaITJZIIgCJg/fz5Onz6NHTt2YNu2bVi+fDmWL1+O4OBg/Pjjj7h27Rr++ecfrFmzBitWrMCaNWvKbPZsDsmTkFp2PzDp+eBaIiIioo4dOyI7OxuHDh3CwYMHLYHpypUrOHr0KBYvXoxXXnkFTzzxhGVihocFkPr160OpVOab6OH8+fOWn7dt2wZ3d3fMnz8fQ4cORUREBGJiYqyasKJevXo4depUvmUnTpwotEelpKKiovDPP/8UORxPqVQiKyvL8jorKwvJycmFHuthvXx16tSxfFkTNoq75sDAQJw7d86yLjMzEzdv3ixwHFdXV/j4+OQLpnq9HufOnUO9evVw9epVzJkzB2FhYXjzzTexYcMG1KhRA3v37sWJEyfw66+/IjIyEpMnT8bmzZuh1WqLnADEFtjDJCGVYP7HmGaoAAOLiYiIiMqYSqVC165dMWfOHAQFBVmGtLm5uUEmk2HDhg3o3Lkzzpw5k+/BrEVxcXFBnz59MHPmTMyePRsajQbz5s2zrPfw8MCdO3dw8OBBBAQEYNOmTdi6datlGKCTkxMA4OLFi/D09Mx37EGDBmHJkiX48ssv0a9fP5w8eRLLly/H1KlTH/l9iIqKwuLFi+Hg4FDoY3SaNm2Kr7/+Gps2bUKjRo0wb968Iic8cHR0RFpaGm7cuIGAgACrzn/p0iXs2bOnwDmLu+bBgwdj+vTpaNSoERo0aICvv/4a2dnZhYa2YcOG4ZtvvkG1atVQp04dLFiwAFqtFj179oTRaMSKFSvg6uqK3r1748qVK7h9+zYaN24MtVqNn3/+GbVq1UK7du1w9OhRZGdnl+hhxCXFwCQhB7k5MKWL9t9FTkRERFQeevXqhTVr1mDy5MmWZdWrV8eMGTPw7bff4ssvv0S9evXw/vvvY9KkSTh//jx8fX2LPN7UqVMxc+ZMDB8+HO7u7hg8eDDmzJkDwPz8p6NHj2Ls2LEQBAFNmzbFpEmTMHfuXOh0OtSoUQNPP/00xo8fj7feeivfcWvWrIn58+fj008/xaJFi1CzZk28++67eOaZZx75PWjSpAnc3NzQtm3bQidqaNu2LYYNG4Zp06ZBJpNh+PDhlh63B7Vp0wZ16tRB7969sXz5cqvO//PPP+Pnn38usOyxxx576DU/9dRTuHnzJqZPnw6tVovnn38e/v7+hQ5NHDFiBDIzMzF16lRkZmYiPDwcv/76q2Wijblz5+Lzzz/HDz/8AG9vb0yYMAHt27eHyWTC5MmTsWjRInz00UeoWbMmPvvsM8usgmVBEEsySX4Fl5iYiDVr1qB///7w8fGRtBadTofvv5yHpfLm8NZnYPOUPpLWQ//R6XRYvHgxhg0bViYPvaPSY9vYL7aN/WLb2K+ybJuYmBjUqlXLpsesSkwmE5KSkuDt7V1mU1VXRkeOHEGtWrVQo0YNAOb7qtq0aYNvv/0WkZGRNjlHadqmqH8P1mYD9jBJSKmQASKQIS/+JjsiIiIiInu2fft2nDhxAh988AGcnZ2xZMkSuLi4oHnz5lKX9kgYmSUkV5nzqk6mRE6OVuJqiIiIiIhKb+zYsahXrx6GDx+OPn364Nq1a1i4cGGRs+JVFOxhkpJKAUWOAQaZAsmJyfCvVUPqioiIiIiISsXFxQWffvqp1GXYHHuYJCTIZHA15AAAUpJSJK6GiIiIiIgexMAkMTfRPBQvJTVD4kqIiIiIiOhBDEwSc4MeAJCSllXMlkRERETWMxqNUpdAJDlb/DtgYJKYm8wEAEjNzJG4EiIiIqosfH19cfv2bYYmqtKMRiNu37790Od0WYOTPkjMTWl+8nFaVtFPqSYiIiIqCbVajWrVqiEuLg5V6JGbNmMymRAXF4fs7Gw+h8nOlLRtqlWrBrX60R7hw8AkMXeVAOiAVI1B6lKIiIioElGr1QgICJC6jApJp9Nhy5YtaNGiBR/4bGekaBtGZol5OCoBAOk6dpkTEREREdkbBiaJuTmZH+SVahAkroSIiIiIiB7EwCQxD1dHAEC6SS5xJURERERE9CAGJol5ujsDANKhlLgSIiIiIiJ6EAOTxNw93AAA6fJHm72DiIiIiIhsj4FJYp5eHgAAnUyJHK1e2mKIiIiIiCgfBiaJuXh5QmEyTymekpwqbTFERERERJQPA5PEZCoVXA05AIDkxFRpiyEiIiIionwYmOyAm0kLAEhNTZe4EiIiIiIiyouByQ64CuZ7l1LTMiWuhIiIiIiI8mJgsgPuMhMAICUjR+JKiIiIiIgoLwYmO+CuEAEAqVlaiSshIiIiIqK8GJjsgLtKDgBI03BacSIiIiIie8LAZAfcnRQAgDStSeJKiIiIiIgoLwYmO+Dh5AAASDNIXAgREREREeXDwGQHPFwcAQDpJrnElRARERERUV4MTHbA090FAJAGpcSVEBERERFRXgxMdsDTyx0AkC5zkLgSIiIiIiLKi4HJDnh6ewAAdDIlcnS8kYmIiIiIyF4wMNkBVy9PyE1GAEBKaobE1RARERERUS4GJjsgc3SChz4TAJBwL0niaoiIiIiIKBcDkx0QBAFepmwAwL2EFImrISIiIiKiXAxMdsJbMN+7lJDMIXlERERERPbCbgKTTqdDr169cPjw4WK3jY2NRXh4uFXbVhTeShMAICEtW+JKiIiIiIgol10EJq1WiwkTJuDy5ctWbT9jxgxkZ1euYOGtNj+0NjFLJ3ElRERERESUS/LAdOXKFTz33HO4deuWVduvW7cOWVlZZVxV+fN1MT+DKUlrkrgSIiIiIiLKpZC6gCNHjiAyMhJvvvkmmjdv/tBtU1JS8Nlnn2HRokXo1atXqc+p1+uh00nbk5N7/tzvXq6OQAqQZJBJXltV92DbkP1g29gvto39YtvYL7aN/WLb2C9bto1er7dqO0EURfGRz2YjwcHBWLJkCSIjIwtdP2nSJPj5+WHChAnFbluYxMRErFmzxlbl2pTxXjIWObSGmz4Lz/vESV0OEREREVGV0L9/f/j4+BS5XvIeJmsdOHAAx44dw99///3Ix+rduze8vb1tUFXp6XQ6LF++HIMGDYJKpUL8hYtYtDURGQonvDR4CBRyyUdLVlkPtg3ZD7aN/WLb2C+2jf1i29gvto39smXbJCUlYf369cVuVyECk0ajwbRp0zB9+nSo1epHPp5SqbSbX36VSgWVSoXqtWpCJsbDJMiRrjWiusejXyc9mty2IfvDtrFfbBv7xbaxX2wb+8W2sV+2aBulUmnVdhWiG+P06dOIiYnB2LFjER4ejvDwcADAqFGjMG3aNImrsw2Fhxc8deZnMN2LS5C4GiIiIiIiAipID1NYWBi2bt2ab1m3bt3w0UcfoV27dhJVZVuCTAYvYw6S4IGEhGQgpK7UJRERERERVXl2HZgSEhLg6uoKtVqNOnXqFFjv5+cn+b1ItuQlmGf7uJeULnElREREREQE2PmQvPbt22Pjxo1Sl1FuvBXmCQsT0irfc6aIiIiIiCoiu+phio6Ofuhra9dVVD6OMsAAJGZxzn8iIiIiIntg1z1MVY2PswMAIEljkrgSIiIiIiICGJjsiq+HEwAg0cBmISIiIiKyB/xkbkd8vdwBAMki5/snIiIiIrIHDEx2pFo1LwBAmkwNg4nD8oiIiIiIpMbAZEe8a1SDTDRCFAQkZWilLoeIiIiIqMpjYLIjSk8feOgyAQD37iVJXA0RERERETEw2RFBoYC3wfwMpnt3EyWuhoiIiIiIGJjsjJegBwAkJKdLXAkRERERETEw2RlvhXmyh4S0LIkrISIiIiIiBiY74602N0lipk7iSoiIiIiIiIHJzvg4m5/BlKQxSlwJERERERExMNkZX3cnAECiXpC4EiIiIiIiYmCyM75ebgCAJFElcSVERERERMTAZGeqVfMGAKTJ1DCYTBJXQ0RERERUtTEw2Rnv6r6QiUaIgoAkTvxARERERCQpBiY7o/L2gYcuAwCQkJAscTVERERERFUbA5OdEVQO8DJkAwDuxSdJXA0RERERUdXGwGSHvKAFACQkpUlcCRERERFR1cbAZIe8FebJHhLSsiSuhIiIiIioamNgskM+DuZmSczUSlwJEREREVHVxsBkh3yclQCAxByjxJUQEREREVVtDEx2yNfdGQCQpBckroSIiIiIqGpjYLJDvl6uAIAkUSlxJUREREREVRsDkx3yreYFAEgTHGAwmSSuhoiIiIio6mJgskPe1XwhE00wCTKkZOulLoeIiIiIqMpiYLJDKh9feOgyAAD3ElOlLYaIiIiIqApjYLJDMkcn+OjNgSnubqLE1RARERERVV0MTHbKT8wGANy+lyptIUREREREVRgDk53yU5one4hLzpS4EiIiIiKiqouByU7VuP/w2jsZOokrISIiIiKquhiY7FQNTycAwF2NxIUQEREREVVhDEx2yt/PEwAQL6ogiqLE1RARERERVU0MTHbK398PAJAtKJGhNUhcDRERERFR1cTAZKeca9S0PIvpTkq2xNUQEREREVVNDEx2Su7tC19NCgAg9k6CxNUQEREREVVNDEx2SpAr4CfmAADuxPHhtUREREREUmBgsmPVlUYAwJ2kDIkrISIiIiKqmhiY7FgNZwUAIC5DK3ElRERERERVEwOTHavhYX4WU5yG04oTEREREUmBgcmO+ft6AADiTXwWExERERGRFOwmMOl0OvTq1QuHDx8ucpt//vkHffr0QXh4OHr37o0dO3aUY4Xlz9+/GgA+i4mIiIiISCp2EZi0Wi0mTJiAy5cvF7nNxYsXMWbMGDzzzDNYu3YtXnjhBYwbNw4XL14sx0rLl1NN//+exZSaI3E1RERERERVj0LqAq5cuYKJEycWO+Ts77//Rps2bTBkyBAAQJ06dbBz505s2rQJjRo1Ko9Sy53C1w++mmSkqlxx+24SGlV3k7okIiIiIqIqRfIepiNHjiAyMhIrV6586Hb9+vXDW2+9VWB5RkblnXJbUKrgZ8oGANzms5iIiIiIiMqd5D1MgwYNsmq7Bg0a5Ht9+fJlHDx4EC+88EKJz6nX66HT6Uq8ny3lnr+4Ovzk5nuXYhNSJa+5qrC2baj8sW3sF9vGfrFt7Bfbxn6xbeyXLdtGr9dbtZ0g2tH0a8HBwViyZAkiIyMful1ycjIGDRoEHx8fLFmyBDKZdR1liYmJWLNmjS1KLTfpl+9gZbXH0Uh7Bx2qZUtdDhERERFRpdK/f3/4+PgUuV7yHqaSSkxMxPDhwyGKIr755hurw1JevXv3hre3dxlUZz2dTofly5dj0KBBUKlURW6366clWJkJaB09MGzYc+VYYdVlbdtQ+WPb2C+2jf1i29gvto39YtvYL1u2TVJSEtavX1/sdhUqMMXHx1smfViyZAm8vLxKdRylUmk3v/wqleqhtdTy8wIygXijEkqlEoIglGN1VVtxbUPSYdvYL7aN/WLb2C+2jf1i29gvW7SNUqm0ajvJJ32wVnZ2NkaOHAmZTIalS5fCz89P6pLKRc2avgD4LCYiIiIiIinYdWBKSEiARqMBAMyfPx+3bt3CnDlzLOsSEhIq9Sx5AOCc51lMcWkaiashIiIiIqpa7DowtW/fHhs3bgQAbNmyBRqNBgMGDED79u0tXx9//LHEVZYtebUa8NUkAwBi41MkroaIiIiIqGqxq3uYoqOji3y9efPm8i7HLsjUjvAzZOIy7j+LKay21CUREREREVUZdt3DRGZ+CiMA4E5imsSVEBERERFVLQxMFUANJ3Mz3eE9TERERERE5YqBqQKo4e4IALirMUlcCRERERFR1cLAVAH4+7oDAO4alBBFUeJqiIiIiIiqDgamCsC/hvlZTDmCAukaPouJiIiIiKi8MDBVAE41av73LKZ03sdERERERFReGJgqAEXeZzElpEtcDRERERFR1cHAVAEILq6orjMHpZjb9ySuhoiIiIio6mBgqgAEQUAtuRYAcIM9TERERERE5YaBqYIIcBIAADGpvIeJiIiIiKi8MDBVELV9XAEAMcxLRERERETlhoGpgqgbYJ5aPFVUIkOjl7gaIiIiIqKqgYGpgnCvVRseWvP9S7dSciSuhoiIiIioamBgqiAU/rXhn5MAALiZmCFxNUREREREVQMDUwUh9/JFTa35WUw3Yjm1OBERERFReWBgqiAEmQwBKiMA4GZ8msTVEBERERFVDQxMFUhtVyUA4Fa6VuJKiIiIiIiqBgamCqR2NQ8AQKxWBlEUpS2GiIiIiKgKYGCqQGoF+EEmGqGBHAmZOqnLISIiIiKq9BiYKhCngNrwy0kBANxKyZa4GiIiIiKiyo+BqQJR+NdGjdypxRPSJa6GiIiIiKjyY2CqQGTunvDXm2fI49TiRERERERlj4GpAhEEAQFq82QPNxP48FoiIiIiorLGwFTB1HF3AADcytBLXAkRERERUeXHwFTB1KnuCQCIMyhgMJokroaIiIiIqHJjYKpg/AJqwsGogwkCbqdppC6HiIiIiKhSY2CqYFQBtVEjJxEApxYnIiIiIiprDEwVjLJmbdTMvj+1eHyqtMUQEREREVVyDEwVjMzFFf6mTADAjduJEldDRERERFS5MTBVQLUczd9vJmVKWwgRERERUSXHwFQB1fZ0AgDEZHOWPCIiIiKissTAVAHVqeENAEgyKpCtM0hcDRERERFR5cXAVAF51QqAm848HC8mJUfiaoiIiIiIKi8GpgpI4f/f1OI3kzm1OBERERFRWWFgqoAUNWvB//7U4tfikiSuhoiIiIio8mJgqoBkakfUhXlI3pXbyRJXQ0RERERUeTEwVVD1nQUAwNUUjcSVEBERERFVXgxMFVSgrwsA4LZWQI7OKHE1RERERESVEwNTBVWtbm246zIgQsC1pCypyyEiIiIiqpQYmCooZd1A1Mm6CwC4kpApcTVERERERJUTA1MFpawTiDqZcQCAy3dTpS2GiIiIiKiSspvApNPp0KtXLxw+fLjIbc6fP48BAwagWbNmeOaZZ3D27NlyrNC+yN09UFc09yxdjuXU4kREREREZcEuApNWq8WECRNw+fLlIrfJzs7G//73P0RERGDNmjUIDw/H6NGjkZ1ddR/c2sBTBQC4kqqFKIoSV0NEREREVPnYLDAZDAakpqaWeL8rV67gueeew61btx663caNG+Hg4IB33nkHDRo0wHvvvQdnZ2ds3ry5lBVXfA0CfCETTUg3ypCUpZO6HCIiIiKiSqdUgclgMGDevHlYv349AODw4cNo164d2rZti6FDhyItLc3qYx05cgSRkZFYuXLlQ7c7deoUWrZsCUEwP39IEAS0aNECJ0+eLM0lVAou9RqgRk4iAOAyJ34gIiIiIrI5RWl2+uabb/DTTz9hypQpAICPPvoIHh4eeP311/Hzzz/jiy++wIcffmjVsQYNGmTVdgkJCQgMDMy3zNvb+6HD+Iqi1+uh00nbI5N7/kepQ6hZG3Uyd+G2UzVE301DS39XW5VXpdmibahssG3sF9vGfrFt7Bfbxn6xbeyXLdtGr9dbtV2pAtOGDRswYcIEvPjii7h69SouX76MTz75BH379oWHhwc+/fRTqwOTtXJycqBSqfItU6lUpXqzcnvG7MHy5ctLva/MYEDtrLs4gGbYfuAEdGe227AyepS2obLFtrFfbBv7xbaxX2wb+8W2sV/l2TalCkz37t1Ds2bNAAD//PMPZDIZHn/8cQBA9erVkZGRYbsK73NwcCgQjnQ6HdRqdYmP1bt3b3h7e9uqtFLR6XRYvnw5Bg0aVCAIlsSGd94FABicvDBsWG9blVel2aptyPbYNvaLbWO/2Db2i21jv9g29suWbZOUlGRVR0qpAlO1atUQGxuLiIgI7Ny5EyEhIfDy8gIAnDhxAtWrVy/NYR/Kz88PiYmJ+ZYlJiaiWrVqJT6WUqm0m19+lUr1SLU09HEGANzKMkEmV0Aht4uJDyuFR20bKjtsG/vFtrFfbBv7xbaxX2wb+2WLtlEqlVZtV6pP17169cLs2bPx8ssv49ixY3jmmWcAAB9//DHmzp2L3r1t39PRrFkznDhxwjJ9tiiKOH78uKWnq6ryr+0PtUELvSjgZkrVnWKdiIiIiKgslCowjR8/HiNGjIAgCJg4caJl4oYzZ85gxIgReO2112xSXEJCAjQaDQDgySefRHp6Oj7++GNcuXIFH3/8MXJyctCjRw+bnKuicqgXiDpZcQCAqwlZEldDRERERFS5lCowCYKA0aNHY+HChRg1apRl+W+//YYJEyZAJrPNsLD27dtj48aNAAAXFxfMnz8fx44dQ//+/XHq1Cn8+OOPcHJyssm5KiplnQaonXUXAHD5nu3vHSMiIiIiqspKdQ8TYH5+kkqlQvPmzXHnzh18+OGHuH37Np588km8/vrrpTpmdHT0Q1+HhYXhzz//LG3JlZLCvxbq5twDAFy+nQQg8OE7EBERERGR1UrVFbR27VoMHToU27ZtAwBMmzYNhw8fRp06dfDDDz/gxx9/tGmRVDRBrkB9Z3MzXknkkDwiIiIiIlsqVWBavHgx+vXrh7fffhsJCQk4cOAAxowZg3nz5uHNN9/EH3/8Yes66SECq7sDAOK1QIbGugdwERERERFR8UoVmK5du4a+ffsCAHbv3g1RFBEVFQUAaNq0KeLi4mxWIBXPq15d+GhSAABX2ctERERERGQzpQpMbm5uyMzMBADs3bsXNWvWRN26dQEAt27dgqenp80KpOLlm/ghIVPiaoiIiIiIKo9SBabIyEjMmzcPP/74I3bs2IGePXsCALZs2YKvv/4a7dq1s2mR9HDKuoGom2nu1bt8N13iaoiIiIiIKo9SBab33nsPnp6emDdvHtq2bYvRo0cDAGbPno2aNWti4sSJNi2SHk7u44f6+iQAwPnYJImrISIiIiKqPEo1rbiXlxd++umnAsuXL1+OmjVrPnJRVDKCICDEQwkAuJKmg9ZghINCLnFVREREREQVX6mfwwQAe/bswZEjR5Ceng5PT09EREQwMEnEv1YNuKVlIl3lgkv3MtG0prvUJRERERERVXilCkw6nQ6vvfYa9u3bB7lcDk9PT6SkpODHH39EmzZtMH/+fKhUKlvXSg/hUL8hAvfE4Lh3CM7fTWdgIiIiIiKygVLdwzR37lwcO3YMn376KU6fPo19+/bh1KlTmD17Nk6ePInvv//e1nVSMZSBIQjMiAUAnIvjxA9ERERERLZQqsD0999/Y8yYMXj66achl5vvlVEoFOjbty/GjBmD9evX27RIKp6qXkMEZt0BAJy/nSJxNURERERElUOpAlNycjIaN25c6LrGjRsjPj7+kYqikhOUKoR4mEdY3krTIVNrkLgiIiIiIqKKr1SBqXbt2jh27Fih644ePYoaNWo8UlFUOtXq14evJhkigIvxGVKXQ0RERERU4ZUqML3wwguYP38+Fi5ciLi4OOj1esTFxWHBggVYsGABnnnmGVvXSVZQNWyEwHTex0REREREZCulmiVv4MCBOH/+PD7//HN88cUXluWiKKJfv3743//+Z7MCyXqqwBAE/nUAB6uF4TwDExERERHRIytVYJLJZPj4448xfPhwy3OY3N3d0bp1azRo0MDWNZKVlHUDEZgdBwA4f4cTPxARERERPapHenBtYGAgAgMDbVULPSJBqUIjTwcIogl3swxIztLBy5nPwyIiIiIiKi2rA1Pnzp0hCIJV2wqCgO3bt5e6KCo9j8BA+CclINbZD+fvpqN9Ax+pSyIiIiIiqrCsDkytW7e2OjCRdFSBIQi8cYWBiYiIiIjIBqwOTJ988klZ1kE2omrYGIF//oN/qkdwpjwiIiIiokdUqnuYjh49WuQ6QRDg7OyMWrVqwcXFpdSFUeko6zRAw6zciR/SIIoiewaJiIiIiEqpVIFp8ODBlg/hoihaluf9YC6TydC3b198+OGHkMvlj1gmWUtQKtHQ1xkKkwGpWiAuXYOa7o5Sl0VEREREVCGV6sG133//PVQqFZ577jn8+uuv2LhxI5YuXYqXXnoJCoUCkydPxpQpU7Bt2zb8+OOPtq6ZiuEcGIQ6WXcBAOfvZkhcDRERERFRxVWqHqYFCxZg0KBBmDRpkmVZ/fr1ERERAScnJ2zbtg2//vorAGDJkiV49dVXbVMtWUXVsDECr5zDVdcAnI9LR5fgalKXRERERERUIZWqh+ncuXPo0KFDoesiIyNx6tQpAEBwcDDi4uJKXx2ViiqwEQIzYgAAZ+LSJK6GiIiIiKjiKlVg8vX1xeHDhwtdd/jwYfj4mKeyTklJgZubW+mro1JR1m6AkMxYAMD5O+nQGUwSV0REREREVDGVakjewIED8cUXXyAnJwfdu3eHt7c3EhMTsX37dixduhRvvPEG7t69i++//x6RkZG2rpmKISiVqFPTC+66DKSpXHH+bjqaB3hIXRYRERERUYVTqsD08ssvIycnBwsXLrTcqySKIlxdXfHGG29g9OjRWLt2LXQ6HSZMmGDTgsk6qsAQNL5xHQerheFEbCoDExERERFRKZQqMAHAmDFj8PLLL+PkyZNITk6Gn58fQkJC4OzsDADo3bs3+vbta6s6qYRUgSFofGqXJTANl7ogIiIiIqIKqFT3MOW6c+cObty4gdu3b+P69euIj4+3rOOzl6TlENIMIWnXAQCnb6fBaBKL2YOIiIiIiB5Uqh4mURQxffp0rFq1qsCDa/v164dZs2bZrEAqHUWtuqgny4aTIQdZcMSVhEwE+7lKXRYRERERUYVSqh6mhQsX4o8//sDYsWOxY8cOnD59Gtu3b8eYMWOwbt06LF682MZlUkkJggDHRk3RKO0mAOBEbKq0BRERERERVUClCkyrV6/GyJEj8eqrr8Lf3x8qlQoBAQF4/fXXMXLkSPz++++2rpNKwSG0uWVYHgMTEREREVHJlSowxcXFoU2bNoWui4yMRGxs7CMVRbbh0Lg5Gt8PTCdjU/MNnyQiIiIiouKVKjD5+/sjOjq60HUXL16El5fXIxVFtqFqGILAnHgoTXokZ+txKyVH6pKIiIiIiCqUUgWmXr16Ye7cudi0aZOl10IURWzcuBHz5s1Dz549bVoklY6gVMG5YTAapscA4LA8IiIiIqKSKtUseaNGjcK///6LN998E2+//TY8PT2RkpICo9GI1q1bY9y4cbauk0rJoXFzNP73Os571MfJ2FT0DaspdUlERERERBVGqQKTSqXCzz//jN27d+Po0aNIS0uDu7s7WrVqhY4dO9q6RnoEDo2bI2T7AaAOe5iIiIiIiEqqVIEpV8eOHQsEpISEBMTExKBFixaPVBjZhkNIGILTb0ImmnAnTYP4DA38XNVSl0VEREREVCGU6h6mh9m4cSNefPFFWx+WSknm6ga3AH/UzbwDwDxbHhERERERWcfmgYnsj0Pj5micmvs8pjSJqyEiIiIiqjgkD0xarRZTpkxBREQE2rdvj0WLFhW57bZt29CjRw+Eh4dj4MCBOHfuXDlWWnHlfR7T8ZhUaYshIiIiIqpAJA9Mn376Kc6ePYtffvkF06dPx7x587B58+YC212+fBkTJ07E6NGj8ddffyEkJASjR49GTg6fLVQch9DmCE29BkE04XpSFuIzNFKXRERERERUIUgamLKzs7Fq1Sq89957CA0NRdeuXTFy5EgsW7aswLb79+9HYGAg+vbti9q1a2PChAlISEjAlStXJKi8YpFXqwEPd2cEZsQCAA7fSJa4IiIiIiKiisHqWfLWrl1r1XanT5+2+uQXL16EwWBAeHi4ZVnLli3xww8/wGQyQSb7L895eHjgypUrOHbsGMLDw7FmzRq4uLigdu3aVp8vl16vh06nK/F+tpR7/vKqQ9EoDM1vX8Jlt9o4cC0RTwb7lMt5K6LybhuyHtvGfrFt7Bfbxn6xbewX28Z+2bJt9Hq9VdsJoiiK1mzYqFEjq08uCAIuXLhQ7HZbtmzBhx9+iP3791uWXb16FT179sTBgwfh5eVlWa7T6fDWW29hy5YtkMvlkMlkmD9/Ptq1a2d1XYmJiVizZo3V21cmda6dhXDzNt5r8TocBCNecr0OmSB1VURERERE0urfvz98fIruTLC6h2nHjh02KSivnJwcqFSqfMtyXz+YGlNSUpCQkIBp06ahWbNmWLFiBSZPnow///wT3t7eJTpv7969S7yPrel0OixfvhyDBg0q8B6UBf31S0iYOAJOBg2yFWq06fEMGld3LfPzVkTl3TZkPbaN/WLb2C+2jf1i29gvto39smXbJCUlYf369cVuZ3Vg8vf3L3LdnTt3UK1aNSgUJXsOroODQ4FglPtarc7/cNXPP/8cQUFBlmc8zZw5Ez169MAff/yB//3vfyU6r1KptJtffpVKVS61KBs2htLNHU1TLuOwb1P8G5uO5rWlDY32rrzahkqObWO/2Db2i21jv9g29ottY79s0TZKpdKq7R550gej0YioqChER0eXeF8/Pz+kpKTAYDBYliUkJECtVsPNzS3ftufOncs3LFAmk6FRo0a4c+dO6YuvQgSZDOpmrdA8+RIA4BAnfiAiIiIiKpZNZsmz8jaoAkJCQqBQKHDy5EnLsmPHjqFp06b5JnwAgGrVquHq1av5ll2/fh0BAQGlOndV5BAeifAUc2A6eycdmVpDMXsQEREREVVtkk4r7ujoiL59+2LGjBk4ffo0tm/fjkWLFmHIkCEAzL1NGo35mUHPPfccfv/9d6xduxY3b97E559/jjt37qBfv35SXkKFog6PRDVNCmpmJ8Aoijh6M0XqkoiIiIiI7FrJbjoqA5MnT8aMGTMwdOhQuLi44I033kC3bt0AAO3bt8fs2bPRv39/9OzZE1lZWZg/fz7u3r2LkJAQ/PLLL5JP3lCRKHyrQxFQB82To3HHyReHbiShU5Cv1GUREREREdmtRw5Mcrkcs2fPLvXQOEdHR8yZMwdz5swpsO7B+6IGDBiAAQMGlOo8ZKZuHonmB89gY0B7HLqRDFEUIQicX5yIiIiIqDA2GZLXr18/uLu72+JQVMbU4ZEITb0KhWjEnTQNYlJzpC6JiIiIiMhuWd3DFBISgpUrVyIsLAyNGjV6aK+EIAg4f/68TQok23IIawlH0YhGqddx1jMQh64no7ank9RlERERERHZJasD0+uvvw4/Pz/LzxzGVTHJnFygatQEzZMv4axnIA7eSMJzLTjTIBERERFRYawOTGPGjLH8/MYbbzx027t375a+Iipz6vBIhP+1HkvRE//eSoHWYISDQi51WUREREREdqdU9zCFhITg9OnTha77999/0aNHj0cqisqWunkk6mbGwVuXDo3exOnFiYiIiIiKYHUP06JFi5CdnQ3A/KDaVatWYc+ePQW2O3HiBFQqle0qJJtTBYdC5uSMVglnsdn/Mey+koj2DXykLouIiIiIyO5YHZi0Wi3mzZsHwDypw6pVqwpsI5PJ4OrqildffdV2FZLNCXIF1GERaB19Dpv9H8OeK4mY3E2EjPelERERERHlY3VgevXVVy1BqFGjRli5ciWaNWtWZoVR2XIIj0To4S/gZNIhORs4eycdYf6cGp6IiIiIKK9S3cN08eJFhqUKTh3eBkrRiJaJFwAAu68kSFwREREREZH9sbqHafLkyVYfVBAEzJo1q1QFUflQ+teGwr82WiWcxd5qzbD7SiLe6BgodVlERERERHbF6sB0+PBhqw/KZzRVDI6RHdHir9+hgAk3k7NxIykLdb2dpS6LiIiIiMhuWB2Ydu7cWZZ1kAQcIx+H05pf0TTtOk64N8DuK4kMTEREREREeZTqHiaqHFQhTSFzc0er+FMAeB8TEREREdGDrO5hyqtz587FDrvbsWNHqQqi8iPIFVBHtEOrffvwY1B/nL2TjsRMLXxcHKQujYiIiIjILpQqMLVu3bpAYMrKysKZM2eg1WoxdOhQmxRHZc8x8nF479yIhpp4XFb7Ye/VRPRr5i91WUREREREdqFUgemTTz4pdLler8drr72GnJycRyqKyo+6RVtAoUSrO8dxuX4P7LnCwERERERElMum9zAplUoMGTIEq1evtuVhqQzJnJyhDotA68TzAIAjN1OQpTNIXBURERERkX2w+aQPaWlpyMrKsvVhqQypIx9Hrex4BBjSoDOasPsyJ38gIiIiIgJKOSRv7dq1BZYZjUbcvXsXS5cuRURExKPWReXIMbIDUr+fg/axh/Fb3W7YfCEePUNrSF0WEREREZHkShWY3n333SLXhYeH4/333y91QVT+FL7VoWwQjPZ3TuK3ut1w5EYKkrN08HJWSV0aEREREZGkShWYCpsyXBAEuLi4wM3N7ZGLovLnGPk4ai5fgCBTKi7JPLA9+h6eaxEgdVlERERERJKyOjBNnjzZ6oMKgoBZs2aVqiCShmNkR6QvX4D2Nw/iUr0e2HzhLgMTEREREVV5VgemP//8E4IgwM/PDzLZw+eKKO6htmR/lA2CIfetjsfi/sXP9XrgzJ10xKbmIMDDUerSiIiIiIgkY3Vg6tGjB/755x/odDo8+eSTeOqpp9CyZcuyrI3KkSAIcOrQFV5rfkUzUxJOyryx7WI8hrepK3VpRERERESSsXpa8a+++goHDhzA+++/j3v37mH48OHo3LkzPv/8c1y4cKEsa6Ry4vR4NwBAu2t7AACbzsdDFEUpSyIiIiIiklSJnsPk6OiInj17Yt68eThw4ADeeOMNREdHY8CAAXjyyScxb948XL9+vaxqpTKmDGwERY0AtLl7AkpBxPWkLFxJ4DO1iIiIiKjqKvWDa11cXNCvXz8sWLAA+/btw8svv4zjx4+jd+/e6N+/vy1rpHIiCAKcHu8GZ4MGrQzxAIDNF+5KXBURERERkXRKHZjy0mq1yMnJgUajgdFoxO3bt21xWJKA4/1heY9d2gkA2HoxHiYOyyMiIiKiKqpUz2ECgPj4eGzevBmbN2/GqVOn4OTkhC5dumD06NFo166dLWukcqSs0wCK2vXRMvYsnEJF3E3X4nhMKiJqe0pdGhERERFRuStRYMobkk6ePAlHR0d06tQJI0eORIcOHaBSqcqqTionubPlGZbNR0ftDWxS1sPa03cYmIiIiIioSrI6MA0cOBCnTp2Cg4MDOnbsiK+//hodO3aEg4NDWdZHEnB6vCvSl81H57N/Y1P4G9h56R5SsxvCw4mBmIiIiIiqFqsD04kTJyCXyxEYGIjk5GQsXboUS5cuLXRbQRDwyy+/2KxIKl/KgLpQ1g9Cg2uXEORowKUcBf4+dxcvtaotdWlEREREROXK6kkfWrVqhRYtWkCtVkMUxYd+mUymsqyZykHuM5m6JZ4EAPx56g6fyUREREREVY7VPUy//vprWdZBdsapQ1ekLZ6HtifXYdETrXErJRvHY1PRshbvZSIiIiKiqsMm04pT5aOo7g9VozA46jXopE4HYO5lIiIiIiKqShiYqEjO3Z4GAESd2wAA9yd/0ElZEhERERFRuWJgoiI5degKQe2IuteOIchNDr1RxIZzd6Uui4iIiIio3DAwUZFkTs5w6tAVAPBkxgUAwJ+nOfkDEREREVUdDEz0UM7d+wIA2hz6HY4KGW4mZ+PfWynSFkVEREREVE4YmOihVI2aQlGrHtQ56ejqlgMAWH4sRuKqiIiIiIjKh+SBSavVYsqUKYiIiED79u2xaNGiIreNjo7GwIEDERYWht69e+PQoUPlWGnVJAgCnLv1AQA8dWEDBAD7ribhelKWtIUREREREZUDyQPTp59+irNnz+KXX37B9OnTMW/ePGzevLnAdhkZGRgxYgQCAwOxfv16dO3aFWPGjEFSUpIEVVctzp17AgoFfC8cQoeajgCAZf/ekrgqIiIiIqKyJ2lgys7OxqpVq/Dee+8hNDQUXbt2xciRI7Fs2bIC2/75559wcnLCjBkzUKdOHYwdOxZ16tTB2bNnJai8apF7eMEx8nEAQL+0UwCAjefuIjFTK2VZRERERERlTtLAdPHiRRgMBoSHh1uWtWzZEqdOnYLJZMq37ZEjRxAVFQW5XG5Z9scff6Bjx47lVm9V5tytLwCg7p5VaFLdFXqjiFUnb0tbFBERERFRGVNIefKEhAR4enpCpVJZlvn4+ECr1SI1NRVeXl6W5TExMQgLC8PUqVOxc+dO+Pv7Y9KkSWjZsmWJz6vX66HTSfsA1tzzS12HtWSh4ZD5+MGUGI/+6gSchRqrT8RiUHgNOCrlxR+gAqlobVOVsG3sF9vGfrFt7Bfbxn6xbeyXLdtGr9dbtZ0gSvhQnbVr1+Lrr7/Grl27LMtiYmLQpUsX7N69G9WrV7cs79q1K1JSUjBkyBB06dIFGzZswLJly7Bp0ybUqFHDqvMlJiZizZo1Nr+OqqJB9HEEXfwXyZ5+eDN8LDJMSjymTkCoQ5rUpRERERERlUr//v3h4+NT5HpJe5gcHBwKpMPc12q1Ot9yuVyOkJAQjB07FgDQuHFj7N+/H3/99RdeeeWVEp23d+/e8Pb2foTKH51Op8Py5csxaNCgfD1s9syU+jQSRvWDV0o8RjRyw9fnc3DDoRY+GdIXcpkgdXk2UxHbpqpg29gvto39YtvYL7aN/WLb2C9btk1SUhLWr19f7HaSBiY/Pz+kpKTAYDBAoTCXkpCQALVaDTc3t3zb+vr6on79+vmW1a1bF3FxcSU+r1KptJtffpVKZTe1FKtadTh17I7sHX+j0/lNWKzugjtpGuy7kYqujfykrs7mKlTbVDFsG/vFtrFfbBv7xbaxX2wb+2WLtlEqlVZtJ+mkDyEhIVAoFDh58qRl2bFjx9C0aVPIZPlLa968OaKjo/Mtu3btGvz9/cujVLrP9ekXAACmvVvwbCPzPWYLDlyH0STZyE4iIiIiojIjaWBydHRE3759MWPGDJw+fRrbt2/HokWLMGTIEADm3iaNRgMAeOGFFxAdHY25c+fi5s2b+PrrrxETE4M+ffpIeQlVjiqwEVShzQGjEb3vHICbWoHrSdnYfP6u1KUREREREdmc5A+unTx5MkJDQzF06FB88MEHeOONN9CtWzcAQPv27bFx40YAgL+/PxYuXIhdu3ahV69e2LVrF3788Uf4+VW+oWD2LreXCVtWYXALcw/fjweuQ280PWQvIiIiIqKKR9J7mABzL9OcOXMwZ86cAuseHILXsmVLznJnBxzbPgG5rx+MCfHolXkBK5w8cCdNg3Vn4vBMcw6RJCIiIqLKQ/IeJqp4BLkCLk8NAAAYNqzA8DZ1AAA/HbwOjd4oZWlERERERDbFwESl4ty9LwSVA/RXo/GUIgHV3RyQkKnDHydvS10aEREREZHNMDBRqcjdPODUqScAQLPmF4xsWw8AsPjwTWTpDFKWRkRERERkMwxMVGquzw4BZDJo/t2Pruo01PZ0RGqOHsuPxkhdGhERERGRTTAwUakpa9aC0+PdAQDZqxbhlfbmBwsvOXoT8RkaKUsjIiIiIrIJBiZ6JG7PDwcA5BzYhY7qDDT3d4dGb8K83VclroyIiIiI6NExMNEjUdauD8d2nQEAGasWY0LnhhAAbL4Qj9O306QtjoiIiIjoETEw0SNze/5lAED2nq0INKaid9MaAIAvdl6CSRSlLI2IiIiI6JEwMNEjUzUIhrp1B8BkQsaqn/Fq+/pwVslx/m4GNp27K3V5RERERESlxsBENuH2/AgAQNbOjfDISsLwNnUBAPP2XEU2pxknIiIiogqKgYlswqFRUzg0bw0YjUhfuQgDW9aCv7saiVk6LDp0U+ryiIiIiIhKhYGJbMb9xdEAgKxt6yDE3cKbnRoCAJYevYXL9zKlLI2IiIiIqFQYmMhmHBo3gzryccBkQtqSb9GxoS86NfSF0SRi5pYLMJhMUpdIRERERFQiDExkUx5DXwdkMuQc2AXtxTN4u0sQXBwUuHA3A78di5W6PCIiIiKiEmFgIptS1mkA56heAIC0Rd/Ax1mFcU8EAgB+2HcNsak5UpZHRERERFQiDExkc24v/g+CygHacyegOboffZrWQERtD2gNJszeehEin81ERERERBUEAxPZnMK3Olx6PwcASFs8FzCZMKVbIzgoZDhyMwXrz8ZJXCERERERkXUYmKhMuA4YBsHZFfqbV5G9axNqeTphdLt6AIAvd17G3XSNxBUSERERERWPgYnKhNzVHW7PDQMApP4yD6bsTAyMqIWmNdyQpTPig00XYOLQPCIiIiKycwxMVGZcn34Bipq1YEpORNqyH6GQyTDjqcZQK2X491YKVh7nrHlEREREZN8YmKjMCCoHeIx+GwCQuW4ldDeuoLanE8Z2NM+a9+2eq7ielCVliURERERED8XARGXKMeIxOD7WCTAZkfLdJxBFEc8290ebul7QGkyYvuE8DEY+0JaIiIiI7BMDE5U5j/9NhOCghu7cSWTv3ABBEDCtRwjc1ApciM/AwoM3pC6RiIiIiKhQDExU5hS+1eE2cCQAIHXRNzBlZsDXxQGTugYDABYdvIGD15OkLJGIiIiIqFAMTFQuXPu+CEVAXZhSk5H263cAgG6N/NA3rCZEAO//fQ6xqTnSFklERERE9AAGJioXglIJz9cmAQAyN6yG9txJAMDbUUFoUsMN6RoD3ll7Bjk6o4RVEhERERHlx8BE5UbdrBWcuz4NiCKS/+9DmLQaqBQyzOnTFF5OKlxOyMTHWy9C5POZiIiIiMhOMDBRufIY+Sbk3r4w3LmF9KXzAQDVXB3wSZ8mkMsEbLkQj2X/xkhcJRERERGRGQMTlSuZiys8x0wBAGSsXQbtxbMAgPAAD0zo1BAAMHf3Fey9mihZjUREREREuRiYqNw5tu4Ap049AJMJyV9/CFGvAwAMCPdHn7AaMInAlPVnceFuusSVEhEREVFVx8BEkvD430TIPLxguHUNacsXAAAEQcC7XYLRpq4XNHoT3lxzGnFpnDmPiIiIiKTDwESSkLt5WGbNy1j9CzRnjgEAFHIZZj/dBA19XZCUpcO4P04jQ6OXslQiIiIiqsIYmEgyTu2i4BTVyzw077P3YUxLAQC4OCjw1TNhqObigOtJWXjnrzPQGjjdOBERERGVPwYmkpTna5OgqFUPxqQEJH8+DaLJBADwc1Xjq2fC4KyS499bqZiy/hwMRpPE1RIRERFRVcPARJKSqR3h/e5sCA4O0Bw/iIzVSyzrgqq54vN+YXBQyLDnSiKmbzwPo4nPaCIiIiKi8sPARJJT1Q2Ex+i3AQBpv34P7bmTlnURtT0xp08TKGQCtl68h1lbL8LEB9sSERERUTlhYCK74NytD5ye6AGYjEiaMwXGlCTLunb1ffBxr1DIBGDdmTh8seMyRIYmIiIiIioHDExkFwRBgOeYyVAE1IUx6R6SZr8LUf/f7Hidg6theo8QAMDvJ2Ixa2s0h+cRERERUZljYCK7IXN0gs/UzyE4OUN77gRSF3yZb33P0Bp4v3sjyARg7ek7eHfdWc6eR0RERERlioGJ7IoyoC683/4IEARkbliFzC1r863vE1YTs59uAqVcwD+XEzB29Slkag3SFEtERERElR4DE9kdx9Yd4P7SKwCAlO/mQHvhdL71nYOq4Ztnm8NZJcfxmFSM/u04EjK1UpRKRERERJWc5IFJq9ViypQpiIiIQPv27bFo0aJi94mNjUV4eDgOHz5cDhWSFFyfHwHHdp0Bgx6JH78Nw727+dZH1PbE/BdawMtJhUv3MjFkyVGcuZMmUbVEREREVFlJHpg+/fRTnD17Fr/88gumT5+OefPmYfPmzQ/dZ8aMGcjOzi6nCkkKgiDA680ZUNYNhCklCQkzxsKUmZFvm2A/V/z0Yks08HFGYpYOo387jnVn7khUMRERERFVRpIGpuzsbKxatQrvvfceQkND0bVrV4wcORLLli0rcp9169YhKyurHKskqcgcneAz/f8g9/aF4eY1JM56J9/MeQAQ4OGIRS+2xBMNfaE3ipi5+SI+33EJBqNJoqqJiIiIqDKRNDBdvHgRBoMB4eHhlmUtW7bEqVOnYDIV/MCbkpKCzz77DB9++GF5lkkSUlSrDp/p/wfB0QnaU0eR/M3MAs9gclIpMKdPE/yvXT0AwMrjsXhl5QncTddIUTIRERERVSIKKU+ekJAAT09PqFQqyzIfHx9otVqkpqbCy8sr3/affPIJ+vXrh4YNGz7SefV6PXQ63SMd41Hlnl/qOiqEWvXg/vZHSP3obWTv3AjBuxpcBv2vwGZDI/xRz1ONj7ZewqnbaXjxlyOY2i0Ij9XzKuSgRWPb2C+2jf1i29gvto39YtvYL7aN/bJl2+gfGLlUFEF88M/15Wjt2rX4+uuvsWvXLsuymJgYdOnSBbt370b16tUtyw8cOIBp06bh77//hlqtRnBwMJYsWYLIyEirz5eYmIg1a9bY9Bqo/ATcvIimJ/cAAC40aYMbDcIK3S7dqMCOnOpINKoBAGGqFLRSJ0EmlFupRERERFRB9O/fHz4+PkWul7SHycHBoUA6zH2tVqstyzQaDaZNm4bp06fnW15avXv3hre39yMf51HodDosX74cgwYNytfDRg+XuXIRsn5biJCzh9C6TVs4PTWg0O1eMZjw7b7rWH0qDqd1ntC4B2BK14Zo6OtS7DnYNvaLbWO/2Db2i21jv9g29ottY79s2TZJSUlYv359sdtJGpj8/PyQkpICg8EAhcJcSkJCAtRqNdzc3CzbnT59GjExMRg7dmy+/UeNGoW+ffuW+J4mpVJpN7/8KpXKbmqpCDxfGg2ZyYiM339GxsKvIFeq4NqrYGhSqYBJ3ULQqq43Pt5yEZcSsvDyb6cwPLIORrStC6W8+Nv32Db2i21jv9g29ottY7/YNvaLbWO/bNE2SqXSqu0kDUwhISFQKBQ4efIkIiIiAADHjh1D06ZNIZP994E2LCwMW7duzbdvt27d8NFHH6Fdu3blWjNJSxAEuA95DTAakfHHEqR+PweCXA6XHv0L3b5zUDWE1XTHp9svYdflBCw8eAO7Lifg/e6N0KSmezlXT0REREQVjaSz5Dk6OqJv376YMWMGTp8+je3bt2PRokUYMmQIAHNvk0ajgVqtRp06dfJ9AeYeKqmH1lH5EwQB7sPfgEu/FwEAKfNmIePvVUVu7+PigE/7NsUnTzeBp5MSVxOzMHzZMczcfAEp2byZk4iIiIiKJvmDaydPnozQ0FAMHToUH3zwAd544w1069YNANC+fXts3LhR4grJHgmCAI+Xx8Olz0AAQOr3c5C+clGBKcfzigquht+HR+KpUPNkIuvOxOGZhYfw+/FYGAqZxp6IiIiISNIheYC5l2nOnDmYM2dOgXXR0dFF7vewdVQ1CIIAj1ETIHN0QvpvPyFtyXcwZWbAfcRYCELhU+J5OKkwo2dj9Gvmj8+2RyP6XiY+23EJa07dxqsd6uPxBkXPkEJEREREVY/kPUxEj0IQBLgPfhUeI8cDADLW/IqUuR9DNBoful8zf3f8MrgVJnUJgptagauJWXjrzzN4efkxnLydVg6VExEREVFFwMBElYJrv5fgOW4qIJMha8taJH70Fkw52Q/dRy4T8Gx4AP4c1RbDIuvAQSHDmTvpeH31GWzKqoFzdzPKqXoiIiIislcMTFRpuHTrA+93ZwNKFTRH9uLeOyNhSIwvdj83tRKvP94Aa0e1xTPN/SGXCYg1OON/K09h3OpTOBeXXg7VExEREZE9YmCiSsWpXRSqfTIfMg8v6K9dQvybQ6G7fMGqfX1cHPBu12AsH9wCQcp0yAXgwPUkDFv6L8b/weBEREREVBUxMFGl49CoKfy+XAxFnfowJSfi3qSRyN67zer9Azwc0dHpHpYPaYleTapDLgjYf80cnN784xTO32VwIiIiIqoqGJioUlL41YTf54ugbvkYRK0WSZ9MRsqPX0DU660+RoCHI6b3aIxVL5unIpcJwL5rSRj6qzk4HbuV8tBpzImIiIio4mNgokpL5uQCn+lfwvXZoQCAzL9W4N67o626rymvWp5OmNGzMVa93CZfcHpl5Qm8tOQo/j4bB52Bz3EiIiIiqowYmKhSE+QKeAx/Az7vfw7B2QW6i6cRP/YlaE4cKvGxat8PTr+PaINnmvtDrZTh0r1MfLDpAnrP34+v/7mCa4lZZXAVRERERCQVBiaqEhzbPoHqXy+Fsn4QTGkpSHh/DFJ/+rpEQ/Ry1fFywrtdg/H36HZ44/EGqObqgORsPZYevYXnfz6MYUv/xR8nbyNDU/JjExEREZF9YWCiKkNRIwDVPl8E557PADA/5DZ+4nDoY2+U6njujkoMiayDv0a1xef9muKJQB/IZQLOxaXjk23R6PH9frz/9zkcup4Eo4n3OhERERFVRAqpCyAqTzIHNbxenwzHFm2R/PVM6K9eRPzYl+AxagKcn+wHQRBKfEyFXIaOgb7oGOiL5CwdNp2/i/Vn43A1MQtbLsRjy4V4+Lk6ICqoGp4I8kVYTXfIZSU/DxERERGVPwYmqpIc2z4Bv4aNkfzldGhPHUXKvFnIObALnuPeB9w8S31cL2cVXmxVG4MiauFCfAbWn4nDlgvxiM/QYvmxGCw/FgMPRyUeD/RBx0BftK7jCbVSbsMrIyIiIiJbYmCiKkvhUw2+H32LzL+WI/WX76A5fhB3X3seriPGAY84XbggCGhc3Q2Nq7thfKdA7L+WhN2XE7HvWiJSc/RYdyYO687EQa2UoW1dbzzR0BeP1feGh6PSRldHRERERLbAwERVmiCTwbXfS1BHtEfyVzOgiz6L9Lkfo6VfLRifehIIqPPI53BQyNE5qBo6B1WDwWjCidhU7L6SiH8uJyA+Q4tdlxOw63ICBAAh1V3Rpp432tb1QpMablDIeZshERERkZQYmIgAKGvVRbXPFiLjz2VI+/UHVIuPQeIbg+A+aBRc+70EQWGbfyoKuQyt6nihVR0vTOzcENH3MvHP5QTsvpyAK4lZOH83A+fvZmDRwRtwUMgQ6OuCRn6uaOTnitDqbmjg6wxZKe6zIiIiIqLSYWAiuk+QK+D27FAoWrTFpRkT4Z0Uh7TF85C9axM8x0yGQ+Pmtj2fIFjC0Cvt6yMhU4tDN5Jx6HoSDt9MQVqOHufi0nEuLt2yj6uDAs383dE8wANh/u5o6OsCFwf+MyYiIiIqK/ykRfQARUBdHGnXC8/X8UPmL/Ogv3kV994eCefufeE+/A3IXd3L5Ly+Lg7o3aQGejepAZMo4nZqDi7EZ+Di3QxciM/A+bh0ZGgN2HctCfuuJVn2q+GmRqCvCwJ9nRHo64KGvi6o5ekIhYzD+YiIiIgeFQMTUWEEAY6de8LlsSeQ9vNcZG39C1lb1iLn4D/wGDkeTp2fKtUU5NaSCQJqeTqhlqcTujXyAwAYTCZcupeJk7GpOBGTivPxGbiXoUVcugZx6RrsvZpo2V8ll6Get5MlQAXe//J2VpVZzURERFT5mUQROoMJeqMJWoMJOuP9L4MJeqMIrcEIncEEnVG0LM/7XSkX0LNxdbiqK85EVwxMRA8hd/OA17ipcI7qheRvZ8Nw6xqSv5yBrG3r4D5iHByCQsutFoVMZpl5b1BEbQBAukaPKwmZuJKQhcsJmbiSkImriVnI0RsRfS8T0fcy8x3Dy0lpCU+Bvi6o6+WEWh6OcHdUlmkAJCIiokcjiiIMJhHaB8PK/e96gwnaQgKK7oFQo70fbPIuz3tMfe52eY6pz7OvwfRoMwkDgNEkWj7LVAQMTERWcGgSjurfLEPGn8uQ/tsCaM8cx703h8KxbSe4D34FyjoNJKnLTa1Ei1qeaFHrv2dHmUQRd1JzcDkhC1cSM+8HqkzEpOQgOVuPIzdTcORmSr7juDooEODpiNqe5gBVy9PR3MPFMEVERATAHFjyho5Cf34wuDz0Z+PDt8nzXXt/3aNHFdsSAKgUMqjkMqgUMjgoZFDK/3utkv+3zPxdgLujEl2C/aQuvUQYmIisJCiVcHtuGJw6dkPash+RvWsjcg7uQs6hf+D0xJNwf3E0FDUCpC4TMkFAgKcTAjyd0CnI17I8R2fEtaQsXEnIxOWETFxNzMStlBzcy9AiQ2vAhbsZuHA3o8DxXB0UlgBVw00NHxcVfJwd4OOsgreL+TsfvktEROXNYDIHCa3eBK3BaP7ZYILGkP+1Vm8sfPkD2+Su1xhM0OiNSMyogzULj+QLRfZEKRcKDSaWAFPYMoUMDnIZlPe/qx4IMw4KGVRyOVQKwXIMlSL//nmPI5cJVeKPqgxMRCWk8KsJ7wkz4PbsEKQt/QE5+3cie9cmZO/ZCudufeD2wkgofKpJXWYBjio5Qmu4IbSGW77lGr0Rsak5iEnJQUxKNmJS//ueG6ZypzsviouDwhygnFVwVSvh6qCAq1oBVwcF3NRKuDgo4Hb/tataaVnnoJBVif/QEhFVdnmHi2n0hYcSjcEIrf7+9wfX6/NsU1iguf+zJk84ssXQsIdTAlm6Qtfk9qw4PNC7kv9necHlD4QVVYl+lkMlFywhh48ZKT8MTESlpKxdHz5TPoXu8gWk/fo9NMcOIGvTGmRt/xsuvQbA7dmhkHt4SV1msdRKueWepgc9GKbuZmiQmKlDYpYWSVk6JGbqoDOakKk1IFNrwI3k7BKdWykX4OpgDlBuDgq4qM0B67/AlX+doxxIMyqRkKmFu7MMaqWMswESUaUniiKMpvvDwfLce5J7X4nemPtatNzLoitkmTbfPuJ/x7DsY15mNJnDiNEkWr5bvsSCy8xByYgyzy8PkdubYvlSyuGgkEGtkMFBcf/n+8sc8izL/Vn9wH5y0YQdWzej39O94OLoYA49efZRVJGeFTJjYCJ6RKqGIfD98Btoz55A6pJvoTt3Epl/LkPWxtVw7vEM3J4ZArmXj9RllsrDwhRg/p94htZgCVEp2TpkaAzI0BryfNcX+tokAnqjiORsHZKzC/8LXuHq4PefjlpeKeUCHJVyqJVyOFq+zP9jVCvkcFLJ4eJg7tFyuR/EXFTmAJa7zFEph6PKvC//YkdUeYji/Q/4RvOHepMomj/U3/9uEkWIuP/9/od9hUwwf8nNf4x5MFDkvn5wmTZfcMldL+YJLvmX6Y3mYWA3M2vi4O+nYDAhX9jRG/Oczw7vXXkYAYCDMk9QKSSg/BdsZFAXsu7BcKPOu16Zf7lKYfveFp1Oh7MKDYKquUCl4gyzVR0DE5GNODQJR7U5C6A5dhDpy+ZDd+kcMtcuR+aG1XB5sh9c+w+Golp1qcu0KUEQ4KZWwk2tRH0fZ6v3E0URWTojMrUGpBcWqPKErnStHpn3X6dr9EjNzIFRkFv+kqk3itAbDUjXGGxyTQ4KmSV4qe+HL/PQB/P9YYIgQCkX/vsffJ7/2ZtD2v3/iT/wP/T//tr534eA3O1zP5iR/RHvf6D+73Wenx/8CCsW+mOB/R7c98F1ACwf7vP+Vb+wn00iLH/hL2x7k0mERqfHVZ0Ltl68B0EmL7C/wfJz/v0LfT+KfqMsAeS/7+YQYjTd/y6KlgBjWY7c9fn3z7td7rFMIu4HH3Pvh8EkWl7nvgfmZf+tN0rZ5WE1J8TFFT3kuTByQYDy/j0muTfYm78LlntMlHnuT1HJhXw34uddlvcmfaXCvFwhM/egyB/4Ugj3v8tlkAv51+UNNEo5e1+ocmFgIrIhQRDgGPEY1C3bQnP8ENJXLIDuwmlkrl+JzA2r4dQ+Ci79XizX6cjtkSAIcLnfu1PdTW31fjqdDosXL8bQoUMBuQI5evNY+Zw8Xxq9ERq9yfI6+34wy9SaQ1fW/e+5rzM1BuTojZYPgrnj5VNz9GVz8YXI+2Hjv7+q5h8iopAJkN3/gJIb3uQyAXJBgMzy/f5yyzLz67zr5YKQf5kAy89yyznM+4kAIP734V4UzR+YxfsrLK8BGPQGXNS54s/TcYBMdv+D94Pb/fdX/NwP0A/+ZT6XAAG5H7dyP3dZluT5ZjSJ0JtMlh4E/f0hSHqjCQbTfz/r73+Qzv0ALQjmo4lA/g/cRjHPUCSTpEOMbKs6dm65JHURdkcm/Pe7YP6dN/8OPNjsclnuDfDCA0Ek9yZ4IX9wuX8Dfb5Ac3+73BvqlXIZZKIJB/ftRZfOT8BJrXog/MigVAjme17y3GyvvH+jPRGVHwYmojIgCAIcW7aFukUbaE//i/SVP0N76giy92xF9p6tUIU2h+vTL8CxzRMQFPxnWFKCINwfSy4HHB/9wXeiaL5ROX/wMiFbZ0CO3mT563vul94oWm5q1uS5YTnvzcqavDMu6f+7aTnvslxGk7nHLUtnBFB+Qc32/LB311Wpi6h0BOC/v+Tn+au+TBDy9QLkhmjF/VCdu1wAkBB/F/41a0Ih/6/nQJa3h+CBn2WyPAHV2joFcyAX7p9bEPKE9jyBXiYI+Xps5ffPlRve867PDTS5383D5WRQyIX/hs7le23+WS4I95fJ7g+vu/9e3T9n7vGKYro/jM8kimUaUHQ6He4dyUTHQB8O+yKyY/ykRlSGBEGAulkrqJu1gu5qNDL+Wo7s3VugO3cSSedOQubpDZfufeH8ZD8ofCvXcL2KRBAE8/A4pRyexW9uE7nP83hw1idN3ulv74cujcGYZ8jU/SFKeYddiSKMImDKM6wqd3jTf+tFmEz5l+UO58pdnzuEy3h/XwH/9e7kfnwWBOTp+RHufwdEk4g7t2NRt04tqBQKywdvS++QcL/XKHd/AZBByDeDlFIuMx/rgV4tIM9QMMtrc2+VXGb+S73y/odjpfy/10qZebhj7rLcXrp8x8N/96zIZQ98yM4NHA98sH7wo/ODn7sL+2hd3PCkB1fL74cDWZ6aS8vcM3scw/p344dyK8kEASoFe3GIyIyBiaicqBoEw3vCB/AYOgaZG1Yhc8tfMKUkIf23n5D++89QR7SDy1PPQt2iLQTO/FbpCYJw/+ZmOUowKtFumT+UH8WwXt35oZyIiCoVBiaicib39oX7kNfgNnAUcg7tRubG1dCe/heaI3uhObIXcj9/uPToB+euT1eIacmJiIiIKjMGJiKJCEolnDp0gVOHLtDH3EDmpj+Qtf1vGONvI23xPKT9+j0cIx+Hc9c+ULdsA0HOf65ERERE5Y2fwIjsgLJWXXj+byLch7yO7L1bkbVxNXSXziPnwC7kHNgFmZcPnDv1hFPH7lDWD+J0rURERETlhIGJyI7I1Gq4dH0aLl2fhu7GFWRtW4fsnRthSk5Exh9LkPHHEigC6sDp8W5werw7lLXqSl0yERERUaXGwERkp1R1A6EaNQEew95AzpG9yN69GTlH9sEQexPpyxcgffkCKOsF3Q9PXaGo7i91yURERESVDgMTkZ0TlEo4tesMp3adYcrORM6hPcjesxWa4wehv34JadcvIe2XeVAFhcKxXWc4PtYZypq1pC6biIiIqFJgYCKqQGROLnDu3BPOnXvCmJGGnAO7kL17K7Rn/oXu0jnoLp1D2s9zoazXEI6PdTKHpzoNeM8TERERUSkxMBFVUHJXd7h07wuX7n1hTE5EzqF/kL1/J7Snj0F//TL01y8jfdmPUNSsBce25vCkCmrMZzwRERERlQADE1ElIPfygUvPZ+HS81kYM9KgObwX2ft3QHPiMAx3YiwTRsi9faGO7Ainx56AQ5OWEJRKqUsnIiIismsMTESVjNzVHc5desG5Sy+YsrOgOXYA2Qd2QnN0P4xJCcjauBpZG1dDcHaBunkk1C3aQN2iDRTVakhdOhEREZHdYWAiqsRkTs5w6tAVTh26QtRpoTl1FDkHdyPn8G6YUpORs38HcvbvAAAo/GtDHW4OTw5NW0Lm5Cxx9URERETSY2AiqiIElQMcW7WHY6v2EI3vQnf5PDTHD0Fz4hB0F8/CcPsWMm/fQubfvwNyORxCmkEdHgmH8EioAkMgyOVSXwIRERFRuZM8MGm1WnzwwQfYunUr1Go1RowYgREjRhS67T///IOvvvoKt27dQkBAAMaPH4+oqKhyrpio4hPkcjg0agqHRk3hPmgUTFmZ0Jz+F5rjh6A9cQiGuFhozx6H9uxx4NfvIXNxg0Pz1lA3bwWH0HAoAupy8ggiIiKqEiQPTJ9++inOnj2LX375BXfu3MGkSZNQs2ZNPPnkk/m2u3jxIsaMGYN33nkHHTt2xL59+zBu3DisXr0ajRo1kqh6ospB5uwCp7ZPwKntEwAAQ1wsNCcOQXP8MDSnjsCUmY6cfduRs2+7eXs3d6hCmsEhtDkcQsOhatCIE0gQERFRpSRpYMrOzsaqVauwYMEChIaGIjQ0FJcvX8ayZcsKBKa///4bbdq0wZAhQwAAderUwc6dO7Fp0yYGJiIbU9QIgEsN86x7otEA3aXz0Bw/CO3ZE9BFn4EpPQ2aw3ugObwHgHm4nyo41ByeGjeHQ0hTyJxcJL4KIiIiokcnaWC6ePEiDAYDwsPDLctatmyJH374ASaTCbI8Q3769esHvV5f4BgZGRklPq9er4dOpytd0TaSe36p66CC2DYFCQ0awbFBIzgOGA5Rr4fh+iXozp+C/sIp6C6chpiRBu2Z49CeOW7eQSaDom4glCFhUIU0gzKkGeRePo9cB9vGfrFt7Bfbxn6xbewX28Z+2bJtCssWhRFEURQf+WyltGXLFnz44YfYv3+/ZdnVq1fRs2dPHDx4EF5eXkXue/nyZfTp0wdff/01unbtatX5EhMTsWbNmkeum4jyEEU4Z6bCM+kuPJPvwivpLpyyC/4hI9vJFcne1ZHm6YdUz2rIcPOCyPugiIiISGL9+/eHj0/Rf9iVtIcpJycHKpUq37Lc1w9LjcnJyXjjjTfQokWLUk360Lt3b3h7e5d4P1vS6XRYvnw5Bg0aVOA9IGmxbR6dMSnB0vukv3AKhhtX4JSdAafsDATEXDZvpFJBWT8YyoaNzV9BoZBVqwFBEIo8LtvGfrFt7Bfbxn6xbewX28Z+2bJtkpKSsH79+mK3kzQwOTg4FAhGua/VanWh+yQmJmL48OEQRRHffPNNvmF71lIqlXbzy69SqeymFsqPbfMIavjDsYY/0LknAMCUlQnthdPQXTgFbfRZ6C6dg5iVCf3FM9BfPGPZTebuCVVQqPkruAkcgkIhc3UrcHi2jf1i29gvto39YtvYL7aN/bJF2yitnLBK0sDk5+eHlJQUGAwGKBTmUhISEqBWq+HmVvBDUnx8vGXShyVLljx0yB4R2Q+ZswscIx6DY8RjAADRZILhzi3oLp2D7n6A0l27BFNaCjRH90FzdJ9lX0XN2lAFm0OUrH4jyIxGqS6DiIiIqiBJA1NISAgUCgVOnjyJiIgIAMCxY8fQtGnTAj1H2dnZGDlyJGQyGZYsWQJfX18pSiYiGxBkMigD6kIZUBfOnZ8CAIg6LXTXLkN36awlRBnuxMBw5xYMd24he9cmAEBXmQxJ0QehbtT0fm9UYyhq1OKDdYmIiKhMSBqYHB0d0bdvX8yYMQOzZs3CvXv3sGjRIsyePRuAubfJ1dUVarUa8+fPx61bt/Drr79a1gHmoXuurq6SXQMR2YagcoBDoyZwaNTEssyYngrdpfP3Q9Q5aKPPQpaRBsPl88i8fP6/fR3UUNZpAGX9ICjrBUFVvyGUdRtC5uQsxaUQERFRJSL5g2snT56MGTNmYOjQoXBxccEbb7yBbt26AQDat2+P2bNno3///tiyZQs0Gg0GDBiQb/9+/frhk08+kaJ0IipjcjePfEP5tFotfv9uLp4OawTT1Wjoos9Bfz0aolZjHtZ36Vz+/av7Q5Ubouo1hLJ+EOTFTCxBRERElJfkgcnR0RFz5szBnDlzCqyLjo62/Lx58+byLIuI7JAgCMhxdoNjh25QRfUCAIhGIwxxMdBfvwzdtUvQX7sE/fXLMCbdg/HubeTcvY2cA7v+O4azC1R1G97vjWoIVf0gKGrXh8yh8IlmiIiIqGqTPDARET0KQS7///buPDqKKtEf+Ld6y76RFQjKJhBI0oFEkAMOCYMKKh5Q8wbBQJRNiPBG0JDA8MQlg4CjA0SFyDqyg4w+RJ0nHh0YZfEXIGwuIQkQSAgJ2dOdXuv3R3cXaZJm0aQ7pr+fc/p0163qqlt9KSrfvlW3pfuhvB+88ZtspppqGC7kw1D4C/RFv8BQmA9DcSHEhnrozp6A7uyJGyuRyaDoeq/UC2W5rK8PZEHB7I0iIiJycwxMRNQhyQMCIVffD0/1/VKZaDDAcPkCDNYApS/8BYaiX2CurYaxuAjG4iLg4P9Jy8sCgqDscZ/l/qhuPaDs1gOKe3pA7h/ogj0iIiIiV2BgIiK3ISiVUPW4D6oe9wEjLWWiKMJcWXGjF6roF+iL8mG8chHmmiroTh6D7uQxu/XIAoIs4alb9xtBqlt3yEPC2SNFRETUwTAwEZFbEwQB8uBQeAWHwithmFRubmyE4VIBDEX5MFwqhLH4AgzFRTBdK7UEqZoq6M4ct1+XlzcUkd2h7NYdym49oezWHYp7ekAR0RWCnP/dEhER/R7xDE5E1AKZpyc8+gyAR58BduXmRi2Mly/CYL2Ez3CpyPK6tBiiVgND/jkYmgx5DgBQKKHo2g3KyB52PVOKyHs52AQREVE7x8BERHQXZJ5eUPXuB1XvfnblotEIY0nxjSBl7ZEyXr4AUdcI48VCGC8WQtv0TYIAeVgXS09U13ug6BwJReduUHTpBkVYZwgK/hdNRETkajwbExG1AkGhgPKeHlDe08OuXDSbYaoos17W1yRIFV+Aua4GprIrMJVdAf7fd/YrlMmhCO9sCVCdIy2PLt0s0xFdIKg8nLh3RERE7ouBiYioDQkyGRRhnaEI6ww0uUdKFEWYa6qkXihjyWUYS4thLCmG8epliDodjKWXYSy93MJKBciDw6AI7wJ5RBcowrtAEd4VioiukEd0gbxTKASZzIl7SURE1HExMBERuYAgCJAHdoI8sBMQE283TzSbYaqsgPHqZUuAKrU9F8NYchmitgGmijKYKsqApr8nZaNQWkJaRBfIw62BKiJSmpb5BXA0PyIiojvEwERE1M4IMhkUIWFQhIQB0YPs5tl6poxXr8B49QpMZSUwlpXAeLUExrIrMF27ChgNMJZcgrHkUsvr9/KxhKfQCCjCOkMeZn0O7QxFWARkgZ3YQ0VERGTFwERE9DvStGfKo19Ms/miyQhTxbUbAapJmDKWlcBcWQFR22AZLr0ov+WNKJRQhEVYA5XlWW69rFAeGgFFaDgEpaqN95SIiKh9YGAiIupABLnCek9TFwAJzeabdY0wlZXCeK0EpmulMJaXWZ6vlcJUfhWm6+XWHirL/VS6FjciQBYUDIUUpCKATqEIK70AQ8FPlsv+2EtFREQdBAMTEZEbkXl4QtbCaH42otEI0/VrMJZfvRGkrpXBVF4K47WrMJWXQtTpYK6sgL6yAvj5jPTeeACVx/7PMiGXQ94pBPLgMMsjJAzy4FDrdCgUIeGQdQrh71AREVG7x8BEREQSQdG0h6o5URRhrq2G6dpVa5gqhbH8KgxXS1D28zl0EkSYq68DJhNM5WUwlZfdcnsyv4AbQeqmUCUPDoO8Uwhk/oHsrSIiIpdhYCIiojsmCALkAUGQBwRBdV+UVK7X6/HJpk1ITU2FUi6Dqeo6TBXlMF0vg+l6OUwV1yzPtunr1yw9VXU1MNfVwHDhvOONyuSQB3WCLDAY8qBgS89VUDBkQdbpoBBLsAoKhszTywmfAhERuRMGJiIialWCXAFFSDgUIeEAoltcRhRFiPV1MF6/Zg1T16QgdSNgXYO5thowm6zzymG43ba9vKUQdSNQBUNmDVnywGDIrINmCAqeAomI6PZ4tiAiIqcTBAGCnz9Ufv5A994OlxONRpiqK2Guum7ptaqqgKmqosn0dZgqK2CuqoCo00HUamDUamAsKb5tHWR+AdbwFGTpvbIGKZn0HGzp2QroBJkn77UiInJXDExERNRuCQqF5feoQsJuuZwoihC1GpiqrlvDVIUUqMy215WWZ3NNNWA2SZcDGouLbl8PL+8bYSogyBKiAgItZdZLFGUBQZZp/0D2XhERdSD8H52IiH73BEGA4O0DmbcP0PWeWy4rms0w19XCXH3d0ntVXQmT9WGuug5TTZVlXpWlDAa91HOF0st3VB+Zrz9kAYE3wpRfAGT+gZD5W57lfgHSa5lfIGS+fhDk8tb4KIiIqJUxMBERkVsRZDLIAwIhDwiE8t5et1zW0nPVAFOVLVhdh7mmCqaaast0bRXM1VXWsirrPVdmmOtrYa6vBa5cusNKCZaQdctgFWDp1fILkJZjTxYRUdvj/7REREQOWHqufCHz9r1tzxVg7b2qr4W5usoapiphrq2GubYGptpqy2WA1mlznaVMbKgHRFG6RBAldxiyAEuvml8g5AEBlp6qJuFKbg1eZi8f+NVUwHStFOagYAhe3hymnYjoLjAwERERtRJBJoPcPxBy/0Ao0fKPA99MNBqlsGQXrGqqpVBlbhq26mpgrqsFRBGipgEmTQNMZVduuY3hACq+3WuZkMkg8/aF4Otn6dXy8YPM9trX1/rsB5mPHwTb6ybLsleLiNwN/9cjIiJyIUGhkIY/v1OiyQRzQ10LwarGvherthrG2mo0XLsKT7MJMOilSwZRXwsTbh20Wqyvl7ddyBJ8rCHLxxcybx9rj5wPZD6+0n1ltl46mY8vBE8v3q9FRL8rDExERES/M4JcLvVkoeu9t1xWr9fjM9uPCkOEub7Oeo9VneXR0GS6oQ5i03m2ZRvqIGoaAMAyGqFWA1NF2a+vv5e3pZfLGqyaBi2pzMvHEsa8fazL2gcxwdMLgiD86joQEd0pBiYiIiI3Iag8IO/kAXmnkLt+r2gywtxQD7GhXhrUwlzf5LWmAaKm3vrcAHNDvV2ZWdNg6eHCjdCF679hZ2QyCF4+zXqzmgYxwTp9q3AmqDwYvIjolhiYiIiI6LYEucLSo+Uf+KvXIRr0lvDUUG8JVRprANM2LbOWaxyXwWwCzGaIDXUwNdTBVP4bdkyhsL+U0LtJ0Gp2WeHNQcxa7uPLe7uIOjAe3UREROQUglIFeYAK8oCgX70OURQh6nTWnitrL1ZDvX2oarGs3j6IaTWAKAJGI8y1NUBtDUy/Zd9UHs0vK/T2sYxK6OkNmZeXpUfM08ta5gWzUoVO5SUwnP8Rgl8ABC8vyDy9IXh5QZDzTzSi9oJHIxEREf1uCIIAwdMT8PT8VZcW2ohmM8RGrV2Iki4n1NRbAlnDzYHrRhATbb1ijVrL+vQ6iHodzNV3d53hEACV33/WfIZS1WLIklmfBS8fy3xbGPP0ttwbZp3XNHzJrPPYC0b06/DIISIiIrcjyGTS5Xa/hWgyQtRoLJcVSoGq3no5YT3MWi3ERg1ErRZm67PYqIFZq4VJU4+qq6UI8FQBjY0wazWA0WBZsUEPs0H/m3u+7NhCWNMg5ekNmbcthHnf6OFq2ivm4QnB0xOCh4MH7wOjDo6BiYiIiOhXEuQKCH7+kPn53/V79Xo99llHMFSpVAAA0WC4KVhpIDZqIWo1MDdqLT1bzUKY5WErvzmY2QbbaBrCWpt9iPKwm5Y5ClpN53s2CV8O5kOhZDAjl2BgIiIiImonBKUScmUA4BfQausUDQbL5Yc393RpG6whTCOFK+lZ22B5jy2w6XQQdY3Sw6xrvBHEAKm8TclkjgOXLaiprK89b5TdUWCTwpoHoFC27X7Q7w4DExEREVEHJiiVEJTKX9ULdiuiyWS5d6tJkLKFKbGxscV50nzbo/H282G2XpRoNku9aW1OpcIfRQHlB/dagpRKddOz9bXSErIE5U3lKhXgcN5Nr5Uq63IegELBXrR2iIGJiIiIiO6aIJdD8PIGvLzbdDui0eg4UDkMZLrbB7Kmga5Raxk10UavhwqAuUrXpvvWjEzWJGBZnmELZnbPSutyKkCpsryWHsqWy1WWZyiVlvU0WYegVFm3Y30/R2m0w0+DiIiIiNotQaGAoPAFfHzbbBuidYh522iH+oZ67N25E+MefxQKUZTKRb3e7jUMTcvs54kGnSW4GW6ef2MerPMkZrNzLm+8HZlcClR2QcoWtFQe1uB1c1BrUq5SQVDcVK7ygMwvAJ5x9/+uQtnvp6ZERERERG1AEATrH/pKwMcXch8/NPgFQtmjjzQgR1sRRdEanKyByqC3Bq0WQph1PgwGaxDTQzTqLfep6XWWcr3OMm3QSw+H5fomr83mG5UymyDqTG0W3AJfeAV+Y//UJutuCwxMREREREQuIggCYL2vCfBzWT1Ek1EKVDeCVNOgpbMPanaBzLZsC+V269JDUCrhGZvgsv38NRiYiIiIiIjcnCBXWC6T8/RydVXaHZmrK0BERERERNReMTARERERERE5wMBERERERETkgMsDk06nw8KFC5GQkIDhw4djw4YNDpc9d+4ckpOToVar8dRTT+HMmTNOrCkREREREbkblwem5cuX48yZM9i8eTNeffVVZGdn48svv2y2nEajwYwZM5CQkIC9e/di4MCBmDlzJjQaJ/zaMxERERERuSWXBiaNRoPdu3dj0aJFGDBgAB566CFMmzYNW7dubbbs559/Dg8PD6Snp6NXr15YtGgRfHx8WgxXRERERERErcGlgemnn36C0WjEwIEDpbL4+Hjk5eXB3PTHswDk5eUhPj7eMlY9LGPWDxo0CCdPnnRmlYmIiIiIyI249HeYysvLERQUZPcLyiEhIdDpdKiurkanTp3slu3du7fd+4ODg5Gfn3/X2zUYDNDr9b++4q3Atn1X14OaY9u0X2yb9ott036xbdovtk37xbZpv1qzbQwGwx0t59LApNVq7cISAGn65g/B0bK/5sPat2/fXb+nrWzbts3VVSAH2DbtF9um/WLbtF9sm/aLbdN+sW3aL2e2jUsDk4eHR7PAY5v29PS8o2VvXu5OjB07FsHBwXf9vtak1+uxbds2TJw4sVkQJNdi27RfbJv2i23TfrFt2i+2TfvFtmm/WrNtrl+/fkcdKS4NTOHh4aiqqoLRaIRCYalKeXk5PD094e/v32zZiooKu7KKigqEhYXd9XaVSmW7+cevUqnaTV3IHtum/WLbtF9sm/aLbdN+sW3aL7ZN+9UabaNUKu9oOZcO+hAVFQWFQmE3cENubi5iYmIgk9lXTa1W48SJExBFEQAgiiKOHz8OtVrtzCoTEREREZEbcWlg8vLywrhx47BkyRKcOnUKBw4cwIYNGzB58mQAlt6mxsZGAMDo0aNRW1uLrKwsnD9/HllZWdBqtRgzZowrd4GIiIiIiDowl/9wbWZmJgYMGIApU6bgtddew5w5c/Dwww8DAIYPH47PP/8cAODr64u1a9ciNzcXTz75JPLy8pCTkwNvb29XVp+IiIiIiDowl97DBFh6mZYtW4Zly5Y1m/fzzz/bTcfGxuKf//yns6pGRERERERuzuU9TERERERERO0VAxMREREREZEDDExEREREREQOuPweJmcyGo0AgKqqKhfXBDAYDAAsP5h1p2PAk3Owbdovtk37xbZpv9g27Rfbpv1i27Rfrdk2tkxgywiOCKLth43cQH5+Pr755htXV4OIiIiIiNqJpKQk3HfffQ7nu1VgamxsRHFxMfz8/KBQuFXnGhERERERNWE0GlFXV4du3brB09PT4XJuFZiIiIiIiIjuBgd9ICIiIiIicoCBiYiIiIiIyAEGJiIiIiIiIgcYmIiIiIiIiBxgYCIiIiIiInKAgYmIiIiIiMgBBiYiIiIiIiIHGJhcQKfTYeHChUhISMDw4cOxYcMGV1fJbZWVlWHu3LkYPHgwHnzwQSxduhQ6nQ4A8Oabb6Jv3752jy1btri4xu7jq6++avb5z507FwBw7tw5JCcnQ61W46mnnsKZM2dcXFv3sXfv3mbt0rdvX/Tr1w8AMGvWrGbzvvnmGxfXuuPT6/V4/PHHcfToUamsuLgYqampiIuLw6OPPor//Oc/du/5/vvv8fjjj0OtVmPy5MkoLi52drXdQkttc/LkSUyYMAEDBw7EI488gt27d9u954knnmh2HP3yyy/OrnqH11Lb3O7c/9lnn2HUqFFQq9VIS0tDZWWlK6re4d3cNhkZGS2eeyZPniy9JyEhodn8hoaGVqmPolXWQndl+fLlOHPmDDZv3oySkhIsWLAAXbp0wejRo11dNbciiiLmzp0Lf39/bN26FTU1NVi4cCFkMhkWLFiAgoICzJ8/H+PHj5fe4+vr68Iau5fz588jKSkJb7zxhlTm4eEBjUaDGTNmYOzYsXjrrbewfft2zJw5E1999RW8vb1dWGP38Oijj+LBBx+Upo1GI6ZMmYLExEQAQEFBAVasWIGhQ4dKywQEBDi7mm5Fp9Nh/vz5yM/Pl8pEUURaWhr69OmDjz/+GAcOHMCLL76Izz//HF26dEFJSQnS0tIwZ84cPPjgg3jvvfcwe/Zs/O///i8EQXDh3nQsLbVNeXk5pk+fjmeeeQZvvfUWzp49i8zMTISGhiIxMREmkwkXLlzAli1b0L17d+l9QUFBLtiDjqultgFwy3P/qVOnsGjRIrz22mvo168fsrKykJmZibVr1zq17h1dS22zaNEizJ8/X5q+cuUKUlJSpMBUVlaGuro6HDhwAJ6entJyrfV3AQOTk2k0GuzevRsffvghBgwYgAEDBiA/Px9bt25lYHKywsJCnDx5Et999x1CQkIAAHPnzsWyZcukwDR16lSEhoa6uKbuqaCgAH369Gn2+e/ZswceHh5IT0+HIAhYtGgRDh48iC+//BJPPvmki2rrPjw9Pe1ORmvXroUoinj55Zeh1+tx+fJlxMTE8LhxkvPnz2P+/PkQRdGu/MiRIyguLsaOHTvg7e2NXr164fDhw/j4448xZ84c7N69G9HR0Xj++ecBAEuXLsWwYcNw7NgxDBkyxBW70uE4apsDBw4gJCQE8+bNAwB0794dR48exb59+5CYmIjLly/DYDAgNjYWHh4erqh6h+eobQDc8ty/ZcsWjBkzBuPGjQNg+QI8KSkJxcXF6NatW1tX2y04ahs/Pz/4+flJ0xkZGRg9ejRGjRoFwNJuoaGhbdYOvCTPyX766ScYjUYMHDhQKouPj0deXh7MZrMLa+Z+QkNDsW7dOiks2dTX16O+vh5lZWV23+6RcxUUFLT4+efl5SE+Pl76FlwQBAwaNAgnT550bgUJ1dXV+PDDDzF//nyoVCoUFhZCEAT+4eBEtoCzc+dOu/K8vDz079/f7tvV+Ph46TjJy8tDQkKCNM/LywsDBgzgcdSKHLWN7fLvm9XX1wOw/MHYuXNnhqU25Khtbnfuv/m46dy5M7p06YK8vLy2rK5bcdQ2TR0+fBg//PCD9KUDYDluevTo0Wb1Yg+Tk5WXlyMoKAgqlUoqCwkJgU6nQ3V1NTp16uTC2rkXf39/u0uLzGYztmzZggceeAAFBQUQBAFr1qzBwYMHERgYiOeee86ui57ajiiKKCoqwn/+8x+sXbsWJpMJo0ePxty5c1FeXo7evXvbLR8cHNzssgpqe9u3b0dYWJjUO15YWAhfX1+kp6fj2LFjiIiIwJw5czBixAgX17TjmjhxYovl5eXlCAsLsysLDg7G1atX72g+/XaO2iYyMhKRkZHS9PXr17F//37MmTMHgOXLIqVSiZkzZ+LMmTPo0aMH0tPTERsb65R6uwNHbXO7c/+1a9d43LQxR23TVE5ODsaPH4/OnTtLZQUFBdBqtUhJSUFRURGioqKwcOHCVgtR7GFyMq1WaxeWAEjTer3eFVUiqxUrVuDcuXN46aWXpG/Ke/bsiZycHCQnJ2Px4sX46quvXF1Nt1BSUiIdK3//+9+xYMEC7Nu3D8uXL3d4DPH4cS5RFLF79248++yzUllhYSEaGxsxfPhwrFu3DiNGjMCsWbNw+vRpF9bUPd3uOOFx1D40NjZizpw5CAkJwZ/+9CcAQFFREWpqapCcnIycnBz06tULU6ZMQWlpqYtr2/Hd7tzf2NjI48bFiouLceTIEaSkpNiVFxYWoqamBrNmzcL7778PT09PpKamSj23vxV7mJzMw8Oj2YFlm256XwA514oVK7B582a8++676NOnD+677z4kJSUhMDAQANCvXz9cuHAB27dvx0MPPeTayrqBrl274ujRowgICIAgCIiKioLZbMYrr7yCwYMHt3gM8fhxrtOnT6OsrAyPPfaYVDZ79mykpKRIgzz069cPZ8+exa5duxATE+OqqrolDw8PVFdX25U1PU4cnYv8/f2dVUW319DQgNmzZ+PChQvYtm0bvLy8AABvvPEGGhsbpYEGlixZguPHj+PTTz/FCy+84Moqd3jjxo275bnf0XFjaztqe//6178QFRXV7EqT9evXw2AwwMfHBwDw9ttvY8SIEfjmm28wduzY37xd9jA5WXh4OKqqqmA0GqWy8vJyeHp68kTlIm+88QY2btyIFStW4JFHHgFguS/G9h+mTc+ePVFWVuaCGrqnwMBAu9G6evXqBZ1Oh9DQUFRUVNgtW1FR0ewyCWpbhw4dQkJCgt0IeDKZrNmIeDxuXCM8PPyWx4mj+Ryswznq6+sxdepU5OfnY/PmzXb3zCgUCrsRWW09HjyO2t7tzv08blzv0KFD+OMf/9isXKVSSWEJsHwpFBkZ2WrHDQOTk0VFRUGhUNjdWJubm4uYmBjIZGwOZ8vOzsaOHTvwzjvv2H1TvnLlSqSmptot+9NPP6Fnz55OrqF7OnToEIYMGQKtViuV/fjjjwgMDER8fDxOnDghjaAjiiKOHz8OtVrtquq6pVOnTmHQoEF2ZRkZGcjMzLQr43HjGmq1GmfPnkVjY6NUlpubKx0narUaubm50jytVotz587xOHICs9mMF198EZcvX8ZHH32E++67z25+SkoKsrOz7Zb/+eefeRw5we3O/TcfN6WlpSgtLeVx4ySiKOL06dPNzj2iKGLUqFHYu3evVKbRaHDx4sVWO274F7qTeXl5Ydy4cViyZAlOnTqFAwcOYMOGDXY/vEXOUVBQgPfffx/Tp09HfHw8ysvLpUdSUhJ++OEHrF+/HpcuXcK2bdvwySefSEPwUtsaOHAgPDw88Je//AWFhYX497//jeXLl2PatGkYPXo0amtrkZWVhfPnzyMrKwtarRZjxoxxdbXdSn5+frNLIkaOHIl9+/bhk08+wcWLF5GdnY3c3Fy7+5zIOQYPHozOnTsjMzMT+fn5yMnJwalTp/D0008DAJ566ikcP34cOTk5yM/PR2ZmJiIjIzmkuBPs2bMHR48exZtvvgl/f3/pvGO7hHLkyJHYtGkTvv76axQWFuL1119HXV0dBx1ygtud+5955hl8+umn2L17N3766Sekp6cjMTGRI4M6yZUrV9DQ0NDs3CMIAhITE7F69WocPXoU+fn5SE9PR0REROsNOiSS02k0GjE9PV2Mi4sThw8fLm7cuNHVVXJLa9euFfv06dPiQxRF8auvvhLHjh0rxsTEiKNHjxb/9a9/ubjG7uWXX34RU1NTxbi4OHHYsGHi6tWrRbPZLIqiKObl5Ynjxo0TY2JixKefflo8e/asi2vrfmJiYsSDBw82K9+1a5f48MMPi9HR0eL48ePFY8eOuaB27qlPnz7ikSNHpOkLFy6IkyZNEqOjo8XHHntM/O677+yW//bbb8WHH35YjI2NFadMmSJeunTJ2VV2G03b5vnnn2/xvPPss8+KoiiKZrNZ/OCDD8TExEQxOjpanDRpkvjzzz+7svod2s3Hze3O/R9//LE4YsQIMS4uTkxLSxMrKyudXWW3cXPbnDx5UuzTp4+o0+maLdvY2CguXbpUHDZsmKhWq8WZM2eKJSUlrVYXQRRb+NUuIiIiIiIi4iV5REREREREjjAwEREREREROcDARERERERE5AADExERERERkQMMTERERERERA4wMBERERERETnAwEREREREROQAAxMREdEdcMXPFvKnEomIXI+BiYioA0lJSUH//v1x+vTpFuePHDkSGRkZTqlLRkYGRo4c6ZRt3Q2j0YiMjAwMHDgQgwYNwpEjR5ots3fvXvTt2xeXL18GAOTn5+OZZ55xaj2//vprLFiwQJo+evQo+vbti6NHjzq1HkRE7o6BiYiogzGZTMjMzIRer3d1VdqlQ4cO4Z///CdSU1Oxdu1axMTENFsmMTERO3fuRFhYGADgyy+/xIkTJ5xaz02bNqG0tFSaHjBgAHbu3IkBAwY4tR5ERO6OgYmIqIPx8/NDfn4+3nvvPVdXpV2qrq4GADz55JO4//774ePj02yZTp06IS4uDiqVysm1c8zX1xdxcXHw9fV1dVWIiNwKAxMRUQcTFRWFcePGYd26dThz5swtl+3bty9Wr15tV7Z69Wr07dtXms7IyMDUqVOxc+dOjBo1CrGxsZgwYQKKiorwzTffYOzYsVCr1UhOTsaPP/7YbBs7d+5EYmIiYmNjMWXKFJw7d85ufklJCebNm4fBgwdDrVY3W+by5cvo27cvNm7ciNGjR0OtVuPjjz9ucX9MJhO2bt2KsWPHIjY2FomJiXj77beh0+mkfbFdkjhq1CikpKS0uJ6ml+StXr0a2dnZzT4vs9mMnJwcPPTQQ4iOjsYjjzyCjz76yG49KSkpePnllzF37lzExcXhueeek/YpPT0dw4cPx4ABAzB06FCkp6ejqqpKet+xY8dw7Ngx6TK8li7JO336NKZOnYohQ4Zg0KBBeOGFF5Cfny/Nt73n8OHDeP7556FWqzFs2DCsWLECJpNJWu67777Df/3Xf2HgwIG4//77MWvWLBQUFLT42RARuRsGJiKiDmjhwoUICgpqtUvzTpw4gS1btiAjIwNLly5FQUEBZsyYgaVLl2LmzJl45513UFpaipdfftnufVevXkV2djb+/Oc/45133kFNTQ1SUlJQUlICAKisrMSECRNw9uxZLF68GH/7299gNpsxadKkZn+wr169GtOnT8fy5csxbNiwFuv5P//zP1i6dClGjRqFDz74AJMmTcKWLVswe/ZsiKKI2bNnY9asWQCA7OxsvPrqq7fd9+TkZDz99NMALOEvOTkZALBkyRKsWrUKTzzxBNasWYPRo0fjr3/9a7OevS+++AI+Pj744IMPMG3aNGi1WkyePBkFBQV49dVXsX79ekyePBn79+/Hu+++CwB49dVX0b9/f/Tv39/hZXhHjhyR7qv661//ijfffBOlpaWYMGFCs8/u5ZdfRnx8PNasWYPHH38c69atw+7duwEAxcXFmD17NqKjo/HBBx8gKysLRUVFmDFjBsxm820/HyKijk7h6goQEVHrCwgIwOuvv45Zs2bhvffew0svvfSb1tfQ0IC///3v6NWrFwDg2LFj2LFjBzZt2oShQ4cCAC5evIhly5ahtrYW/v7+ACw9Pu+99x5iY2MBAGq1GqNGjcJHH32EBQsWYPPmzaiursb27dvRtWtXAMAf/vAHPProo1i5ciVWrVol1WHMmDF46qmnHNbx/Pnz2LNnD+bPn48ZM2YAAIYNG4awsDCkp6fj4MGDGDFiBO655x4Alp64yMjI2+57REQEIiIiAABxcXEAgKKiIuzatQvz5s2TtjV8+HAIgoC1a9di4sSJCAoKAgAolUq89tpr0uV9P/74IyIiIrBs2TJ069YNAPDAAw8gLy8Px44dAwD07t1buvTOts2b/e1vf8O9996LnJwcyOVyqQ4PPfQQVq1ahZUrV0rLJicnIy0tDQAwdOhQHDhwAN9++y0mTJiAU6dOobGxETNnzkR4eLi0z19//TU0Gg0vASQit8ceJiKiDmrkyJF44oknsG7dOpw9e/Y3rSsgIEAKSwAQEhICwBKAbAIDAwEAtbW1Ulm3bt2ksAQAoaGhiIuLww8//AAAOHz4MKKiohAeHg6j0Qij0QiZTIY//OEP+P777+3qEBUVdcs62sLGY489Zlf+2GOPQS6Xt+rockeOHIEoihg5cqRUb6PRiJEjR0Kn0yE3N1datmfPnnb3QkVFRWHbtm3o2rUrLly4gH//+99Yv349CgsL77g3UKPR4PTp0xgzZowUlgDA398fSUlJ0mdhM3DgQLvpiIgIaDQaAJY29PDwwNNPP42srCwcOnQI/fr1w0svvcSwREQE9jAREXVof/nLX3D48GFkZmY6vO/nTjj6w9nb2/uW77MFq6aCg4Ol0d+qq6tx8eJFhyO/abXaO95WTU0NAEsoa0qhUCAoKAh1dXW3fP/dsA0ccXM4sykrK5NetzSoxMaNG7FmzRpUV1cjJCQE0dHR8PLyuuM61tXVQRTFFj/fkJCQZuvx9PS0m5bJZNJvPEVGRmLLli3IycnBnj178I9//AP+/v6YOHEi/vznP0MQhDuqExFRR8XARETUgQUEBGDJkiVIS0vD+++/3+IyTW/+ByD1PLQGW4hpqry8HJ06dQJgGdFv8ODBSE9Pb/H9dzNKXUBAgLR+2+V9AGAwGFBVVSVdItcabJccbt68ucVA1KVLF4fv3bdvH9566y288sorePLJJ6XP4r//+78d/n7Wzfz8/CAIAioqKprNKy8vl3r77lRsbCyys7Oh1+uRm5uLnTt3Ys2aNejXrx/GjBlzV+siIupoeEkeEVEHN2rUKDz++OPIyclBZWWl3TxfX1+73hAAOH78eKttu6ioCJcuXZKmS0tLceLECQwZMgQAMHjwYBQVFaFHjx6IiYmRHp9++in27Nljd7nZ7QwePBgAsH//frvy/fv3w2QyIT4+/lfvh0xmf7pMSEgAAFRVVdnVu7KyEitXrpR6oFqSm5sLf39/TJs2TQpLDQ0NyM3NtRtk4eZtNuXt7Y3o6Gh88cUXdoG3rq4O33777V3t66ZNm5CUlAS9Xg+VSoWhQ4fijTfeAABpcA4iInfGHiYiIjewePFiHDlypFmPRGJiIvbv3w+1Wo17770Xe/fuxcWLF1ttux4eHpg1axZeeuklmEwmrFy5EoGBgZgyZQoAIDU1FZ9++ilSU1Px/PPPIygoCJ9//jl27dqFzMzMu9pW7969MX78eKxatQparRb3338/fvzxR2RnZ2PIkCF48MEHf/V+2HqUPvvsM6jVavTt2xdPPPEEFi9ejCtXriA6OhpFRUV49913ERkZie7duztcV2xsLLZv34633noLSUlJuHbtGtavX4+Kigqpl8y2zRMnTuDw4cPo379/s/XMnz8fU6dOxYwZMzBx4kQYDAbk5ORAr9dLAzzciQceeABvv/020tLS8Oyzz0Iul2PHjh1QqVRISkq68w+JiKiDYg8TEZEbCAwMxJIlS5qVZ2ZmIikpCcuWLcPcuXPh7e2N+fPnt9p2+/fvj+TkZCxZsgTp6em45557sG3bNqlnJTw8HDt27EDXrl2xZMkSvPDCCzh16hSysrKQmpp619vLyspCWloa9u3bhxkzZmDr1q2YPHkyPvzww1v22NzOww8/jJiYGGRkZGD9+vUAgKVLl+K5557Djh07MG3aNKxZswaPPvooNmzYcMuesfHjxyMtLQ1ffPEFpk+fjlWrViEhIQGvv/46qqurpSHBJ02aBKVSienTp+PgwYPN1jN06FBs3LgRjY2NmDdvHhYvXozw8HDs2rULffr0ueN969evH9asWYP6+nrMmzcPL774Iqqrq7Fhwwb07NnzLj8pIqKORxBtd30SERERERGRHfYwEREREREROcDARERERERE5AADExERERERkQMMTERERERERA4wMBERERERETnAwEREREREROQAAxMREREREZEDDExEREREREQOMDARERERERE5wMBERERERETkAAMTERERERGRA/8fBG4i3gvpjrUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 최적 파라미터시도한 값, loss값 시각화\n",
    "\n",
    "# 훈련 세트 및 검증 세트에 대한 손실 값을 얻습니다.\n",
    "train_loss = lgbm_clf.evals_result_['training']['multi_logloss']\n",
    "val_loss = lgbm_clf.evals_result_['valid_1']['multi_logloss']\n",
    "\n",
    "# 손실 값 그래프를 그립니다.\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_loss, label='Training Multi-Logloss')\n",
    "plt.plot(val_loss, label='Validation Multi-Logloss')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Multi-Logloss')\n",
    "plt.title('Training and Validation Multi-Logloss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.최종 모델로, X_pred 의 y값 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13835</th>\n",
       "      <td>34593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13836</th>\n",
       "      <td>34594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13837</th>\n",
       "      <td>34595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13838</th>\n",
       "      <td>34596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13839</th>\n",
       "      <td>34597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13840 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id\n",
       "0      20758\n",
       "1      20759\n",
       "2      20760\n",
       "3      20761\n",
       "4      20762\n",
       "...      ...\n",
       "13835  34593\n",
       "13836  34594\n",
       "13837  34595\n",
       "13838  34596\n",
       "13839  34597\n",
       "\n",
       "[13840 rows x 1 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[['id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20758</td>\n",
       "      <td>Obesity_Type_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20759</td>\n",
       "      <td>Overweight_Level_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20760</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20761</td>\n",
       "      <td>Obesity_Type_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20762</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13835</th>\n",
       "      <td>34593</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13836</th>\n",
       "      <td>34594</td>\n",
       "      <td>Overweight_Level_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13837</th>\n",
       "      <td>34595</td>\n",
       "      <td>Insufficient_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13838</th>\n",
       "      <td>34596</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13839</th>\n",
       "      <td>34597</td>\n",
       "      <td>Obesity_Type_II</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13840 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id           NObeyesdad\n",
       "0      20758      Obesity_Type_II\n",
       "1      20759   Overweight_Level_I\n",
       "2      20760     Obesity_Type_III\n",
       "3      20761       Obesity_Type_I\n",
       "4      20762     Obesity_Type_III\n",
       "...      ...                  ...\n",
       "13835  34593  Overweight_Level_II\n",
       "13836  34594   Overweight_Level_I\n",
       "13837  34595  Insufficient_Weight\n",
       "13838  34596        Normal_Weight\n",
       "13839  34597      Obesity_Type_II\n",
       "\n",
       "[13840 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lgbm_wrapper.predict(X_pred)\n",
    "\n",
    "y_pred_decoded = le.inverse_transform(y_pred) # 디코딩\n",
    "\n",
    "# 'id' 컬럼과 예측된 클래스를 가진 DataFrame 생성\n",
    "final_df = pd.DataFrame({'id': test['id'], 'NObeyesdad': y_pred_decoded})\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('../csv/submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envFirstMini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
